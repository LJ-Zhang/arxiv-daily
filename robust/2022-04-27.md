### Title: TransHER: Translating Knowledge Graph Embedding with Hyper-Ellipsoidal Restriction
* Paper ID: 2204.13221v1
* Paper URL: [http://arxiv.org/abs/2204.13221v1](http://arxiv.org/abs/2204.13221v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Knowledge graph embedding methods are important for knowledge graph
completion (link prediction) due to their robust performance and efficiency on
large-magnitude datasets. One state-of-the-art method, PairRE, leverages two
separate vectors for relations to model complex relations (i.e., 1-to-N,
N-to-1, and N-to-N) in knowledge graphs. However, such a method strictly
restricts entities on the hyper-ellipsoid surface and thus limits the
optimization of entity distribution, which largely hinders the performance of
knowledge graph completion. To address this problem, we propose a novel score
function TransHER, which leverages relation-specific translations between head
and tail entities restricted on separate hyper-ellipsoids. Specifically, given
a triplet, our model first maps entities onto two separate hyper-ellipsoids and
then conducts a relation-specific translation on one of them. The
relation-specific translation provides TransHER with more direct guidance in
optimization and the ability to learn semantic characteristics of entities with
complex relations. Experimental results show that TransHER can achieve
state-of-the-art performance and generalize to datasets in different domains
and scales. All our code will be publicly available.

### Title: Structural Cumulative Survival Models for Robust Estimation of Treatment Effects Accounting for Treatment Switching in Randomized Experiments
* Paper ID: 2204.13219v1
* Paper URL: [http://arxiv.org/abs/2204.13219v1](http://arxiv.org/abs/2204.13219v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: We propose an instrumental variable estimator to estimate the treatment
causal effect when treatment switching is present in a randomized experiment,
under a structural cumulative survival model. Our estimator is robust to
violation of the exclusion restriction, a commonly adopted assumption for IV
methods that is untestable and usually subject to questioning in practice,
especially in an open-label randomized trial. We derive large-sample properties
of our proposed estimator, along with inferential tools. We apply the estimator
to evaluate the treatment effect of Nucleoside Reverse Transcriptase Inhibitors
on a safety outcome in the Optimized Treatment That Includes or Omits NRTIs
trial.

### Title: Online Distributed Evolutionary Optimization of Time Division Multiple Access Protocols
* Paper ID: 2204.13190v1
* Paper URL: [http://arxiv.org/abs/2204.13190v1](http://arxiv.org/abs/2204.13190v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: With the advent of cheap, miniaturized electronics, ubiquitous networking has
reached an unprecedented level of complexity, scale and heterogeneity, becoming
the core of several modern applications such as smart industry, smart buildings
and smart cities. A crucial element for network performance is the protocol
stack, namely the sets of rules and data formats that determine how the nodes
in the network exchange information. A great effort has been put to devise
formal techniques to synthesize (offline) network protocols, starting from
system specifications and strict assumptions on the network environment.
However, offline design can be hard to apply in the most modern network
applications, either due to numerical complexity, or to the fact that the
environment might be unknown and the specifications might not available. In
these cases, online protocol design and adaptation has the potential to offer a
much more scalable and robust solution. Nevertheless, so far only a few
attempts have been done towards online automatic protocol design. Here, we
envision a protocol as an emergent property of a network, obtained by an
environment-driven Distributed Hill Climbing algorithm that uses node-local
reinforcement signals to evolve, at runtime and without any central
coordination, a network protocol from scratch. We test this approach with a
3-state Time Division Multiple Access (TDMA) Medium Access Control (MAC)
protocol and we observe its emergence in networks of various scales and with
various settings. We also show how Distributed Hill Climbing can reach
different trade-offs in terms of energy consumption and protocol performance.

### Title: SSR-GNNs: Stroke-based Sketch Representation with Graph Neural Networks
* Paper ID: 2204.13153v1
* Paper URL: [http://arxiv.org/abs/2204.13153v1](http://arxiv.org/abs/2204.13153v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: This paper follows cognitive studies to investigate a graph representation
for sketches, where the information of strokes, i.e., parts of a sketch, are
encoded on vertices and information of inter-stroke on edges. The resultant
graph representation facilitates the training of a Graph Neural Networks for
classification tasks, and achieves accuracy and robustness comparable to the
state-of-the-art against translation and rotation attacks, as well as stronger
attacks on graph vertices and topologies, i.e., modifications and addition of
strokes, all without resorting to adversarial training. Prior studies on
sketches, e.g., graph transformers, encode control points of stroke on
vertices, which are not invariant to spatial transformations. In contrary, we
encode vertices and edges using pairwise distances among control points to
achieve invariance. Compared with existing generative sketch model for one-shot
classification, our method does not rely on run-time statistical inference.
Lastly, the proposed representation enables generation of novel sketches that
are structurally similar to while separable from the existing dataset.

### Title: Proximal Causal Inference for Marginal Counterfactual Survival Curves
* Paper ID: 2204.13144v1
* Paper URL: [http://arxiv.org/abs/2204.13144v1](http://arxiv.org/abs/2204.13144v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Contrasting marginal counterfactual survival curves across treatment arms is
an effective and popular approach for inferring the causal effect of an
intervention on a right-censored time-to-event outcome. A key challenge to
drawing such inferences in observational settings is the possible existence of
unmeasured confounding, which may invalidate most commonly used methods that
assume no hidden confounding bias. In this paper, rather than making the
standard no unmeasured confounding assumption, we extend the recently proposed
proximal causal inference framework of Miao et al. (2018), Tchetgen et al.
(2020), Cui et al. (2020) to obtain nonparametric identification of a causal
survival contrast by leveraging observed covariates as imperfect proxies of
unmeasured confounders. Specifically, we develop a proximal inverse
probability-weighted (PIPW) estimator, the proximal analog of standard IPW,
which allows the observed data distribution for the time-to-event outcome to
remain completely unrestricted. PIPW estimation relies on a parametric model
for a so-called treatment confounding bridge function relating the treatment
process to confounding proxies. As a result, PIPW might be sensitive to model
misspecification. To improve robustness and efficiency, we also propose a
proximal doubly robust estimator and establish uniform consistency and
asymptotic normality of both estimators. We conduct extensive simulations to
examine the finite sample performance of our estimators, and proposed methods
are applied to a study evaluating the effectiveness of right heart
catheterization in the intensive care unit of critically ill patients.

### Title: On robustness and related properties on toric ideals
* Paper ID: 2204.13136v1
* Paper URL: [http://arxiv.org/abs/2204.13136v1](http://arxiv.org/abs/2204.13136v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: A toric ideal is called robust if its universal Gr\"obner basis is a minimal
set of generators, and is called generalized robust if its universal Gr\"obner
basis equals its universal Markov basis (the union of all its minimal sets of
binomial generators). Robust and generalized robust toric ideals are both
interesting from both a Commutative Algebra and an Algebraic Statistics
perspective. However, only a few nontrivial examples of such ideals are known.
In this work we study these properties for toric ideals of both graphs and
numerical semigroups. For toric ideals of graphs, we characterize
combinatorially the graphs giving rise to robust and to generalized robust
toric ideals generated by quadratic binomials. As a byproduct, we obtain
families of Koszul rings. For toric ideals of numerical semigroups, we
determine that one of its initial ideals is a complete intersection if and only
if the semigroup belongs to the so-called family of free numerical semigroups.
Hence, we characterize all complete intersection numerical semigroups which are
minimally generated by one of its Gr\"obner basis and, as a consequence, all
the Betti numbers of the toric ideal and its corresponding initial ideal
coincide. Moreover, also for numerical semigroups, we prove that the ideal is
generalized robust if and only if the semigroup has a unique Betti element and
that there are only trivial examples of robust ideals. We finish the paper with
some open questions.

### Title: HRDA: Context-Aware High-Resolution Domain-Adaptive Semantic Segmentation
* Paper ID: 2204.13132v1
* Paper URL: [http://arxiv.org/abs/2204.13132v1](http://arxiv.org/abs/2204.13132v1)
* Updated Date: 2022-04-27
* Code URL: [https://github.com/lhoyer/hrda](https://github.com/lhoyer/hrda)
* Summary: Unsupervised domain adaptation (UDA) aims to adapt a model trained on the
source domain (e.g. synthetic data) to the target domain (e.g. real-world data)
without requiring further annotations on the target domain. This work focuses
on UDA for semantic segmentation as real-world pixel-wise annotations are
particularly expensive to acquire. As UDA methods for semantic segmentation are
usually GPU memory intensive, most previous methods operate only on downscaled
images. We question this design as low-resolution predictions often fail to
preserve fine details. The alternative of training with random crops of
high-resolution images alleviates this problem but falls short in capturing
long-range, domain-robust context information. Therefore, we propose HRDA, a
multi-resolution training approach for UDA, that combines the strengths of
small high-resolution crops to preserve fine segmentation details and large
low-resolution crops to capture long-range context dependencies with a learned
scale attention, while maintaining a manageable GPU memory footprint. HRDA
enables adapting small objects and preserving fine segmentation details. It
significantly improves the state-of-the-art performance by 5.5 mIoU for
GTA-to-Cityscapes and 4.9 mIoU for Synthia-to-Cityscapes, resulting in
unprecedented 73.8 and 65.8 mIoU, respectively. The implementation is available
at https://github.com/lhoyer/HRDA.

### Title: Moments for positivity: using Drell-Yan data to test positivity bounds and reverse-engineer new physics
* Paper ID: 2204.13121v1
* Paper URL: [http://arxiv.org/abs/2204.13121v1](http://arxiv.org/abs/2204.13121v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Moments of the leptonic angular distribution in the Drell-Yan process have
recently been shown to be sensitive probes of a specific class of dimension-8,
four-fermion operators in the Standard Model Effective Field Theory, involving
a pair of quarks and leptons. The same operators are also subject to positivity
bounds, when requiring the associated (unknown) UV completion to obey basic
principles of quantum field theory. We perform a phenomenological study to
quantify the sensitivity of the high-luminosity LHC to this set of operators
and, by extension, the positivity bounds. We further extend the angular basis
of moments and consider double differential information to improve the ability
to disentangle the different operators, leading to a sensitivity to new physics
scales up to 3 TeV. We use this information to explore the violation of
positivity at the LHC as a way to test the underlying principles of quantum
field theory. Finally, we present a case study which combines our results with
information from other (current and prospective) experiments, as well as the
positivity cone to infer the properties of possible tree-level UV completions.
The data lead to robust, model-independent lower bounds on the $M/\sqrt{g}$
combination of the particle mass and coupling, for states that couple to
right-handed leptons and/or up quarks.

### Title: Attention Consistency on Visual Corruptions for Single-Source Domain Generalization
* Paper ID: 2204.13091v1
* Paper URL: [http://arxiv.org/abs/2204.13091v1](http://arxiv.org/abs/2204.13091v1)
* Updated Date: 2022-04-27
* Code URL: [https://github.com/explainableml/acvc](https://github.com/explainableml/acvc)
* Summary: Generalizing visual recognition models trained on a single distribution to
unseen input distributions (i.e. domains) requires making them robust to
superfluous correlations in the training set. In this work, we achieve this
goal by altering the training images to simulate new domains and imposing
consistent visual attention across the different views of the same sample. We
discover that the first objective can be simply and effectively met through
visual corruptions. Specifically, we alter the content of the training images
using the nineteen corruptions of the ImageNet-C benchmark and three additional
transformations based on Fourier transform. Since these corruptions preserve
object locations, we propose an attention consistency loss to ensure that class
activation maps across original and corrupted versions of the same training
sample are aligned. We name our model Attention Consistency on Visual
Corruptions (ACVC). We show that ACVC consistently achieves the state of the
art on three single-source domain generalization benchmarks, PACS, COCO, and
the large-scale DomainNet.

### Title: Bosonic pair production and squeezing for optical phase measurements in long-lived dipoles coupled to a cavity
* Paper ID: 2204.13090v1
* Paper URL: [http://arxiv.org/abs/2204.13090v1](http://arxiv.org/abs/2204.13090v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: We propose to simulate bosonic pair creation using large arrays of long-lived
dipoles with multilevel internal structure coupled to an undriven optical
cavity. Entanglement between the atoms, generated by the exchange of virtual
photons through a common cavity mode, grows exponentially fast and is described
by two-mode squeezing (TMS) of effective bosonic quadratures. The mapping
between an effective bosonic model and the natural spin description of the
dipoles allows us to realize the analog of optical homodyne measurements via
straightforward global rotations and population measurements of the electronic
states, and we propose to exploit this for quantum-enhanced sensing of an
optical phase (common and differential between two ensembles). We discuss a
specific implementation based on Sr atoms and show that our sensing protocol is
robust to sources of decoherence intrinsic to cavity platforms. Our proposal
can open unique opportunities for the observation of continuous variable
entanglement in atomic systems and associated applications in next-generation
optical atomic clocks.

### Title: Variational Kalman Filtering with Hinf-Based Correction for Robust Bayesian Learning in High Dimensions
* Paper ID: 2204.13089v1
* Paper URL: [http://arxiv.org/abs/2204.13089v1](http://arxiv.org/abs/2204.13089v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: In this paper, we address the problem of convergence of sequential
variational inference filter (VIF) through the application of a robust
variational objective and Hinf-norm based correction for a linear Gaussian
system. As the dimension of state or parameter space grows, performing the full
Kalman update with the dense covariance matrix for a large scale system
requires increased storage and computational complexity, making it impractical.
The VIF approach, based on mean-field Gaussian variational inference, reduces
this burden through the variational approximation to the covariance usually in
the form of a diagonal covariance approximation. The challenge is to retain
convergence and correct for biases introduced by the sequential VIF steps. We
desire a framework that improves feasibility while still maintaining reasonable
proximity to the optimal Kalman filter as data is assimilated. To accomplish
this goal, a Hinf-norm based optimization perturbs the VIF covariance matrix to
improve robustness. This yields a novel VIF- Hinf recursion that employs
consecutive variational inference and Hinf based optimization steps. We explore
the development of this method and investigate a numerical example to
illustrate the effectiveness of the proposed filter.

### Title: Local Order Metrics for Two-Phase Media Across Length Scales
* Paper ID: 2204.13088v1
* Paper URL: [http://arxiv.org/abs/2204.13088v1](http://arxiv.org/abs/2204.13088v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: The capacity to devise order metrics for microstructures of multiphase
heterogeneous media is a highly challenging task, given the richness of the
possible geometries and topologies of the phases that can arise. This
investigation initiates a program to formulate order metrics to characterize
the degree of order/disorder of the microstructures of two-phase media in
$d$-dimensional Euclidean space $\mathbb{R}^d$ across length scales. In
particular, we propose the use of the local volume-fraction variance
$\sigma^2_{_V}(R)$ associated with a spherical window of radius $R$ as an order
metric. We determine $\sigma^2_{_V}(R)$ as a function of $R$ for 22 different
models across the first three space dimensions, including both hyperuniform and
nonhyperuniform systems with varying degrees of short- and long-range order. We
find that the local volume-fraction variance as well as asymptotic coefficients
and integral measures derived from it provide reasonably robust and sensitive
order metrics to categorize disordered and ordered two-phase media across all
length scales.

### Title: The Rise of Buoyant Magnetic Structures through Convection with a Background Magnetic Field
* Paper ID: 2204.13078v1
* Paper URL: [http://arxiv.org/abs/2204.13078v1](http://arxiv.org/abs/2204.13078v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Inspired by observations of sunspots embedded in active regions, it is often
assumed that large-scale, strong magnetic flux emerges from the Sun's deep
interior in the form of arched, cylindrical structures, colloquially known as
flux tubes. Here, we continue to examine the different dynamics encountered
when these structures are considered as concentrations in a volume-filling
magnetic field rather than as isolated entities in a field-free background. Via
2.5D numerical simulations, we consider the buoyant rise of magnetic flux
concentrations from a radiative zone through an overshooting convection zone
that self-consistently (via magnetic pumping) arranges a volume-filling
large-scale background field. This work extends earlier papers that considered
the evolution of such structures in a purely adiabatic stratification with an
assumed form of the background field. This earlier work established the
existence of a bias that created an increased likelihood of successful rise for
magnetic structures with one (relative) orientation of twist and a decreased
likelihood for the other. When applied to the solar context, this bias is
commensurate with the solar hemispherical helicity rules (SHHR). This paper
establishes the robustness of this selection mechanism in a model incorporating
a more realistic background state, consisting of overshooting convection and a
turbulently-pumped mean magnetic field. Ultimately, convection only weakly
influences the selection mechanism, since it is enacted at the initiation of
the rise, at the edge of the overshoot zone. Convection does however add
another layer of statistical fluctuations to the bias, which we investigate in
order to explain variations in the SHHR.

### Title: Robust interpolation for dispersed gas-droplet flows using statistical learning with the Fully Lagrangian Approach
* Paper ID: 2204.13071v1
* Paper URL: [http://arxiv.org/abs/2204.13071v1](http://arxiv.org/abs/2204.13071v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: A novel methodology is presented for reconstructing the Eulerian number
density field of dispersed gas-droplet flows modelled using the Fully
Lagrangian Approach (FLA). In this work, the nonparametric framework of kernel
regression is used to accumulate the FLA number density contributions of
individual droplets in accordance with the spatial structure of the dispersed
phase. The high variation which is observed in the droplet number density field
for unsteady flows is accounted for by using the Eulerian-Lagrangian
transformation tensor, which is central to the FLA, to specify the size and
shape of the kernel associated with each droplet. This procedure enables a high
level of structural detail to be retained, and it is demonstrated that far
fewer droplets have to be tracked in order to reconstruct a faithful Eulerian
representation of the dispersed phase. Furthermore, the kernel regression
procedure is easily extended to higher dimensions, and inclusion of the droplet
radius within the phase space description additionally enables the droplet size
distribution and its statistics, such as average and variance, to be determined
for polydisperse flows. The developed methodology is applied to a range of 1D
and 2D steady-state and transient flows, for both monodisperse and polydisperse
droplets, and it is shown that kernel regression performs well across this
variety of cases. A comparison is made against conventional direct trajectory
methods to determine the saving in computational expense which can be gained,
and it is found that $10^3$ times fewer droplet realisations are needed to
reconstruct a qualitatively similar representation of the number density field
in which the absolute error is generally below $10^{-1}$.

### Title: A Uniform Framework for Diagnosis of Discrete-Event Systems with Unreliable Sensors using Linear Temporal Logic
* Paper ID: 2204.13057v1
* Paper URL: [http://arxiv.org/abs/2204.13057v1](http://arxiv.org/abs/2204.13057v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: In this paper, we investigate the diagnosability verification problem of
partially-observed discrete-event systems (DES) subject to unreliable sensors.
In this setting, upon the occurrence of each event, the sensor reading may be
non-deterministic due to measurement noises or possible sensor failures.
Existing works on this topic mainly consider specific types of unreliable
sensors such as the cases of intermittent sensors failures, permanent sensor
failures or their combinations. In this work, we propose a novel \emph{uniform
framework} for diagnosability of DES subject to, not only sensor failures, but
also a very general class of unreliable sensors. Our approach is to use linear
temporal logic (LTL) with semantics on infinite traces to describe the possible
behaviors of the sensors. A new notion of $\varphi$-diagnosability is proposed
as the necessary and sufficient condition for the existence of a diagnoser when
the behaviors of sensors satisfy the LTL formula $\varphi$. Effective approach
is provided to verify this notion. We show that, our new notion of
$\varphi$-diagnosability subsumes all existing notions of robust diagnosability
of DES subject to sensor failures. Furthermore, the proposed framework is
user-friendly and flexible since it supports an arbitrary user-defined
unreliable sensor type based on the specific scenario of the application. As
examples, we provide two new notions of diagnosability, which have never been
investigated in the literature, using our uniform framework.

### Title: Minimax Robust Quickest Change Detection using Wasserstein Ambiguity Sets
* Paper ID: 2204.13034v1
* Paper URL: [http://arxiv.org/abs/2204.13034v1](http://arxiv.org/abs/2204.13034v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: We study the robust quickest change detection under unknown pre- and
post-change distributions. To deal with uncertainties in the data-generating
distributions, we formulate two data-driven ambiguity sets based on the
Wasserstein distance, without any parametric assumptions. The minimax robust
test is constructed as the CUSUM test under least favorable distributions, a
representative pair of distributions in the ambiguity sets. We show that the
minimax robust test can be obtained in a tractable way and is asymptotically
optimal. We investigate the effectiveness of the proposed robust test over
existing methods, including the generalized likelihood ratio test and the
robust test under KL divergence based ambiguity sets.

### Title: Quantitative inverse problem in visco-acoustic media under attenuation model uncertainty
* Paper ID: 2204.13017v1
* Paper URL: [http://arxiv.org/abs/2204.13017v1](http://arxiv.org/abs/2204.13017v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: We consider the inverse problem of quantitative reconstruction of properties
(e.g., bulk modulus, density) of visco-acoustic materials based on measurements
of responding waves after stimulation of the medium. Numerical reconstruction
is performed by an iterative minimization algorithm. Firstly, we investigate
the robustness of the algorithm with respect to attenuation model uncertainty,
that is, when different attenuation models are used to simulate synthetic
observation data and for the inversion, respectively. Secondly, to handle
data-sets with multiple reflections generated by wall boundaries around the
domain, we perform inversion using complex frequencies, and show that it offers
a robust framework that alleviates the difficulties of multiple reflections. To
illustrate the efficiency of the algorithm, we perform numerical simulations of
ultrasound imaging experiments to reconstruct a synthetic breast sample that
contains an inclusion of sharp contrast, in two and three dimensions, where the
latter also serves to demonstrate the numerical feasibility in a large-scale
configuration.

### Title: Relevance-based Margin for Contrastively-trained Video Retrieval Models
* Paper ID: 2204.13001v1
* Paper URL: [http://arxiv.org/abs/2204.13001v1](http://arxiv.org/abs/2204.13001v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Video retrieval using natural language queries has attracted increasing
interest due to its relevance in real-world applications, from intelligent
access in private media galleries to web-scale video search. Learning the
cross-similarity of video and text in a joint embedding space is the dominant
approach. To do so, a contrastive loss is usually employed because it organizes
the embedding space by putting similar items close and dissimilar items far.
This framework leads to competitive recall rates, as they solely focus on the
rank of the groundtruth items. Yet, assessing the quality of the ranking list
is of utmost importance when considering intelligent retrieval systems, since
multiple items may share similar semantics, hence a high relevance. Moreover,
the aforementioned framework uses a fixed margin to separate similar and
dissimilar items, treating all non-groundtruth items as equally irrelevant. In
this paper we propose to use a variable margin: we argue that varying the
margin used during training based on how much relevant an item is to a given
query, i.e. a relevance-based margin, easily improves the quality of the
ranking lists measured through nDCG and mAP. We demonstrate the advantages of
our technique using different models on EPIC-Kitchens-100 and YouCook2. We show
that even if we carefully tuned the fixed margin, our technique (which does not
have the margin as a hyper-parameter) would still achieve better performance.
Finally, extensive ablation studies and qualitative analysis support the
robustness of our approach. Code will be released at
\url{https://github.com/aranciokov/RelevanceMargin-ICMR22}.

### Title: KL-Mat : Fair Recommender System via Information Geometry
* Paper ID: 2204.13583v1
* Paper URL: [http://arxiv.org/abs/2204.13583v1](http://arxiv.org/abs/2204.13583v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Recommender system has intrinsic problems such as sparsity and fairness.
Although it has been widely adopted for the past decades, research on fairness
of recommendation algorithms has been largely neglected until recently. One
important paradigm for resolving the issue is regularization. However,
researchers have not been able to come up with a consensusly agreed
regularization term like regularization framework in other fields such as Lasso
or Ridge Regression. In this paper, we borrow concepts from information
geometry and propose a new regularization-based fair algorithm called KL-Mat.
The algorithmic technique leads to a more robust performance in accuracy
performance such as MAE. More importantly, the algorithm produces much fairer
results than vanilla matrix factorization approach. KL-Mat is fast,
easy-to-implement and explainable.

### Title: Dashlet: Taming Swipe Uncertainty for Robust Short Video Streaming
* Paper ID: 2204.12954v1
* Paper URL: [http://arxiv.org/abs/2204.12954v1](http://arxiv.org/abs/2204.12954v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Short video streaming applications have recently gained substantial traction,
but the non-linear video presentation they afford swiping users fundamentally
changes the problem of maximizing user quality of experience in the face of the
vagaries of network throughput and user swipe timing. This paper describes the
design and implementation of Dashlet, a system tailored for high quality of
experience in short video streaming applications. With the insights we glean
from an in-the-wild TikTok performance study and a user study focused on swipe
patterns, Dashlet proposes a novel out-of-order video chunk pre-buffering
mechanism that leverages a simple, non machine learning-based model of users'
swipe statistics to determine the pre-buffering order and bitrate. The net
result is a system that achieves 77-99% of an oracle system's QoE and
outperforms TikTok by 43.9-45.1x, while also reducing by 30% the number of
bytes wasted on downloaded video that is never watched.

### Title: Epicardial Adipose Tissue Segmentation from CT Images with A Semi-3D Neural Network
* Paper ID: 2204.12904v1
* Paper URL: [http://arxiv.org/abs/2204.12904v1](http://arxiv.org/abs/2204.12904v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Epicardial adipose tissue is a type of adipose tissue located between the
heart wall and a protective layer around the heart called the pericardium. The
volume and thickness of epicardial adipose tissue are linked to various
cardiovascular diseases. It is shown to be an independent cardiovascular
disease risk factor. Fully automatic and reliable measurements of epicardial
adipose tissue from CT scans could provide better disease risk assessment and
enable the processing of large CT image data sets for a systemic epicardial
adipose tissue study. This paper proposes a method for fully automatic semantic
segmentation of epicardial adipose tissue from CT images using a deep neural
network. The proposed network uses a U-Net-based architecture with slice depth
information embedded in the input image to segment a pericardium region of
interest, which is used to obtain an epicardial adipose tissue segmentation.
Image augmentation is used to increase model robustness. Cross-validation of
the proposed method yields a Dice score of 0.86 on the CT scans of 20 patients.

### Title: Global Trajectory Helps Person Retrieval in a Camera Network
* Paper ID: 2204.12900v1
* Paper URL: [http://arxiv.org/abs/2204.12900v1](http://arxiv.org/abs/2204.12900v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: We are concerned about retrieving a query person from the videos taken by a
non-overlapping camera network. Existing methods often rely on pure visual
matching or consider temporal constraint, but ignore the spatial information of
the camera network. To address this problem, we propose a framework of person
retrieval based on cross-camera trajectory generation which integrates both
temporal and spatial information. To obtain the pedestrian trajectories, we
propose a new cross-camera spatio-temporal model that integrates the walking
habits of pedestrians and the path layout between cameras, forming a joint
probability distribution. Such a spatio-temporal model among a camera network
can be specified using sparsely sampled pedestrian data. Based on the
spatio-temporal model, the cross-camera trajectories of a specific pedestrian
can be extracted by the conditional random field model, and further optimized
by the restricted nonnegative matrix factorization. Finally, a trajectory
re-ranking technology is proposed to improve the person retrieval results. To
verify the effectiveness of our approach, we build the first dataset of
cross-camera pedestrian trajectories over an actual monitoring scenario, namely
the Person Trajectory Dataset. Extensive experiments have verified the
effectiveness and robustness of the proposed method.

### Title: Large-scale geometry obstructs localization
* Paper ID: 2204.12895v1
* Paper URL: [http://arxiv.org/abs/2204.12895v1](http://arxiv.org/abs/2204.12895v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: We explain the coarse geometric origin of the fact that certain spectral
subspaces of topological insulator Hamiltonians are delocalized, in the sense
that they cannot admit an orthonormal basis of localized wavefunctions, with
respect to any uniformly discrete set of localization centers. This is a robust
result requiring neither spatial homogeneity nor symmetries, and applies to
Landau levels of disordered quantum Hall systems on general Riemannian
manifolds.

### Title: Beyond Duplicates: Towards Understanding and Predicting Link Types in Issue Tracking Systems
* Paper ID: 2204.12893v1
* Paper URL: [http://arxiv.org/abs/2204.12893v1](http://arxiv.org/abs/2204.12893v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Software projects use Issue Tracking Systems (ITS) like JIRA to track issues
and organize the workflows around them. Issues are often inter-connected via
different links such as the default JIRA link types Duplicate, Relate, Block,
or Subtask. While previous research has mostly focused on analyzing and
predicting duplication links, this work aims at understanding the various other
link types, their prevalence, and characteristics towards a more reliable link
type prediction. For this, we studied 607,208 links connecting 698,790 issues
in 15 public JIRA repositories. Besides the default types, the custom types
Depend, Incorporate, Split, and Cause were also common. We manually grouped all
75 link types used in the repositories into five general categories: General
Relation, Duplication, Composition, Temporal / Causal, and Workflow. Comparing
the structures of the corresponding graphs, we observed several trends. For
instance, Duplication links tend to represent simpler issue graphs often with
two components and Composition links present the highest amount of hierarchical
tree structures (97.7%). Surprisingly, General Relation links have a
significantly higher transitivity score than Duplication and Temporal / Causal
links. Motivated by the differences between the link types and by their
popularity, we evaluated the robustness of two state-of-the-art duplicate
detection approaches from the literature on the JIRA dataset. We found that
current deep-learning approaches confuse between Duplication and other links in
almost all repositories. On average, the classification accuracy dropped by 6%
for one approach and 12% for the other. Extending the training sets with other
link types seems to partly solve this issue. We discuss our findings and their
implications for research and practice.

### Title: Universal approach to sending-or-not-sending twin field quantum key distribution
* Paper ID: 2204.12890v1
* Paper URL: [http://arxiv.org/abs/2204.12890v1](http://arxiv.org/abs/2204.12890v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: We present the method of decoy-state analysis after bit-flip error correction
and using confidential observed numbers. Taking this tool we then construct a
universal approach to sending-or-not-sending (SNS) protocol of twin-field
quantum key distribution. In this improved protocol, the code bits are not
limited to heralded events in time windows participated by pulses of intensity
$\mu_z$ and vacuum. All kinds of heralded events can be used for code bits to
distill the final keys. The number of intensities (3 or 4) and the kinds of
heralded events for code bits are automatically chosen by the key rate
optimization itself. Numerical simulation shows that the key rate rises
drastically in typical settings, up to 80\% improvement compared with the prior
results. Also, larger intensity value can be used for decoy pulses. This makes
the protocol more robust in practical experiments.

### Title: Designer magnetic topological graphene nanoribbons
* Paper ID: 2204.12880v1
* Paper URL: [http://arxiv.org/abs/2204.12880v1](http://arxiv.org/abs/2204.12880v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: The interplay of magnetism and topology lies at the heart of condensed matter
physics, which offers great opportunities to design intrinsic magnetic
topological materials hosting a variety of exotic topological quantum states
including the quantum anomalous Hall effect (QAHE), axion insulator state, and
Majorana bound states. Extending this concept to one-dimension (1D) systems
offers additional rich quantum spin physics with great promise for
molecular-scale spintronics. Despite recent progress in the discovery of
symmetry-protected topological quantum phases in 1D graphene nanoribbons
(GNRs), the rational design and realization of magnetic topological GNRs
(MT-GNRs) represents a grand challenge, as one must tackle multiple dimensions
of complexity including time-reversal symmetry (TRS), spatial symmetry (width,
edge, end geometry) and many-electron correlations. Here, we devised a new
route involving the real- and reciprocal-space descriptions by unifying the
chemists and physicists perspectives, for the design of such MT-GNRs with
non-trivial electronic topology and robust magnetic terminal. Classic Clar's
rule offers a conceptually qualitative real-space picture to predict the
transition from closed-shell to open-shell with terminal magnetism, and band
gap reopening with possible non-trivial electronic topology in a series of
wave-like GNRs, which are further verified by first principle calculations of
band-structure topology in a momentum-space. With the advance of on-surface
synthesis and careful design of molecular precursors, we have fabricated these
MT-GNRs with observation of topological edge bands, whose terminal pi-magnetism
can be directly captured using a single-nickelocene spin sensor. Moreover, the
transition from strong anti-ferromagnetic to weak coupling (paramagnetism-like)
between terminal spins can be controlled by tuning the length of MT-GNRs.

### Title: Reducing number of gates in quantum random walk search algorithm via modification of coin operators
* Paper ID: 2204.12858v1
* Paper URL: [http://arxiv.org/abs/2204.12858v1](http://arxiv.org/abs/2204.12858v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: This paper examines a way to simplify the circuit of quantum random walk
search algorithm, when the traversing coin is constructed by both generalized
Householder reflection and an additional phase multiplier. If an appropriate
relation between corresponding parameters is realized, our algorithm becomes
more robust to deviations in the phases. In this modification marking coin is
not needed, and all advantages from above mentioned optimization to the
stability, are preserved. It is shown explicitly how to construct such walk
coin in order to obtain more robust quantum algorithm.

### Title: Learning to Parallelize in a Shared-Memory Environment with Transformers
* Paper ID: 2204.12835v1
* Paper URL: [http://arxiv.org/abs/2204.12835v1](http://arxiv.org/abs/2204.12835v1)
* Updated Date: 2022-04-27
* Code URL: [https://github.com/scientific-computing-lab-nrcn/pragformer](https://github.com/scientific-computing-lab-nrcn/pragformer)
* Summary: In past years, the world has switched to many-core and multi-core shared
memory architectures.
  As a result, there is a growing need to utilize these architectures by
introducing shared memory parallelization schemes to software applications.
OpenMP is the most comprehensive API that implements such schemes,
characterized by a readable interface. Nevertheless, introducing OpenMP into
code is challenging due to pervasive pitfalls in management of parallel shared
memory. To facilitate the performance of this task, many source-to-source (S2S)
compilers have been created over the years, tasked with inserting OpenMP
directives into code automatically.
  In addition to having limited robustness to their input format, these
compilers still do not achieve satisfactory coverage and precision in locating
parallelizable code and generating appropriate directives.
  In this work, we propose leveraging recent advances in ML techniques,
specifically in natural language processing (NLP), to replace S2S compilers
altogether.
  We create a database (corpus), Open-OMP, specifically for this goal. Open-OMP
contains over 28,000 code snippets, half of which contain OpenMP directives
while the other half do not need parallelization at all with high probability.
  We use the corpus to train systems to automatically classify code segments in
need of parallelization, as well as suggest individual OpenMP clauses.
  We train several transformer models, named PragFormer, for these tasks, and
show that they outperform statistically-trained baselines and automatic S2S
parallelization compilers in both classifying the overall need for an OpenMP
directive and the introduction of private and reduction clauses.
  Our source code and database are available at:
https://github.com/Scientific-Computing-Lab-NRCN/PragFormer.

### Title: The Revisiting Problem in Simultaneous Localization and Mapping: A Survey on Visual Loop Closure Detection
* Paper ID: 2204.12831v1
* Paper URL: [http://arxiv.org/abs/2204.12831v1](http://arxiv.org/abs/2204.12831v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Where am I? This is one of the most critical questions that any intelligent
system should answer to decide whether it navigates to a previously visited
area. This problem has long been acknowledged for its challenging nature in
simultaneous localization and mapping (SLAM), wherein the robot needs to
correctly associate the incoming sensory data to the database allowing
consistent map generation. The significant advances in computer vision achieved
over the last 20 years, the increased computational power, and the growing
demand for long-term exploration contributed to efficiently performing such a
complex task with inexpensive perception sensors. In this article, visual loop
closure detection, which formulates a solution based solely on appearance input
data, is surveyed. We start by briefly introducing place recognition and SLAM
concepts in robotics. Then, we describe a loop closure detection system's
structure, covering an extensive collection of topics, including the feature
extraction, the environment representation, the decision-making step, and the
evaluation process. We conclude by discussing open and new research challenges,
particularly concerning the robustness in dynamic environments, the
computational complexity, and scalability in long-term operations. The article
aims to serve as a tutorial and a position paper for newcomers to visual loop
closure detection.

### Title: CATrans: Context and Affinity Transformer for Few-Shot Segmentation
* Paper ID: 2204.12817v1
* Paper URL: [http://arxiv.org/abs/2204.12817v1](http://arxiv.org/abs/2204.12817v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Few-shot segmentation (FSS) aims to segment novel categories given scarce
annotated support images. The crux of FSS is how to aggregate dense
correlations between support and query images for query segmentation while
being robust to the large variations in appearance and context. To this end,
previous Transformer-based methods explore global consensus either on context
similarity or affinity map between support-query pairs. In this work, we
effectively integrate the context and affinity information via the proposed
novel Context and Affinity Transformer (CATrans) in a hierarchical
architecture. Specifically, the Relation-guided Context Transformer (RCT)
propagates context information from support to query images conditioned on more
informative support features. Based on the observation that a huge feature
distinction between support and query pairs brings barriers for context
knowledge transfer, the Relation-guided Affinity Transformer (RAT) measures
attention-aware affinity as auxiliary information for FSS, in which the
self-affinity is responsible for more reliable cross-affinity. We conduct
experiments to demonstrate the effectiveness of the proposed model,
outperforming the state-of-the-art methods.

### Title: A Comprehensive Understanding of Code-mixed Language Semantics using Hierarchical Transformer
* Paper ID: 2204.12753v1
* Paper URL: [http://arxiv.org/abs/2204.12753v1](http://arxiv.org/abs/2204.12753v1)
* Updated Date: 2022-04-27
* Code URL: [https://github.com/lcs2-iiitd/code-mixed-classification](https://github.com/lcs2-iiitd/code-mixed-classification)
* Summary: Being a popular mode of text-based communication in multilingual communities,
code-mixing in online social media has became an important subject to study.
Learning the semantics and morphology of code-mixed language remains a key
challenge, due to scarcity of data and unavailability of robust and
language-invariant representation learning technique. Any morphologically-rich
language can benefit from character, subword, and word-level embeddings, aiding
in learning meaningful correlations. In this paper, we explore a hierarchical
transformer-based architecture (HIT) to learn the semantics of code-mixed
languages. HIT consists of multi-headed self-attention and outer product
attention components to simultaneously comprehend the semantic and syntactic
structures of code-mixed texts. We evaluate the proposed method across 6 Indian
languages (Bengali, Gujarati, Hindi, Tamil, Telugu and Malayalam) and Spanish
for 9 NLP tasks on 17 datasets. The HIT model outperforms state-of-the-art
code-mixed representation learning and multilingual language models in all
tasks. We further demonstrate the generalizability of the HIT architecture
using masked language modeling-based pre-training, zero-shot learning, and
transfer learning approaches. Our empirical results show that the pre-training
objectives significantly improve the performance on downstream tasks.

### Title: Self-Supervised Text Erasing with Controllable Image Synthesis
* Paper ID: 2204.12743v1
* Paper URL: [http://arxiv.org/abs/2204.12743v1](http://arxiv.org/abs/2204.12743v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Recent efforts on scene text erasing have shown promising results. However,
existing methods require rich yet costly label annotations to obtain robust
models, which limits the use for practical applications. To this end, we study
an unsupervised scenario by proposing a novel Self-supervised Text Erasing
(STE) framework that jointly learns to synthesize training images with erasure
ground-truth and accurately erase texts in the real world. We first design a
style-aware image synthesis function to generate synthetic images with diverse
styled texts based on two synthetic mechanisms. To bridge the text style gap
between the synthetic and real-world data, a policy network is constructed to
control the synthetic mechanisms by picking style parameters with the guidance
of two specifically designed rewards. The synthetic training images with
erasure ground-truth are then fed to train a coarse-to-fine erasing network. To
produce better erasing outputs, a triplet erasure loss is designed to enforce
the refinement stage to recover background textures. Moreover, we provide a new
dataset (called PosterErase), which contains 60K high-resolution posters with
texts and is more challenging for the text erasing task. The proposed method
has been extensively evaluated with both PosterErase and the widely-used
SCUT-Enstext dataset. Notably, on PosterErase, our unsupervised method achieves
5.07 in terms of FID, with a relative performance of 20.9% over existing
supervised baselines.

### Title: Discrete energy analysis of the third-order variable-step BDF time-stepping for diffusion equations
* Paper ID: 2204.12742v1
* Paper URL: [http://arxiv.org/abs/2204.12742v1](http://arxiv.org/abs/2204.12742v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: This is one of our series works on discrete energy analysis of the
variable-step BDF schemes. In this part, we present stability and convergence
analysis of the third-order BDF (BDF3) schemes with variable steps for linear
diffusion equations, see e.g. [SIAM J. Numer. Anal., 58:2294-2314] and [Math.
Comp., 90: 1207-1226] for our previous works on the BDF2 scheme. To this aim,
we first build up a discrete gradient structure of the variable-step BDF3
formula under the condition that the adjacent step ratios are less than 1.4877,
by which we can establish a discrete energy dissipation law. Mesh-robust
stability and convergence analysis in the $L^2$ norm are then obtained. Here
the mesh robustness means that the solution errors are well controlled by the
maximum time-step size but independent of the adjacent time-step ratios. We
also present numerical tests to support our theoretical results.

### Title: A cost-effective quantum eraser demonstration
* Paper ID: 2204.12728v1
* Paper URL: [http://arxiv.org/abs/2204.12728v1](http://arxiv.org/abs/2204.12728v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: The quantum eraser is a variation of the celebrated Young's interference
experiment that can be used to demonstrate the elusive complementarity
principle in quantum physics. Here we show the construction of its classical
analogue for deployment in classrooms in a simple, cost-effective yet robust
manner by employing a laser pointer, double-slits, and polarizers.

### Title: Dataset for Robust and Accurate Leading Vehicle Velocity Recognition
* Paper ID: 2204.12717v1
* Paper URL: [http://arxiv.org/abs/2204.12717v1](http://arxiv.org/abs/2204.12717v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Recognition of the surrounding environment using a camera is an important
technology in Advanced Driver-Assistance Systems and Autonomous Driving, and
recognition technology is often solved by machine learning approaches such as
deep learning in recent years. Machine learning requires datasets for learning
and evaluation. To develop robust recognition technology in the real world, in
addition to normal driving environment, data in environments that are difficult
for cameras such as rainy weather or nighttime are essential. We have
constructed a dataset that one can benchmark the technology, targeting the
velocity recognition of the leading vehicle. This task is an important one for
the Advanced Driver-Assistance Systems and Autonomous Driving. The dataset is
available at https://signate.jp/competitions/657

### Title: Heterogeneous Ensemble Knowledge Transfer for Training Large Models in Federated Learning
* Paper ID: 2204.12703v1
* Paper URL: [http://arxiv.org/abs/2204.12703v1](http://arxiv.org/abs/2204.12703v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Federated learning (FL) enables edge-devices to collaboratively learn a model
without disclosing their private data to a central aggregating server. Most
existing FL algorithms require models of identical architecture to be deployed
across the clients and server, making it infeasible to train large models due
to clients' limited system resources. In this work, we propose a novel ensemble
knowledge transfer method named Fed-ET in which small models (different in
architecture) are trained on clients, and used to train a larger model at the
server. Unlike in conventional ensemble learning, in FL the ensemble can be
trained on clients' highly heterogeneous data. Cognizant of this property,
Fed-ET uses a weighted consensus distillation scheme with diversity
regularization that efficiently extracts reliable consensus from the ensemble
while improving generalization by exploiting the diversity within the ensemble.
We show the generalization bound for the ensemble of weighted models trained on
heterogeneous datasets that supports the intuition of Fed-ET. Our experiments
on image and language tasks show that Fed-ET significantly outperforms other
state-of-the-art FL algorithms with fewer communicated parameters, and is also
robust against high data-heterogeneity.

### Title: Grasping the Arrow of Time from the Singularity: Decoding Micromotion in Low-dimensional Latent Spaces from StyleGAN
* Paper ID: 2204.12696v1
* Paper URL: [http://arxiv.org/abs/2204.12696v1](http://arxiv.org/abs/2204.12696v1)
* Updated Date: 2022-04-27
* Code URL: [https://github.com/wuqiuche/micromotion-stylegan](https://github.com/wuqiuche/micromotion-stylegan)
* Summary: The disentanglement of StyleGAN latent space has paved the way for realistic
and controllable image editing, but does StyleGAN know anything about temporal
motion, as it was only trained on static images? To study the motion features
in the latent space of StyleGAN, in this paper, we hypothesize and demonstrate
that a series of meaningful, natural, and versatile small, local movements
(referred to as "micromotion", such as expression, head movement, and aging
effect) can be represented in low-rank spaces extracted from the latent space
of a conventionally pre-trained StyleGAN-v2 model for face generation, with the
guidance of proper "anchors" in the form of either short text or video clips.
Starting from one target face image, with the editing direction decoded from
the low-rank space, its micromotion features can be represented as simple as an
affine transformation over its latent feature. Perhaps more surprisingly, such
micromotion subspace, even learned from just single target face, can be
painlessly transferred to other unseen face images, even those from vastly
different domains (such as oil painting, cartoon, and sculpture faces). It
demonstrates that the local feature geometry corresponding to one type of
micromotion is aligned across different face subjects, and hence that
StyleGAN-v2 is indeed "secretly" aware of the subject-disentangled feature
variations caused by that micromotion. We present various successful examples
of applying our low-dimensional micromotion subspace technique to directly and
effortlessly manipulate faces, showing high robustness, low computational
overhead, and impressive domain transferability. Our codes are available at
https://github.com/wuqiuche/micromotion-StyleGAN.

### Title: Robust Face Anti-Spoofing with Dual Probabilistic Modeling
* Paper ID: 2204.12685v1
* Paper URL: [http://arxiv.org/abs/2204.12685v1](http://arxiv.org/abs/2204.12685v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: The field of face anti-spoofing (FAS) has witnessed great progress with the
surge of deep learning. Due to its data-driven nature, existing FAS methods are
sensitive to the noise in the dataset, which will hurdle the learning process.
However, very few works consider noise modeling in FAS. In this work, we
attempt to fill this gap by automatically addressing the noise problem from
both label and data perspectives in a probabilistic manner. Specifically, we
propose a unified framework called Dual Probabilistic Modeling (DPM), with two
dedicated modules, DPM-LQ (Label Quality aware learning) and DPM-DQ (Data
Quality aware learning). Both modules are designed based on the assumption that
data and label should form coherent probabilistic distributions. DPM-LQ is able
to produce robust feature representations without overfitting to the
distribution of noisy semantic labels. DPM-DQ can eliminate data noise from
`False Reject' and `False Accept' during inference by correcting the prediction
confidence of noisy data based on its quality distribution. Both modules can be
incorporated into existing deep networks seamlessly and efficiently.
Furthermore, we propose the generalized DPM to address the noise problem in
practical usage without the need of semantic annotations. Extensive experiments
demonstrate that this probabilistic modeling can 1) significantly improve the
accuracy, and 2) make the model robust to the noise in real-world datasets.
Without bells and whistles, our proposed DPM achieves state-of-the-art
performance on multiple standard FAS benchmarks.

### Title: Document-Level Relation Extraction with Sentences Importance Estimation and Focusing
* Paper ID: 2204.12679v1
* Paper URL: [http://arxiv.org/abs/2204.12679v1](http://arxiv.org/abs/2204.12679v1)
* Updated Date: 2022-04-27
* Code URL: [https://github.com/xwjim/sief](https://github.com/xwjim/sief)
* Summary: Document-level relation extraction (DocRE) aims to determine the relation
between two entities from a document of multiple sentences. Recent studies
typically represent the entire document by sequence- or graph-based models to
predict the relations of all entity pairs. However, we find that such a model
is not robust and exhibits bizarre behaviors: it predicts correctly when an
entire test document is fed as input, but errs when non-evidence sentences are
removed. To this end, we propose a Sentence Importance Estimation and Focusing
(SIEF) framework for DocRE, where we design a sentence importance score and a
sentence focusing loss, encouraging DocRE models to focus on evidence
sentences. Experimental results on two domains show that our SIEF not only
improves overall performance, but also makes DocRE models more robust.
Moreover, SIEF is a general framework, shown to be effective when combined with
a variety of base DocRE models.

### Title: The Multimarginal Optimal Transport Formulation of Adversarial Multiclass Classification
* Paper ID: 2204.12676v1
* Paper URL: [http://arxiv.org/abs/2204.12676v1](http://arxiv.org/abs/2204.12676v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: We study a family of adversarial multiclass classification problems and
provide equivalent reformulations in terms of: 1) a family of generalized
barycenter problems introduced in the paper and 2) a family of multimarginal
optimal transport problems where the number of marginals is equal to the number
of classes in the original classification problem. These new theoretical
results reveal a rich geometric structure of adversarial learning problems in
multiclass classification and extend recent results restricted to the binary
classification setting. A direct computational implication of our results is
that by solving either the barycenter problem and its dual, or the MOT problem
and its dual, we can recover the optimal robust classification rule and the
optimal adversarial strategy for the original adversarial problem. Examples
with synthetic and real data illustrate our results.

### Title: Transit Frequency Setting Problem with Demand Uncertainty
* Paper ID: 2204.12666v1
* Paper URL: [http://arxiv.org/abs/2204.12666v1](http://arxiv.org/abs/2204.12666v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Public transit systems are the backbone of efficient and sustainable urban
mobility systems in the era of urbanization. This paper proposes a transit
frequency setting model for a single transit line to generate transit schedules
that could better serve passengers. The proposed model optimizes both service
patterns and frequency for transit routes during a service period, and crowding
levels on transit vehicles are also considered. To handle demand uncertainties
when designing transit schedules, both stochastic programming and robust
optimization techniques are introduced to protect transit schedules against
inaccurate demand estimates. To address the computation complexity in both
extended models under large-scale demand matrices, a Bender decomposition
algorithm and two dimension reduction techniques are designed. The proposed
models will be tested with real-world data from Chicago Transit Authority
(CTA).

### Title: SCGC : Self-Supervised Contrastive Graph Clustering
* Paper ID: 2204.12656v1
* Paper URL: [http://arxiv.org/abs/2204.12656v1](http://arxiv.org/abs/2204.12656v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Graph clustering discovers groups or communities within networks. Deep
learning methods such as autoencoders (AE) extract effective clustering and
downstream representations but cannot incorporate rich structural information.
While Graph Neural Networks (GNN) have shown great success in encoding graph
structure, typical GNNs based on convolution or attention variants suffer from
over-smoothing, noise, heterophily, are computationally expensive and typically
require the complete graph being present. Instead, we propose Self-Supervised
Contrastive Graph Clustering (SCGC), which imposes graph-structure via
contrastive loss signals to learn discriminative node representations and
iteratively refined soft cluster labels. We also propose SCGC*, with a more
effective, novel, Influence Augmented Contrastive (IAC) loss to fuse richer
structural information, and half the original model parameters. SCGC(*) is
faster with simple linear units, completely eliminate convolutions and
attention of traditional GNNs, yet efficiently incorporates structure. It is
impervious to layer depth and robust to over-smoothing, incorrect edges and
heterophily. It is scalable by batching, a limitation in many prior GNN models,
and trivially parallelizable. We obtain significant improvements over
state-of-the-art on a wide range of benchmark graph datasets, including images,
sensor data, text, and citation networks efficiently. Specifically, 20% on ARI
and 18% on NMI for DBLP; overall 55% reduction in training time and overall,
81% reduction on inference time. Our code is available at :
https://github.com/gayanku/SCGC

### Title: Chiral Hinge Transports in Disordered Non-Hermitian Second-Order Topological Insulators
* Paper ID: 2204.12655v1
* Paper URL: [http://arxiv.org/abs/2204.12655v1](http://arxiv.org/abs/2204.12655v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: The generalized bulk-boundary correspondence predicts the existence of the
chiral hinge states in three-dimensional second-order topological insulators
(3DSOTIs), resulting in a quantized Hall effect in three dimensions. Chiral
hinge states in Hermitian 3DSOTIs are characterized by the quantized
transmission coefficients with zero fluctuations, even in the presence of
disorders. Here, we show that chiral hinge transport in disordered
non-Hermitian systems deviates from the paradigm of the Hermitian case. Our
numerical calculations prove the robustness of hinge states of disordered
non-Hermitian 3DSOTIs. The mean transmission coefficients may or may not equal
the number of chiral hinge channels, depending on the Hermiticity of chiral
hinge states, while the fluctuations of transmission coefficients are always
non-zero. Such fluctuations are not due to the broken chirality of hinge states
but the incoherent scatterings of non-Hermitian potentials. The physics
revealed here should also be true for one-dimensional chiral channels in
topological materials that support chiral boundary states, such as Chern
insulators, three-dimensional anomalous Hall insulators, and Weyl semimetals.

### Title: Study on the Fairness of Speaker Verification Systems on Underrepresented Accents in English
* Paper ID: 2204.12649v1
* Paper URL: [http://arxiv.org/abs/2204.12649v1](http://arxiv.org/abs/2204.12649v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Speaker verification (SV) systems are currently being used to make sensitive
decisions like giving access to bank accounts or deciding whether the voice of
a suspect coincides with that of the perpetrator of a crime. Ensuring that
these systems are fair and do not disfavor any particular group is crucial. In
this work, we analyze the performance of several state-of-the-art SV systems
across groups defined by the accent of the speakers when speaking English. To
this end, we curated a new dataset based on the VoxCeleb corpus where we
carefully selected samples from speakers with accents from different countries.
We use this dataset to evaluate system performance for several SV systems
trained with VoxCeleb data. We show that, while discrimination performance is
reasonably robust across accent groups, calibration performance degrades
dramatically on some accents that are not well represented in the training
data. Finally, we show that a simple data balancing approach mitigates this
undesirable bias, being particularly effective when applied to our
recently-proposed discriminative condition-aware backend.

### Title: Understanding The Robustness in Vision Transformers
* Paper ID: 2204.12451v2
* Paper URL: [http://arxiv.org/abs/2204.12451v2](http://arxiv.org/abs/2204.12451v2)
* Updated Date: 2022-04-27
* Code URL: [https://github.com/nvlabs/fan](https://github.com/nvlabs/fan)
* Summary: Recent studies show that Vision Transformers(ViTs) exhibit strong robustness
against various corruptions. Although this property is partly attributed to the
self-attention mechanism, there is still a lack of systematic understanding. In
this paper, we examine the role of self-attention in learning robust
representations. Our study is motivated by the intriguing properties of the
emerging visual grouping in Vision Transformers, which indicates that
self-attention may promote robustness through improved mid-level
representations. We further propose a family of fully attentional networks
(FANs) that strengthen this capability by incorporating an attentional channel
processing design. We validate the design comprehensively on various
hierarchical backbones. Our model achieves a state of-the-art 87.1% accuracy
and 35.8% mCE on ImageNet-1k and ImageNet-C with 76.8M parameters. We also
demonstrate state-of-the-art accuracy and robustness in two downstream tasks:
semantic segmentation and object detection. Code will be available at
https://github.com/NVlabs/FAN.

### Title: A Quantum Optical Microphone in the Audio Band
* Paper ID: 2204.12429v2
* Paper URL: [http://arxiv.org/abs/2204.12429v2](http://arxiv.org/abs/2204.12429v2)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: The ability to perform high-precision optical measurements is paramount to
science and engineering. Laser interferometry enables interaction-free sensing
with a precision ultimately limited by shot noise. Quantum optical sensors can
surpass this limit, but single- or multi-photon schemes are challenged by low
experimental sampling rates, while squeezed-light approaches require complex
optical setups and sophisticated time gating. Here, we introduce a simple
method that infers optical phase shifts through standard intensity measurements
while still maintaining the quantum advantage in the measurement precision.
Capitalising on the robustness and high sampling rates of our device, we
implement a quantum optical microphone in the audio band. Its performance is
benchmarked against a classical laser microphone in a standardised
medically-approved speech recognition test on 45 subjects. We find that
quantum-recorded words improve the speech recognition threshold by $-0.57\,
\text{dB}_{\text{SPL}}$, thus making the quantum advantage audible. Not only do
these results open the door towards applications in quantum nonlinear
interferometry, but they also show that quantum phenomena can be experienced by
humans.

### Title: Hypergraph Contrastive Collaborative Filtering
* Paper ID: 2204.12200v2
* Paper URL: [http://arxiv.org/abs/2204.12200v2](http://arxiv.org/abs/2204.12200v2)
* Updated Date: 2022-04-27
* Code URL: [https://github.com/akaxlh/hccf](https://github.com/akaxlh/hccf)
* Summary: Collaborative Filtering (CF) has emerged as fundamental paradigms for
parameterizing users and items into latent representation space, with their
correlative patterns from interaction data. Among various CF techniques, the
development of GNN-based recommender systems, e.g., PinSage and LightGCN, has
offered the state-of-the-art performance. However, two key challenges have not
been well explored in existing solutions: i) The over-smoothing effect with
deeper graph-based CF architecture, may cause the indistinguishable user
representations and degradation of recommendation results. ii) The supervision
signals (i.e., user-item interactions) are usually scarce and skewed
distributed in reality, which limits the representation power of CF paradigms.
To tackle these challenges, we propose a new self-supervised recommendation
framework Hypergraph Contrastive Collaborative Filtering (HCCF) to jointly
capture local and global collaborative relations with a hypergraph-enhanced
cross-view contrastive learning architecture. In particular, the designed
hypergraph structure learning enhances the discrimination ability of GNN-based
CF paradigm, so as to comprehensively capture the complex high-order
dependencies among users. Additionally, our HCCF model effectively integrates
the hypergraph structure encoding with self-supervised learning to reinforce
the representation quality of recommender systems, based on the
hypergraph-enhanced self-discrimination. Extensive experiments on three
benchmark datasets demonstrate the superiority of our model over various
state-of-the-art recommendation methods, and the robustness against sparse user
interaction data. Our model implementation codes are available at
https://github.com/akaxlh/HCCF.

### Title: Trusted Multi-View Classification with Dynamic Evidential Fusion
* Paper ID: 2204.11423v2
* Paper URL: [http://arxiv.org/abs/2204.11423v2](http://arxiv.org/abs/2204.11423v2)
* Updated Date: 2022-04-27
* Code URL: [https://github.com/hanmenghan/TMC](https://github.com/hanmenghan/TMC)
* Summary: Existing multi-view classification algorithms focus on promoting accuracy by
exploiting different views, typically integrating them into common
representations for follow-up tasks. Although effective, it is also crucial to
ensure the reliability of both the multi-view integration and the final
decision, especially for noisy, corrupted and out-of-distribution data.
Dynamically assessing the trustworthiness of each view for different samples
could provide reliable integration. This can be achieved through uncertainty
estimation. With this in mind, we propose a novel multi-view classification
algorithm, termed trusted multi-view classification (TMC), providing a new
paradigm for multi-view learning by dynamically integrating different views at
an evidence level. The proposed TMC can promote classification reliability by
considering evidence from each view. Specifically, we introduce the variational
Dirichlet to characterize the distribution of the class probabilities,
parameterized with evidence from different views and integrated with the
Dempster-Shafer theory. The unified learning framework induces accurate
uncertainty and accordingly endows the model with both reliability and
robustness against possible noise or corruption. Both theoretical and
experimental results validate the effectiveness of the proposed model in
accuracy, robustness and trustworthiness.

### Title: Robust Self-Augmentation for Named Entity Recognition with Meta Reweighting
* Paper ID: 2204.11406v2
* Paper URL: [http://arxiv.org/abs/2204.11406v2](http://arxiv.org/abs/2204.11406v2)
* Updated Date: 2022-04-27
* Code URL: [https://github.com/LindgeW/MetaAug4NER](https://github.com/LindgeW/MetaAug4NER)
* Summary: Self-augmentation has been received increasing research interest recently to
improve named entity recognition (NER) performance in low-resource scenarios.
Token substitution and mixup are two feasible heterogeneous self-augmentation
techniques for NER that can achieve effective performance with certain
specialized efforts. Noticeably, self-augmentation may introduce potentially
noisy augmented data. Prior research has mainly resorted to heuristic rule
based constraints to reduce the noise for specific self-augmentation
individually. In this paper, we revisit the two self-augmentation methods for
NER, and propose a unified meta-reweighting strategy for these heterogeneous
methods to achieve a natural integration. Our method is easily extensible,
imposing little effort on a specific self-augmentation method. Experiments on
different Chinese and English NER benchmarks demonstrate that our token
substitution and mixup method, as well as their integration, can obtain
effective performance improvement. Based on the meta-reweighting mechanism, we
can enhance the advantages of the self-augmentation techniques without extra
efforts.

