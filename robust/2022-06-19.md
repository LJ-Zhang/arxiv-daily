### Title: DoG-HiT: A novel VLBI Multiscale Imaging Approach
* Paper ID: 2206.09501v1
* Paper URL: [http://arxiv.org/abs/2206.09501v1](http://arxiv.org/abs/2206.09501v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Reconstructing images from very long baseline interferometry (VLBI) data with
sparse sampling of the Fourier domain (uv-coverage) constitutes an ill-posed
deconvolution problem. It requires application of robust algorithms maximizing
the information extraction from all of the sampled spatial scales and
minimizing the influence of the unsampled scales on image quality. We develop a
new multiscale wavelet deconvolution algorithm DoG-HiT for imaging sparsely
sampled interferometric data which combines the difference of Gaussian (DoG)
wavelets and hard image thresholding (HiT). Based on DoG-HiT, we propose a
multi-step imaging pipeline for analysis of interferometric data. DoG-HiT
applies the compressed sensing approach to imaging by employing a flexible DoG
wavelet dictionary which is designed to adapt smoothly to the uv-coverage. It
uses closure properties as data fidelity terms only initially and perform
non-convex, non-smooth optimization by an amplitude conserving and total flux
conserving hard thresholding splitting. DoG-HiT calculates a multiresolution
support as a side product. The final reconstruction is refined through
self-calibration loops and imaging with amplitude and phase information applied
for the multiresolution support only. We demonstrate the stability of DoG-HiT
and benchmark its performance against image reconstructions made with CLEAN and
Regularized Maximum-Likelihood (RML) methods using synthetic data. The
comparison shows that DoG-HiT matches the superresolution achieved by the RML
reconstructions and surpasses the sensitivity to extended emission reached by
CLEAN. Application of regularized maximum likelihood methods outfitted with
flexible multiscale wavelet dictionaries to imaging of interferometric data
matches the performance of state-of-the art convex optimization imaging
algorithms and requires fewer prior and user defined constraints.

### Title: Learning Multi-Task Transferable Rewards via Variational Inverse Reinforcement Learning
* Paper ID: 2206.09498v1
* Paper URL: [http://arxiv.org/abs/2206.09498v1](http://arxiv.org/abs/2206.09498v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Many robotic tasks are composed of a lot of temporally correlated sub-tasks
in a highly complex environment. It is important to discover situational
intentions and proper actions by deliberating on temporal abstractions to solve
problems effectively. To understand the intention separated from changing task
dynamics, we extend an empowerment-based regularization technique to situations
with multiple tasks based on the framework of a generative adversarial network.
Under the multitask environments with unknown dynamics, we focus on learning a
reward and policy from the unlabeled expert examples. In this study, we define
situational empowerment as the maximum of mutual information representing how
an action conditioned on both a certain state and sub-task affects the future.
Our proposed method derives the variational lower bound of the situational
mutual information to optimize it. We simultaneously learn the transferable
multi-task reward function and policy by adding an induced term to the
objective function. By doing so, the multi-task reward function helps to learn
a robust policy for environmental change. We validate the advantages of our
approach on multi-task learning and multi-task transfer learning. We
demonstrate our proposed method has the robustness of both randomness and
changing task dynamics. Finally, we prove that our method has significantly
better performance and data efficiency than existing imitation learning methods
on various benchmarks.

### Title: On the Limitations of Stochastic Pre-processing Defenses
* Paper ID: 2206.09491v1
* Paper URL: [http://arxiv.org/abs/2206.09491v1](http://arxiv.org/abs/2206.09491v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Defending against adversarial examples remains an open problem. A common
belief is that randomness at inference increases the cost of finding
adversarial inputs. An example of such a defense is to apply a random
transformation to inputs prior to feeding them to the model. In this paper, we
empirically and theoretically investigate such stochastic pre-processing
defenses and demonstrate that they are flawed. First, we show that most
stochastic defenses are weaker than previously thought; they lack sufficient
randomness to withstand even standard attacks like projected gradient descent.
This casts doubt on a long-held assumption that stochastic defenses invalidate
attacks designed to evade deterministic defenses and force attackers to
integrate the Expectation over Transformation (EOT) concept. Second, we show
that stochastic defenses confront a trade-off between adversarial robustness
and model invariance; they become less effective as the defended model acquires
more invariance to their randomization. Future work will need to decouple these
two effects. Our code is available in the supplementary material.

### Title: Data Augmentation vs. Equivariant Networks: A Theory of Generalization on Dynamics Forecasting
* Paper ID: 2206.09450v1
* Paper URL: [http://arxiv.org/abs/2206.09450v1](http://arxiv.org/abs/2206.09450v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Exploiting symmetry in dynamical systems is a powerful way to improve the
generalization of deep learning. The model learns to be invariant to
transformation and hence is more robust to distribution shift. Data
augmentation and equivariant networks are two major approaches to injecting
symmetry into learning. However, their exact role in improving generalization
is not well understood. In this work, we derive the generalization bounds for
data augmentation and equivariant networks, characterizing their effect on
learning in a unified framework. Unlike most prior theories for the i.i.d.
setting, we focus on non-stationary dynamics forecasting with complex temporal
dependencies.

### Title: 3-stage and 4-stage tests with deterministic stage sizes and non-iid data
* Paper ID: 2206.09433v1
* Paper URL: [http://arxiv.org/abs/2206.09433v1](http://arxiv.org/abs/2206.09433v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Given a fixed-sample-size test that controls the error probabili-ties under
two specific, but arbitrary, distributions, a 3-stage and two 4-stage tests are
proposed and analyzed. For each of them, a novel, concrete, non-asymptotic,
non-conservative design is specified, which guarantees the same error control
as the given fixed-sample-size test. Moreover, first-order asymptotic
approximation are established on their expected sample sizes under the two
prescribed distributions as the error probabilities go to zero. As a corollary,
it is shown that the proposed multistage tests can achieve, in this asymptotic
sense, the optimal expected sample size under these two distributions in the
class of all sequential tests with the same error control. Furthermore, they
are shown to be much more robust than Wald's SPRT when applied to one-sided
testing problems and the error probabilities under control are small enough.
These general results are applied to testing problems in the iid setup and
beyond, such as testing the correlation coefficient of a first-order
autoregression, or the transition matrix of a finite-state Markov chain, and
are illustrated in various numerical studies.

### Title: Data-Driven Synthesis of Symbolic Abstractions with Guaranteed Confidence
* Paper ID: 2206.09397v1
* Paper URL: [http://arxiv.org/abs/2206.09397v1](http://arxiv.org/abs/2206.09397v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: In this work, we propose a data-driven approach for the construction of
finite abstractions (a.k.a., symbolic models) for discrete-time deterministic
control systems with unknown dynamics. We leverage notions of so-called
alternating bisimulation functions (ABF), as a relation between each unknown
system and its symbolic model, to quantify the mismatch between state behaviors
of two systems. Accordingly, one can employ our proposed results to perform
formal verification and synthesis over symbolic models and then carry the
results back over unknown original systems. In our data-driven setting, we
first cast the required conditions for constructing ABF as a robust
optimization program (ROP). Solving the provided ROP is not tractable due to
the existence of unknown models in the constraints of ROP. To tackle this
difficulty, we collect finite numbers of data from trajectories of unknown
systems and propose a scenario optimization program (SOP) corresponding to the
original ROP. By establishing a probabilistic relation between optimal values
of SOP and ROP, we formally construct ABF between unknown systems and their
symbolic models based on the number of data and a required confidence level. We
verify the effectiveness of our data-driven results over two physical case
studies with unknown models including (i) a DC motor and (ii) a nonlinear jet
engine compressor. We construct symbolic models from data as appropriate
substitutes of original systems and synthesize policies maintaining states of
unknown systems in a safe set within infinite time horizons with some
guaranteed confidence levels.

### Title: Transfer Learning for Robust Low-Resource Children's Speech ASR with Transformers and Source-Filter Warping
* Paper ID: 2206.09396v1
* Paper URL: [http://arxiv.org/abs/2206.09396v1](http://arxiv.org/abs/2206.09396v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Automatic Speech Recognition (ASR) systems are known to exhibit difficulties
when transcribing children's speech. This can mainly be attributed to the
absence of large children's speech corpora to train robust ASR models and the
resulting domain mismatch when decoding children's speech with systems trained
on adult data. In this paper, we propose multiple enhancements to alleviate
these issues. First, we propose a data augmentation technique based on the
source-filter model of speech to close the domain gap between adult and
children's speech. This enables us to leverage the data availability of adult
speech corpora by making these samples perceptually similar to children's
speech. Second, using this augmentation strategy, we apply transfer learning on
a Transformer model pre-trained on adult data. This model follows the recently
introduced XLS-R architecture, a wav2vec 2.0 model pre-trained on several
cross-lingual adult speech corpora to learn general and robust acoustic
frame-level representations. Adopting this model for the ASR task using adult
data augmented with the proposed source-filter warping strategy and a limited
amount of in-domain children's speech significantly outperforms previous
state-of-the-art results on the PF-STAR British English Children's Speech
corpus with a 4.86% WER on the official test set.

### Title: Towards Adversarial Attack on Vision-Language Pre-training Models
* Paper ID: 2206.09391v1
* Paper URL: [http://arxiv.org/abs/2206.09391v1](http://arxiv.org/abs/2206.09391v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: While vision-language pre-training model (VLP) has shown revolutionary
improvements on various vision-language (V+L) tasks, the studies regarding its
adversarial robustness remain largely unexplored. This paper studied the
adversarial attack on popular VLP models and V+L tasks. First, we analyzed the
performance of adversarial attacks under different settings. By examining the
influence of different perturbed objects and attack targets, we concluded some
key observations as guidance on both designing strong multimodal adversarial
attack and constructing robust VLP models. Second, we proposed a novel
multimodal attack method on the VLP models called Collaborative Multimodal
Adversarial Attack (Co-Attack), which collectively carries out the attacks on
the image modality and the text modality. Experimental results demonstrated
that the proposed method achieves improved attack performances on different V+L
downstream tasks and VLP models. The analysis observations and novel attack
method hopefully provide new understanding into the adversarial robustness of
VLP models, so as to contribute their safe and reliable deployment in more
real-world scenarios.

### Title: 0/1 Deep Neural Networks via Block Coordinate Descent
* Paper ID: 2206.09379v1
* Paper URL: [http://arxiv.org/abs/2206.09379v1](http://arxiv.org/abs/2206.09379v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: The step function is one of the simplest and most natural activation
functions for deep neural networks (DNNs). As it counts 1 for positive
variables and 0 for others, its intrinsic characteristics (e.g., discontinuity
and no viable information of subgradients) impede its development for several
decades. Even if there is an impressive body of work on designing DNNs with
continuous activation functions that can be deemed as surrogates of the step
function, it is still in the possession of some advantageous properties, such
as complete robustness to outliers and being capable of attaining the best
learning-theoretic guarantee of predictive accuracy. Hence, in this paper, we
aim to train DNNs with the step function used as an activation function (dubbed
as 0/1 DNNs). We first reformulate 0/1 DNNs as an unconstrained optimization
problem and then solve it by a block coordinate descend (BCD) method. Moreover,
we acquire closed-form solutions for sub-problems of BCD as well as its
convergence properties. Furthermore, we also integrate
$\ell_{2,0}$-regularization into 0/1 DNN to accelerate the training process and
compress the network scale. As a result, the proposed algorithm has a high
performance on classifying MNIST and Fashion-MNIST datasets.

### Title: Gray Learning from Non-IID Data with Out-of-distribution Samples
* Paper ID: 2206.09375v1
* Paper URL: [http://arxiv.org/abs/2206.09375v1](http://arxiv.org/abs/2206.09375v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: The quality of the training data annotated by experts cannot be guaranteed,
even more so for non-IID data consisting of both in- and out-of-distribution
samples (i.e., in-distribution and out-of-distribution samples hold different
distributions). Experts may mistakenly annotate out-of-distribution samples the
same as in-distribution samples, incurring untrustworthy ground-truth labels.
Learning such non-IID data mixing in- and out-of-distribution samples with
untrustworthy labels significantly challenges both shallow and deep learning,
with no relevant work reported. It would be possible to identify trustworthy
complementary labels of a sample indicating which classes it does not belong
to, because both in- and out-of-distribution samples do not belong to the
classes except those corresponding to the ground-truth label. With this
insight, we propose a novel \textit{gray learning} approach to robustly learn
from non-IID data with both in- and out-of-distribution samples. Due to the
uncertain distributions of training samples, we reject the complementary labels
for low-confidence inputs while mapping high-confidence inputs to the
ground-truth labels in training. Building on the statistical learning theory,
we derive the generalization error which shows that gray learning achieves a
tight bound on the non-IID data. Extensive experiments show that our method
provides significant improvement over alternative methods from robust
statistics.

### Title: A robust and conservative dynamical low-rank algorithm
* Paper ID: 2206.09374v1
* Paper URL: [http://arxiv.org/abs/2206.09374v1](http://arxiv.org/abs/2206.09374v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Dynamical low-rank approximation, as has been demonstrated recently, can be
extremely efficient in solving kinetic equations. However, a major deficiency
is that they do not preserve the structure of the underlying physical problem.
For example, the classic dynamical low-rank methods violate mass, momentum, and
energy conservation. In [L. Einkemmer, I. Joseph, J. Comput. Phys. 443:110495,
2021] a conservative dynamical low-rank approach has been proposed. However,
directly integrating the resulting equations of motion, similar to the classic
dynamical low-rank approach, results in an ill-posed scheme. In this work we
propose a robust, i.e.~well-posed, integrator for the conservative dynamical
low-rank approach that conserves mass and momentum (up to machine precision)
and significantly improves energy conservation. We also report improved
qualitative results for some problems and show how the approach can be combined
with a rank adaptive scheme.

### Title: Frank-Wolfe-based Algorithms for Approximating Tyler's M-estimator
* Paper ID: 2206.09370v1
* Paper URL: [http://arxiv.org/abs/2206.09370v1](http://arxiv.org/abs/2206.09370v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Tyler's M-estimator is a well known procedure for robust and heavy-tailed
covariance estimation. Tyler himself suggested an iterative fixed-point
algorithm for computing his estimator however, it requires super-linear (in the
size of the data) runtime per iteration, which may be prohibitive in large
scale. In this work we propose, to the best of our knowledge, the first
Frank-Wolfe-based algorithms for computing Tyler's estimator. One variant uses
standard Frank-Wolfe steps, the second also considers \textit{away-steps}
(AFW), and the third is a \textit{geodesic} version of AFW (GAFW). AFW provably
requires, up to a log factor, only linear time per iteration, while GAFW runs
in linear time (up to a log factor) in a large $n$ (number of data-points)
regime. All three variants are shown to provably converge to the optimal
solution with sublinear rate, under standard assumptions, despite the fact that
the underlying optimization problem is not convex nor smooth. Under an
additional fairly mild assumption, that holds with probability 1 when the
(normalized) data-points are i.i.d. samples from a continuous distribution
supported on the entire unit sphere, AFW and GAFW are proved to converge with
linear rates. Importantly, all three variants are parameter-free and use
adaptive step-sizes.

### Title: Quantifying Uncertainty In Traffic State Estimation Using Generative Adversarial Networks
* Paper ID: 2206.09349v1
* Paper URL: [http://arxiv.org/abs/2206.09349v1](http://arxiv.org/abs/2206.09349v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: This paper aims to quantify uncertainty in traffic state estimation (TSE)
using the generative adversarial network based physics-informed deep learning
(PIDL). The uncertainty of the focus arises from fundamental diagrams, in other
words, the mapping from traffic density to velocity. To quantify uncertainty
for the TSE problem is to characterize the robustness of predicted traffic
states. Since its inception, generative adversarial networks (GAN) have become
a popular probabilistic machine learning framework. In this paper, we will
inform the GAN based predictions using stochastic traffic flow models and
develop a GAN based PIDL framework for TSE, named ``PhysGAN-TSE". By conducting
experiments on a real-world dataset, the Next Generation SIMulation (NGSIM)
dataset, this method is shown to be more robust for uncertainty quantification
than the pure GAN model or pure traffic flow models. Two physics models, the
Lighthill-Whitham-Richards (LWR) and the Aw-Rascle-Zhang (ARZ) models, are
compared as the physics components for the PhysGAN, and results show that the
ARZ-based PhysGAN achieves a better performance than the LWR-based one.

### Title: LogGENE: A smooth alternative to check loss for Deep Healthcare Inference Tasks
* Paper ID: 2206.09333v1
* Paper URL: [http://arxiv.org/abs/2206.09333v1](http://arxiv.org/abs/2206.09333v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: High-throughput Genomics is ushering a new era in personalized health care,
and targeted drug design and delivery. Mining these large datasets, and
obtaining calibrated predictions is of immediate relevance and utility. In our
work, we develop methods for Gene Expression Inference based on Deep neural
networks. However, unlike typical Deep learning methods, our inferential
technique, while achieving state-of-the-art performance in terms of accuracy,
can also provide explanations, and report uncertainty estimates. We adopt the
Quantile Regression framework to predict full conditional quantiles for a given
set of house keeping gene expressions. Conditional quantiles, in addition to
being useful in providing rich interpretations of the predictions, are also
robust to measurement noise. However, check loss, used in quantile regression
to drive the estimation process is not differentiable. We propose log-cosh as a
smooth-alternative to the check loss. We apply our methods on GEO microarray
dataset. We also extend the method to binary classification setting.
Furthermore, we investigate other consequences of the smoothness of the loss in
faster convergence.

### Title: Toward Agile and Robust Supply Chains: A Lesson from Stochastic Job-Shop Scheduling
* Paper ID: 2206.09326v1
* Paper URL: [http://arxiv.org/abs/2206.09326v1](http://arxiv.org/abs/2206.09326v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Motivated by the presence of uncertainties as well as combinatorial
complexity within the links of supply chains, this paper addresses the
outstanding and timely challenge illustrated through a case study of stochastic
job-shop scheduling problems arising within low-volume high-variety
manufacturing. These problems have been classically formulated as integer
linear programs (ILPs), which are known to be NP-hard, and are computationally
intractable. Yet, optimal or near-optimal solutions must be obtained within
strict computational time requirements. While the deterministic cases have been
efficiently solved by state-of-the-art methods such as branch-and-cut (B&C),
uncertainties may compromise the entire schedule thereby potentially affecting
the entire supply chain downstream, thus, uncertainties must be explicitly
captured to ensure the feasibility of operations. The stochastic nature of the
resulting problem adds a layer of computational difficulty on top of an already
intractable problem, as evidenced by the presented case studies with some cases
taking hours without being able to find a "near-optimal" schedule. To
efficiently solve the stochastic JSS problem, a recent Surrogate "Level-Based"
Lagrangian Relaxation is used to reduce computational effort while efficiently
exploiting geometric convergence potential inherent to Polyak's step-sizing
formula thereby leading to fast convergence. Computational results demonstrate
that the new method is more than two orders of magnitude faster compared to
B&C. Moreover, insights based on a small intuitive example are provided through
simulations demonstrating an advantage of scholastic scheduling.

### Title: TrafficFlowGAN: Physics-informed Flow based Generative Adversarial Network for Uncertainty Quantification
* Paper ID: 2206.09319v1
* Paper URL: [http://arxiv.org/abs/2206.09319v1](http://arxiv.org/abs/2206.09319v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: This paper proposes the TrafficFlowGAN, a physics-informed flow based
generative adversarial network (GAN), for uncertainty quantification (UQ) of
dynamical systems. TrafficFlowGAN adopts a normalizing flow model as the
generator to explicitly estimate the data likelihood. This flow model is
trained to maximize the data likelihood and to generate synthetic data that can
fool a convolutional discriminator. We further regularize this training process
using prior physics information, so-called physics-informed deep learning
(PIDL). To the best of our knowledge, we are the first to propose an
integration of flow, GAN and PIDL for the UQ problems. We take the traffic
state estimation (TSE), which aims to estimate the traffic variables (e.g.
traffic density and velocity) using partially observed data, as an example to
demonstrate the performance of our proposed model. We conduct numerical
experiments where the proposed model is applied to learn the solutions of
stochastic differential equations. The results demonstrate the robustness and
accuracy of the proposed model, together with the ability to learn a machine
learning surrogate model. We also test it on a real-world dataset, the Next
Generation SIMulation (NGSIM), to show that the proposed TrafficFlowGAN can
outperform the baselines, including the pure flow model, the physics-informed
flow model, and the flow based GAN model.

### Title: Robust Imitation Learning against Variations in Environment Dynamics
* Paper ID: 2206.09314v1
* Paper URL: [http://arxiv.org/abs/2206.09314v1](http://arxiv.org/abs/2206.09314v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: In this paper, we propose a robust imitation learning (IL) framework that
improves the robustness of IL when environment dynamics are perturbed. The
existing IL framework trained in a single environment can catastrophically fail
with perturbations in environment dynamics because it does not capture the
situation that underlying environment dynamics can be changed. Our framework
effectively deals with environments with varying dynamics by imitating multiple
experts in sampled environment dynamics to enhance the robustness in general
variations in environment dynamics. In order to robustly imitate the multiple
sample experts, we minimize the risk with respect to the Jensen-Shannon
divergence between the agent's policy and each of the sample experts. Numerical
results show that our algorithm significantly improves robustness against
dynamics perturbations compared to conventional IL baselines.

### Title: TBraTS: Trusted Brain Tumor Segmentation
* Paper ID: 2206.09309v1
* Paper URL: [http://arxiv.org/abs/2206.09309v1](http://arxiv.org/abs/2206.09309v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Despite recent improvements in the accuracy of brain tumor segmentation, the
results still exhibit low levels of confidence and robustness. Uncertainty
estimation is one effective way to change this situation, as it provides a
measure of confidence in the segmentation results. In this paper, we propose a
trusted brain tumor segmentation network which can generate robust segmentation
results and reliable uncertainty estimations without excessive computational
burden and modification of the backbone network. In our method, uncertainty is
modeled explicitly using subjective logic theory, which treats the predictions
of backbone neural network as subjective opinions by parameterizing the class
probabilities of the segmentation as a Dirichlet distribution. Meanwhile, the
trusted segmentation framework learns the function that gathers reliable
evidence from the feature leading to the final segmentation results. Overall,
our unified trusted segmentation framework endows the model with reliability
and robustness to out-of-distribution samples. To evaluate the effectiveness of
our model in robustness and reliability, qualitative and quantitative
experiments are conducted on the BraTS 2019 dataset.

### Title: Robust ab initio prediction of nuclear electric quadrupole observables by scaling to the charge radius
* Paper ID: 2206.09307v1
* Paper URL: [http://arxiv.org/abs/2206.09307v1](http://arxiv.org/abs/2206.09307v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Meaningful predictions for electric quadrupole (E2) observables from ab
initio nuclear theory are necessary, if the ab initio description of collective
correlations is to be confronted with experiment, as well as to provide
predictive power for unknown E2 observables. However, converged results for E2
observables are notoriously challenging to obtain in ab initio no-core
configuration interaction (NCCI) approaches. Matrix elements of the E2 operator
are sensitive to the large-distance tails of the nuclear wave function, which
converge slowly in an oscillator basis expansion. Similar convergence
challenges beset ab initio prediction of the nuclear charge radius. We
demonstrate that the convergence patterns of the E2 and radius observables are
strongly correlated, and that meaningful predictions for the absolute scale of
E2 observables may be made by calibrating to the experimentally-known
ground-state charge radius. We illustrate by providing robust ab initio
predictions for several E2 transition strengths and quadrupole moments in
p-shell nuclei, in cases where experimental results are available for
comparison.

### Title: Adversarial Scrutiny of Evidentiary Statistical Software
* Paper ID: 2206.09305v1
* Paper URL: [http://arxiv.org/abs/2206.09305v1](http://arxiv.org/abs/2206.09305v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: The U.S. criminal legal system increasingly relies on software output to
convict and incarcerate people. In a large number of cases each year, the
government makes these consequential decisions based on evidence from
statistical software -- such as probabilistic genotyping, environmental audio
detection, and toolmark analysis tools -- that defense counsel cannot fully
cross-examine or scrutinize. This undermines the commitments of the adversarial
criminal legal system, which relies on the defense's ability to probe and test
the prosecution's case to safeguard individual rights.
  Responding to this need to adversarially scrutinize output from such
software, we propose robust adversarial testing as an audit framework to
examine the validity of evidentiary statistical software. We define and
operationalize this notion of robust adversarial testing for defense use by
drawing on a large body of recent work in robust machine learning and
algorithmic fairness. We demonstrate how this framework both standardizes the
process for scrutinizing such tools and empowers defense lawyers to examine
their validity for instances most relevant to the case at hand. We further
discuss existing structural and institutional challenges within the U.S.
criminal legal system that may create barriers for implementing this and other
such audit frameworks and close with a discussion on policy changes that could
help address these concerns.

