### Title: Stochastic Optimization Approaches for an Operating Room and Anesthesiologist Scheduling Problem
* Paper ID: 2204.11374v1
* Paper URL: [http://arxiv.org/abs/2204.11374v1](http://arxiv.org/abs/2204.11374v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: We propose combined allocation, assignment, sequencing, and scheduling
problems under uncertainty involving multiple operation rooms (ORs),
anesthesiologists, and surgeries, as well as methodologies for solving such
problems. Specifically, given sets of ORs, regular anesthesiologists, on-call
anesthesiologists, and surgeries, our methodologies solve the following
decision-making problems simultaneously: (1) an allocation problem that decides
which ORs to open and which on-call anesthesiologists to call in, (2) an
assignment problem that assigns an OR and an anesthesiologist to each surgery,
and (3) a sequencing and scheduling problem that determines the order of
surgeries and their scheduled start times in each OR. To address uncertainty of
each surgery's duration, we propose and analyze stochastic programming (SP) and
distributionally robust optimization (DRO) methodologies. We obtain
near-optimal solutions of our SP model using sample average approximation and
propose a computationally efficient column-and-constraint generation method to
solve our DRO model. In addition, we derive symmetry-breaking constraints that
improve the models' solvability. Using real-world, publicly available surgery
data and a case study from a health system in New York, we conduct extensive
computational experiments comparing the proposed methodologies empirically and
theoretically, demonstrating where significant performance improvements can be
gained. Additionally, we derive several managerial insights relevant to
practice.

### Title: Entity-Conditioned Question Generation for Robust Attention Distribution in Neural Information Retrieval
* Paper ID: 2204.11373v1
* Paper URL: [http://arxiv.org/abs/2204.11373v1](http://arxiv.org/abs/2204.11373v1)
* Updated Date: 2022-04-24
* Code URL: [https://github.com/blender-nlp/entityconditionedqgen](https://github.com/blender-nlp/entityconditionedqgen)
* Summary: We show that supervised neural information retrieval (IR) models are prone to
learning sparse attention patterns over passage tokens, which can result in key
phrases including named entities receiving low attention weights, eventually
leading to model under-performance. Using a novel targeted synthetic data
generation method that identifies poorly attended entities and conditions the
generation episodes on those, we teach neural IR to attend more uniformly and
robustly to all entities in a given passage. On two public IR benchmarks, we
empirically show that the proposed method helps improve both the model's
attention patterns and retrieval performance, including in zero-shot settings.

### Title: Noise-resilient Majorana Edge Modes on a Chain of Superconducting Qubits
* Paper ID: 2204.11372v1
* Paper URL: [http://arxiv.org/abs/2204.11372v1](http://arxiv.org/abs/2204.11372v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: Inherent symmetry of a quantum system may protect its otherwise fragile
states. Leveraging such protection requires testing its robustness against
uncontrolled environmental interactions. Using 47 superconducting qubits, we
implement the kicked Ising model which exhibits Majorana edge modes (MEMs)
protected by $\mathbb{Z}_2$ parity symmetry. Remarkably, we find that any
multi-qubit Pauli operator overlapping with the MEMs exhibits a uniform decay
rate comparable to single-qubit relaxation rates, irrespective of its size or
composition. This finding allows us to accurately reconstruct the exponentially
localized spatial profiles of the MEMs. Spectroscopic measurements further
indicate exponentially suppressed hybridization between the MEMs at larger
system sizes, which manifests as a strong resilience against low-frequency
noise. Our work elucidates the noise sensitivity of symmetry-protected edge
modes in a solid-state environment.

### Title: Improving Deep Learning Model Robustness Against Adversarial Attack by Increasing the Network Capacity
* Paper ID: 2204.11357v1
* Paper URL: [http://arxiv.org/abs/2204.11357v1](http://arxiv.org/abs/2204.11357v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: Nowadays, we are more and more reliant on Deep Learning (DL) models and thus
it is essential to safeguard the security of these systems. This paper explores
the security issues in Deep Learning and analyses, through the use of
experiments, the way forward to build more resilient models. Experiments are
conducted to identify the strengths and weaknesses of a new approach to improve
the robustness of DL models against adversarial attacks. The results show
improvements and new ideas that can be used as recommendations for researchers
and practitioners to create increasingly better DL algorithms.

### Title: Extraordinary Disordered Hyperuniform Multifunctional Composites
* Paper ID: 2204.11345v1
* Paper URL: [http://arxiv.org/abs/2204.11345v1](http://arxiv.org/abs/2204.11345v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: A variety of performance demands are being placed on material systems,
including desirable mechanical, thermal, electrical, optical, acoustic and flow
properties. The purpose of the present article is to review the emerging field
of disordered hyperuniform composites and their novel multifunctional
characteristics. Disordered hyperuniform media are exotic amorphous states of
matter that are characterized by an anomalous suppression of large-scale
volume-fraction fluctuations compared to those in "garden-variety" disordered
materials. Such unusual composites can have advantages over their periodic
counterparts, such as unique or nearly optimal, direction-independent physical
properties and robustness against defects. It will be shown that disordered
hyperuniform composites and porous media can be endowed with a broad spectrum
of extraordinary physical properties, including photonic, phononic, transport,
chemical and mechanical characteristics that are only beginning to be discov

### Title: Simulating Fluids in Real-World Still Images
* Paper ID: 2204.11335v1
* Paper URL: [http://arxiv.org/abs/2204.11335v1](http://arxiv.org/abs/2204.11335v1)
* Updated Date: 2022-04-24
* Code URL: [https://github.com/simon3dv/slr-sfs](https://github.com/simon3dv/slr-sfs)
* Summary: In this work, we tackle the problem of real-world fluid animation from a
still image. The key of our system is a surface-based layered representation
deriving from video decomposition, where the scene is decoupled into a surface
fluid layer and an impervious background layer with corresponding
transparencies to characterize the composition of the two layers. The animated
video can be produced by warping only the surface fluid layer according to the
estimation of fluid motions and recombining it with the background. In
addition, we introduce surface-only fluid simulation, a $2.5D$ fluid
calculation version, as a replacement for motion estimation. Specifically, we
leverage the triangular mesh based on a monocular depth estimator to represent
the fluid surface layer and simulate the motion in the physics-based framework
with the inspiration of the classic theory of the hybrid Lagrangian-Eulerian
method, along with a learnable network so as to adapt to complex real-world
image textures. We demonstrate the effectiveness of the proposed system through
comparison with existing methods in both standard objective metrics and
subjective ranking scores. Extensive experiments not only indicate our method's
competitive performance for common fluid scenes but also better robustness and
reasonability under complex transparent fluid scenarios. Moreover, as the
proposed surface-based layer representation and surface-only fluid simulation
naturally disentangle the scene, interactive editing such as adding objects to
the river and texture replacing could be easily achieved with realistic
results.

### Title: A Generic Approach to Quantitative Verification
* Paper ID: 2204.11302v1
* Paper URL: [http://arxiv.org/abs/2204.11302v1](http://arxiv.org/abs/2204.11302v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: This thesis is concerned with quantitative verification, that is, the
verification of quantitative properties of quantitative systems. These systems
are found in numerous applications, and their quantitative verification is
important, but also rather challenging. In particular, given that most systems
found in applications are rather big, compositionality and incrementality of
verification methods are essential.
  In order to ensure robustness of verification, we replace the Boolean yes-no
answers of standard verification with distances. Depending on the application
context, many different types of distances are being employed in quantitative
verification. Consequently, there is a need for a general theory of system
distances which abstracts away from the concrete distances and develops
quantitative verification at a level independent of the distance. It is our
view that in a theory of quantitative verification, the quantitative aspects
should be treated just as much as input to a verification problem as the
qualitative aspects are. In this work we develop such a general theory of
quantitative verification. We assume as input a distance between traces, or
executions, and then employ the theory of games with quantitative objectives to
define distances between quantitative systems. Different versions of the
quantitative bisimulation game give rise to different types of distances,
viz.~bisimulation distance, simulation distance, trace equivalence distance,
etc., enabling us to construct a quantitative generalization of van Glabbeek's
linear-time--branching-time spectrum. We also extend our general theory of
quantitative verification to a theory of quantitative specifications. For this
we use modal transition systems, and we develop the quantitative properties of
the usual operators for behavioral specification theories.

### Title: Large Scale Time-Series Representation Learning via Simultaneous Low and High Frequency Feature Bootstrapping
* Paper ID: 2204.11291v1
* Paper URL: [http://arxiv.org/abs/2204.11291v1](http://arxiv.org/abs/2204.11291v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: Learning representation from unlabeled time series data is a challenging
problem. Most existing self-supervised and unsupervised approaches in the
time-series domain do not capture low and high-frequency features at the same
time. Further, some of these methods employ large scale models like
transformers or rely on computationally expensive techniques such as
contrastive learning. To tackle these problems, we propose a non-contrastive
self-supervised learning approach efficiently captures low and high-frequency
time-varying features in a cost-effective manner. Our method takes raw time
series data as input and creates two different augmented views for two branches
of the model, by randomly sampling the augmentations from same family.
Following the terminology of BYOL, the two branches are called online and
target network which allows bootstrapping of the latent representation. In
contrast to BYOL, where a backbone encoder is followed by multilayer perceptron
(MLP) heads, the proposed model contains additional temporal convolutional
network (TCN) heads. As the augmented views are passed through large kernel
convolution blocks of the encoder, the subsequent combination of MLP and TCN
enables an effective representation of low as well as high-frequency
time-varying features due to the varying receptive fields. The two modules (MLP
and TCN) act in a complementary manner. We train an online network where each
module learns to predict the outcome of the respective module of target network
branch. To demonstrate the robustness of our model we performed extensive
experiments and ablation studies on five real-world time-series datasets. Our
method achieved state-of-art performance on all five real-world datasets.

### Title: Source-Free Domain Adaptation via Distribution Estimation
* Paper ID: 2204.11257v1
* Paper URL: [http://arxiv.org/abs/2204.11257v1](http://arxiv.org/abs/2204.11257v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: Domain Adaptation aims to transfer the knowledge learned from a labeled
source domain to an unlabeled target domain whose data distributions are
different. However, the training data in source domain required by most of the
existing methods is usually unavailable in real-world applications due to
privacy preserving policies. Recently, Source-Free Domain Adaptation (SFDA) has
drawn much attention, which tries to tackle domain adaptation problem without
using source data. In this work, we propose a novel framework called SFDA-DE to
address SFDA task via source Distribution Estimation. Firstly, we produce
robust pseudo-labels for target data with spherical k-means clustering, whose
initial class centers are the weight vectors (anchors) learned by the
classifier of pretrained model. Furthermore, we propose to estimate the
class-conditioned feature distribution of source domain by exploiting target
data and corresponding anchors. Finally, we sample surrogate features from the
estimated distribution, which are then utilized to align two domains by
minimizing a contrastive adaptation loss function. Extensive experiments show
that the proposed method achieves state-of-the-art performance on multiple DA
benchmarks, and even outperforms traditional DA methods which require plenty of
source data.

### Title: RealNet: Combining Optimized Object Detection with Information Fusion Depth Estimation Co-Design Method on IoT
* Paper ID: 2204.11216v1
* Paper URL: [http://arxiv.org/abs/2204.11216v1](http://arxiv.org/abs/2204.11216v1)
* Updated Date: 2022-04-24
* Code URL: [https://github.com/edithlzh/VNL_Estimation](https://github.com/edithlzh/VNL_Estimation)
* Summary: Depth Estimation and Object Detection Recognition play an important role in
autonomous driving technology under the guidance of deep learning artificial
intelligence. We propose a hybrid structure called RealNet: a co-design method
combining the model-streamlined recognition algorithm, the depth estimation
algorithm with information fusion, and deploying them on the Jetson-Nano for
unmanned vehicles with monocular vision sensors. We use ROS for experiment. The
method proposed in this paper is suitable for mobile platforms with high
real-time request. Innovation of our method is using information fusion to
compensate the problem of insufficient frame rate of output image, and improve
the robustness of target detection and depth estimation under monocular
vision.Object Detection is based on YOLO-v5. We have simplified the network
structure of its DarkNet53 and realized a prediction speed up to 0.01s. Depth
Estimation is based on the VNL Depth Estimation, which considers multiple
geometric constraints in 3D global space. It calculates the loss function by
calculating the deviation of the virtual normal vector VN and the label, which
can obtain deeper depth information. We use PnP fusion algorithm to solve the
problem of insufficient frame rate of depth map output. It solves the motion
estimation depth from three-dimensional target to two-dimensional point based
on corner feature matching, which is faster than VNL calculation. We
interpolate VNL output and PnP output to achieve information fusion.
Experiments show that this can effectively eliminate the jitter of depth
information and improve robustness. At the control end, this method combines
the results of target detection and depth estimation to calculate the target
position, and uses a pure tracking control algorithm to track it.

### Title: PUERT: Probabilistic Under-sampling and Explicable Reconstruction Network for CS-MRI
* Paper ID: 2204.11189v1
* Paper URL: [http://arxiv.org/abs/2204.11189v1](http://arxiv.org/abs/2204.11189v1)
* Updated Date: 2022-04-24
* Code URL: [https://github.com/chuan1093/puert](https://github.com/chuan1093/puert)
* Summary: Compressed Sensing MRI (CS-MRI) aims at reconstructing de-aliased images from
sub-Nyquist sampling k-space data to accelerate MR Imaging, thus presenting two
basic issues, i.e., where to sample and how to reconstruct. To deal with both
problems simultaneously, we propose a novel end-to-end Probabilistic
Under-sampling and Explicable Reconstruction neTwork, dubbed PUERT, to jointly
optimize the sampling pattern and the reconstruction network. Instead of
learning a deterministic mask, the proposed sampling subnet explores an optimal
probabilistic sub-sampling pattern, which describes independent Bernoulli
random variables at each possible sampling point, thus retaining robustness and
stochastics for a more reliable CS reconstruction. A dynamic gradient
estimation strategy is further introduced to gradually approximate the
binarization function in backward propagation, which efficiently preserves the
gradient information and further improves the reconstruction quality. Moreover,
in our reconstruction subnet, we adopt a model-based network design scheme with
high efficiency and interpretability, which is shown to assist in further
exploitation for the sampling subnet. Extensive experiments on two widely used
MRI datasets demonstrate that our proposed PUERT not only achieves
state-of-the-art results in terms of both quantitative metrics and visual
quality but also yields a sub-sampling pattern and a reconstruction model that
are both customized to training data.

### Title: Generalized Lagrange Coded Computing: A Flexible Computation-Communication Tradeoff
* Paper ID: 2204.11168v1
* Paper URL: [http://arxiv.org/abs/2204.11168v1](http://arxiv.org/abs/2204.11168v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: We consider the problem of evaluating arbitrary multivariate polynomials over
a massive dataset, in a distributed computing system with a master node and
multiple worker nodes. Generalized Lagrange Coded Computing (GLCC) codes are
proposed to provide robustness against stragglers who do not return computation
results in time, adversarial workers who deliberately modify results for their
benefit, and information-theoretic security of the dataset amidst possible
collusion of workers. GLCC codes are constructed by first partitioning the
dataset into multiple groups, and then encoding the dataset using carefully
designed interpolation polynomials, such that interference computation results
across groups can be eliminated at the master. Particularly, GLCC codes include
the state-of-the-art Lagrange Coded Computing (LCC) codes as a special case,
and achieve a more flexible tradeoff between communication and computation
overheads in optimizing system efficiency.

### Title: RelViT: Concept-guided Vision Transformer for Visual Relational Reasoning
* Paper ID: 2204.11167v1
* Paper URL: [http://arxiv.org/abs/2204.11167v1](http://arxiv.org/abs/2204.11167v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: Reasoning about visual relationships is central to how humans interpret the
visual world. This task remains challenging for current deep learning
algorithms since it requires addressing three key technical problems jointly:
1) identifying object entities and their properties, 2) inferring semantic
relations between pairs of entities, and 3) generalizing to novel
object-relation combinations, i.e., systematic generalization. In this work, we
use vision transformers (ViTs) as our base model for visual reasoning and make
better use of concepts defined as object entities and their relations to
improve the reasoning ability of ViTs. Specifically, we introduce a novel
concept-feature dictionary to allow flexible image feature retrieval at
training time with concept keys. This dictionary enables two new concept-guided
auxiliary tasks: 1) a global task for promoting relational reasoning, and 2) a
local task for facilitating semantic object-centric correspondence learning. To
examine the systematic generalization of visual reasoning models, we introduce
systematic splits for the standard HICO and GQA benchmarks. We show the
resulting model, Concept-guided Vision Transformer (or RelViT for short)
significantly outperforms prior approaches on HICO and GQA by 16% and 13% in
the original split, and by 43% and 18% in the systematic split. Our ablation
analyses also reveal our model's compatibility with multiple ViT variants and
robustness to hyper-parameters.

### Title: Stochastic Optimization Approaches for an Operating Room and Anesthesiologist Scheduling Problem
* Paper ID: 2204.11374v1
* Paper URL: [http://arxiv.org/abs/2204.11374v1](http://arxiv.org/abs/2204.11374v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: We propose combined allocation, assignment, sequencing, and scheduling
problems under uncertainty involving multiple operation rooms (ORs),
anesthesiologists, and surgeries, as well as methodologies for solving such
problems. Specifically, given sets of ORs, regular anesthesiologists, on-call
anesthesiologists, and surgeries, our methodologies solve the following
decision-making problems simultaneously: (1) an allocation problem that decides
which ORs to open and which on-call anesthesiologists to call in, (2) an
assignment problem that assigns an OR and an anesthesiologist to each surgery,
and (3) a sequencing and scheduling problem that determines the order of
surgeries and their scheduled start times in each OR. To address uncertainty of
each surgery's duration, we propose and analyze stochastic programming (SP) and
distributionally robust optimization (DRO) methodologies. We obtain
near-optimal solutions of our SP model using sample average approximation and
propose a computationally efficient column-and-constraint generation method to
solve our DRO model. In addition, we derive symmetry-breaking constraints that
improve the models' solvability. Using real-world, publicly available surgery
data and a case study from a health system in New York, we conduct extensive
computational experiments comparing the proposed methodologies empirically and
theoretically, demonstrating where significant performance improvements can be
gained. Additionally, we derive several managerial insights relevant to
practice.

### Title: Entity-Conditioned Question Generation for Robust Attention Distribution in Neural Information Retrieval
* Paper ID: 2204.11373v1
* Paper URL: [http://arxiv.org/abs/2204.11373v1](http://arxiv.org/abs/2204.11373v1)
* Updated Date: 2022-04-24
* Code URL: [https://github.com/blender-nlp/entityconditionedqgen](https://github.com/blender-nlp/entityconditionedqgen)
* Summary: We show that supervised neural information retrieval (IR) models are prone to
learning sparse attention patterns over passage tokens, which can result in key
phrases including named entities receiving low attention weights, eventually
leading to model under-performance. Using a novel targeted synthetic data
generation method that identifies poorly attended entities and conditions the
generation episodes on those, we teach neural IR to attend more uniformly and
robustly to all entities in a given passage. On two public IR benchmarks, we
empirically show that the proposed method helps improve both the model's
attention patterns and retrieval performance, including in zero-shot settings.

### Title: Noise-resilient Majorana Edge Modes on a Chain of Superconducting Qubits
* Paper ID: 2204.11372v1
* Paper URL: [http://arxiv.org/abs/2204.11372v1](http://arxiv.org/abs/2204.11372v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: Inherent symmetry of a quantum system may protect its otherwise fragile
states. Leveraging such protection requires testing its robustness against
uncontrolled environmental interactions. Using 47 superconducting qubits, we
implement the kicked Ising model which exhibits Majorana edge modes (MEMs)
protected by $\mathbb{Z}_2$ parity symmetry. Remarkably, we find that any
multi-qubit Pauli operator overlapping with the MEMs exhibits a uniform decay
rate comparable to single-qubit relaxation rates, irrespective of its size or
composition. This finding allows us to accurately reconstruct the exponentially
localized spatial profiles of the MEMs. Spectroscopic measurements further
indicate exponentially suppressed hybridization between the MEMs at larger
system sizes, which manifests as a strong resilience against low-frequency
noise. Our work elucidates the noise sensitivity of symmetry-protected edge
modes in a solid-state environment.

### Title: Improving Deep Learning Model Robustness Against Adversarial Attack by Increasing the Network Capacity
* Paper ID: 2204.11357v1
* Paper URL: [http://arxiv.org/abs/2204.11357v1](http://arxiv.org/abs/2204.11357v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: Nowadays, we are more and more reliant on Deep Learning (DL) models and thus
it is essential to safeguard the security of these systems. This paper explores
the security issues in Deep Learning and analyses, through the use of
experiments, the way forward to build more resilient models. Experiments are
conducted to identify the strengths and weaknesses of a new approach to improve
the robustness of DL models against adversarial attacks. The results show
improvements and new ideas that can be used as recommendations for researchers
and practitioners to create increasingly better DL algorithms.

### Title: Extraordinary Disordered Hyperuniform Multifunctional Composites
* Paper ID: 2204.11345v1
* Paper URL: [http://arxiv.org/abs/2204.11345v1](http://arxiv.org/abs/2204.11345v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: A variety of performance demands are being placed on material systems,
including desirable mechanical, thermal, electrical, optical, acoustic and flow
properties. The purpose of the present article is to review the emerging field
of disordered hyperuniform composites and their novel multifunctional
characteristics. Disordered hyperuniform media are exotic amorphous states of
matter that are characterized by an anomalous suppression of large-scale
volume-fraction fluctuations compared to those in "garden-variety" disordered
materials. Such unusual composites can have advantages over their periodic
counterparts, such as unique or nearly optimal, direction-independent physical
properties and robustness against defects. It will be shown that disordered
hyperuniform composites and porous media can be endowed with a broad spectrum
of extraordinary physical properties, including photonic, phononic, transport,
chemical and mechanical characteristics that are only beginning to be discov

### Title: Simulating Fluids in Real-World Still Images
* Paper ID: 2204.11335v1
* Paper URL: [http://arxiv.org/abs/2204.11335v1](http://arxiv.org/abs/2204.11335v1)
* Updated Date: 2022-04-24
* Code URL: [https://github.com/simon3dv/slr-sfs](https://github.com/simon3dv/slr-sfs)
* Summary: In this work, we tackle the problem of real-world fluid animation from a
still image. The key of our system is a surface-based layered representation
deriving from video decomposition, where the scene is decoupled into a surface
fluid layer and an impervious background layer with corresponding
transparencies to characterize the composition of the two layers. The animated
video can be produced by warping only the surface fluid layer according to the
estimation of fluid motions and recombining it with the background. In
addition, we introduce surface-only fluid simulation, a $2.5D$ fluid
calculation version, as a replacement for motion estimation. Specifically, we
leverage the triangular mesh based on a monocular depth estimator to represent
the fluid surface layer and simulate the motion in the physics-based framework
with the inspiration of the classic theory of the hybrid Lagrangian-Eulerian
method, along with a learnable network so as to adapt to complex real-world
image textures. We demonstrate the effectiveness of the proposed system through
comparison with existing methods in both standard objective metrics and
subjective ranking scores. Extensive experiments not only indicate our method's
competitive performance for common fluid scenes but also better robustness and
reasonability under complex transparent fluid scenarios. Moreover, as the
proposed surface-based layer representation and surface-only fluid simulation
naturally disentangle the scene, interactive editing such as adding objects to
the river and texture replacing could be easily achieved with realistic
results.

### Title: A Generic Approach to Quantitative Verification
* Paper ID: 2204.11302v1
* Paper URL: [http://arxiv.org/abs/2204.11302v1](http://arxiv.org/abs/2204.11302v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: This thesis is concerned with quantitative verification, that is, the
verification of quantitative properties of quantitative systems. These systems
are found in numerous applications, and their quantitative verification is
important, but also rather challenging. In particular, given that most systems
found in applications are rather big, compositionality and incrementality of
verification methods are essential.
  In order to ensure robustness of verification, we replace the Boolean yes-no
answers of standard verification with distances. Depending on the application
context, many different types of distances are being employed in quantitative
verification. Consequently, there is a need for a general theory of system
distances which abstracts away from the concrete distances and develops
quantitative verification at a level independent of the distance. It is our
view that in a theory of quantitative verification, the quantitative aspects
should be treated just as much as input to a verification problem as the
qualitative aspects are. In this work we develop such a general theory of
quantitative verification. We assume as input a distance between traces, or
executions, and then employ the theory of games with quantitative objectives to
define distances between quantitative systems. Different versions of the
quantitative bisimulation game give rise to different types of distances,
viz.~bisimulation distance, simulation distance, trace equivalence distance,
etc., enabling us to construct a quantitative generalization of van Glabbeek's
linear-time--branching-time spectrum. We also extend our general theory of
quantitative verification to a theory of quantitative specifications. For this
we use modal transition systems, and we develop the quantitative properties of
the usual operators for behavioral specification theories.

### Title: Large Scale Time-Series Representation Learning via Simultaneous Low and High Frequency Feature Bootstrapping
* Paper ID: 2204.11291v1
* Paper URL: [http://arxiv.org/abs/2204.11291v1](http://arxiv.org/abs/2204.11291v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: Learning representation from unlabeled time series data is a challenging
problem. Most existing self-supervised and unsupervised approaches in the
time-series domain do not capture low and high-frequency features at the same
time. Further, some of these methods employ large scale models like
transformers or rely on computationally expensive techniques such as
contrastive learning. To tackle these problems, we propose a non-contrastive
self-supervised learning approach efficiently captures low and high-frequency
time-varying features in a cost-effective manner. Our method takes raw time
series data as input and creates two different augmented views for two branches
of the model, by randomly sampling the augmentations from same family.
Following the terminology of BYOL, the two branches are called online and
target network which allows bootstrapping of the latent representation. In
contrast to BYOL, where a backbone encoder is followed by multilayer perceptron
(MLP) heads, the proposed model contains additional temporal convolutional
network (TCN) heads. As the augmented views are passed through large kernel
convolution blocks of the encoder, the subsequent combination of MLP and TCN
enables an effective representation of low as well as high-frequency
time-varying features due to the varying receptive fields. The two modules (MLP
and TCN) act in a complementary manner. We train an online network where each
module learns to predict the outcome of the respective module of target network
branch. To demonstrate the robustness of our model we performed extensive
experiments and ablation studies on five real-world time-series datasets. Our
method achieved state-of-art performance on all five real-world datasets.

### Title: Source-Free Domain Adaptation via Distribution Estimation
* Paper ID: 2204.11257v1
* Paper URL: [http://arxiv.org/abs/2204.11257v1](http://arxiv.org/abs/2204.11257v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: Domain Adaptation aims to transfer the knowledge learned from a labeled
source domain to an unlabeled target domain whose data distributions are
different. However, the training data in source domain required by most of the
existing methods is usually unavailable in real-world applications due to
privacy preserving policies. Recently, Source-Free Domain Adaptation (SFDA) has
drawn much attention, which tries to tackle domain adaptation problem without
using source data. In this work, we propose a novel framework called SFDA-DE to
address SFDA task via source Distribution Estimation. Firstly, we produce
robust pseudo-labels for target data with spherical k-means clustering, whose
initial class centers are the weight vectors (anchors) learned by the
classifier of pretrained model. Furthermore, we propose to estimate the
class-conditioned feature distribution of source domain by exploiting target
data and corresponding anchors. Finally, we sample surrogate features from the
estimated distribution, which are then utilized to align two domains by
minimizing a contrastive adaptation loss function. Extensive experiments show
that the proposed method achieves state-of-the-art performance on multiple DA
benchmarks, and even outperforms traditional DA methods which require plenty of
source data.

### Title: RealNet: Combining Optimized Object Detection with Information Fusion Depth Estimation Co-Design Method on IoT
* Paper ID: 2204.11216v1
* Paper URL: [http://arxiv.org/abs/2204.11216v1](http://arxiv.org/abs/2204.11216v1)
* Updated Date: 2022-04-24
* Code URL: [https://github.com/edithlzh/VNL_Estimation](https://github.com/edithlzh/VNL_Estimation)
* Summary: Depth Estimation and Object Detection Recognition play an important role in
autonomous driving technology under the guidance of deep learning artificial
intelligence. We propose a hybrid structure called RealNet: a co-design method
combining the model-streamlined recognition algorithm, the depth estimation
algorithm with information fusion, and deploying them on the Jetson-Nano for
unmanned vehicles with monocular vision sensors. We use ROS for experiment. The
method proposed in this paper is suitable for mobile platforms with high
real-time request. Innovation of our method is using information fusion to
compensate the problem of insufficient frame rate of output image, and improve
the robustness of target detection and depth estimation under monocular
vision.Object Detection is based on YOLO-v5. We have simplified the network
structure of its DarkNet53 and realized a prediction speed up to 0.01s. Depth
Estimation is based on the VNL Depth Estimation, which considers multiple
geometric constraints in 3D global space. It calculates the loss function by
calculating the deviation of the virtual normal vector VN and the label, which
can obtain deeper depth information. We use PnP fusion algorithm to solve the
problem of insufficient frame rate of depth map output. It solves the motion
estimation depth from three-dimensional target to two-dimensional point based
on corner feature matching, which is faster than VNL calculation. We
interpolate VNL output and PnP output to achieve information fusion.
Experiments show that this can effectively eliminate the jitter of depth
information and improve robustness. At the control end, this method combines
the results of target detection and depth estimation to calculate the target
position, and uses a pure tracking control algorithm to track it.

### Title: PUERT: Probabilistic Under-sampling and Explicable Reconstruction Network for CS-MRI
* Paper ID: 2204.11189v1
* Paper URL: [http://arxiv.org/abs/2204.11189v1](http://arxiv.org/abs/2204.11189v1)
* Updated Date: 2022-04-24
* Code URL: [https://github.com/chuan1093/puert](https://github.com/chuan1093/puert)
* Summary: Compressed Sensing MRI (CS-MRI) aims at reconstructing de-aliased images from
sub-Nyquist sampling k-space data to accelerate MR Imaging, thus presenting two
basic issues, i.e., where to sample and how to reconstruct. To deal with both
problems simultaneously, we propose a novel end-to-end Probabilistic
Under-sampling and Explicable Reconstruction neTwork, dubbed PUERT, to jointly
optimize the sampling pattern and the reconstruction network. Instead of
learning a deterministic mask, the proposed sampling subnet explores an optimal
probabilistic sub-sampling pattern, which describes independent Bernoulli
random variables at each possible sampling point, thus retaining robustness and
stochastics for a more reliable CS reconstruction. A dynamic gradient
estimation strategy is further introduced to gradually approximate the
binarization function in backward propagation, which efficiently preserves the
gradient information and further improves the reconstruction quality. Moreover,
in our reconstruction subnet, we adopt a model-based network design scheme with
high efficiency and interpretability, which is shown to assist in further
exploitation for the sampling subnet. Extensive experiments on two widely used
MRI datasets demonstrate that our proposed PUERT not only achieves
state-of-the-art results in terms of both quantitative metrics and visual
quality but also yields a sub-sampling pattern and a reconstruction model that
are both customized to training data.

### Title: Generalized Lagrange Coded Computing: A Flexible Computation-Communication Tradeoff
* Paper ID: 2204.11168v1
* Paper URL: [http://arxiv.org/abs/2204.11168v1](http://arxiv.org/abs/2204.11168v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: We consider the problem of evaluating arbitrary multivariate polynomials over
a massive dataset, in a distributed computing system with a master node and
multiple worker nodes. Generalized Lagrange Coded Computing (GLCC) codes are
proposed to provide robustness against stragglers who do not return computation
results in time, adversarial workers who deliberately modify results for their
benefit, and information-theoretic security of the dataset amidst possible
collusion of workers. GLCC codes are constructed by first partitioning the
dataset into multiple groups, and then encoding the dataset using carefully
designed interpolation polynomials, such that interference computation results
across groups can be eliminated at the master. Particularly, GLCC codes include
the state-of-the-art Lagrange Coded Computing (LCC) codes as a special case,
and achieve a more flexible tradeoff between communication and computation
overheads in optimizing system efficiency.

### Title: RelViT: Concept-guided Vision Transformer for Visual Relational Reasoning
* Paper ID: 2204.11167v1
* Paper URL: [http://arxiv.org/abs/2204.11167v1](http://arxiv.org/abs/2204.11167v1)
* Updated Date: 2022-04-24
* Code URL: null
* Summary: Reasoning about visual relationships is central to how humans interpret the
visual world. This task remains challenging for current deep learning
algorithms since it requires addressing three key technical problems jointly:
1) identifying object entities and their properties, 2) inferring semantic
relations between pairs of entities, and 3) generalizing to novel
object-relation combinations, i.e., systematic generalization. In this work, we
use vision transformers (ViTs) as our base model for visual reasoning and make
better use of concepts defined as object entities and their relations to
improve the reasoning ability of ViTs. Specifically, we introduce a novel
concept-feature dictionary to allow flexible image feature retrieval at
training time with concept keys. This dictionary enables two new concept-guided
auxiliary tasks: 1) a global task for promoting relational reasoning, and 2) a
local task for facilitating semantic object-centric correspondence learning. To
examine the systematic generalization of visual reasoning models, we introduce
systematic splits for the standard HICO and GQA benchmarks. We show the
resulting model, Concept-guided Vision Transformer (or RelViT for short)
significantly outperforms prior approaches on HICO and GQA by 16% and 13% in
the original split, and by 43% and 18% in the systematic split. Our ablation
analyses also reveal our model's compatibility with multiple ViT variants and
robustness to hyper-parameters.

