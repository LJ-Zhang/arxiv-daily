### Title: For Learning in Symmetric Teams, Local Optima are Global Nash Equilibria
* Paper ID: 2207.03470v1
* Paper URL: [http://arxiv.org/abs/2207.03470v1](http://arxiv.org/abs/2207.03470v1)
* Updated Date: 2022-07-07
* Categories: ['cs.GT', 'cs.AI', 'cs.LG', 'cs.MA']
* Code URL: [https://github.com/scottemmons/coordination](https://github.com/scottemmons/coordination)
* Summary: Although it has been known since the 1970s that a globally optimal strategy
profile in a common-payoff game is a Nash equilibrium, global optimality is a
strict requirement that limits the result's applicability. In this work, we
show that any locally optimal symmetric strategy profile is also a (global)
Nash equilibrium. Furthermore, we show that this result is robust to
perturbations to the common payoff and to the local optimum. Applied to machine
learning, our result provides a global guarantee for any gradient method that
finds a local optimum in symmetric strategy space. While this result indicates
stability to unilateral deviation, we nevertheless identify broad classes of
games where mixed local optima are unstable under joint, asymmetric deviations.
We analyze the prevalence of instability by running learning algorithms in a
suite of symmetric games, and we conclude by discussing the applicability of
our results to multi-agent RL, cooperative inverse RL, and decentralized
POMDPs.

### Title: Stochastic optimal well control in subsurface reservoirs using reinforcement learning
* Paper ID: 2207.03456v1
* Paper URL: [http://arxiv.org/abs/2207.03456v1](http://arxiv.org/abs/2207.03456v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LG', 'cs.SY', 'eess.SY']
* Code URL: [https://github.com/atishdixit16/rl_robust_owc](https://github.com/atishdixit16/rl_robust_owc)
* Summary: We present a case study of model-free reinforcement learning (RL) framework
to solve stochastic optimal control for a predefined parameter uncertainty
distribution and partially observable system. We focus on robust optimal well
control problem which is a subject of intensive research activities in the
field of subsurface reservoir management. For this problem, the system is
partially observed since the data is only available at well locations.
Furthermore, the model parameters are highly uncertain due to sparsity of
available field data. In principle, RL algorithms are capable of learning
optimal action policies -- a map from states to actions -- to maximize a
numerical reward signal. In deep RL, this mapping from state to action is
parameterized using a deep neural network. In the RL formulation of the robust
optimal well control problem, the states are represented by saturation and
pressure values at well locations while the actions represent the valve
openings controlling the flow through wells. The numerical reward refers to the
total sweep efficiency and the uncertain model parameter is the subsurface
permeability field. The model parameter uncertainties are handled by
introducing a domain randomisation scheme that exploits cluster analysis on its
uncertainty distribution. We present numerical results using two
state-of-the-art RL algorithms, proximal policy optimization (PPO) and
advantage actor-critic (A2C), on two subsurface flow test cases representing
two distinct uncertainty distributions of permeability field. The results were
benchmarked against optimisation results obtained using differential evolution
algorithm. Furthermore, we demonstrate the robustness of the proposed use of RL
by evaluating the learned control policy on unseen samples drawn from the
parameter uncertainty distribution that were not used during the training
process.

### Title: TFCNs: A CNN-Transformer Hybrid Network for Medical Image Segmentation
* Paper ID: 2207.03450v1
* Paper URL: [http://arxiv.org/abs/2207.03450v1](http://arxiv.org/abs/2207.03450v1)
* Updated Date: 2022-07-07
* Categories: ['eess.IV', 'cs.CV']
* Code URL: [https://github.com/huanglizi/tfcns](https://github.com/huanglizi/tfcns)
* Summary: Medical image segmentation is one of the most fundamental tasks concerning
medical information analysis. Various solutions have been proposed so far,
including many deep learning-based techniques, such as U-Net, FC-DenseNet, etc.
However, high-precision medical image segmentation remains a highly challenging
task due to the existence of inherent magnification and distortion in medical
images as well as the presence of lesions with similar density to normal
tissues. In this paper, we propose TFCNs (Transformers for Fully Convolutional
denseNets) to tackle the problem by introducing ResLinear-Transformer
(RL-Transformer) and Convolutional Linear Attention Block (CLAB) to
FC-DenseNet. TFCNs is not only able to utilize more latent information from the
CT images for feature extraction, but also can capture and disseminate semantic
features and filter non-semantic features more effectively through the CLAB
module. Our experimental results show that TFCNs can achieve state-of-the-art
performance with dice scores of 83.72\% on the Synapse dataset. In addition, we
evaluate the robustness of TFCNs for lesion area effects on the COVID-19 public
datasets. The Python code will be made publicly available on
https://github.com/HUANGLIZI/TFCNs.

### Title: Back to the Source: Diffusion-Driven Test-Time Adaptation
* Paper ID: 2207.03442v1
* Paper URL: [http://arxiv.org/abs/2207.03442v1](http://arxiv.org/abs/2207.03442v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LG', 'cs.CV']
* Code URL: null
* Summary: Test-time adaptation harnesses test inputs to improve the accuracy of a model
trained on source data when tested on shifted target data. Existing methods
update the source model by (re-)training on each target domain. While
effective, re-training is sensitive to the amount and order of the data and the
hyperparameters for optimization. We instead update the target data, by
projecting all test inputs toward the source domain with a generative diffusion
model. Our diffusion-driven adaptation method, DDA, shares its models for
classification and generation across all domains. Both models are trained on
the source domain, then fixed during testing. We augment diffusion with image
guidance and self-ensembling to automatically decide how much to adapt. Input
adaptation by DDA is more robust than prior model adaptation approaches across
a variety of corruptions, architectures, and data regimes on the ImageNet-C
benchmark. With its input-wise updates, DDA succeeds where model adaptation
degrades on too little data in small batches, dependent data in non-uniform
order, or mixed data with multiple corruptions.

### Title: LASSIE: Learning Articulated Shapes from Sparse Image Ensemble via 3D Part Discovery
* Paper ID: 2207.03434v1
* Paper URL: [http://arxiv.org/abs/2207.03434v1](http://arxiv.org/abs/2207.03434v1)
* Updated Date: 2022-07-07
* Categories: ['cs.CV']
* Code URL: null
* Summary: Creating high-quality articulated 3D models of animals is challenging either
via manual creation or using 3D scanning tools. Therefore, techniques to
reconstruct articulated 3D objects from 2D images are crucial and highly
useful. In this work, we propose a practical problem setting to estimate 3D
pose and shape of animals given only a few (10-30) in-the-wild images of a
particular animal species (say, horse). Contrary to existing works that rely on
pre-defined template shapes, we do not assume any form of 2D or 3D ground-truth
annotations, nor do we leverage any multi-view or temporal information.
Moreover, each input image ensemble can contain animal instances with varying
poses, backgrounds, illuminations, and textures. Our key insight is that 3D
parts have much simpler shape compared to the overall animal and that they are
robust w.r.t. animal pose articulations. Following these insights, we propose
LASSIE, a novel optimization framework which discovers 3D parts in a
self-supervised manner with minimal user intervention. A key driving force
behind LASSIE is the enforcing of 2D-3D part consistency using self-supervisory
deep features. Experiments on Pascal-Part and self-collected in-the-wild animal
datasets demonstrate considerably better 3D reconstructions as well as both 2D
and 3D part discovery compared to prior arts. Project page:
chhankyao.github.io/lassie/

### Title: Robust Watermarking for Video Forgery Detection with Improved Imperceptibility and Robustness
* Paper ID: 2207.03409v1
* Paper URL: [http://arxiv.org/abs/2207.03409v1](http://arxiv.org/abs/2207.03409v1)
* Updated Date: 2022-07-07
* Categories: ['cs.CV']
* Code URL: null
* Summary: Videos are prone to tampering attacks that alter the meaning and deceive the
audience. Previous video forgery detection schemes find tiny clues to locate
the tampered areas. However, attackers can successfully evade supervision by
destroying such clues using video compression or blurring. This paper proposes
a video watermarking network for tampering localization. We jointly train a
3D-UNet-based watermark embedding network and a decoder that predicts the
tampering mask. The perturbation made by watermark embedding is close to
imperceptible. Considering that there is no off-the-shelf differentiable video
codec simulator, we propose to mimic video compression by ensembling simulation
results of other typical attacks, e.g., JPEG compression and blurring, as an
approximation. Experimental results demonstrate that our method generates
watermarked videos with good imperceptibility and robustly and accurately
locates tampered areas within the attacked version.

### Title: On the Relationship Between Adversarial Robustness and Decision Region in Deep Neural Network
* Paper ID: 2207.03400v1
* Paper URL: [http://arxiv.org/abs/2207.03400v1](http://arxiv.org/abs/2207.03400v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LG']
* Code URL: null
* Summary: In general, Deep Neural Networks (DNNs) are evaluated by the generalization
performance measured on unseen data excluded from the training phase. Along
with the development of DNNs, the generalization performance converges to the
state-of-the-art and it becomes difficult to evaluate DNNs solely based on this
metric. The robustness against adversarial attack has been used as an
additional metric to evaluate DNNs by measuring their vulnerability. However,
few studies have been performed to analyze the adversarial robustness in terms
of the geometry in DNNs. In this work, we perform an empirical study to analyze
the internal properties of DNNs that affect model robustness under adversarial
attacks. In particular, we propose the novel concept of the Populated Region
Set (PRS), where training samples are populated more frequently, to represent
the internal properties of DNNs in a practical setting. From systematic
experiments with the proposed concept, we provide empirical evidence to
validate that a low PRS ratio has a strong relationship with the adversarial
robustness of DNNs. We also devise PRS regularizer leveraging the
characteristics of PRS to improve the adversarial robustness without
adversarial training.

### Title: Diagnosing and Remedying Shot Sensitivity with Cosine Few-Shot Learners
* Paper ID: 2207.03398v1
* Paper URL: [http://arxiv.org/abs/2207.03398v1](http://arxiv.org/abs/2207.03398v1)
* Updated Date: 2022-07-07
* Categories: ['cs.CV', 'cs.AI', 'cs.LG']
* Code URL: null
* Summary: Few-shot recognition involves training an image classifier to distinguish
novel concepts at test time using few examples (shot). Existing approaches
generally assume that the shot number at test time is known in advance. This is
not realistic, and the performance of a popular and foundational method has
been shown to suffer when train and test shots do not match. We conduct a
systematic empirical study of this phenomenon. In line with prior work, we find
that shot sensitivity is broadly present across metric-based few-shot learners,
but in contrast to prior work, larger neural architectures provide a degree of
built-in robustness to varying test shot. More importantly, a simple,
previously known but greatly overlooked class of approaches based on cosine
distance consistently and greatly improves robustness to shot variation, by
removing sensitivity to sample noise. We derive cosine alternatives to popular
and recent few-shot classifiers, broadening their applicability to realistic
settings. These cosine models consistently improve shot-robustness, outperform
prior shot-robust state of the art, and provide competitive accuracy on a range
of benchmarks and architectures, including notable gains in the very-low-shot
regime.

### Title: Group Fairness in Adaptive Submodular Maximization
* Paper ID: 2207.03364v1
* Paper URL: [http://arxiv.org/abs/2207.03364v1](http://arxiv.org/abs/2207.03364v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LG', 'cs.DS']
* Code URL: null
* Summary: In this paper, we study the classic submodular maximization problem subject
to a group fairness constraint under both non-adaptive and adaptive settings.
It has been shown that the utility function of many machine learning
applications, including data summarization, influence maximization in social
networks, and personalized recommendation, satisfies the property of
submodularity. Hence, maximizing a submodular function subject to various
constraints can be found at the heart of many of those applications. On a high
level, submodular maximization aims to select a group of most representative
items (e.g., data points). However, the design of most existing algorithms does
not incorporate the fairness constraint, leading to under- or
over-representation some particular groups. This motivates us to study the fair
submodular maximization problem, where we aim to select a group of items to
maximize a (possibly non-monotone) submodular utility function subject to a
group fairness constraint. To this end, we develop the first constant-factor
approximation algorithm for this problem. The design of our algorithm is robust
enough to be extended to solving the submodular maximization problem under a
more complicated adaptive setting. Moreover, we further extend our study to
incorporating a global cardinality constraint.

### Title: Calibrate to Interpret
* Paper ID: 2207.03324v1
* Paper URL: [http://arxiv.org/abs/2207.03324v1](http://arxiv.org/abs/2207.03324v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LG', 'I.2.6; I.2.10; I.4.8; I.5.2']
* Code URL: [https://github.com/euranova/calibrate_to_interpret](https://github.com/euranova/calibrate_to_interpret)
* Summary: Trustworthy machine learning is driving a large number of ML community works
in order to improve ML acceptance and adoption. The main aspect of trustworthy
machine learning are the followings: fairness, uncertainty, robustness,
explainability and formal guaranties. Each of these individual domains gains
the ML community interest, visible by the number of related publications.
However few works tackle the interconnection between these fields. In this
paper we show a first link between uncertainty and explainability, by studying
the relation between calibration and interpretation. As the calibration of a
given model changes the way it scores samples, and interpretation approaches
often rely on these scores, it seems safe to assume that the
confidence-calibration of a model interacts with our ability to interpret such
model. In this paper, we show, in the context of networks trained on image
classification tasks, to what extent interpretations are sensitive to
confidence-calibration. It leads us to suggest a simple practice to improve the
interpretation outcomes: Calibrate to Interpret.

### Title: D2HNet: Joint Denoising and Deblurring with Hierarchical Network for Robust Night Image Restoration
* Paper ID: 2207.03294v1
* Paper URL: [http://arxiv.org/abs/2207.03294v1](http://arxiv.org/abs/2207.03294v1)
* Updated Date: 2022-07-07
* Categories: ['cs.CV', 'eess.IV']
* Code URL: [https://github.com/zhaoyuzhi/d2hnet](https://github.com/zhaoyuzhi/d2hnet)
* Summary: Night imaging with modern smartphone cameras is troublesome due to low photon
count and unavoidable noise in the imaging system. Directly adjusting exposure
time and ISO ratings cannot obtain sharp and noise-free images at the same time
in low-light conditions. Though many methods have been proposed to enhance
noisy or blurry night images, their performances on real-world night photos are
still unsatisfactory due to two main reasons: 1) Limited information in a
single image and 2) Domain gap between synthetic training images and real-world
photos (e.g., differences in blur area and resolution). To exploit the
information from successive long- and short-exposure images, we propose a
learning-based pipeline to fuse them. A D2HNet framework is developed to
recover a high-quality image by deblurring and enhancing a long-exposure image
under the guidance of a short-exposure image. To shrink the domain gap, we
leverage a two-phase DeblurNet-EnhanceNet architecture, which performs accurate
blur removal on a fixed low resolution so that it is able to handle large
ranges of blur in different resolution inputs. In addition, we synthesize a
D2-Dataset from HD videos and experiment on it. The results on the validation
set and real photos demonstrate our methods achieve better visual quality and
state-of-the-art quantitative scores. The D2HNet codes, models, and D2-Dataset
can be found at https://github.com/zhaoyuzhi/D2HNet.

### Title: NESC: Robust Neural End-2-End Speech Coding with GANs
* Paper ID: 2207.03282v1
* Paper URL: [http://arxiv.org/abs/2207.03282v1](http://arxiv.org/abs/2207.03282v1)
* Updated Date: 2022-07-07
* Categories: ['eess.AS', 'cs.LG', 'cs.SD', 'eess.SP']
* Code URL: null
* Summary: Neural networks have proven to be a formidable tool to tackle the problem of
speech coding at very low bit rates. However, the design of a neural coder that
can be operated robustly under real-world conditions remains a major challenge.
Therefore, we present Neural End-2-End Speech Codec (NESC) a robust, scalable
end-to-end neural speech codec for high-quality wideband speech coding at 3
kbps. The encoder uses a new architecture configuration, which relies on our
proposed Dual-PathConvRNN (DPCRNN) layer, while the decoder architecture is
based on our previous work Streamwise-StyleMelGAN. Our subjective listening
tests on clean and noisy speech show that NESC is particularly robust to unseen
conditions and signal perturbations.

### Title: Robust optimal well control using an adaptive multi-grid reinforcement learning framework
* Paper ID: 2207.03253v1
* Paper URL: [http://arxiv.org/abs/2207.03253v1](http://arxiv.org/abs/2207.03253v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LG']
* Code URL: [https://github.com/atishdixit16/ada_multigrid_ppo](https://github.com/atishdixit16/ada_multigrid_ppo)
* Summary: Reinforcement learning (RL) is a promising tool to solve robust optimal well
control problems where the model parameters are highly uncertain, and the
system is partially observable in practice. However, RL of robust control
policies often relies on performing a large number of simulations. This could
easily become computationally intractable for cases with computationally
intensive simulations. To address this bottleneck, an adaptive multi-grid RL
framework is introduced which is inspired by principles of geometric multi-grid
methods used in iterative numerical algorithms. RL control policies are
initially learned using computationally efficient low fidelity simulations
using coarse grid discretization of the underlying partial differential
equations (PDEs). Subsequently, the simulation fidelity is increased in an
adaptive manner towards the highest fidelity simulation that correspond to
finest discretization of the model domain. The proposed framework is
demonstrated using a state-of-the-art, model-free policy-based RL algorithm,
namely the Proximal Policy Optimisation (PPO) algorithm. Results are shown for
two case studies of robust optimal well control problems which are inspired
from SPE-10 model 2 benchmark case studies. Prominent gains in the
computational efficiency is observed using the proposed framework saving around
60-70% of computational cost of its single fine-grid counterpart.

### Title: BMD-GAN: Bone mineral density estimation using x-ray image decomposition into projections of bone-segmented quantitative computed tomography using hierarchical learning
* Paper ID: 2207.03210v1
* Paper URL: [http://arxiv.org/abs/2207.03210v1](http://arxiv.org/abs/2207.03210v1)
* Updated Date: 2022-07-07
* Categories: ['eess.IV', 'cs.CV']
* Code URL: null
* Summary: We propose a method for estimating the bone mineral density (BMD) from a
plain x-ray image. Dual-energy X-ray absorptiometry (DXA) and quantitative
computed tomography (QCT) provide high accuracy in diagnosing osteoporosis;
however, these modalities require special equipment and scan protocols.
Measuring BMD from an x-ray image provides an opportunistic screening, which is
potentially useful for early diagnosis. The previous methods that directly
learn the relationship between x-ray images and BMD require a large training
dataset to achieve high accuracy because of large intensity variations in the
x-ray images. Therefore, we propose an approach using the QCT for training a
generative adversarial network (GAN) and decomposing an x-ray image into a
projection of bone-segmented QCT. The proposed hierarchical learning improved
the robustness and accuracy of quantitatively decomposing a small-area target.
The evaluation of 200 patients with osteoarthritis using the proposed method,
which we named BMD-GAN, demonstrated a Pearson correlation coefficient of 0.888
between the predicted and ground truth DXA-measured BMD. Besides not requiring
a large-scale training database, another advantage of our method is its
extensibility to other anatomical areas, such as the vertebrae and rib bones.

### Title: Harnessing Out-Of-Distribution Examples via Augmenting Content and Style
* Paper ID: 2207.03162v1
* Paper URL: [http://arxiv.org/abs/2207.03162v1](http://arxiv.org/abs/2207.03162v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LG']
* Code URL: null
* Summary: Machine learning models are vulnerable to Out-Of-Distribution (OOD) examples,
such a problem has drawn much attention. However, current methods lack a full
understanding of different types of OOD data: there are benign OOD data that
can be properly adapted to enhance the learning performance, while other malign
OOD data would severely degenerate the classification result. To Harness OOD
data, this paper proposes HOOD method that can leverage the content and style
from each image instance to identify benign and malign OOD data. Particularly,
we design a variational inference framework to causally disentangle content and
style features by constructing a structural causal model. Subsequently, we
augment the content and style through an intervention process to produce malign
and benign OOD data, respectively. The benign OOD data contain novel styles but
hold our interested contents, and they can be leveraged to help train a
style-invariant model. In contrast, the malign OOD data inherit unknown
contents but carry familiar styles, by detecting them can improve model
robustness against deceiving anomalies. Thanks to the proposed novel
disentanglement and data augmentation techniques, HOOD can effectively deal
with OOD examples in unknown and open environments, whose effectiveness is
empirically validated in three typical OOD applications including OOD
detection, open-set semi-supervised learning, and open-set domain adaptation.

### Title: Deep Rotation Correction without Angle Prior
* Paper ID: 2207.03054v1
* Paper URL: [http://arxiv.org/abs/2207.03054v1](http://arxiv.org/abs/2207.03054v1)
* Updated Date: 2022-07-07
* Categories: ['cs.CV']
* Code URL: [https://github.com/nie-lang/rotationcorrection](https://github.com/nie-lang/rotationcorrection)
* Summary: Not everybody can be equipped with professional photography skills and
sufficient shooting time, and there can be some tilts in the captured images
occasionally. In this paper, we propose a new and practical task, named
Rotation Correction, to automatically correct the tilt with high content
fidelity in the condition that the rotated angle is unknown. This task can be
easily integrated into image editing applications, allowing users to correct
the rotated images without any manual operations. To this end, we leverage a
neural network to predict the optical flows that can warp the tilted images to
be perceptually horizontal. Nevertheless, the pixel-wise optical flow
estimation from a single image is severely unstable, especially in large-angle
tilted images. To enhance its robustness, we propose a simple but effective
prediction strategy to form a robust elastic warp. Particularly, we first
regress the mesh deformation that can be transformed into robust initial
optical flows. Then we estimate residual optical flows to facilitate our
network the flexibility of pixel-wise deformation, further correcting the
details of the tilted images. To establish an evaluation benchmark and train
the learning framework, a comprehensive rotation correction dataset is
presented with a large diversity in scenes and rotated angles. Extensive
experiments demonstrate that even in the absence of the angle prior, our
algorithm can outperform other state-of-the-art solutions requiring this prior.
The codes and dataset will be available at
https://github.com/nie-lang/RotationCorrection.

### Title: Not All Models Are Equal: Predicting Model Transferability in a Self-challenging Fisher Space
* Paper ID: 2207.03036v1
* Paper URL: [http://arxiv.org/abs/2207.03036v1](http://arxiv.org/abs/2207.03036v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LG', 'cs.AI']
* Code URL: null
* Summary: This paper addresses an important problem of ranking the pre-trained deep
neural networks and screening the most transferable ones for downstream tasks.
It is challenging because the ground-truth model ranking for each task can only
be generated by fine-tuning the pre-trained models on the target dataset, which
is brute-force and computationally expensive. Recent advanced methods proposed
several lightweight transferability metrics to predict the fine-tuning results.
However, these approaches only capture static representations but neglect the
fine-tuning dynamics. To this end, this paper proposes a new transferability
metric, called \textbf{S}elf-challenging \textbf{F}isher \textbf{D}iscriminant
\textbf{A}nalysis (\textbf{SFDA}), which has many appealing benefits that
existing works do not have. First, SFDA can embed the static features into a
Fisher space and refine them for better separability between classes. Second,
SFDA uses a self-challenging mechanism to encourage different pre-trained
models to differentiate on hard examples. Third, SFDA can easily select
multiple pre-trained models for the model ensemble. Extensive experiments on
$33$ pre-trained models of $11$ downstream tasks show that SFDA is efficient,
effective, and robust when measuring the transferability of pre-trained models.
For instance, compared with the state-of-the-art method NLEEP, SFDA
demonstrates an average of $59.1$\% gain while bringing $22.5$x speedup in
wall-clock time. The code will be available at
\url{https://github.com/TencentARC/SFDA}.

