### Title: One-Class Model for Fabric Defect Detection
* Paper ID: 2204.09648v1
* Paper URL: [http://arxiv.org/abs/2204.09648v1](http://arxiv.org/abs/2204.09648v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: An automated and accurate fabric defect inspection system is in high demand
as a replacement for slow, inconsistent, error-prone, and expensive human
operators in the textile industry. Previous efforts focused on certain types of
fabrics or defects, which is not an ideal solution. In this paper, we propose a
novel one-class model that is capable of detecting various defects on different
fabric types. Our model takes advantage of a well-designed Gabor filter bank to
analyze fabric texture. We then leverage an advanced deep learning algorithm,
autoencoder, to learn general feature representations from the outputs of the
Gabor filter bank. Lastly, we develop a nearest neighbor density estimator to
locate potential defects and draw them on the fabric images. We demonstrate the
effectiveness and robustness of the proposed model by testing it on various
types of fabrics such as plain, patterned, and rotated fabrics. Our model also
achieves a true positive rate (a.k.a recall) value of 0.895 with no false
alarms on our dataset based upon the Standard Fabric Defect Glossary.

### Title: Assembly Planning from Observations under Physical Constraints
* Paper ID: 2204.09616v1
* Paper URL: [http://arxiv.org/abs/2204.09616v1](http://arxiv.org/abs/2204.09616v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: This paper addresses the problem of copying an unknown assembly of primitives
with known shape and appearance using information extracted from a single
photograph by an off-the-shelf procedure for object detection and pose
estimation. The proposed algorithm uses a simple combination of physical
stability constraints, convex optimization and Monte Carlo tree search to plan
assemblies as sequences of pick-and-place operations represented by STRIPS
operators. It is efficient and, most importantly, robust to the errors in
object detection and pose estimation unavoidable in any real robotic system.
The proposed approach is demonstrated with thorough experiments on a UR5
manipulator.

### Title: On the Practical Design of Tube-Enhanced Multi-Stage Nonlinear Model Predictive Control
* Paper ID: 2204.09607v1
* Paper URL: [http://arxiv.org/abs/2204.09607v1](http://arxiv.org/abs/2204.09607v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Tube-enhanced multi-stage nonlinear model predictive control is a robust
control scheme that can handle a wide range of uncertainties with reduced
conservatism and manageable computational complexity. In this paper, we
elaborate on the flexibility of the approach from an application point of view.
We discuss the path to making design decisions to implement the novel scheme
systematically. We illustrate the critical steps in the design and
implementation of the scheme for an industrial example.

### Title: Federated Learning for Distributed Energy-Efficient Resource Allocation
* Paper ID: 2204.09602v1
* Paper URL: [http://arxiv.org/abs/2204.09602v1](http://arxiv.org/abs/2204.09602v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: In cellular networks, resource allocation is performed in a centralized way,
which brings huge computation complexity to the base station (BS) and high
transmission overhead. This paper investigates the distributed resource
allocation scheme for cellular networks to maximize the energy efficiency of
the system in the uplink transmission, while guaranteeing the quality of
service (QoS) for cellular users. Particularly, to cope the fast varying
channels in wireless communication environment, we propose a robust federated
reinforcement learning (FRL_suc) framework to enable local users to perform
distributed resource allocation in items of transmit power and channel
assignment by the guidance of the local neural network trained at each user.
Analysis and numerical results show that the proposed FRL_suc framework can
lower the transmission overhead and offload the computation from the central
server to the local users, while outperforming the conventional multi-agent
reinforcement learning algorithm in terms of EE, and is more robust to channel
variations.

### Title: Improved Worst-Group Robustness via Classifier Retraining on Independent Splits
* Paper ID: 2204.09583v1
* Paper URL: [http://arxiv.org/abs/2204.09583v1](http://arxiv.org/abs/2204.09583v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: High-capacity deep neural networks (DNNs) trained with Empirical Risk
Minimization (ERM) often suffer from poor worst-group accuracy despite good
on-average performance, where worst-group accuracy measures a model's
robustness towards certain subpopulations of the input space. Spurious
correlations and memorization behaviors of ERM trained DNNs are typically
attributed to this degradation in performance. We develop a method, called
CRIS, that address these issues by performing robust classifier retraining on
independent splits of the dataset. This results in a simple method that
improves upon state-of-the-art methods, such as Group DRO, on standard datasets
while relying on much fewer group labels and little additional hyperparameter
tuning.

### Title: Fast and Robust Femur Segmentation from Computed Tomography Images for Patient-Specific Hip Fracture Risk Screening
* Paper ID: 2204.09575v1
* Paper URL: [http://arxiv.org/abs/2204.09575v1](http://arxiv.org/abs/2204.09575v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Osteoporosis is a common bone disease that increases the risk of bone
fracture. Hip-fracture risk screening methods based on finite element analysis
depend on segmented computed tomography (CT) images; however, current femur
segmentation methods require manual delineations of large data sets. Here we
propose a deep neural network for fully automated, accurate, and fast
segmentation of the proximal femur from CT. Evaluation on a set of 1147
proximal femurs with ground truth segmentations demonstrates that our method is
apt for hip-fracture risk screening, bringing us one step closer to a
clinically viable option for screening at-risk patients for hip-fracture
susceptibility.

### Title: Tunable and giant valley-selective Hall effect in gapped bilayer graphene
* Paper ID: 2204.09525v1
* Paper URL: [http://arxiv.org/abs/2204.09525v1](http://arxiv.org/abs/2204.09525v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Berry curvature is analogous to magnetic field but in momentum space and is
commonly present in materials with non-trivial quantum geometry. It endows
Bloch electrons with transverse anomalous velocities to produce Hall-like
currents even in the absence of a magnetic field. We report the direct
observation of in situ tunable valley-selective Hall effect (VSHE), where
inversion symmetry, and thus the geometric phase of electrons, is controllable
by an out-of-plane electric field. We use high-quality bilayer graphene with an
intrinsic and tunable bandgap, illuminated by circularly polarized mid-infrared
light and confirm that the observed Hall voltage arises from an
optically-induced valley population. Compared with molybdenum disulfide, we
find orders of magnitude larger VSHE, attributed to the inverse scaling of the
Berry curvature with bandgap. By monitoring the valley-selective Hall
conductivity, we study Berry curvature's evolution with bandgap. This in situ
manipulation of VSHE paves the way for topological and quantum geometric
opto-electronic devices, such as more robust switches and detectors.

### Title: A Data-Driven Method for Automated Data Superposition with Applications in Soft Matter Science
* Paper ID: 2204.09521v1
* Paper URL: [http://arxiv.org/abs/2204.09521v1](http://arxiv.org/abs/2204.09521v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: The superposition of data sets with internal parametric self-similarity is a
longstanding and widespread technique for the analysis of many types of
experimental data across the physical sciences. Typically, this superposition
is performed manually, or recently by one of a few automated algorithms.
However, these methods are often heuristic in nature, are prone to user bias
via manual data shifting or parameterization, and lack a native framework for
handling uncertainty in both the data and the resulting model of the superposed
data. In this work, we develop a data-driven, non-parametric method for
superposing experimental data with arbitrary coordinate transformations, which
employs Gaussian process regression to learn statistical models that describe
the data, and then uses maximum a posteriori estimation to optimally superpose
the data sets. This statistical framework is robust to experimental noise, and
automatically produces uncertainty estimates for the learned coordinate
transformations. Moreover, it is distinguished from black-box machine learning
in its interpretability -- specifically, it produces a model that may itself be
interrogated to gain insight into the system under study. We demonstrate these
salient features of our method through its application to four representative
data sets characterizing the mechanics of soft materials. In every case, our
method replicates results obtained using other approaches, but with reduced
bias and the addition of uncertainty estimates. This method enables a
standardized, statistical treatment of self-similar data across many fields,
producing interpretable data-driven models that may inform applications such as
materials classification, design, and discovery.

### Title: A Reinforcement Learning-based Volt-VAR Control Dataset and Testing Environment
* Paper ID: 2204.09500v1
* Paper URL: [http://arxiv.org/abs/2204.09500v1](http://arxiv.org/abs/2204.09500v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: To facilitate the development of reinforcement learning (RL) based power
distribution system Volt-VAR control (VVC), this paper introduces a suite of
open-source datasets for RL-based VVC algorithm research that is sample
efficient, safe, and robust. The dataset consists of two components: 1. a
Gym-like VVC testing environment for the IEEE-13, 123, and 8500-bus test
feeders and 2. a historical operational dataset for each of the feeders.
Potential users of the dataset and testing environment could first train an
sample-efficient off-line (batch) RL algorithm on the historical dataset and
then evaluate the performance of the trained RL agent on the testing
environments. This dataset serves as a useful testbed to conduct RL-based VVC
research mimicking the real-world operational challenges faced by electric
utilities. Meanwhile, it allows researchers to conduct fair performance
comparisons between different algorithms.

### Title: THORN: Temporal Human-Object Relation Network for Action Recognition
* Paper ID: 2204.09468v1
* Paper URL: [http://arxiv.org/abs/2204.09468v1](http://arxiv.org/abs/2204.09468v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Most action recognition models treat human activities as unitary events.
However, human activities often follow a certain hierarchy. In fact, many human
activities are compositional. Also, these actions are mostly human-object
interactions. In this paper we propose to recognize human action by leveraging
the set of interactions that define an action. In this work, we present an
end-to-end network: THORN, that can leverage important human-object and
object-object interactions to predict actions. This model is built on top of a
3D backbone network. The key components of our model are: 1) An object
representation filter for modeling object. 2) An object relation reasoning
module to capture object relations. 3) A classification layer to predict the
action labels. To show the robustness of THORN, we evaluate it on
EPIC-Kitchen55 and EGTEA Gaze+, two of the largest and most challenging
first-person and human-object interaction datasets. THORN achieves
state-of-the-art performance on both datasets.

### Title: Is BERT Robust to Label Noise? A Study on Learning with Noisy Labels in Text Classification
* Paper ID: 2204.09371v1
* Paper URL: [http://arxiv.org/abs/2204.09371v1](http://arxiv.org/abs/2204.09371v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Incorrect labels in training data occur when human annotators make mistakes
or when the data is generated via weak or distant supervision. It has been
shown that complex noise-handling techniques - by modeling, cleaning or
filtering the noisy instances - are required to prevent models from fitting
this label noise. However, we show in this work that, for text classification
tasks with modern NLP models like BERT, over a variety of noise types, existing
noisehandling methods do not always improve its performance, and may even
deteriorate it, suggesting the need for further investigation. We also back our
observations with a comprehensive analysis.

### Title: NFormer: Robust Person Re-identification with Neighbor Transformer
* Paper ID: 2204.09331v1
* Paper URL: [http://arxiv.org/abs/2204.09331v1](http://arxiv.org/abs/2204.09331v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Person re-identification aims to retrieve persons in highly varying settings
across different cameras and scenarios, in which robust and discriminative
representation learning is crucial. Most research considers learning
representations from single images, ignoring any potential interactions between
them. However, due to the high intra-identity variations, ignoring such
interactions typically leads to outlier features. To tackle this issue, we
propose a Neighbor Transformer Network, or NFormer, which explicitly models
interactions across all input images, thus suppressing outlier features and
leading to more robust representations overall. As modelling interactions
between enormous amount of images is a massive task with lots of distractors,
NFormer introduces two novel modules, the Landmark Agent Attention, and the
Reciprocal Neighbor Softmax. Specifically, the Landmark Agent Attention
efficiently models the relation map between images by a low-rank factorization
with a few landmarks in feature space. Moreover, the Reciprocal Neighbor
Softmax achieves sparse attention to relevant -- rather than all -- neighbors
only, which alleviates interference of irrelevant representations and further
relieves the computational burden. In experiments on four large-scale datasets,
NFormer achieves a new state-of-the-art. The code is released at
\url{https://github.com/haochenheheda/NFormer}.

### Title: Group relations, resilience and the I Ching
* Paper ID: 2204.09330v1
* Paper URL: [http://arxiv.org/abs/2204.09330v1](http://arxiv.org/abs/2204.09330v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: We evaluate the robustness and adaptivity of social groups with heterogeneous
agents that are characterized by their binary state, their ability to change
this state, their status and their preferred relations to other agents. To
define group structures, we operationalize the hexagrams of the \emph{I Ching}.
The relations and properties of agents are used to quantify their influence
according to the social impact theory. From these influence values we derive a
weighted stability measure for triads involving three agents, which is based on
the weighted balance theory. It allows to quantify the robustness of groups and
to propose a novel measure for group resilience which combines robustness and
adaptivity. A stochastic approach determines the probabilities to find robust
and adaptive groups. The discussion focuses on the generalization of our
approach.

### Title: Logarithmic Morphological Neural Nets robust to lighting variations
* Paper ID: 2204.09319v1
* Paper URL: [http://arxiv.org/abs/2204.09319v1](http://arxiv.org/abs/2204.09319v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Morphological neural networks allow to learn the weights of a structuring
function knowing the desired output image. However, those networks are not
intrinsically robust to lighting variations in images with an optical cause,
such as a change of light intensity. In this paper, we introduce a
morphological neural network which possesses such a robustness to lighting
variations. It is based on the recent framework of Logarithmic Mathematical
Morphology (LMM), i.e. Mathematical Morphology defined with the Logarithmic
Image Processing (LIP) model. This model has a LIP additive law which simulates
in images a variation of the light intensity. We especially learn the
structuring function of a LMM operator robust to those variations, namely : the
map of LIP-additive Asplund distances. Results in images show that our neural
network verifies the required property.

### Title: Massive Twinning to Enhance Emergent Intelligence
* Paper ID: 2204.09316v1
* Paper URL: [http://arxiv.org/abs/2204.09316v1](http://arxiv.org/abs/2204.09316v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Future Industrial Internet-of-Things in the upcoming 6G era is expected to
deploy artificial intelligence (AI) and digital twins (DTs) ubiquitously. As a
complement to conventional AI solutions, emergent intelligence (EI) exhibits
various outstanding features including robustness, protection to privacy, and
scalability, which makes it competitive for 6G IIoT applications. However,
despite its low computational complexity, it is challenged by its high demand
of data traffic in massive deployment. In this paper, we propose to exploit the
massive twinning paradigm, which 6G is envisaged to support, to reduce the data
traffic in EI and therewith enhance its performance.

### Title: Improving generalization of machine learning-identified biomarkers with causal modeling: an investigation into immune receptor diagnostics
* Paper ID: 2204.09291v1
* Paper URL: [http://arxiv.org/abs/2204.09291v1](http://arxiv.org/abs/2204.09291v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Machine learning is increasingly used to discover diagnostic and prognostic
biomarkers from high-dimensional molecular data. However, a variety of factors
related to experimental design may affect the ability to learn generalizable
and clinically applicable diagnostics. Here, we argue that a causal perspective
improves the identification of these challenges, and formalizes their relation
to the robustness and generalization of machine learning-based diagnostics. To
make for a concrete discussion, we focus on a specific, recently established
high-dimensional biomarker - adaptive immune receptor repertoires (AIRRs). We
discuss how the main biological and experimental factors of the AIRR domain may
influence the learned biomarkers and provide easily adjustable simulations of
such effects. In conclusion, we find that causal modeling improves machine
learning-based biomarker robustness by identifying stable relations between
variables and by guiding the adjustment of the relations and variables that
vary between populations.

### Title: Varied magnetic phases in a van der Waals easy-plane antiferromagnet revealed by nitrogen-vacancy center microscopy
* Paper ID: 2204.09277v1
* Paper URL: [http://arxiv.org/abs/2204.09277v1](http://arxiv.org/abs/2204.09277v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Interest in van der Waals materials often stems from a desire to miniaturise
existing technologies by exploiting their intrinsic layered structure to create
near atomically-thin components that do not suffer from surface defects. One
appealing property is easily-switchable yet robust magnetic order, a quality
only sparsely demonstrated in the case of in-plane anisotropy. In this work, we
use widefield nitrogen-vacancy (NV) center magnetic imaging to measure the
properties of individual flakes of CuCrP$_2$S$_6$, a multiferroic van der Waals
magnet known to exhibit weak easy-plane anisotropy in the bulk. We chart the
crossover between in-plane ferromagnetism in thin flakes down to the trilayer,
and the bulk behaviour dominated by a low-field spin-flop transition. Further,
by exploiting the directional dependence of NV center magnetometry, we are able
to observe an instance of a predominantly out-of-plane ferromagetic phase near
zero field, in contradiction with expectation and previous experiments on the
bulk material. We attribute this to the presence of surface anisotropies
arising from the sample preparation process or exposure to the ambient
environment, which is expected to have more general implications for a broader
class of weakly anisotropic van der Waals magnets.

### Title: Synthetic Target Domain Supervision for Open Retrieval QA
* Paper ID: 2204.09248v1
* Paper URL: [http://arxiv.org/abs/2204.09248v1](http://arxiv.org/abs/2204.09248v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Neural passage retrieval is a new and promising approach in open retrieval
question answering. In this work, we stress-test the Dense Passage Retriever
(DPR) -- a state-of-the-art (SOTA) open domain neural retrieval model -- on
closed and specialized target domains such as COVID-19, and find that it lags
behind standard BM25 in this important real-world setting. To make DPR more
robust under domain shift, we explore its fine-tuning with synthetic training
examples, which we generate from unlabeled target domain text using a
text-to-text generator. In our experiments, this noisy but fully automated
target domain supervision gives DPR a sizable advantage over BM25 in
out-of-domain settings, making it a more viable model in practice. Finally, an
ensemble of BM25 and our improved DPR model yields the best results, further
pushing the SOTA for open retrieval QA on multiple out-of-domain test sets.

### Title: Visual-based Positioning and Pose Estimation
* Paper ID: 2204.09232v1
* Paper URL: [http://arxiv.org/abs/2204.09232v1](http://arxiv.org/abs/2204.09232v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Recent advances in deep learning and computer vision offer an excellent
opportunity to investigate high-level visual analysis tasks such as human
localization and human pose estimation. Although the performance of human
localization and human pose estimation has significantly improved in recent
reports, they are not perfect and erroneous localization and pose estimation
can be expected among video frames. Studies on the integration of these
techniques into a generic pipeline that is robust to noise introduced from
those errors are still lacking. This paper fills the missing study. We explored
and developed two working pipelines that suited the visual-based positioning
and pose estimation tasks. Analyses of the proposed pipelines were conducted on
a badminton game. We showed that the concept of tracking by detection could
work well, and errors in position and pose could be effectively handled by a
linear interpolation technique using information from nearby frames. The
results showed that the Visual-based Positioning and Pose Estimation could
deliver position and pose estimations with good spatial and temporal
resolutions.

### Title: Dark Spot Detection from SAR Images Based on Superpixel Deeper Graph Convolutional Network
* Paper ID: 2204.09230v1
* Paper URL: [http://arxiv.org/abs/2204.09230v1](http://arxiv.org/abs/2204.09230v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Synthetic Aperture Radar (SAR) is the main instrument utilized for the
detection of oil slicks on the ocean surface. In SAR images, some areas
affected by ocean phenomena, such as rain cells, upwellings, and internal
waves, or discharge from oil spills appear as dark spots on images. Dark spot
detection is the first step in the detection of oil spills, which then become
oil slick candidates. The accuracy of dark spot segmentation ultimately affects
the accuracy of oil slick identification. Although some advanced deep learning
methods that use pixels as processing units perform well in remote sensing
image semantic segmentation, detecting some dark spots with weak boundaries
from noisy SAR images remains a huge challenge. We propose a dark spot
detection method based on superpixels deeper graph convolutional networks
(SGDCN) in this paper, which takes the superpixels as the processing units and
extracts features for each superpixel. The features calculated from superpixel
regions are more robust than those from fixed pixel neighborhoods. To reduce
the difficulty of learning tasks, we discard irrelevant features and obtain an
optimal subset of features. After superpixel segmentation, the images are
transformed into graphs with superpixels as nodes, which are fed into the
deeper graph convolutional neural network for node classification. This graph
neural network uses a differentiable aggregation function to aggregate the
features of nodes and neighbors to form more advanced features. It is the first
time using it for dark spot detection. To validate our method, we mark all dark
spots on six SAR images covering the Baltic Sea and construct a dark spots
detection dataset, which has been made publicly available
(https://drive.google.com/drive/folders/12UavrntkDSPrItISQ8iGefXn2gIZHxJ6?usp=sharing).
The experimental results demonstrate that our proposed SGDCN is robust and
effective.

### Title: Interventional Multi-Instance Learning with Deconfounded Instance-Level Prediction
* Paper ID: 2204.09204v1
* Paper URL: [http://arxiv.org/abs/2204.09204v1](http://arxiv.org/abs/2204.09204v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: When applying multi-instance learning (MIL) to make predictions for bags of
instances, the prediction accuracy of an instance often depends on not only the
instance itself but also its context in the corresponding bag. From the
viewpoint of causal inference, such bag contextual prior works as a confounder
and may result in model robustness and interpretability issues. Focusing on
this problem, we propose a novel interventional multi-instance learning (IMIL)
framework to achieve deconfounded instance-level prediction. Unlike traditional
likelihood-based strategies, we design an Expectation-Maximization (EM)
algorithm based on causal intervention, providing a robust instance selection
in the training phase and suppressing the bias caused by the bag contextual
prior. Experiments on pathological image analysis demonstrate that our IMIL
method substantially reduces false positives and outperforms state-of-the-art
MIL methods.

### Title: Functional Calibration under Non-Probability Survey Sampling
* Paper ID: 2204.09193v1
* Paper URL: [http://arxiv.org/abs/2204.09193v1](http://arxiv.org/abs/2204.09193v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Non-probability sampling is prevailing in survey sampling, but ignoring its
selection bias leads to erroneous inferences. We offer a unified nonparametric
calibration method to estimate the sampling weights for a non-probability
sample by calibrating functions of auxiliary variables in a reproducing kernel
Hilbert space. The consistency and the limiting distribution of the proposed
estimator are established, and the corresponding variance estimator is also
investigated. Compared with existing works, the proposed method is more robust
since no parametric assumption is made for the selection mechanism of the
non-probability sample. Numerical results demonstrate that the proposed method
outperforms its competitors, especially when the model is misspecified. The
proposed method is applied to analyze the average total cholesterol of Korean
citizens based on a non-probability sample from the National Health Insurance
Sharing Service and a reference probability sample from the Korea National
Health and Nutrition Examination Survey.

### Title: Robustness Testing of Data and Knowledge Driven Anomaly Detection in Cyber-Physical Systems
* Paper ID: 2204.09183v1
* Paper URL: [http://arxiv.org/abs/2204.09183v1](http://arxiv.org/abs/2204.09183v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: The growing complexity of Cyber-Physical Systems (CPS) and challenges in
ensuring safety and security have led to the increasing use of deep learning
methods for accurate and scalable anomaly detection. However, machine learning
(ML) models often suffer from low performance in predicting unexpected data and
are vulnerable to accidental or malicious perturbations. Although robustness
testing of deep learning models has been extensively explored in applications
such as image classification and speech recognition, less attention has been
paid to ML-driven safety monitoring in CPS. This paper presents the preliminary
results on evaluating the robustness of ML-based anomaly detection methods in
safety-critical CPS against two types of accidental and malicious input
perturbations, generated using a Gaussian-based noise model and the Fast
Gradient Sign Method (FGSM). We test the hypothesis of whether integrating the
domain knowledge (e.g., on unsafe system behavior) with the ML models can
improve the robustness of anomaly detection without sacrificing accuracy and
transparency. Experimental results with two case studies of Artificial Pancreas
Systems (APS) for diabetes management show that ML-based safety monitors
trained with domain knowledge can reduce on average up to 54.2% of robustness
error and keep the average F1 scores high while improving transparency.

### Title: Learned Monocular Depth Priors in Visual-Inertial Initialization
* Paper ID: 2204.09171v1
* Paper URL: [http://arxiv.org/abs/2204.09171v1](http://arxiv.org/abs/2204.09171v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Visual-inertial odometry (VIO) is the pose estimation backbone for most AR/VR
and autonomous robotic systems today, in both academia and industry. However,
these systems are highly sensitive to the initialization of key parameters such
as sensor biases, gravity direction, and metric scale. In practical scenarios
where high-parallax or variable acceleration assumptions are rarely met (e.g.
hovering aerial robot, smartphone AR user not gesticulating with phone),
classical visual-inertial initialization formulations often become
ill-conditioned and/or fail to meaningfully converge. In this paper we target
visual-inertial initialization specifically for these low-excitation scenarios
critical to in-the-wild usage. We propose to circumvent the limitations of
classical visual-inertial structure-from-motion (SfM) initialization by
incorporating a new learning-based measurement as a higher-level input. We
leverage learned monocular depth images (mono-depth) to constrain the relative
depth of features, and upgrade the mono-depth to metric scale by jointly
optimizing for its scale and shift. Our experiments show a significant
improvement in problem conditioning compared to a classical formulation for
visual-inertial initialization, and demonstrate significant accuracy and
robustness improvements relative to the state-of-the-art on public benchmarks,
particularly under motion-restricted scenarios. We further extend this
improvement to implementation within an existing odometry system to illustrate
the impact of our improved initialization method on resulting tracking
trajectories.

### Title: Radio Galaxy Zoo: Using semi-supervised learning to leverage large unlabelled data-sets for radio galaxy classification under data-set shift
* Paper ID: 2204.08816v2
* Paper URL: [http://arxiv.org/abs/2204.08816v2](http://arxiv.org/abs/2204.08816v2)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: In this work we examine the classification accuracy and robustness of a
state-of-the-art semi-supervised learning (SSL) algorithm applied to the
morphological classification of radio galaxies. We test if SSL with fewer
labels can achieve test accuracies comparable to the supervised
state-of-the-art and whether this holds when incorporating previously unseen
data. We find that for the radio galaxy classification problem considered, SSL
provides additional regularisation and outperforms the baseline test accuracy.
However, in contrast to model performance metrics reported on computer science
benchmarking data-sets, we find that improvement is limited to a narrow range
of label volumes, with performance falling off rapidly at low label volumes.
Additionally, we show that SSL does not improve model calibration, regardless
of whether classification is improved. Moreover, we find that when different
underlying catalogues drawn from the same radio survey are used to provide the
labelled and unlabelled data-sets required for SSL, a significant drop in
classification performance is observered, highlighting the difficulty of
applying SSL techniques under dataset shift. We show that a class-imbalanced
unlabelled data pool negatively affects performance through prior probability
shift, which we suggest may explain this performance drop, and that using the
Frechet Distance between labelled and unlabelled data-sets as a measure of
data-set shift can provide a prediction of model performance, but that for
typical radio galaxy data-sets with labelled sample volumes of O(1000), the
sample variance associated with this technique is high and the technique is in
general not sufficiently robust to replace a train-test cycle.

### Title: Audio-Visual Wake Word Spotting System For MISP Challenge 2021
* Paper ID: 2204.08686v2
* Paper URL: [http://arxiv.org/abs/2204.08686v2](http://arxiv.org/abs/2204.08686v2)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: This paper presents the details of our system designed for the Task 1 of
Multimodal Information Based Speech Processing (MISP) Challenge 2021. The
purpose of Task 1 is to leverage both audio and video information to improve
the environmental robustness of far-field wake word spotting. In the proposed
system, firstly, we take advantage of speech enhancement algorithms such as
beamforming and weighted prediction error (WPE) to address the multi-microphone
conversational audio. Secondly, several data augmentation techniques are
applied to simulate a more realistic far-field scenario. For the video
information, the provided region of interest (ROI) is used to obtain visual
representation. Then the multi-layer CNN is proposed to learn audio and visual
representations, and these representations are fed into our two-branch
attention-based network which can be employed for fusion, such as transformer
and conformed. The focal loss is used to fine-tune the model and improve the
performance significantly. Finally, multiple trained models are integrated by
casting vote to achieve our final 0.091 score.

### Title: Learning Forward Dynamics Model and Informed Trajectory Sampler for Safe Quadruped Navigation
* Paper ID: 2204.08647v2
* Paper URL: [http://arxiv.org/abs/2204.08647v2](http://arxiv.org/abs/2204.08647v2)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: For autonomous quadruped robot navigation in various complex environments, a
typical SOTA system is composed of four main modules -- mapper, global planner,
local planner, and command-tracking controller -- in a hierarchical manner. In
this paper, we build a robust and safe local planner which is designed to
generate a velocity plan to track a coarsely planned path from the global
planner. Previous works used waypoint-based methods (e.g.
Proportional-Differential control and pure pursuit) which simplify the path
tracking problem to local point-goal navigation. However, they suffer from
frequent collisions in geometrically complex and narrow environments because of
two reasons; the global planner uses a coarse and inaccurate model and the
local planner is unable to track the global plan sufficiently well. Currently,
deep learning methods are an appealing alternative because they can learn
safety and path feasibility from experience more accurately. However, existing
deep learning methods are not capable of planning for a long horizon. In this
work, we propose a learning-based fully autonomous navigation framework
composed of three innovative elements: a learned forward dynamics model (FDM),
an online sampling-based model-predictive controller, and an informed
trajectory sampler (ITS). Using our framework, a quadruped robot can
autonomously navigate in various complex environments without a collision and
generate a smoother command plan compared to the baseline method. Furthermore,
our method can reactively handle unexpected obstacles on the planned path and
avoid them. Project page
https://awesomericky.github.io/projects/FDM_ITS_navigation/.

