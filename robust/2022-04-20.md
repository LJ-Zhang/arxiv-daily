### Title: One-Class Model for Fabric Defect Detection
* Paper ID: 2204.09648v1
* Paper URL: [http://arxiv.org/abs/2204.09648v1](http://arxiv.org/abs/2204.09648v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: An automated and accurate fabric defect inspection system is in high demand
as a replacement for slow, inconsistent, error-prone, and expensive human
operators in the textile industry. Previous efforts focused on certain types of
fabrics or defects, which is not an ideal solution. In this paper, we propose a
novel one-class model that is capable of detecting various defects on different
fabric types. Our model takes advantage of a well-designed Gabor filter bank to
analyze fabric texture. We then leverage an advanced deep learning algorithm,
autoencoder, to learn general feature representations from the outputs of the
Gabor filter bank. Lastly, we develop a nearest neighbor density estimator to
locate potential defects and draw them on the fabric images. We demonstrate the
effectiveness and robustness of the proposed model by testing it on various
types of fabrics such as plain, patterned, and rotated fabrics. Our model also
achieves a true positive rate (a.k.a recall) value of 0.895 with no false
alarms on our dataset based upon the Standard Fabric Defect Glossary.

### Title: Assembly Planning from Observations under Physical Constraints
* Paper ID: 2204.09616v1
* Paper URL: [http://arxiv.org/abs/2204.09616v1](http://arxiv.org/abs/2204.09616v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: This paper addresses the problem of copying an unknown assembly of primitives
with known shape and appearance using information extracted from a single
photograph by an off-the-shelf procedure for object detection and pose
estimation. The proposed algorithm uses a simple combination of physical
stability constraints, convex optimization and Monte Carlo tree search to plan
assemblies as sequences of pick-and-place operations represented by STRIPS
operators. It is efficient and, most importantly, robust to the errors in
object detection and pose estimation unavoidable in any real robotic system.
The proposed approach is demonstrated with thorough experiments on a UR5
manipulator.

### Title: On the Practical Design of Tube-Enhanced Multi-Stage Nonlinear Model Predictive Control
* Paper ID: 2204.09607v1
* Paper URL: [http://arxiv.org/abs/2204.09607v1](http://arxiv.org/abs/2204.09607v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Tube-enhanced multi-stage nonlinear model predictive control is a robust
control scheme that can handle a wide range of uncertainties with reduced
conservatism and manageable computational complexity. In this paper, we
elaborate on the flexibility of the approach from an application point of view.
We discuss the path to making design decisions to implement the novel scheme
systematically. We illustrate the critical steps in the design and
implementation of the scheme for an industrial example.

### Title: Federated Learning for Distributed Energy-Efficient Resource Allocation
* Paper ID: 2204.09602v1
* Paper URL: [http://arxiv.org/abs/2204.09602v1](http://arxiv.org/abs/2204.09602v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: In cellular networks, resource allocation is performed in a centralized way,
which brings huge computation complexity to the base station (BS) and high
transmission overhead. This paper investigates the distributed resource
allocation scheme for cellular networks to maximize the energy efficiency of
the system in the uplink transmission, while guaranteeing the quality of
service (QoS) for cellular users. Particularly, to cope the fast varying
channels in wireless communication environment, we propose a robust federated
reinforcement learning (FRL_suc) framework to enable local users to perform
distributed resource allocation in items of transmit power and channel
assignment by the guidance of the local neural network trained at each user.
Analysis and numerical results show that the proposed FRL_suc framework can
lower the transmission overhead and offload the computation from the central
server to the local users, while outperforming the conventional multi-agent
reinforcement learning algorithm in terms of EE, and is more robust to channel
variations.

### Title: Improved Worst-Group Robustness via Classifier Retraining on Independent Splits
* Paper ID: 2204.09583v1
* Paper URL: [http://arxiv.org/abs/2204.09583v1](http://arxiv.org/abs/2204.09583v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: High-capacity deep neural networks (DNNs) trained with Empirical Risk
Minimization (ERM) often suffer from poor worst-group accuracy despite good
on-average performance, where worst-group accuracy measures a model's
robustness towards certain subpopulations of the input space. Spurious
correlations and memorization behaviors of ERM trained DNNs are typically
attributed to this degradation in performance. We develop a method, called
CRIS, that address these issues by performing robust classifier retraining on
independent splits of the dataset. This results in a simple method that
improves upon state-of-the-art methods, such as Group DRO, on standard datasets
while relying on much fewer group labels and little additional hyperparameter
tuning.

### Title: Fast and Robust Femur Segmentation from Computed Tomography Images for Patient-Specific Hip Fracture Risk Screening
* Paper ID: 2204.09575v1
* Paper URL: [http://arxiv.org/abs/2204.09575v1](http://arxiv.org/abs/2204.09575v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Osteoporosis is a common bone disease that increases the risk of bone
fracture. Hip-fracture risk screening methods based on finite element analysis
depend on segmented computed tomography (CT) images; however, current femur
segmentation methods require manual delineations of large data sets. Here we
propose a deep neural network for fully automated, accurate, and fast
segmentation of the proximal femur from CT. Evaluation on a set of 1147
proximal femurs with ground truth segmentations demonstrates that our method is
apt for hip-fracture risk screening, bringing us one step closer to a
clinically viable option for screening at-risk patients for hip-fracture
susceptibility.

### Title: Tunable and giant valley-selective Hall effect in gapped bilayer graphene
* Paper ID: 2204.09525v1
* Paper URL: [http://arxiv.org/abs/2204.09525v1](http://arxiv.org/abs/2204.09525v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Berry curvature is analogous to magnetic field but in momentum space and is
commonly present in materials with non-trivial quantum geometry. It endows
Bloch electrons with transverse anomalous velocities to produce Hall-like
currents even in the absence of a magnetic field. We report the direct
observation of in situ tunable valley-selective Hall effect (VSHE), where
inversion symmetry, and thus the geometric phase of electrons, is controllable
by an out-of-plane electric field. We use high-quality bilayer graphene with an
intrinsic and tunable bandgap, illuminated by circularly polarized mid-infrared
light and confirm that the observed Hall voltage arises from an
optically-induced valley population. Compared with molybdenum disulfide, we
find orders of magnitude larger VSHE, attributed to the inverse scaling of the
Berry curvature with bandgap. By monitoring the valley-selective Hall
conductivity, we study Berry curvature's evolution with bandgap. This in situ
manipulation of VSHE paves the way for topological and quantum geometric
opto-electronic devices, such as more robust switches and detectors.

### Title: A Data-Driven Method for Automated Data Superposition with Applications in Soft Matter Science
* Paper ID: 2204.09521v1
* Paper URL: [http://arxiv.org/abs/2204.09521v1](http://arxiv.org/abs/2204.09521v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/krlennon/mastercurves](https://github.com/krlennon/mastercurves)
* Summary: The superposition of data sets with internal parametric self-similarity is a
longstanding and widespread technique for the analysis of many types of
experimental data across the physical sciences. Typically, this superposition
is performed manually, or recently by one of a few automated algorithms.
However, these methods are often heuristic in nature, are prone to user bias
via manual data shifting or parameterization, and lack a native framework for
handling uncertainty in both the data and the resulting model of the superposed
data. In this work, we develop a data-driven, non-parametric method for
superposing experimental data with arbitrary coordinate transformations, which
employs Gaussian process regression to learn statistical models that describe
the data, and then uses maximum a posteriori estimation to optimally superpose
the data sets. This statistical framework is robust to experimental noise, and
automatically produces uncertainty estimates for the learned coordinate
transformations. Moreover, it is distinguished from black-box machine learning
in its interpretability -- specifically, it produces a model that may itself be
interrogated to gain insight into the system under study. We demonstrate these
salient features of our method through its application to four representative
data sets characterizing the mechanics of soft materials. In every case, our
method replicates results obtained using other approaches, but with reduced
bias and the addition of uncertainty estimates. This method enables a
standardized, statistical treatment of self-similar data across many fields,
producing interpretable data-driven models that may inform applications such as
materials classification, design, and discovery.

### Title: A Reinforcement Learning-based Volt-VAR Control Dataset and Testing Environment
* Paper ID: 2204.09500v1
* Paper URL: [http://arxiv.org/abs/2204.09500v1](http://arxiv.org/abs/2204.09500v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/yg-smile/rl_vvc_dataset](https://github.com/yg-smile/rl_vvc_dataset)
* Summary: To facilitate the development of reinforcement learning (RL) based power
distribution system Volt-VAR control (VVC), this paper introduces a suite of
open-source datasets for RL-based VVC algorithm research that is sample
efficient, safe, and robust. The dataset consists of two components: 1. a
Gym-like VVC testing environment for the IEEE-13, 123, and 8500-bus test
feeders and 2. a historical operational dataset for each of the feeders.
Potential users of the dataset and testing environment could first train an
sample-efficient off-line (batch) RL algorithm on the historical dataset and
then evaluate the performance of the trained RL agent on the testing
environments. This dataset serves as a useful testbed to conduct RL-based VVC
research mimicking the real-world operational challenges faced by electric
utilities. Meanwhile, it allows researchers to conduct fair performance
comparisons between different algorithms.

### Title: THORN: Temporal Human-Object Relation Network for Action Recognition
* Paper ID: 2204.09468v1
* Paper URL: [http://arxiv.org/abs/2204.09468v1](http://arxiv.org/abs/2204.09468v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Most action recognition models treat human activities as unitary events.
However, human activities often follow a certain hierarchy. In fact, many human
activities are compositional. Also, these actions are mostly human-object
interactions. In this paper we propose to recognize human action by leveraging
the set of interactions that define an action. In this work, we present an
end-to-end network: THORN, that can leverage important human-object and
object-object interactions to predict actions. This model is built on top of a
3D backbone network. The key components of our model are: 1) An object
representation filter for modeling object. 2) An object relation reasoning
module to capture object relations. 3) A classification layer to predict the
action labels. To show the robustness of THORN, we evaluate it on
EPIC-Kitchen55 and EGTEA Gaze+, two of the largest and most challenging
first-person and human-object interaction datasets. THORN achieves
state-of-the-art performance on both datasets.

### Title: Is BERT Robust to Label Noise? A Study on Learning with Noisy Labels in Text Classification
* Paper ID: 2204.09371v1
* Paper URL: [http://arxiv.org/abs/2204.09371v1](http://arxiv.org/abs/2204.09371v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/uds-lsv/bert-lnl](https://github.com/uds-lsv/bert-lnl)
* Summary: Incorrect labels in training data occur when human annotators make mistakes
or when the data is generated via weak or distant supervision. It has been
shown that complex noise-handling techniques - by modeling, cleaning or
filtering the noisy instances - are required to prevent models from fitting
this label noise. However, we show in this work that, for text classification
tasks with modern NLP models like BERT, over a variety of noise types, existing
noisehandling methods do not always improve its performance, and may even
deteriorate it, suggesting the need for further investigation. We also back our
observations with a comprehensive analysis.

### Title: NFormer: Robust Person Re-identification with Neighbor Transformer
* Paper ID: 2204.09331v1
* Paper URL: [http://arxiv.org/abs/2204.09331v1](http://arxiv.org/abs/2204.09331v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Person re-identification aims to retrieve persons in highly varying settings
across different cameras and scenarios, in which robust and discriminative
representation learning is crucial. Most research considers learning
representations from single images, ignoring any potential interactions between
them. However, due to the high intra-identity variations, ignoring such
interactions typically leads to outlier features. To tackle this issue, we
propose a Neighbor Transformer Network, or NFormer, which explicitly models
interactions across all input images, thus suppressing outlier features and
leading to more robust representations overall. As modelling interactions
between enormous amount of images is a massive task with lots of distractors,
NFormer introduces two novel modules, the Landmark Agent Attention, and the
Reciprocal Neighbor Softmax. Specifically, the Landmark Agent Attention
efficiently models the relation map between images by a low-rank factorization
with a few landmarks in feature space. Moreover, the Reciprocal Neighbor
Softmax achieves sparse attention to relevant -- rather than all -- neighbors
only, which alleviates interference of irrelevant representations and further
relieves the computational burden. In experiments on four large-scale datasets,
NFormer achieves a new state-of-the-art. The code is released at
\url{https://github.com/haochenheheda/NFormer}.

### Title: Group relations, resilience and the I Ching
* Paper ID: 2204.09330v1
* Paper URL: [http://arxiv.org/abs/2204.09330v1](http://arxiv.org/abs/2204.09330v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: We evaluate the robustness and adaptivity of social groups with heterogeneous
agents that are characterized by their binary state, their ability to change
this state, their status and their preferred relations to other agents. To
define group structures, we operationalize the hexagrams of the \emph{I Ching}.
The relations and properties of agents are used to quantify their influence
according to the social impact theory. From these influence values we derive a
weighted stability measure for triads involving three agents, which is based on
the weighted balance theory. It allows to quantify the robustness of groups and
to propose a novel measure for group resilience which combines robustness and
adaptivity. A stochastic approach determines the probabilities to find robust
and adaptive groups. The discussion focuses on the generalization of our
approach.

### Title: Logarithmic Morphological Neural Nets robust to lighting variations
* Paper ID: 2204.09319v1
* Paper URL: [http://arxiv.org/abs/2204.09319v1](http://arxiv.org/abs/2204.09319v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Morphological neural networks allow to learn the weights of a structuring
function knowing the desired output image. However, those networks are not
intrinsically robust to lighting variations in images with an optical cause,
such as a change of light intensity. In this paper, we introduce a
morphological neural network which possesses such a robustness to lighting
variations. It is based on the recent framework of Logarithmic Mathematical
Morphology (LMM), i.e. Mathematical Morphology defined with the Logarithmic
Image Processing (LIP) model. This model has a LIP additive law which simulates
in images a variation of the light intensity. We especially learn the
structuring function of a LMM operator robust to those variations, namely : the
map of LIP-additive Asplund distances. Results in images show that our neural
network verifies the required property.

### Title: Massive Twinning to Enhance Emergent Intelligence
* Paper ID: 2204.09316v1
* Paper URL: [http://arxiv.org/abs/2204.09316v1](http://arxiv.org/abs/2204.09316v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Future Industrial Internet-of-Things in the upcoming 6G era is expected to
deploy artificial intelligence (AI) and digital twins (DTs) ubiquitously. As a
complement to conventional AI solutions, emergent intelligence (EI) exhibits
various outstanding features including robustness, protection to privacy, and
scalability, which makes it competitive for 6G IIoT applications. However,
despite its low computational complexity, it is challenged by its high demand
of data traffic in massive deployment. In this paper, we propose to exploit the
massive twinning paradigm, which 6G is envisaged to support, to reduce the data
traffic in EI and therewith enhance its performance.

### Title: Improving generalization of machine learning-identified biomarkers with causal modeling: an investigation into immune receptor diagnostics
* Paper ID: 2204.09291v1
* Paper URL: [http://arxiv.org/abs/2204.09291v1](http://arxiv.org/abs/2204.09291v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/uio-bmi/causalairr](https://github.com/uio-bmi/causalairr)
* Summary: Machine learning is increasingly used to discover diagnostic and prognostic
biomarkers from high-dimensional molecular data. However, a variety of factors
related to experimental design may affect the ability to learn generalizable
and clinically applicable diagnostics. Here, we argue that a causal perspective
improves the identification of these challenges, and formalizes their relation
to the robustness and generalization of machine learning-based diagnostics. To
make for a concrete discussion, we focus on a specific, recently established
high-dimensional biomarker - adaptive immune receptor repertoires (AIRRs). We
discuss how the main biological and experimental factors of the AIRR domain may
influence the learned biomarkers and provide easily adjustable simulations of
such effects. In conclusion, we find that causal modeling improves machine
learning-based biomarker robustness by identifying stable relations between
variables and by guiding the adjustment of the relations and variables that
vary between populations.

### Title: Varied magnetic phases in a van der Waals easy-plane antiferromagnet revealed by nitrogen-vacancy center microscopy
* Paper ID: 2204.09277v1
* Paper URL: [http://arxiv.org/abs/2204.09277v1](http://arxiv.org/abs/2204.09277v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Interest in van der Waals materials often stems from a desire to miniaturise
existing technologies by exploiting their intrinsic layered structure to create
near atomically-thin components that do not suffer from surface defects. One
appealing property is easily-switchable yet robust magnetic order, a quality
only sparsely demonstrated in the case of in-plane anisotropy. In this work, we
use widefield nitrogen-vacancy (NV) center magnetic imaging to measure the
properties of individual flakes of CuCrP$_2$S$_6$, a multiferroic van der Waals
magnet known to exhibit weak easy-plane anisotropy in the bulk. We chart the
crossover between in-plane ferromagnetism in thin flakes down to the trilayer,
and the bulk behaviour dominated by a low-field spin-flop transition. Further,
by exploiting the directional dependence of NV center magnetometry, we are able
to observe an instance of a predominantly out-of-plane ferromagetic phase near
zero field, in contradiction with expectation and previous experiments on the
bulk material. We attribute this to the presence of surface anisotropies
arising from the sample preparation process or exposure to the ambient
environment, which is expected to have more general implications for a broader
class of weakly anisotropic van der Waals magnets.

### Title: Synthetic Target Domain Supervision for Open Retrieval QA
* Paper ID: 2204.09248v1
* Paper URL: [http://arxiv.org/abs/2204.09248v1](http://arxiv.org/abs/2204.09248v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Neural passage retrieval is a new and promising approach in open retrieval
question answering. In this work, we stress-test the Dense Passage Retriever
(DPR) -- a state-of-the-art (SOTA) open domain neural retrieval model -- on
closed and specialized target domains such as COVID-19, and find that it lags
behind standard BM25 in this important real-world setting. To make DPR more
robust under domain shift, we explore its fine-tuning with synthetic training
examples, which we generate from unlabeled target domain text using a
text-to-text generator. In our experiments, this noisy but fully automated
target domain supervision gives DPR a sizable advantage over BM25 in
out-of-domain settings, making it a more viable model in practice. Finally, an
ensemble of BM25 and our improved DPR model yields the best results, further
pushing the SOTA for open retrieval QA on multiple out-of-domain test sets.

### Title: Visual-based Positioning and Pose Estimation
* Paper ID: 2204.09232v1
* Paper URL: [http://arxiv.org/abs/2204.09232v1](http://arxiv.org/abs/2204.09232v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Recent advances in deep learning and computer vision offer an excellent
opportunity to investigate high-level visual analysis tasks such as human
localization and human pose estimation. Although the performance of human
localization and human pose estimation has significantly improved in recent
reports, they are not perfect and erroneous localization and pose estimation
can be expected among video frames. Studies on the integration of these
techniques into a generic pipeline that is robust to noise introduced from
those errors are still lacking. This paper fills the missing study. We explored
and developed two working pipelines that suited the visual-based positioning
and pose estimation tasks. Analyses of the proposed pipelines were conducted on
a badminton game. We showed that the concept of tracking by detection could
work well, and errors in position and pose could be effectively handled by a
linear interpolation technique using information from nearby frames. The
results showed that the Visual-based Positioning and Pose Estimation could
deliver position and pose estimations with good spatial and temporal
resolutions.

### Title: Dark Spot Detection from SAR Images Based on Superpixel Deeper Graph Convolutional Network
* Paper ID: 2204.09230v1
* Paper URL: [http://arxiv.org/abs/2204.09230v1](http://arxiv.org/abs/2204.09230v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Synthetic Aperture Radar (SAR) is the main instrument utilized for the
detection of oil slicks on the ocean surface. In SAR images, some areas
affected by ocean phenomena, such as rain cells, upwellings, and internal
waves, or discharge from oil spills appear as dark spots on images. Dark spot
detection is the first step in the detection of oil spills, which then become
oil slick candidates. The accuracy of dark spot segmentation ultimately affects
the accuracy of oil slick identification. Although some advanced deep learning
methods that use pixels as processing units perform well in remote sensing
image semantic segmentation, detecting some dark spots with weak boundaries
from noisy SAR images remains a huge challenge. We propose a dark spot
detection method based on superpixels deeper graph convolutional networks
(SGDCN) in this paper, which takes the superpixels as the processing units and
extracts features for each superpixel. The features calculated from superpixel
regions are more robust than those from fixed pixel neighborhoods. To reduce
the difficulty of learning tasks, we discard irrelevant features and obtain an
optimal subset of features. After superpixel segmentation, the images are
transformed into graphs with superpixels as nodes, which are fed into the
deeper graph convolutional neural network for node classification. This graph
neural network uses a differentiable aggregation function to aggregate the
features of nodes and neighbors to form more advanced features. It is the first
time using it for dark spot detection. To validate our method, we mark all dark
spots on six SAR images covering the Baltic Sea and construct a dark spots
detection dataset, which has been made publicly available
(https://drive.google.com/drive/folders/12UavrntkDSPrItISQ8iGefXn2gIZHxJ6?usp=sharing).
The experimental results demonstrate that our proposed SGDCN is robust and
effective.

### Title: Interventional Multi-Instance Learning with Deconfounded Instance-Level Prediction
* Paper ID: 2204.09204v1
* Paper URL: [http://arxiv.org/abs/2204.09204v1](http://arxiv.org/abs/2204.09204v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: When applying multi-instance learning (MIL) to make predictions for bags of
instances, the prediction accuracy of an instance often depends on not only the
instance itself but also its context in the corresponding bag. From the
viewpoint of causal inference, such bag contextual prior works as a confounder
and may result in model robustness and interpretability issues. Focusing on
this problem, we propose a novel interventional multi-instance learning (IMIL)
framework to achieve deconfounded instance-level prediction. Unlike traditional
likelihood-based strategies, we design an Expectation-Maximization (EM)
algorithm based on causal intervention, providing a robust instance selection
in the training phase and suppressing the bias caused by the bag contextual
prior. Experiments on pathological image analysis demonstrate that our IMIL
method substantially reduces false positives and outperforms state-of-the-art
MIL methods.

### Title: Functional Calibration under Non-Probability Survey Sampling
* Paper ID: 2204.09193v1
* Paper URL: [http://arxiv.org/abs/2204.09193v1](http://arxiv.org/abs/2204.09193v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Non-probability sampling is prevailing in survey sampling, but ignoring its
selection bias leads to erroneous inferences. We offer a unified nonparametric
calibration method to estimate the sampling weights for a non-probability
sample by calibrating functions of auxiliary variables in a reproducing kernel
Hilbert space. The consistency and the limiting distribution of the proposed
estimator are established, and the corresponding variance estimator is also
investigated. Compared with existing works, the proposed method is more robust
since no parametric assumption is made for the selection mechanism of the
non-probability sample. Numerical results demonstrate that the proposed method
outperforms its competitors, especially when the model is misspecified. The
proposed method is applied to analyze the average total cholesterol of Korean
citizens based on a non-probability sample from the National Health Insurance
Sharing Service and a reference probability sample from the Korea National
Health and Nutrition Examination Survey.

### Title: Robustness Testing of Data and Knowledge Driven Anomaly Detection in Cyber-Physical Systems
* Paper ID: 2204.09183v1
* Paper URL: [http://arxiv.org/abs/2204.09183v1](http://arxiv.org/abs/2204.09183v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: The growing complexity of Cyber-Physical Systems (CPS) and challenges in
ensuring safety and security have led to the increasing use of deep learning
methods for accurate and scalable anomaly detection. However, machine learning
(ML) models often suffer from low performance in predicting unexpected data and
are vulnerable to accidental or malicious perturbations. Although robustness
testing of deep learning models has been extensively explored in applications
such as image classification and speech recognition, less attention has been
paid to ML-driven safety monitoring in CPS. This paper presents the preliminary
results on evaluating the robustness of ML-based anomaly detection methods in
safety-critical CPS against two types of accidental and malicious input
perturbations, generated using a Gaussian-based noise model and the Fast
Gradient Sign Method (FGSM). We test the hypothesis of whether integrating the
domain knowledge (e.g., on unsafe system behavior) with the ML models can
improve the robustness of anomaly detection without sacrificing accuracy and
transparency. Experimental results with two case studies of Artificial Pancreas
Systems (APS) for diabetes management show that ML-based safety monitors
trained with domain knowledge can reduce on average up to 54.2% of robustness
error and keep the average F1 scores high while improving transparency.

### Title: Learned Monocular Depth Priors in Visual-Inertial Initialization
* Paper ID: 2204.09171v1
* Paper URL: [http://arxiv.org/abs/2204.09171v1](http://arxiv.org/abs/2204.09171v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Visual-inertial odometry (VIO) is the pose estimation backbone for most AR/VR
and autonomous robotic systems today, in both academia and industry. However,
these systems are highly sensitive to the initialization of key parameters such
as sensor biases, gravity direction, and metric scale. In practical scenarios
where high-parallax or variable acceleration assumptions are rarely met (e.g.
hovering aerial robot, smartphone AR user not gesticulating with phone),
classical visual-inertial initialization formulations often become
ill-conditioned and/or fail to meaningfully converge. In this paper we target
visual-inertial initialization specifically for these low-excitation scenarios
critical to in-the-wild usage. We propose to circumvent the limitations of
classical visual-inertial structure-from-motion (SfM) initialization by
incorporating a new learning-based measurement as a higher-level input. We
leverage learned monocular depth images (mono-depth) to constrain the relative
depth of features, and upgrade the mono-depth to metric scale by jointly
optimizing for its scale and shift. Our experiments show a significant
improvement in problem conditioning compared to a classical formulation for
visual-inertial initialization, and demonstrate significant accuracy and
robustness improvements relative to the state-of-the-art on public benchmarks,
particularly under motion-restricted scenarios. We further extend this
improvement to implementation within an existing odometry system to illustrate
the impact of our improved initialization method on resulting tracking
trajectories.

### Title: Audio-Visual Wake Word Spotting System For MISP Challenge 2021
* Paper ID: 2204.08686v2
* Paper URL: [http://arxiv.org/abs/2204.08686v2](http://arxiv.org/abs/2204.08686v2)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: This paper presents the details of our system designed for the Task 1 of
Multimodal Information Based Speech Processing (MISP) Challenge 2021. The
purpose of Task 1 is to leverage both audio and video information to improve
the environmental robustness of far-field wake word spotting. In the proposed
system, firstly, we take advantage of speech enhancement algorithms such as
beamforming and weighted prediction error (WPE) to address the multi-microphone
conversational audio. Secondly, several data augmentation techniques are
applied to simulate a more realistic far-field scenario. For the video
information, the provided region of interest (ROI) is used to obtain visual
representation. Then the multi-layer CNN is proposed to learn audio and visual
representations, and these representations are fed into our two-branch
attention-based network which can be employed for fusion, such as transformer
and conformed. The focal loss is used to fine-tune the model and improve the
performance significantly. Finally, multiple trained models are integrated by
casting vote to achieve our final 0.091 score.

### Title: Multimodal Gaussian Mixture Model for Realtime Roadside LiDAR Object Detection
* Paper ID: 2204.09804v1
* Paper URL: [http://arxiv.org/abs/2204.09804v1](http://arxiv.org/abs/2204.09804v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Background modeling is widely used for intelligent surveillance systems to
detect the moving targets by subtracting the static background components. Most
roadside LiDAR object detection methods filter out foreground points by
comparing new points to pre-trained background references based on descriptive
statistics over many frames (e.g., voxel density, slopes, maximum distance).
These solutions are not efficient under heavy traffic, and parameter values are
hard to transfer from one scenario to another. In early studies, the
video-based background modeling methods were considered not suitable for
roadside LiDAR surveillance systems due to the sparse and unstructured point
clouds data. In this paper, the raw LiDAR data were transformed into a
multi-dimensional tensor structure based on the elevation and azimuth value of
each LiDAR point. With this high-order data representation, we break the
barrier to allow the efficient Gaussian Mixture Model (GMM) method for roadside
LiDAR background modeling. The probabilistic GMM is built with superior agility
and real-time capability. The proposed Method was compared against two
state-of-the-art roadside LiDAR background models and evaluated based on point
level, object level, and path level, demonstrating better robustness under
heavy traffic and challenging weather. This multimodal GMM method is capable of
handling dynamic backgrounds with noisy measurements and substantially enhances
the infrastructure-based LiDAR object detection, whereby various 3D modeling
for smart city applications could be created

### Title: GUARD: Graph Universal Adversarial Defense
* Paper ID: 2204.09803v1
* Paper URL: [http://arxiv.org/abs/2204.09803v1](http://arxiv.org/abs/2204.09803v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/edisonleeeee/guard](https://github.com/edisonleeeee/guard)
* Summary: Recently, graph convolutional networks (GCNs) have shown to be vulnerable to
small adversarial perturbations, which becomes a severe threat and largely
limits their applications in security-critical scenarios. To mitigate such a
threat, considerable research efforts have been devoted to increasing the
robustness of GCNs against adversarial attacks. However, current approaches for
defense are typically designed for the whole graph and consider the global
performance, posing challenges in protecting important local nodes from
stronger adversarial targeted attacks. In this work, we present a simple yet
effective method, named \textbf{\underline{G}}raph
\textbf{\underline{U}}niversal
\textbf{\underline{A}}dve\textbf{\underline{R}}sarial
\textbf{\underline{D}}efense (GUARD). Unlike previous works, GUARD protects
each individual node from attacks with a universal defensive patch, which is
generated once and can be applied to any node (node-agnostic) in a graph.
Extensive experiments on four benchmark datasets demonstrate that our method
significantly improves robustness for several established GCNs against multiple
adversarial attacks and outperforms existing adversarial defense methods by
large margins. Our code is publicly available at
https://github.com/EdisonLeeeee/GUARD.

### Title: Mobility unevenness in rock-paper-scissors models
* Paper ID: 2204.09798v1
* Paper URL: [http://arxiv.org/abs/2204.09798v1](http://arxiv.org/abs/2204.09798v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: We investigate a tritrophic system whose cyclic dominance is modelled by the
rock-paper-scissors game. We consider that organisms of one or two species are
affected by movement limitations, which unbalances the cyclic spatial game.
Performing stochastic simulations, we show that mobility unevenness controls
the population dynamics. In the case of one slow species, the predominant
species depends on the level of mobility restriction, with the slow species
being preponderant if the mobility limitations are substantial. If two species
face mobility limitations, our outcomes show that being higher dispersive does
not constitute an advantage in terms of population growth. On the contrary, if
organisms move with higher mobility, they expose themselves to enemies more
frequently, being more vulnerable to being eliminated. Finally, our findings
show that biodiversity benefits in regions where species are slowed.
Biodiversity loss for high mobility organisms, common to cyclic systems, may be
avoided with coexistence probability being higher for robust mobility
limitations. Our results may help biologists understand the dynamics of
unbalanced spatial systems where organisms' dispersal is fundamental to
biodiversity conservation.

### Title: Robust Phase Retrieval via Reverse Kullback-Leibler Divergence and Wirtinger Flow
* Paper ID: 2204.09791v1
* Paper URL: [http://arxiv.org/abs/2204.09791v1](http://arxiv.org/abs/2204.09791v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Robustness to noise and outliers is a desirable trait in phase retrieval
algorithms for many applications in imaging and signal processing. In this
paper, we develop a novel robust phase retrieval algorithm based on the
minimization of reverse Kullback-Leibler divergence (RKLD) within the Wirtinger
Flow (WF) framework. We use RKLD over intensity-only measurements in two
distinct ways: i) to design a novel initial estimate based on minimum
distortion design of spectral estimates, and ii) as a loss function for
iterative refinement based on WF. The RKLD-based loss function offers implicit
regularization by processing data at the logarithmic scale and provides the
following benefits: suppressing the influence of large magnitude errors and
promoting projections orthogonal to noise subspace. We present three algorithms
based on RKLD minimization, including two with truncation schemes to enhance
the robustness to significant contamination. Our numerical study demonstrates
the advantages of our algorithms in terms of sample efficiency, convergence
speed, and robustness to outliers over the state-of-the-art techniques using
both synthetic and real optical imaging data.

### Title: Evaluation of Robust Point Set Registration Applied to Automotive Doppler Radar
* Paper ID: 2204.09786v1
* Paper URL: [http://arxiv.org/abs/2204.09786v1](http://arxiv.org/abs/2204.09786v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Point set registration is the process of finding the best alignment between
two point sets, and it is a common task in different domains, especially in the
automotive and mobile robotics domains. Lots of approaches are proposed in the
literature, where the iterative closest point ICP is a well-known approach in
this vein, which builds an explicit correspondence between both point sets to
achieve the registration task. However, this work is interested in achieving
the registration without building any explicit correspondence between both
point sets, following a probabilistic framework.
  The most critical task in point set registration is how to elaborate the cost
function, which measures the distance between both point sets. The
probabilistic framework includes two possible ways to build the cost function:
The summing and the likelihood. The main focus of this work is to analyze and
compare the behavior of both approaches. Therefore, a 1D synthetic scenario is
used to build the cost function step by step, besides the estimation error.
Finally, this work uses two data sets for evaluation: A 2D synthetic data set
and a real data set. The evaluation process compares and analyzes the
estimation error and estimated uncertainty. Thus, two different methods are
used in the evaluation process: The normalized estimation error squared NEES
and noncredibility index NCI. A 77 GHz automotive Doppler radar provides the
real data set, and in the real evaluation, we evaluate the ego-motion
estimation of a robot as an application for the registration.

### Title: Can Voters Detect Errors on Their Printed Ballots? Absolutely
* Paper ID: 2204.09780v1
* Paper URL: [http://arxiv.org/abs/2204.09780v1](http://arxiv.org/abs/2204.09780v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: There is still debate on whether voters can detect malicious changes in their
printed ballot after making their selections on a Ballot Marking Device (BMD).
In this study, we altered votes on a voter's ballot after they had made their
selections on a BMD. We then required them to examine their ballots for any
changes from the slate they used to vote. Overall accuracy was exceptionally
high. Participants saw 1440 total contests, and of those 1440, there were a
total of 4 errors, so total accuracy was 99.8%. Participants were able to
perform with near-perfect accuracy regardless of ballot length, ballot type,
number of altered races, and location of altered races. Detection performance
was extremely robust. We conclude that with proper direction and resources,
voters can be near-perfect detectors of ballot changes on printed paper ballots
after voting with a BMD. This finding has significant implications for the
voting community as BMD use continues to grow. Research should now focus on
identifying administrative and behavioral methods that will prompt and
encourage voters to check their BMD-generated ballots before they drop them in
the ballot box.

### Title: Multi-Focus Image Fusion based on Gradient Transform
* Paper ID: 2204.09777v1
* Paper URL: [http://arxiv.org/abs/2204.09777v1](http://arxiv.org/abs/2204.09777v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Multi-focus image fusion is a challenging field of study that aims to provide
a completely focused image by integrating focused and un-focused pixels. Most
existing methods suffer from shift variance, misregistered images, and
data-dependent. In this study, we introduce a novel gradient information-based
multi-focus image fusion method that is robust for the aforementioned problems.
The proposed method first generates gradient images from original images by
using Halftoning-Inverse Halftoning (H-IH) transform. Then, Energy of Gradient
(EOG) and Standard Deviation functions are used as the focus measurement on the
gradient images to form a fused image. Finally, in order to enhance the fused
image a decision fusion approach is applied with the majority voting method.
The proposed method is compared with 17 different novel and conventional
techniques both visually and objectively. For objective evaluation, 6 different
quantitative metrics are used. It is observed that the proposed method is
promising according to visual evaluation and 83.3% success is achieved by being
first in five out of six metrics according to objective evaluation.

### Title: Delamination prediction in composite panels using unsupervised-feature learning methods with wavelet-enhanced guided wave representations
* Paper ID: 2204.09764v1
* Paper URL: [http://arxiv.org/abs/2204.09764v1](http://arxiv.org/abs/2204.09764v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: With the introduction of damage tolerance-based design philosophies, the
demand for reliable and robust structural health monitoring (SHM) procedures
for aerospace composite structures is increasing rapidly. The performance of
supervised learning algorithms for SHM depends on the amount of labeled and
balanced datasets. Apart from this, collecting datasets accommodating all
possible damage scenarios is cumbersome, costly, and inaccessible for aerospace
applications. In this paper, we have proposed two different
unsupervised-feature learning approaches where the algorithms are trained only
on the baseline scenarios to learn the distribution of baseline signals. The
trained unsupervised feature learner is used for delamination prediction with
an anomaly detection philosophy. In the first approach, we have combined
dimensionality reduction techniques (principal component analysis and
independent component analysis) with a one-class support vector machine. In
another approach, we have utilized deep learning-based deep convolutional
autoencoders (CAE). These state-of-the-art algorithms are applied on three
different guided wave-based experimental datasets. The raw guided wave signals
present in the datasets are converted into wavelet-enhanced higher-order
representations for training unsupervised feature-learning algorithms. We have
also compared different techniques, and it is seen that CAE generates better
reconstructions with lower mean squared error and can provide higher accuracy
on all the datasets.

### Title: An Adaptive and Robust Method for Multi-trait Analysis of Genome-wide Association Studies Using Summary Statistics
* Paper ID: 2204.09751v1
* Paper URL: [http://arxiv.org/abs/2204.09751v1](http://arxiv.org/abs/2204.09751v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Genome-wide association studies (GWAS) have identified thousands of genetic
variants associated with human traits or diseases in the past decade.
Nevertheless, much of the heritability of many traits is still unaccounted for.
Commonly used single-trait analysis methods are conservative, while multi-trait
methods improve statistical power by integrating association evidence across
multiple traits. In contrast to individual-level data, GWAS summary statistics
are usually publicly available, and thus methods using only summary statistics
have greater usage. Although many methods have been developed for joint
analysis of multiple traits using summary statistics, there are many issues,
including inconsistent performance, computational inefficiency, and numerical
problems when considering lots of traits. To address these challenges, we
propose a multi-trait adaptive Fisher method for summary statistics (MTAFS), a
computationally efficient method with robust power performance. We applied
MTAFS to two sets of brain image-derived phenotypes (IDPs) from the UK Biobank,
including a set of 58 Volumetric IDPs and a set of 212 Area IDPs. Together with
results from a simulation study, MTAFS shows its advantage over existing
multi-trait methods, with robust performance across a range of underlying
settings. It controls type 1 error well, and can efficiently handle a large
number of traits.

### Title: Is the $\bar θ$ parameter of QCD constant?
* Paper ID: 2204.09694v1
* Paper URL: [http://arxiv.org/abs/2204.09694v1](http://arxiv.org/abs/2204.09694v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Testing the variation of fundamental constants of Nature can provide valuable
insights into new physics scenarios. While many constraints have been derived
for Standard Model coupling constants and masses, the $\bar{\theta}$ parameter
of QCD has often been ignored in these studies. This letter discusses
potentially promising paths to investigate the time dependence of the
$\bar{\theta}$ parameter. While laboratory searches for CP-violating signals of
$\bar{\theta}$ yield the most robust bounds on today's value of $\bar{\theta}$,
we show that CP-conserving effects provide constraints on the variation of
$\bar{\theta}$ over cosmological time scales. We find no significant evidence
for a variation of $\bar{\theta}$ except for a mild hint around $z\sim 4$ which
would imply an "iron-deficient" Universe at high redshifts. Finally, we also
sketch an axion model which results in a varying $\bar{\theta}$ and could lead
to excess diffuse gamma ray background, from decays of axions produced in high
redshift supernova explosions.

### Title: Atmospheric Dynamics of a Near Tidally Locked Earth-Size Planet
* Paper ID: 2204.09696v1
* Paper URL: [http://arxiv.org/abs/2204.09696v1](http://arxiv.org/abs/2204.09696v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: The discovery and characterization of Earth-sized planets that are in, or
near, a tidally-locked state are of crucial importance to understanding
terrestrial planet evolution, and for which Venus is a clear analog.
Exoplanetary science lies at the threshold of characterizing hundreds of
terrestrial planetary atmospheres, thereby providing a statistical sample far
greater than the limited inventory of terrestrial planetary atmospheres within
the Solar System. However, the model-based approach for characterizing
exoplanet atmospheres relies on Solar System data, resulting in our limited
inventory being both foundational and critical atmospheric laboratories.
Present terrestrial exoplanet demographics are heavily biased toward
short-period planets, many of which are expected to be tidally locked, and also
potentially runaway greenhouse candidates, similar to Venus. Here we describe
the rise in the terrestrial exoplanet population and the study of tidal locking
on climate simulations. These exoplanet studies are placed within the context
of Venus, a local example of an Earth-sized, asynchronous rotator that is near
the tidal locking limit. We describe the recent lessons learned regarding the
dynamics of the Venusian atmosphere and how those lessons pertain to the
evolution of our sibling planet. We discuss the implications of these lessons
for exoplanet atmospheres, and outline the need for a full characterization of
the Venusian climate in order to achieve a full and robust interpretation of
terrestrial planetary atmospheres.

### Title: The Age of Discovery with the James Webb: Excavating the Spectral Signatures of the First Massive Black Holes
* Paper ID: 2204.09692v1
* Paper URL: [http://arxiv.org/abs/2204.09692v1](http://arxiv.org/abs/2204.09692v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: The James Webb Space Telescope (JWST) will open a new window of the most
distant universe and unveil the early growth of supermassive black holes (BHs)
in the first galaxies. In preparation for deep JWST imaging surveys, it is
crucial to understand the color selection of high-redshift accreting seed BHs.
We model the spectral energy distribution of super-Eddington accreting BHs with
millions of solar masses in metal-poor galaxies at $z\gtrsim 8$, applying
post-process line transfer calculations to radiation hydrodynamical simulation
results. Ten kilosecond exposures with the NIRCam and MIRI broad-band filters
are sufficient to detect the radiation flux from the seed BHs with bolometric
luminosities of $L_{\rm bol}\simeq 10^{45}~{\rm erg~s}^{-1}$. While the
continuum colors are similar to those of typical low-$z$ quasars, strong
H$\alpha$ line emission with a rest-frame equivalent width ${\rm EW}_{\rm
rest}\simeq 1300~\r{A}$ is so prominent that the line flux affects the
broad-band colors significantly. The unique colors, for instance F356W$-$F560W
$\gtrsim 1$ at $7<z<8$ and F444W$-$F770W $\gtrsim 1$ at $9<z<12$, provide
robust criteria for photometric selection of the rapidly growing seed BHs.
Moreover, NIRSpec observations of low-ionization emission lines can test
whether the BH is fed via a dense accretion disk at super-Eddington rates.

### Title: One-Class Model for Fabric Defect Detection
* Paper ID: 2204.09648v1
* Paper URL: [http://arxiv.org/abs/2204.09648v1](http://arxiv.org/abs/2204.09648v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: An automated and accurate fabric defect inspection system is in high demand
as a replacement for slow, inconsistent, error-prone, and expensive human
operators in the textile industry. Previous efforts focused on certain types of
fabrics or defects, which is not an ideal solution. In this paper, we propose a
novel one-class model that is capable of detecting various defects on different
fabric types. Our model takes advantage of a well-designed Gabor filter bank to
analyze fabric texture. We then leverage an advanced deep learning algorithm,
autoencoder, to learn general feature representations from the outputs of the
Gabor filter bank. Lastly, we develop a nearest neighbor density estimator to
locate potential defects and draw them on the fabric images. We demonstrate the
effectiveness and robustness of the proposed model by testing it on various
types of fabrics such as plain, patterned, and rotated fabrics. Our model also
achieves a true positive rate (a.k.a recall) value of 0.895 with no false
alarms on our dataset based upon the Standard Fabric Defect Glossary.

### Title: Assembly Planning from Observations under Physical Constraints
* Paper ID: 2204.09616v1
* Paper URL: [http://arxiv.org/abs/2204.09616v1](http://arxiv.org/abs/2204.09616v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: This paper addresses the problem of copying an unknown assembly of primitives
with known shape and appearance using information extracted from a single
photograph by an off-the-shelf procedure for object detection and pose
estimation. The proposed algorithm uses a simple combination of physical
stability constraints, convex optimization and Monte Carlo tree search to plan
assemblies as sequences of pick-and-place operations represented by STRIPS
operators. It is efficient and, most importantly, robust to the errors in
object detection and pose estimation unavoidable in any real robotic system.
The proposed approach is demonstrated with thorough experiments on a UR5
manipulator.

### Title: On the Practical Design of Tube-Enhanced Multi-Stage Nonlinear Model Predictive Control
* Paper ID: 2204.09607v1
* Paper URL: [http://arxiv.org/abs/2204.09607v1](http://arxiv.org/abs/2204.09607v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Tube-enhanced multi-stage nonlinear model predictive control is a robust
control scheme that can handle a wide range of uncertainties with reduced
conservatism and manageable computational complexity. In this paper, we
elaborate on the flexibility of the approach from an application point of view.
We discuss the path to making design decisions to implement the novel scheme
systematically. We illustrate the critical steps in the design and
implementation of the scheme for an industrial example.

### Title: Federated Learning for Distributed Energy-Efficient Resource Allocation
* Paper ID: 2204.09602v1
* Paper URL: [http://arxiv.org/abs/2204.09602v1](http://arxiv.org/abs/2204.09602v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: In cellular networks, resource allocation is performed in a centralized way,
which brings huge computation complexity to the base station (BS) and high
transmission overhead. This paper investigates the distributed resource
allocation scheme for cellular networks to maximize the energy efficiency of
the system in the uplink transmission, while guaranteeing the quality of
service (QoS) for cellular users. Particularly, to cope the fast varying
channels in wireless communication environment, we propose a robust federated
reinforcement learning (FRL_suc) framework to enable local users to perform
distributed resource allocation in items of transmit power and channel
assignment by the guidance of the local neural network trained at each user.
Analysis and numerical results show that the proposed FRL_suc framework can
lower the transmission overhead and offload the computation from the central
server to the local users, while outperforming the conventional multi-agent
reinforcement learning algorithm in terms of EE, and is more robust to channel
variations.

### Title: Improved Worst-Group Robustness via Classifier Retraining on Independent Splits
* Paper ID: 2204.09583v1
* Paper URL: [http://arxiv.org/abs/2204.09583v1](http://arxiv.org/abs/2204.09583v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: High-capacity deep neural networks (DNNs) trained with Empirical Risk
Minimization (ERM) often suffer from poor worst-group accuracy despite good
on-average performance, where worst-group accuracy measures a model's
robustness towards certain subpopulations of the input space. Spurious
correlations and memorization behaviors of ERM trained DNNs are typically
attributed to this degradation in performance. We develop a method, called
CRIS, that address these issues by performing robust classifier retraining on
independent splits of the dataset. This results in a simple method that
improves upon state-of-the-art methods, such as Group DRO, on standard datasets
while relying on much fewer group labels and little additional hyperparameter
tuning.

### Title: Fast and Robust Femur Segmentation from Computed Tomography Images for Patient-Specific Hip Fracture Risk Screening
* Paper ID: 2204.09575v1
* Paper URL: [http://arxiv.org/abs/2204.09575v1](http://arxiv.org/abs/2204.09575v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Osteoporosis is a common bone disease that increases the risk of bone
fracture. Hip-fracture risk screening methods based on finite element analysis
depend on segmented computed tomography (CT) images; however, current femur
segmentation methods require manual delineations of large data sets. Here we
propose a deep neural network for fully automated, accurate, and fast
segmentation of the proximal femur from CT. Evaluation on a set of 1147
proximal femurs with ground truth segmentations demonstrates that our method is
apt for hip-fracture risk screening, bringing us one step closer to a
clinically viable option for screening at-risk patients for hip-fracture
susceptibility.

### Title: Tunable and giant valley-selective Hall effect in gapped bilayer graphene
* Paper ID: 2204.09525v1
* Paper URL: [http://arxiv.org/abs/2204.09525v1](http://arxiv.org/abs/2204.09525v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Berry curvature is analogous to magnetic field but in momentum space and is
commonly present in materials with non-trivial quantum geometry. It endows
Bloch electrons with transverse anomalous velocities to produce Hall-like
currents even in the absence of a magnetic field. We report the direct
observation of in situ tunable valley-selective Hall effect (VSHE), where
inversion symmetry, and thus the geometric phase of electrons, is controllable
by an out-of-plane electric field. We use high-quality bilayer graphene with an
intrinsic and tunable bandgap, illuminated by circularly polarized mid-infrared
light and confirm that the observed Hall voltage arises from an
optically-induced valley population. Compared with molybdenum disulfide, we
find orders of magnitude larger VSHE, attributed to the inverse scaling of the
Berry curvature with bandgap. By monitoring the valley-selective Hall
conductivity, we study Berry curvature's evolution with bandgap. This in situ
manipulation of VSHE paves the way for topological and quantum geometric
opto-electronic devices, such as more robust switches and detectors.

### Title: A Data-Driven Method for Automated Data Superposition with Applications in Soft Matter Science
* Paper ID: 2204.09521v1
* Paper URL: [http://arxiv.org/abs/2204.09521v1](http://arxiv.org/abs/2204.09521v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/krlennon/mastercurves](https://github.com/krlennon/mastercurves)
* Summary: The superposition of data sets with internal parametric self-similarity is a
longstanding and widespread technique for the analysis of many types of
experimental data across the physical sciences. Typically, this superposition
is performed manually, or recently by one of a few automated algorithms.
However, these methods are often heuristic in nature, are prone to user bias
via manual data shifting or parameterization, and lack a native framework for
handling uncertainty in both the data and the resulting model of the superposed
data. In this work, we develop a data-driven, non-parametric method for
superposing experimental data with arbitrary coordinate transformations, which
employs Gaussian process regression to learn statistical models that describe
the data, and then uses maximum a posteriori estimation to optimally superpose
the data sets. This statistical framework is robust to experimental noise, and
automatically produces uncertainty estimates for the learned coordinate
transformations. Moreover, it is distinguished from black-box machine learning
in its interpretability -- specifically, it produces a model that may itself be
interrogated to gain insight into the system under study. We demonstrate these
salient features of our method through its application to four representative
data sets characterizing the mechanics of soft materials. In every case, our
method replicates results obtained using other approaches, but with reduced
bias and the addition of uncertainty estimates. This method enables a
standardized, statistical treatment of self-similar data across many fields,
producing interpretable data-driven models that may inform applications such as
materials classification, design, and discovery.

### Title: A Reinforcement Learning-based Volt-VAR Control Dataset and Testing Environment
* Paper ID: 2204.09500v1
* Paper URL: [http://arxiv.org/abs/2204.09500v1](http://arxiv.org/abs/2204.09500v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/yg-smile/rl_vvc_dataset](https://github.com/yg-smile/rl_vvc_dataset)
* Summary: To facilitate the development of reinforcement learning (RL) based power
distribution system Volt-VAR control (VVC), this paper introduces a suite of
open-source datasets for RL-based VVC algorithm research that is sample
efficient, safe, and robust. The dataset consists of two components: 1. a
Gym-like VVC testing environment for the IEEE-13, 123, and 8500-bus test
feeders and 2. a historical operational dataset for each of the feeders.
Potential users of the dataset and testing environment could first train an
sample-efficient off-line (batch) RL algorithm on the historical dataset and
then evaluate the performance of the trained RL agent on the testing
environments. This dataset serves as a useful testbed to conduct RL-based VVC
research mimicking the real-world operational challenges faced by electric
utilities. Meanwhile, it allows researchers to conduct fair performance
comparisons between different algorithms.

### Title: THORN: Temporal Human-Object Relation Network for Action Recognition
* Paper ID: 2204.09468v1
* Paper URL: [http://arxiv.org/abs/2204.09468v1](http://arxiv.org/abs/2204.09468v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Most action recognition models treat human activities as unitary events.
However, human activities often follow a certain hierarchy. In fact, many human
activities are compositional. Also, these actions are mostly human-object
interactions. In this paper we propose to recognize human action by leveraging
the set of interactions that define an action. In this work, we present an
end-to-end network: THORN, that can leverage important human-object and
object-object interactions to predict actions. This model is built on top of a
3D backbone network. The key components of our model are: 1) An object
representation filter for modeling object. 2) An object relation reasoning
module to capture object relations. 3) A classification layer to predict the
action labels. To show the robustness of THORN, we evaluate it on
EPIC-Kitchen55 and EGTEA Gaze+, two of the largest and most challenging
first-person and human-object interaction datasets. THORN achieves
state-of-the-art performance on both datasets.

### Title: Is BERT Robust to Label Noise? A Study on Learning with Noisy Labels in Text Classification
* Paper ID: 2204.09371v1
* Paper URL: [http://arxiv.org/abs/2204.09371v1](http://arxiv.org/abs/2204.09371v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/uds-lsv/bert-lnl](https://github.com/uds-lsv/bert-lnl)
* Summary: Incorrect labels in training data occur when human annotators make mistakes
or when the data is generated via weak or distant supervision. It has been
shown that complex noise-handling techniques - by modeling, cleaning or
filtering the noisy instances - are required to prevent models from fitting
this label noise. However, we show in this work that, for text classification
tasks with modern NLP models like BERT, over a variety of noise types, existing
noisehandling methods do not always improve its performance, and may even
deteriorate it, suggesting the need for further investigation. We also back our
observations with a comprehensive analysis.

### Title: NFormer: Robust Person Re-identification with Neighbor Transformer
* Paper ID: 2204.09331v1
* Paper URL: [http://arxiv.org/abs/2204.09331v1](http://arxiv.org/abs/2204.09331v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Person re-identification aims to retrieve persons in highly varying settings
across different cameras and scenarios, in which robust and discriminative
representation learning is crucial. Most research considers learning
representations from single images, ignoring any potential interactions between
them. However, due to the high intra-identity variations, ignoring such
interactions typically leads to outlier features. To tackle this issue, we
propose a Neighbor Transformer Network, or NFormer, which explicitly models
interactions across all input images, thus suppressing outlier features and
leading to more robust representations overall. As modelling interactions
between enormous amount of images is a massive task with lots of distractors,
NFormer introduces two novel modules, the Landmark Agent Attention, and the
Reciprocal Neighbor Softmax. Specifically, the Landmark Agent Attention
efficiently models the relation map between images by a low-rank factorization
with a few landmarks in feature space. Moreover, the Reciprocal Neighbor
Softmax achieves sparse attention to relevant -- rather than all -- neighbors
only, which alleviates interference of irrelevant representations and further
relieves the computational burden. In experiments on four large-scale datasets,
NFormer achieves a new state-of-the-art. The code is released at
\url{https://github.com/haochenheheda/NFormer}.

### Title: Group relations, resilience and the I Ching
* Paper ID: 2204.09330v1
* Paper URL: [http://arxiv.org/abs/2204.09330v1](http://arxiv.org/abs/2204.09330v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: We evaluate the robustness and adaptivity of social groups with heterogeneous
agents that are characterized by their binary state, their ability to change
this state, their status and their preferred relations to other agents. To
define group structures, we operationalize the hexagrams of the \emph{I Ching}.
The relations and properties of agents are used to quantify their influence
according to the social impact theory. From these influence values we derive a
weighted stability measure for triads involving three agents, which is based on
the weighted balance theory. It allows to quantify the robustness of groups and
to propose a novel measure for group resilience which combines robustness and
adaptivity. A stochastic approach determines the probabilities to find robust
and adaptive groups. The discussion focuses on the generalization of our
approach.

### Title: Logarithmic Morphological Neural Nets robust to lighting variations
* Paper ID: 2204.09319v1
* Paper URL: [http://arxiv.org/abs/2204.09319v1](http://arxiv.org/abs/2204.09319v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Morphological neural networks allow to learn the weights of a structuring
function knowing the desired output image. However, those networks are not
intrinsically robust to lighting variations in images with an optical cause,
such as a change of light intensity. In this paper, we introduce a
morphological neural network which possesses such a robustness to lighting
variations. It is based on the recent framework of Logarithmic Mathematical
Morphology (LMM), i.e. Mathematical Morphology defined with the Logarithmic
Image Processing (LIP) model. This model has a LIP additive law which simulates
in images a variation of the light intensity. We especially learn the
structuring function of a LMM operator robust to those variations, namely : the
map of LIP-additive Asplund distances. Results in images show that our neural
network verifies the required property.

### Title: Massive Twinning to Enhance Emergent Intelligence
* Paper ID: 2204.09316v1
* Paper URL: [http://arxiv.org/abs/2204.09316v1](http://arxiv.org/abs/2204.09316v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Future Industrial Internet-of-Things in the upcoming 6G era is expected to
deploy artificial intelligence (AI) and digital twins (DTs) ubiquitously. As a
complement to conventional AI solutions, emergent intelligence (EI) exhibits
various outstanding features including robustness, protection to privacy, and
scalability, which makes it competitive for 6G IIoT applications. However,
despite its low computational complexity, it is challenged by its high demand
of data traffic in massive deployment. In this paper, we propose to exploit the
massive twinning paradigm, which 6G is envisaged to support, to reduce the data
traffic in EI and therewith enhance its performance.

### Title: Improving generalization of machine learning-identified biomarkers with causal modeling: an investigation into immune receptor diagnostics
* Paper ID: 2204.09291v1
* Paper URL: [http://arxiv.org/abs/2204.09291v1](http://arxiv.org/abs/2204.09291v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/uio-bmi/causalairr](https://github.com/uio-bmi/causalairr)
* Summary: Machine learning is increasingly used to discover diagnostic and prognostic
biomarkers from high-dimensional molecular data. However, a variety of factors
related to experimental design may affect the ability to learn generalizable
and clinically applicable diagnostics. Here, we argue that a causal perspective
improves the identification of these challenges, and formalizes their relation
to the robustness and generalization of machine learning-based diagnostics. To
make for a concrete discussion, we focus on a specific, recently established
high-dimensional biomarker - adaptive immune receptor repertoires (AIRRs). We
discuss how the main biological and experimental factors of the AIRR domain may
influence the learned biomarkers and provide easily adjustable simulations of
such effects. In conclusion, we find that causal modeling improves machine
learning-based biomarker robustness by identifying stable relations between
variables and by guiding the adjustment of the relations and variables that
vary between populations.

### Title: Varied magnetic phases in a van der Waals easy-plane antiferromagnet revealed by nitrogen-vacancy center microscopy
* Paper ID: 2204.09277v1
* Paper URL: [http://arxiv.org/abs/2204.09277v1](http://arxiv.org/abs/2204.09277v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Interest in van der Waals materials often stems from a desire to miniaturise
existing technologies by exploiting their intrinsic layered structure to create
near atomically-thin components that do not suffer from surface defects. One
appealing property is easily-switchable yet robust magnetic order, a quality
only sparsely demonstrated in the case of in-plane anisotropy. In this work, we
use widefield nitrogen-vacancy (NV) center magnetic imaging to measure the
properties of individual flakes of CuCrP$_2$S$_6$, a multiferroic van der Waals
magnet known to exhibit weak easy-plane anisotropy in the bulk. We chart the
crossover between in-plane ferromagnetism in thin flakes down to the trilayer,
and the bulk behaviour dominated by a low-field spin-flop transition. Further,
by exploiting the directional dependence of NV center magnetometry, we are able
to observe an instance of a predominantly out-of-plane ferromagetic phase near
zero field, in contradiction with expectation and previous experiments on the
bulk material. We attribute this to the presence of surface anisotropies
arising from the sample preparation process or exposure to the ambient
environment, which is expected to have more general implications for a broader
class of weakly anisotropic van der Waals magnets.

### Title: Synthetic Target Domain Supervision for Open Retrieval QA
* Paper ID: 2204.09248v1
* Paper URL: [http://arxiv.org/abs/2204.09248v1](http://arxiv.org/abs/2204.09248v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Neural passage retrieval is a new and promising approach in open retrieval
question answering. In this work, we stress-test the Dense Passage Retriever
(DPR) -- a state-of-the-art (SOTA) open domain neural retrieval model -- on
closed and specialized target domains such as COVID-19, and find that it lags
behind standard BM25 in this important real-world setting. To make DPR more
robust under domain shift, we explore its fine-tuning with synthetic training
examples, which we generate from unlabeled target domain text using a
text-to-text generator. In our experiments, this noisy but fully automated
target domain supervision gives DPR a sizable advantage over BM25 in
out-of-domain settings, making it a more viable model in practice. Finally, an
ensemble of BM25 and our improved DPR model yields the best results, further
pushing the SOTA for open retrieval QA on multiple out-of-domain test sets.

### Title: Visual-based Positioning and Pose Estimation
* Paper ID: 2204.09232v1
* Paper URL: [http://arxiv.org/abs/2204.09232v1](http://arxiv.org/abs/2204.09232v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Recent advances in deep learning and computer vision offer an excellent
opportunity to investigate high-level visual analysis tasks such as human
localization and human pose estimation. Although the performance of human
localization and human pose estimation has significantly improved in recent
reports, they are not perfect and erroneous localization and pose estimation
can be expected among video frames. Studies on the integration of these
techniques into a generic pipeline that is robust to noise introduced from
those errors are still lacking. This paper fills the missing study. We explored
and developed two working pipelines that suited the visual-based positioning
and pose estimation tasks. Analyses of the proposed pipelines were conducted on
a badminton game. We showed that the concept of tracking by detection could
work well, and errors in position and pose could be effectively handled by a
linear interpolation technique using information from nearby frames. The
results showed that the Visual-based Positioning and Pose Estimation could
deliver position and pose estimations with good spatial and temporal
resolutions.

### Title: Dark Spot Detection from SAR Images Based on Superpixel Deeper Graph Convolutional Network
* Paper ID: 2204.09230v1
* Paper URL: [http://arxiv.org/abs/2204.09230v1](http://arxiv.org/abs/2204.09230v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Synthetic Aperture Radar (SAR) is the main instrument utilized for the
detection of oil slicks on the ocean surface. In SAR images, some areas
affected by ocean phenomena, such as rain cells, upwellings, and internal
waves, or discharge from oil spills appear as dark spots on images. Dark spot
detection is the first step in the detection of oil spills, which then become
oil slick candidates. The accuracy of dark spot segmentation ultimately affects
the accuracy of oil slick identification. Although some advanced deep learning
methods that use pixels as processing units perform well in remote sensing
image semantic segmentation, detecting some dark spots with weak boundaries
from noisy SAR images remains a huge challenge. We propose a dark spot
detection method based on superpixels deeper graph convolutional networks
(SGDCN) in this paper, which takes the superpixels as the processing units and
extracts features for each superpixel. The features calculated from superpixel
regions are more robust than those from fixed pixel neighborhoods. To reduce
the difficulty of learning tasks, we discard irrelevant features and obtain an
optimal subset of features. After superpixel segmentation, the images are
transformed into graphs with superpixels as nodes, which are fed into the
deeper graph convolutional neural network for node classification. This graph
neural network uses a differentiable aggregation function to aggregate the
features of nodes and neighbors to form more advanced features. It is the first
time using it for dark spot detection. To validate our method, we mark all dark
spots on six SAR images covering the Baltic Sea and construct a dark spots
detection dataset, which has been made publicly available
(https://drive.google.com/drive/folders/12UavrntkDSPrItISQ8iGefXn2gIZHxJ6?usp=sharing).
The experimental results demonstrate that our proposed SGDCN is robust and
effective.

### Title: Interventional Multi-Instance Learning with Deconfounded Instance-Level Prediction
* Paper ID: 2204.09204v1
* Paper URL: [http://arxiv.org/abs/2204.09204v1](http://arxiv.org/abs/2204.09204v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: When applying multi-instance learning (MIL) to make predictions for bags of
instances, the prediction accuracy of an instance often depends on not only the
instance itself but also its context in the corresponding bag. From the
viewpoint of causal inference, such bag contextual prior works as a confounder
and may result in model robustness and interpretability issues. Focusing on
this problem, we propose a novel interventional multi-instance learning (IMIL)
framework to achieve deconfounded instance-level prediction. Unlike traditional
likelihood-based strategies, we design an Expectation-Maximization (EM)
algorithm based on causal intervention, providing a robust instance selection
in the training phase and suppressing the bias caused by the bag contextual
prior. Experiments on pathological image analysis demonstrate that our IMIL
method substantially reduces false positives and outperforms state-of-the-art
MIL methods.

### Title: Functional Calibration under Non-Probability Survey Sampling
* Paper ID: 2204.09193v1
* Paper URL: [http://arxiv.org/abs/2204.09193v1](http://arxiv.org/abs/2204.09193v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Non-probability sampling is prevailing in survey sampling, but ignoring its
selection bias leads to erroneous inferences. We offer a unified nonparametric
calibration method to estimate the sampling weights for a non-probability
sample by calibrating functions of auxiliary variables in a reproducing kernel
Hilbert space. The consistency and the limiting distribution of the proposed
estimator are established, and the corresponding variance estimator is also
investigated. Compared with existing works, the proposed method is more robust
since no parametric assumption is made for the selection mechanism of the
non-probability sample. Numerical results demonstrate that the proposed method
outperforms its competitors, especially when the model is misspecified. The
proposed method is applied to analyze the average total cholesterol of Korean
citizens based on a non-probability sample from the National Health Insurance
Sharing Service and a reference probability sample from the Korea National
Health and Nutrition Examination Survey.

### Title: Robustness Testing of Data and Knowledge Driven Anomaly Detection in Cyber-Physical Systems
* Paper ID: 2204.09183v1
* Paper URL: [http://arxiv.org/abs/2204.09183v1](http://arxiv.org/abs/2204.09183v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: The growing complexity of Cyber-Physical Systems (CPS) and challenges in
ensuring safety and security have led to the increasing use of deep learning
methods for accurate and scalable anomaly detection. However, machine learning
(ML) models often suffer from low performance in predicting unexpected data and
are vulnerable to accidental or malicious perturbations. Although robustness
testing of deep learning models has been extensively explored in applications
such as image classification and speech recognition, less attention has been
paid to ML-driven safety monitoring in CPS. This paper presents the preliminary
results on evaluating the robustness of ML-based anomaly detection methods in
safety-critical CPS against two types of accidental and malicious input
perturbations, generated using a Gaussian-based noise model and the Fast
Gradient Sign Method (FGSM). We test the hypothesis of whether integrating the
domain knowledge (e.g., on unsafe system behavior) with the ML models can
improve the robustness of anomaly detection without sacrificing accuracy and
transparency. Experimental results with two case studies of Artificial Pancreas
Systems (APS) for diabetes management show that ML-based safety monitors
trained with domain knowledge can reduce on average up to 54.2% of robustness
error and keep the average F1 scores high while improving transparency.

### Title: Learned Monocular Depth Priors in Visual-Inertial Initialization
* Paper ID: 2204.09171v1
* Paper URL: [http://arxiv.org/abs/2204.09171v1](http://arxiv.org/abs/2204.09171v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Visual-inertial odometry (VIO) is the pose estimation backbone for most AR/VR
and autonomous robotic systems today, in both academia and industry. However,
these systems are highly sensitive to the initialization of key parameters such
as sensor biases, gravity direction, and metric scale. In practical scenarios
where high-parallax or variable acceleration assumptions are rarely met (e.g.
hovering aerial robot, smartphone AR user not gesticulating with phone),
classical visual-inertial initialization formulations often become
ill-conditioned and/or fail to meaningfully converge. In this paper we target
visual-inertial initialization specifically for these low-excitation scenarios
critical to in-the-wild usage. We propose to circumvent the limitations of
classical visual-inertial structure-from-motion (SfM) initialization by
incorporating a new learning-based measurement as a higher-level input. We
leverage learned monocular depth images (mono-depth) to constrain the relative
depth of features, and upgrade the mono-depth to metric scale by jointly
optimizing for its scale and shift. Our experiments show a significant
improvement in problem conditioning compared to a classical formulation for
visual-inertial initialization, and demonstrate significant accuracy and
robustness improvements relative to the state-of-the-art on public benchmarks,
particularly under motion-restricted scenarios. We further extend this
improvement to implementation within an existing odometry system to illustrate
the impact of our improved initialization method on resulting tracking
trajectories.

### Title: Multimodal Gaussian Mixture Model for Realtime Roadside LiDAR Object Detection
* Paper ID: 2204.09804v1
* Paper URL: [http://arxiv.org/abs/2204.09804v1](http://arxiv.org/abs/2204.09804v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Background modeling is widely used for intelligent surveillance systems to
detect the moving targets by subtracting the static background components. Most
roadside LiDAR object detection methods filter out foreground points by
comparing new points to pre-trained background references based on descriptive
statistics over many frames (e.g., voxel density, slopes, maximum distance).
These solutions are not efficient under heavy traffic, and parameter values are
hard to transfer from one scenario to another. In early studies, the
video-based background modeling methods were considered not suitable for
roadside LiDAR surveillance systems due to the sparse and unstructured point
clouds data. In this paper, the raw LiDAR data were transformed into a
multi-dimensional tensor structure based on the elevation and azimuth value of
each LiDAR point. With this high-order data representation, we break the
barrier to allow the efficient Gaussian Mixture Model (GMM) method for roadside
LiDAR background modeling. The probabilistic GMM is built with superior agility
and real-time capability. The proposed Method was compared against two
state-of-the-art roadside LiDAR background models and evaluated based on point
level, object level, and path level, demonstrating better robustness under
heavy traffic and challenging weather. This multimodal GMM method is capable of
handling dynamic backgrounds with noisy measurements and substantially enhances
the infrastructure-based LiDAR object detection, whereby various 3D modeling
for smart city applications could be created

### Title: GUARD: Graph Universal Adversarial Defense
* Paper ID: 2204.09803v1
* Paper URL: [http://arxiv.org/abs/2204.09803v1](http://arxiv.org/abs/2204.09803v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/edisonleeeee/guard](https://github.com/edisonleeeee/guard)
* Summary: Recently, graph convolutional networks (GCNs) have shown to be vulnerable to
small adversarial perturbations, which becomes a severe threat and largely
limits their applications in security-critical scenarios. To mitigate such a
threat, considerable research efforts have been devoted to increasing the
robustness of GCNs against adversarial attacks. However, current approaches for
defense are typically designed for the whole graph and consider the global
performance, posing challenges in protecting important local nodes from
stronger adversarial targeted attacks. In this work, we present a simple yet
effective method, named \textbf{\underline{G}}raph
\textbf{\underline{U}}niversal
\textbf{\underline{A}}dve\textbf{\underline{R}}sarial
\textbf{\underline{D}}efense (GUARD). Unlike previous works, GUARD protects
each individual node from attacks with a universal defensive patch, which is
generated once and can be applied to any node (node-agnostic) in a graph.
Extensive experiments on four benchmark datasets demonstrate that our method
significantly improves robustness for several established GCNs against multiple
adversarial attacks and outperforms existing adversarial defense methods by
large margins. Our code is publicly available at
https://github.com/EdisonLeeeee/GUARD.

### Title: Mobility unevenness in rock-paper-scissors models
* Paper ID: 2204.09798v1
* Paper URL: [http://arxiv.org/abs/2204.09798v1](http://arxiv.org/abs/2204.09798v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: We investigate a tritrophic system whose cyclic dominance is modelled by the
rock-paper-scissors game. We consider that organisms of one or two species are
affected by movement limitations, which unbalances the cyclic spatial game.
Performing stochastic simulations, we show that mobility unevenness controls
the population dynamics. In the case of one slow species, the predominant
species depends on the level of mobility restriction, with the slow species
being preponderant if the mobility limitations are substantial. If two species
face mobility limitations, our outcomes show that being higher dispersive does
not constitute an advantage in terms of population growth. On the contrary, if
organisms move with higher mobility, they expose themselves to enemies more
frequently, being more vulnerable to being eliminated. Finally, our findings
show that biodiversity benefits in regions where species are slowed.
Biodiversity loss for high mobility organisms, common to cyclic systems, may be
avoided with coexistence probability being higher for robust mobility
limitations. Our results may help biologists understand the dynamics of
unbalanced spatial systems where organisms' dispersal is fundamental to
biodiversity conservation.

### Title: Robust Phase Retrieval via Reverse Kullback-Leibler Divergence and Wirtinger Flow
* Paper ID: 2204.09791v1
* Paper URL: [http://arxiv.org/abs/2204.09791v1](http://arxiv.org/abs/2204.09791v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Robustness to noise and outliers is a desirable trait in phase retrieval
algorithms for many applications in imaging and signal processing. In this
paper, we develop a novel robust phase retrieval algorithm based on the
minimization of reverse Kullback-Leibler divergence (RKLD) within the Wirtinger
Flow (WF) framework. We use RKLD over intensity-only measurements in two
distinct ways: i) to design a novel initial estimate based on minimum
distortion design of spectral estimates, and ii) as a loss function for
iterative refinement based on WF. The RKLD-based loss function offers implicit
regularization by processing data at the logarithmic scale and provides the
following benefits: suppressing the influence of large magnitude errors and
promoting projections orthogonal to noise subspace. We present three algorithms
based on RKLD minimization, including two with truncation schemes to enhance
the robustness to significant contamination. Our numerical study demonstrates
the advantages of our algorithms in terms of sample efficiency, convergence
speed, and robustness to outliers over the state-of-the-art techniques using
both synthetic and real optical imaging data.

### Title: Evaluation of Robust Point Set Registration Applied to Automotive Doppler Radar
* Paper ID: 2204.09786v1
* Paper URL: [http://arxiv.org/abs/2204.09786v1](http://arxiv.org/abs/2204.09786v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Point set registration is the process of finding the best alignment between
two point sets, and it is a common task in different domains, especially in the
automotive and mobile robotics domains. Lots of approaches are proposed in the
literature, where the iterative closest point ICP is a well-known approach in
this vein, which builds an explicit correspondence between both point sets to
achieve the registration task. However, this work is interested in achieving
the registration without building any explicit correspondence between both
point sets, following a probabilistic framework.
  The most critical task in point set registration is how to elaborate the cost
function, which measures the distance between both point sets. The
probabilistic framework includes two possible ways to build the cost function:
The summing and the likelihood. The main focus of this work is to analyze and
compare the behavior of both approaches. Therefore, a 1D synthetic scenario is
used to build the cost function step by step, besides the estimation error.
Finally, this work uses two data sets for evaluation: A 2D synthetic data set
and a real data set. The evaluation process compares and analyzes the
estimation error and estimated uncertainty. Thus, two different methods are
used in the evaluation process: The normalized estimation error squared NEES
and noncredibility index NCI. A 77 GHz automotive Doppler radar provides the
real data set, and in the real evaluation, we evaluate the ego-motion
estimation of a robot as an application for the registration.

### Title: Can Voters Detect Errors on Their Printed Ballots? Absolutely
* Paper ID: 2204.09780v1
* Paper URL: [http://arxiv.org/abs/2204.09780v1](http://arxiv.org/abs/2204.09780v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: There is still debate on whether voters can detect malicious changes in their
printed ballot after making their selections on a Ballot Marking Device (BMD).
In this study, we altered votes on a voter's ballot after they had made their
selections on a BMD. We then required them to examine their ballots for any
changes from the slate they used to vote. Overall accuracy was exceptionally
high. Participants saw 1440 total contests, and of those 1440, there were a
total of 4 errors, so total accuracy was 99.8%. Participants were able to
perform with near-perfect accuracy regardless of ballot length, ballot type,
number of altered races, and location of altered races. Detection performance
was extremely robust. We conclude that with proper direction and resources,
voters can be near-perfect detectors of ballot changes on printed paper ballots
after voting with a BMD. This finding has significant implications for the
voting community as BMD use continues to grow. Research should now focus on
identifying administrative and behavioral methods that will prompt and
encourage voters to check their BMD-generated ballots before they drop them in
the ballot box.

### Title: Multi-Focus Image Fusion based on Gradient Transform
* Paper ID: 2204.09777v1
* Paper URL: [http://arxiv.org/abs/2204.09777v1](http://arxiv.org/abs/2204.09777v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Multi-focus image fusion is a challenging field of study that aims to provide
a completely focused image by integrating focused and un-focused pixels. Most
existing methods suffer from shift variance, misregistered images, and
data-dependent. In this study, we introduce a novel gradient information-based
multi-focus image fusion method that is robust for the aforementioned problems.
The proposed method first generates gradient images from original images by
using Halftoning-Inverse Halftoning (H-IH) transform. Then, Energy of Gradient
(EOG) and Standard Deviation functions are used as the focus measurement on the
gradient images to form a fused image. Finally, in order to enhance the fused
image a decision fusion approach is applied with the majority voting method.
The proposed method is compared with 17 different novel and conventional
techniques both visually and objectively. For objective evaluation, 6 different
quantitative metrics are used. It is observed that the proposed method is
promising according to visual evaluation and 83.3% success is achieved by being
first in five out of six metrics according to objective evaluation.

### Title: Delamination prediction in composite panels using unsupervised-feature learning methods with wavelet-enhanced guided wave representations
* Paper ID: 2204.09764v1
* Paper URL: [http://arxiv.org/abs/2204.09764v1](http://arxiv.org/abs/2204.09764v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: With the introduction of damage tolerance-based design philosophies, the
demand for reliable and robust structural health monitoring (SHM) procedures
for aerospace composite structures is increasing rapidly. The performance of
supervised learning algorithms for SHM depends on the amount of labeled and
balanced datasets. Apart from this, collecting datasets accommodating all
possible damage scenarios is cumbersome, costly, and inaccessible for aerospace
applications. In this paper, we have proposed two different
unsupervised-feature learning approaches where the algorithms are trained only
on the baseline scenarios to learn the distribution of baseline signals. The
trained unsupervised feature learner is used for delamination prediction with
an anomaly detection philosophy. In the first approach, we have combined
dimensionality reduction techniques (principal component analysis and
independent component analysis) with a one-class support vector machine. In
another approach, we have utilized deep learning-based deep convolutional
autoencoders (CAE). These state-of-the-art algorithms are applied on three
different guided wave-based experimental datasets. The raw guided wave signals
present in the datasets are converted into wavelet-enhanced higher-order
representations for training unsupervised feature-learning algorithms. We have
also compared different techniques, and it is seen that CAE generates better
reconstructions with lower mean squared error and can provide higher accuracy
on all the datasets.

### Title: An Adaptive and Robust Method for Multi-trait Analysis of Genome-wide Association Studies Using Summary Statistics
* Paper ID: 2204.09751v1
* Paper URL: [http://arxiv.org/abs/2204.09751v1](http://arxiv.org/abs/2204.09751v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/qiaolan/mtafs](https://github.com/qiaolan/mtafs)
* Summary: Genome-wide association studies (GWAS) have identified thousands of genetic
variants associated with human traits or diseases in the past decade.
Nevertheless, much of the heritability of many traits is still unaccounted for.
Commonly used single-trait analysis methods are conservative, while multi-trait
methods improve statistical power by integrating association evidence across
multiple traits. In contrast to individual-level data, GWAS summary statistics
are usually publicly available, and thus methods using only summary statistics
have greater usage. Although many methods have been developed for joint
analysis of multiple traits using summary statistics, there are many issues,
including inconsistent performance, computational inefficiency, and numerical
problems when considering lots of traits. To address these challenges, we
propose a multi-trait adaptive Fisher method for summary statistics (MTAFS), a
computationally efficient method with robust power performance. We applied
MTAFS to two sets of brain image-derived phenotypes (IDPs) from the UK Biobank,
including a set of 58 Volumetric IDPs and a set of 212 Area IDPs. Together with
results from a simulation study, MTAFS shows its advantage over existing
multi-trait methods, with robust performance across a range of underlying
settings. It controls type 1 error well, and can efficiently handle a large
number of traits.

### Title: Is the $\bar θ$ parameter of QCD constant?
* Paper ID: 2204.09694v1
* Paper URL: [http://arxiv.org/abs/2204.09694v1](http://arxiv.org/abs/2204.09694v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Testing the variation of fundamental constants of Nature can provide valuable
insights into new physics scenarios. While many constraints have been derived
for Standard Model coupling constants and masses, the $\bar{\theta}$ parameter
of QCD has often been ignored in these studies. This letter discusses
potentially promising paths to investigate the time dependence of the
$\bar{\theta}$ parameter. While laboratory searches for CP-violating signals of
$\bar{\theta}$ yield the most robust bounds on today's value of $\bar{\theta}$,
we show that CP-conserving effects provide constraints on the variation of
$\bar{\theta}$ over cosmological time scales. We find no significant evidence
for a variation of $\bar{\theta}$ except for a mild hint around $z\sim 4$ which
would imply an "iron-deficient" Universe at high redshifts. Finally, we also
sketch an axion model which results in a varying $\bar{\theta}$ and could lead
to excess diffuse gamma ray background, from decays of axions produced in high
redshift supernova explosions.

### Title: Atmospheric Dynamics of a Near Tidally Locked Earth-Size Planet
* Paper ID: 2204.09696v1
* Paper URL: [http://arxiv.org/abs/2204.09696v1](http://arxiv.org/abs/2204.09696v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: The discovery and characterization of Earth-sized planets that are in, or
near, a tidally-locked state are of crucial importance to understanding
terrestrial planet evolution, and for which Venus is a clear analog.
Exoplanetary science lies at the threshold of characterizing hundreds of
terrestrial planetary atmospheres, thereby providing a statistical sample far
greater than the limited inventory of terrestrial planetary atmospheres within
the Solar System. However, the model-based approach for characterizing
exoplanet atmospheres relies on Solar System data, resulting in our limited
inventory being both foundational and critical atmospheric laboratories.
Present terrestrial exoplanet demographics are heavily biased toward
short-period planets, many of which are expected to be tidally locked, and also
potentially runaway greenhouse candidates, similar to Venus. Here we describe
the rise in the terrestrial exoplanet population and the study of tidal locking
on climate simulations. These exoplanet studies are placed within the context
of Venus, a local example of an Earth-sized, asynchronous rotator that is near
the tidal locking limit. We describe the recent lessons learned regarding the
dynamics of the Venusian atmosphere and how those lessons pertain to the
evolution of our sibling planet. We discuss the implications of these lessons
for exoplanet atmospheres, and outline the need for a full characterization of
the Venusian climate in order to achieve a full and robust interpretation of
terrestrial planetary atmospheres.

### Title: The Age of Discovery with the James Webb: Excavating the Spectral Signatures of the First Massive Black Holes
* Paper ID: 2204.09692v1
* Paper URL: [http://arxiv.org/abs/2204.09692v1](http://arxiv.org/abs/2204.09692v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: The James Webb Space Telescope (JWST) will open a new window of the most
distant universe and unveil the early growth of supermassive black holes (BHs)
in the first galaxies. In preparation for deep JWST imaging surveys, it is
crucial to understand the color selection of high-redshift accreting seed BHs.
We model the spectral energy distribution of super-Eddington accreting BHs with
millions of solar masses in metal-poor galaxies at $z\gtrsim 8$, applying
post-process line transfer calculations to radiation hydrodynamical simulation
results. Ten kilosecond exposures with the NIRCam and MIRI broad-band filters
are sufficient to detect the radiation flux from the seed BHs with bolometric
luminosities of $L_{\rm bol}\simeq 10^{45}~{\rm erg~s}^{-1}$. While the
continuum colors are similar to those of typical low-$z$ quasars, strong
H$\alpha$ line emission with a rest-frame equivalent width ${\rm EW}_{\rm
rest}\simeq 1300~\r{A}$ is so prominent that the line flux affects the
broad-band colors significantly. The unique colors, for instance F356W$-$F560W
$\gtrsim 1$ at $7<z<8$ and F444W$-$F770W $\gtrsim 1$ at $9<z<12$, provide
robust criteria for photometric selection of the rapidly growing seed BHs.
Moreover, NIRSpec observations of low-ionization emission lines can test
whether the BH is fed via a dense accretion disk at super-Eddington rates.

### Title: One-Class Model for Fabric Defect Detection
* Paper ID: 2204.09648v1
* Paper URL: [http://arxiv.org/abs/2204.09648v1](http://arxiv.org/abs/2204.09648v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: An automated and accurate fabric defect inspection system is in high demand
as a replacement for slow, inconsistent, error-prone, and expensive human
operators in the textile industry. Previous efforts focused on certain types of
fabrics or defects, which is not an ideal solution. In this paper, we propose a
novel one-class model that is capable of detecting various defects on different
fabric types. Our model takes advantage of a well-designed Gabor filter bank to
analyze fabric texture. We then leverage an advanced deep learning algorithm,
autoencoder, to learn general feature representations from the outputs of the
Gabor filter bank. Lastly, we develop a nearest neighbor density estimator to
locate potential defects and draw them on the fabric images. We demonstrate the
effectiveness and robustness of the proposed model by testing it on various
types of fabrics such as plain, patterned, and rotated fabrics. Our model also
achieves a true positive rate (a.k.a recall) value of 0.895 with no false
alarms on our dataset based upon the Standard Fabric Defect Glossary.

### Title: Assembly Planning from Observations under Physical Constraints
* Paper ID: 2204.09616v1
* Paper URL: [http://arxiv.org/abs/2204.09616v1](http://arxiv.org/abs/2204.09616v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: This paper addresses the problem of copying an unknown assembly of primitives
with known shape and appearance using information extracted from a single
photograph by an off-the-shelf procedure for object detection and pose
estimation. The proposed algorithm uses a simple combination of physical
stability constraints, convex optimization and Monte Carlo tree search to plan
assemblies as sequences of pick-and-place operations represented by STRIPS
operators. It is efficient and, most importantly, robust to the errors in
object detection and pose estimation unavoidable in any real robotic system.
The proposed approach is demonstrated with thorough experiments on a UR5
manipulator.

### Title: On the Practical Design of Tube-Enhanced Multi-Stage Nonlinear Model Predictive Control
* Paper ID: 2204.09607v1
* Paper URL: [http://arxiv.org/abs/2204.09607v1](http://arxiv.org/abs/2204.09607v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Tube-enhanced multi-stage nonlinear model predictive control is a robust
control scheme that can handle a wide range of uncertainties with reduced
conservatism and manageable computational complexity. In this paper, we
elaborate on the flexibility of the approach from an application point of view.
We discuss the path to making design decisions to implement the novel scheme
systematically. We illustrate the critical steps in the design and
implementation of the scheme for an industrial example.

### Title: Federated Learning for Distributed Energy-Efficient Resource Allocation
* Paper ID: 2204.09602v1
* Paper URL: [http://arxiv.org/abs/2204.09602v1](http://arxiv.org/abs/2204.09602v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: In cellular networks, resource allocation is performed in a centralized way,
which brings huge computation complexity to the base station (BS) and high
transmission overhead. This paper investigates the distributed resource
allocation scheme for cellular networks to maximize the energy efficiency of
the system in the uplink transmission, while guaranteeing the quality of
service (QoS) for cellular users. Particularly, to cope the fast varying
channels in wireless communication environment, we propose a robust federated
reinforcement learning (FRL_suc) framework to enable local users to perform
distributed resource allocation in items of transmit power and channel
assignment by the guidance of the local neural network trained at each user.
Analysis and numerical results show that the proposed FRL_suc framework can
lower the transmission overhead and offload the computation from the central
server to the local users, while outperforming the conventional multi-agent
reinforcement learning algorithm in terms of EE, and is more robust to channel
variations.

### Title: Improved Worst-Group Robustness via Classifier Retraining on Independent Splits
* Paper ID: 2204.09583v1
* Paper URL: [http://arxiv.org/abs/2204.09583v1](http://arxiv.org/abs/2204.09583v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: High-capacity deep neural networks (DNNs) trained with Empirical Risk
Minimization (ERM) often suffer from poor worst-group accuracy despite good
on-average performance, where worst-group accuracy measures a model's
robustness towards certain subpopulations of the input space. Spurious
correlations and memorization behaviors of ERM trained DNNs are typically
attributed to this degradation in performance. We develop a method, called
CRIS, that address these issues by performing robust classifier retraining on
independent splits of the dataset. This results in a simple method that
improves upon state-of-the-art methods, such as Group DRO, on standard datasets
while relying on much fewer group labels and little additional hyperparameter
tuning.

### Title: Fast and Robust Femur Segmentation from Computed Tomography Images for Patient-Specific Hip Fracture Risk Screening
* Paper ID: 2204.09575v1
* Paper URL: [http://arxiv.org/abs/2204.09575v1](http://arxiv.org/abs/2204.09575v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Osteoporosis is a common bone disease that increases the risk of bone
fracture. Hip-fracture risk screening methods based on finite element analysis
depend on segmented computed tomography (CT) images; however, current femur
segmentation methods require manual delineations of large data sets. Here we
propose a deep neural network for fully automated, accurate, and fast
segmentation of the proximal femur from CT. Evaluation on a set of 1147
proximal femurs with ground truth segmentations demonstrates that our method is
apt for hip-fracture risk screening, bringing us one step closer to a
clinically viable option for screening at-risk patients for hip-fracture
susceptibility.

### Title: Tunable and giant valley-selective Hall effect in gapped bilayer graphene
* Paper ID: 2204.09525v1
* Paper URL: [http://arxiv.org/abs/2204.09525v1](http://arxiv.org/abs/2204.09525v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Berry curvature is analogous to magnetic field but in momentum space and is
commonly present in materials with non-trivial quantum geometry. It endows
Bloch electrons with transverse anomalous velocities to produce Hall-like
currents even in the absence of a magnetic field. We report the direct
observation of in situ tunable valley-selective Hall effect (VSHE), where
inversion symmetry, and thus the geometric phase of electrons, is controllable
by an out-of-plane electric field. We use high-quality bilayer graphene with an
intrinsic and tunable bandgap, illuminated by circularly polarized mid-infrared
light and confirm that the observed Hall voltage arises from an
optically-induced valley population. Compared with molybdenum disulfide, we
find orders of magnitude larger VSHE, attributed to the inverse scaling of the
Berry curvature with bandgap. By monitoring the valley-selective Hall
conductivity, we study Berry curvature's evolution with bandgap. This in situ
manipulation of VSHE paves the way for topological and quantum geometric
opto-electronic devices, such as more robust switches and detectors.

### Title: A Data-Driven Method for Automated Data Superposition with Applications in Soft Matter Science
* Paper ID: 2204.09521v1
* Paper URL: [http://arxiv.org/abs/2204.09521v1](http://arxiv.org/abs/2204.09521v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/krlennon/mastercurves](https://github.com/krlennon/mastercurves)
* Summary: The superposition of data sets with internal parametric self-similarity is a
longstanding and widespread technique for the analysis of many types of
experimental data across the physical sciences. Typically, this superposition
is performed manually, or recently by one of a few automated algorithms.
However, these methods are often heuristic in nature, are prone to user bias
via manual data shifting or parameterization, and lack a native framework for
handling uncertainty in both the data and the resulting model of the superposed
data. In this work, we develop a data-driven, non-parametric method for
superposing experimental data with arbitrary coordinate transformations, which
employs Gaussian process regression to learn statistical models that describe
the data, and then uses maximum a posteriori estimation to optimally superpose
the data sets. This statistical framework is robust to experimental noise, and
automatically produces uncertainty estimates for the learned coordinate
transformations. Moreover, it is distinguished from black-box machine learning
in its interpretability -- specifically, it produces a model that may itself be
interrogated to gain insight into the system under study. We demonstrate these
salient features of our method through its application to four representative
data sets characterizing the mechanics of soft materials. In every case, our
method replicates results obtained using other approaches, but with reduced
bias and the addition of uncertainty estimates. This method enables a
standardized, statistical treatment of self-similar data across many fields,
producing interpretable data-driven models that may inform applications such as
materials classification, design, and discovery.

### Title: A Reinforcement Learning-based Volt-VAR Control Dataset and Testing Environment
* Paper ID: 2204.09500v1
* Paper URL: [http://arxiv.org/abs/2204.09500v1](http://arxiv.org/abs/2204.09500v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/yg-smile/rl_vvc_dataset](https://github.com/yg-smile/rl_vvc_dataset)
* Summary: To facilitate the development of reinforcement learning (RL) based power
distribution system Volt-VAR control (VVC), this paper introduces a suite of
open-source datasets for RL-based VVC algorithm research that is sample
efficient, safe, and robust. The dataset consists of two components: 1. a
Gym-like VVC testing environment for the IEEE-13, 123, and 8500-bus test
feeders and 2. a historical operational dataset for each of the feeders.
Potential users of the dataset and testing environment could first train an
sample-efficient off-line (batch) RL algorithm on the historical dataset and
then evaluate the performance of the trained RL agent on the testing
environments. This dataset serves as a useful testbed to conduct RL-based VVC
research mimicking the real-world operational challenges faced by electric
utilities. Meanwhile, it allows researchers to conduct fair performance
comparisons between different algorithms.

### Title: THORN: Temporal Human-Object Relation Network for Action Recognition
* Paper ID: 2204.09468v1
* Paper URL: [http://arxiv.org/abs/2204.09468v1](http://arxiv.org/abs/2204.09468v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Most action recognition models treat human activities as unitary events.
However, human activities often follow a certain hierarchy. In fact, many human
activities are compositional. Also, these actions are mostly human-object
interactions. In this paper we propose to recognize human action by leveraging
the set of interactions that define an action. In this work, we present an
end-to-end network: THORN, that can leverage important human-object and
object-object interactions to predict actions. This model is built on top of a
3D backbone network. The key components of our model are: 1) An object
representation filter for modeling object. 2) An object relation reasoning
module to capture object relations. 3) A classification layer to predict the
action labels. To show the robustness of THORN, we evaluate it on
EPIC-Kitchen55 and EGTEA Gaze+, two of the largest and most challenging
first-person and human-object interaction datasets. THORN achieves
state-of-the-art performance on both datasets.

### Title: Is BERT Robust to Label Noise? A Study on Learning with Noisy Labels in Text Classification
* Paper ID: 2204.09371v1
* Paper URL: [http://arxiv.org/abs/2204.09371v1](http://arxiv.org/abs/2204.09371v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/uds-lsv/bert-lnl](https://github.com/uds-lsv/bert-lnl)
* Summary: Incorrect labels in training data occur when human annotators make mistakes
or when the data is generated via weak or distant supervision. It has been
shown that complex noise-handling techniques - by modeling, cleaning or
filtering the noisy instances - are required to prevent models from fitting
this label noise. However, we show in this work that, for text classification
tasks with modern NLP models like BERT, over a variety of noise types, existing
noisehandling methods do not always improve its performance, and may even
deteriorate it, suggesting the need for further investigation. We also back our
observations with a comprehensive analysis.

### Title: NFormer: Robust Person Re-identification with Neighbor Transformer
* Paper ID: 2204.09331v1
* Paper URL: [http://arxiv.org/abs/2204.09331v1](http://arxiv.org/abs/2204.09331v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/haochenheheda/nformer](https://github.com/haochenheheda/nformer)
* Summary: Person re-identification aims to retrieve persons in highly varying settings
across different cameras and scenarios, in which robust and discriminative
representation learning is crucial. Most research considers learning
representations from single images, ignoring any potential interactions between
them. However, due to the high intra-identity variations, ignoring such
interactions typically leads to outlier features. To tackle this issue, we
propose a Neighbor Transformer Network, or NFormer, which explicitly models
interactions across all input images, thus suppressing outlier features and
leading to more robust representations overall. As modelling interactions
between enormous amount of images is a massive task with lots of distractors,
NFormer introduces two novel modules, the Landmark Agent Attention, and the
Reciprocal Neighbor Softmax. Specifically, the Landmark Agent Attention
efficiently models the relation map between images by a low-rank factorization
with a few landmarks in feature space. Moreover, the Reciprocal Neighbor
Softmax achieves sparse attention to relevant -- rather than all -- neighbors
only, which alleviates interference of irrelevant representations and further
relieves the computational burden. In experiments on four large-scale datasets,
NFormer achieves a new state-of-the-art. The code is released at
\url{https://github.com/haochenheheda/NFormer}.

### Title: Group relations, resilience and the I Ching
* Paper ID: 2204.09330v1
* Paper URL: [http://arxiv.org/abs/2204.09330v1](http://arxiv.org/abs/2204.09330v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: We evaluate the robustness and adaptivity of social groups with heterogeneous
agents that are characterized by their binary state, their ability to change
this state, their status and their preferred relations to other agents. To
define group structures, we operationalize the hexagrams of the \emph{I Ching}.
The relations and properties of agents are used to quantify their influence
according to the social impact theory. From these influence values we derive a
weighted stability measure for triads involving three agents, which is based on
the weighted balance theory. It allows to quantify the robustness of groups and
to propose a novel measure for group resilience which combines robustness and
adaptivity. A stochastic approach determines the probabilities to find robust
and adaptive groups. The discussion focuses on the generalization of our
approach.

### Title: Logarithmic Morphological Neural Nets robust to lighting variations
* Paper ID: 2204.09319v1
* Paper URL: [http://arxiv.org/abs/2204.09319v1](http://arxiv.org/abs/2204.09319v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Morphological neural networks allow to learn the weights of a structuring
function knowing the desired output image. However, those networks are not
intrinsically robust to lighting variations in images with an optical cause,
such as a change of light intensity. In this paper, we introduce a
morphological neural network which possesses such a robustness to lighting
variations. It is based on the recent framework of Logarithmic Mathematical
Morphology (LMM), i.e. Mathematical Morphology defined with the Logarithmic
Image Processing (LIP) model. This model has a LIP additive law which simulates
in images a variation of the light intensity. We especially learn the
structuring function of a LMM operator robust to those variations, namely : the
map of LIP-additive Asplund distances. Results in images show that our neural
network verifies the required property.

### Title: Massive Twinning to Enhance Emergent Intelligence
* Paper ID: 2204.09316v1
* Paper URL: [http://arxiv.org/abs/2204.09316v1](http://arxiv.org/abs/2204.09316v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Future Industrial Internet-of-Things in the upcoming 6G era is expected to
deploy artificial intelligence (AI) and digital twins (DTs) ubiquitously. As a
complement to conventional AI solutions, emergent intelligence (EI) exhibits
various outstanding features including robustness, protection to privacy, and
scalability, which makes it competitive for 6G IIoT applications. However,
despite its low computational complexity, it is challenged by its high demand
of data traffic in massive deployment. In this paper, we propose to exploit the
massive twinning paradigm, which 6G is envisaged to support, to reduce the data
traffic in EI and therewith enhance its performance.

### Title: Improving generalization of machine learning-identified biomarkers with causal modeling: an investigation into immune receptor diagnostics
* Paper ID: 2204.09291v1
* Paper URL: [http://arxiv.org/abs/2204.09291v1](http://arxiv.org/abs/2204.09291v1)
* Updated Date: 2022-04-20
* Code URL: [https://github.com/uio-bmi/causalairr](https://github.com/uio-bmi/causalairr)
* Summary: Machine learning is increasingly used to discover diagnostic and prognostic
biomarkers from high-dimensional molecular data. However, a variety of factors
related to experimental design may affect the ability to learn generalizable
and clinically applicable diagnostics. Here, we argue that a causal perspective
improves the identification of these challenges, and formalizes their relation
to the robustness and generalization of machine learning-based diagnostics. To
make for a concrete discussion, we focus on a specific, recently established
high-dimensional biomarker - adaptive immune receptor repertoires (AIRRs). We
discuss how the main biological and experimental factors of the AIRR domain may
influence the learned biomarkers and provide easily adjustable simulations of
such effects. In conclusion, we find that causal modeling improves machine
learning-based biomarker robustness by identifying stable relations between
variables and by guiding the adjustment of the relations and variables that
vary between populations.

### Title: Varied magnetic phases in a van der Waals easy-plane antiferromagnet revealed by nitrogen-vacancy center microscopy
* Paper ID: 2204.09277v1
* Paper URL: [http://arxiv.org/abs/2204.09277v1](http://arxiv.org/abs/2204.09277v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Interest in van der Waals materials often stems from a desire to miniaturise
existing technologies by exploiting their intrinsic layered structure to create
near atomically-thin components that do not suffer from surface defects. One
appealing property is easily-switchable yet robust magnetic order, a quality
only sparsely demonstrated in the case of in-plane anisotropy. In this work, we
use widefield nitrogen-vacancy (NV) center magnetic imaging to measure the
properties of individual flakes of CuCrP$_2$S$_6$, a multiferroic van der Waals
magnet known to exhibit weak easy-plane anisotropy in the bulk. We chart the
crossover between in-plane ferromagnetism in thin flakes down to the trilayer,
and the bulk behaviour dominated by a low-field spin-flop transition. Further,
by exploiting the directional dependence of NV center magnetometry, we are able
to observe an instance of a predominantly out-of-plane ferromagetic phase near
zero field, in contradiction with expectation and previous experiments on the
bulk material. We attribute this to the presence of surface anisotropies
arising from the sample preparation process or exposure to the ambient
environment, which is expected to have more general implications for a broader
class of weakly anisotropic van der Waals magnets.

### Title: Synthetic Target Domain Supervision for Open Retrieval QA
* Paper ID: 2204.09248v1
* Paper URL: [http://arxiv.org/abs/2204.09248v1](http://arxiv.org/abs/2204.09248v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Neural passage retrieval is a new and promising approach in open retrieval
question answering. In this work, we stress-test the Dense Passage Retriever
(DPR) -- a state-of-the-art (SOTA) open domain neural retrieval model -- on
closed and specialized target domains such as COVID-19, and find that it lags
behind standard BM25 in this important real-world setting. To make DPR more
robust under domain shift, we explore its fine-tuning with synthetic training
examples, which we generate from unlabeled target domain text using a
text-to-text generator. In our experiments, this noisy but fully automated
target domain supervision gives DPR a sizable advantage over BM25 in
out-of-domain settings, making it a more viable model in practice. Finally, an
ensemble of BM25 and our improved DPR model yields the best results, further
pushing the SOTA for open retrieval QA on multiple out-of-domain test sets.

### Title: Visual-based Positioning and Pose Estimation
* Paper ID: 2204.09232v1
* Paper URL: [http://arxiv.org/abs/2204.09232v1](http://arxiv.org/abs/2204.09232v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Recent advances in deep learning and computer vision offer an excellent
opportunity to investigate high-level visual analysis tasks such as human
localization and human pose estimation. Although the performance of human
localization and human pose estimation has significantly improved in recent
reports, they are not perfect and erroneous localization and pose estimation
can be expected among video frames. Studies on the integration of these
techniques into a generic pipeline that is robust to noise introduced from
those errors are still lacking. This paper fills the missing study. We explored
and developed two working pipelines that suited the visual-based positioning
and pose estimation tasks. Analyses of the proposed pipelines were conducted on
a badminton game. We showed that the concept of tracking by detection could
work well, and errors in position and pose could be effectively handled by a
linear interpolation technique using information from nearby frames. The
results showed that the Visual-based Positioning and Pose Estimation could
deliver position and pose estimations with good spatial and temporal
resolutions.

### Title: Dark Spot Detection from SAR Images Based on Superpixel Deeper Graph Convolutional Network
* Paper ID: 2204.09230v1
* Paper URL: [http://arxiv.org/abs/2204.09230v1](http://arxiv.org/abs/2204.09230v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Synthetic Aperture Radar (SAR) is the main instrument utilized for the
detection of oil slicks on the ocean surface. In SAR images, some areas
affected by ocean phenomena, such as rain cells, upwellings, and internal
waves, or discharge from oil spills appear as dark spots on images. Dark spot
detection is the first step in the detection of oil spills, which then become
oil slick candidates. The accuracy of dark spot segmentation ultimately affects
the accuracy of oil slick identification. Although some advanced deep learning
methods that use pixels as processing units perform well in remote sensing
image semantic segmentation, detecting some dark spots with weak boundaries
from noisy SAR images remains a huge challenge. We propose a dark spot
detection method based on superpixels deeper graph convolutional networks
(SGDCN) in this paper, which takes the superpixels as the processing units and
extracts features for each superpixel. The features calculated from superpixel
regions are more robust than those from fixed pixel neighborhoods. To reduce
the difficulty of learning tasks, we discard irrelevant features and obtain an
optimal subset of features. After superpixel segmentation, the images are
transformed into graphs with superpixels as nodes, which are fed into the
deeper graph convolutional neural network for node classification. This graph
neural network uses a differentiable aggregation function to aggregate the
features of nodes and neighbors to form more advanced features. It is the first
time using it for dark spot detection. To validate our method, we mark all dark
spots on six SAR images covering the Baltic Sea and construct a dark spots
detection dataset, which has been made publicly available
(https://drive.google.com/drive/folders/12UavrntkDSPrItISQ8iGefXn2gIZHxJ6?usp=sharing).
The experimental results demonstrate that our proposed SGDCN is robust and
effective.

### Title: Interventional Multi-Instance Learning with Deconfounded Instance-Level Prediction
* Paper ID: 2204.09204v1
* Paper URL: [http://arxiv.org/abs/2204.09204v1](http://arxiv.org/abs/2204.09204v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: When applying multi-instance learning (MIL) to make predictions for bags of
instances, the prediction accuracy of an instance often depends on not only the
instance itself but also its context in the corresponding bag. From the
viewpoint of causal inference, such bag contextual prior works as a confounder
and may result in model robustness and interpretability issues. Focusing on
this problem, we propose a novel interventional multi-instance learning (IMIL)
framework to achieve deconfounded instance-level prediction. Unlike traditional
likelihood-based strategies, we design an Expectation-Maximization (EM)
algorithm based on causal intervention, providing a robust instance selection
in the training phase and suppressing the bias caused by the bag contextual
prior. Experiments on pathological image analysis demonstrate that our IMIL
method substantially reduces false positives and outperforms state-of-the-art
MIL methods.

### Title: Functional Calibration under Non-Probability Survey Sampling
* Paper ID: 2204.09193v1
* Paper URL: [http://arxiv.org/abs/2204.09193v1](http://arxiv.org/abs/2204.09193v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Non-probability sampling is prevailing in survey sampling, but ignoring its
selection bias leads to erroneous inferences. We offer a unified nonparametric
calibration method to estimate the sampling weights for a non-probability
sample by calibrating functions of auxiliary variables in a reproducing kernel
Hilbert space. The consistency and the limiting distribution of the proposed
estimator are established, and the corresponding variance estimator is also
investigated. Compared with existing works, the proposed method is more robust
since no parametric assumption is made for the selection mechanism of the
non-probability sample. Numerical results demonstrate that the proposed method
outperforms its competitors, especially when the model is misspecified. The
proposed method is applied to analyze the average total cholesterol of Korean
citizens based on a non-probability sample from the National Health Insurance
Sharing Service and a reference probability sample from the Korea National
Health and Nutrition Examination Survey.

### Title: Robustness Testing of Data and Knowledge Driven Anomaly Detection in Cyber-Physical Systems
* Paper ID: 2204.09183v1
* Paper URL: [http://arxiv.org/abs/2204.09183v1](http://arxiv.org/abs/2204.09183v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: The growing complexity of Cyber-Physical Systems (CPS) and challenges in
ensuring safety and security have led to the increasing use of deep learning
methods for accurate and scalable anomaly detection. However, machine learning
(ML) models often suffer from low performance in predicting unexpected data and
are vulnerable to accidental or malicious perturbations. Although robustness
testing of deep learning models has been extensively explored in applications
such as image classification and speech recognition, less attention has been
paid to ML-driven safety monitoring in CPS. This paper presents the preliminary
results on evaluating the robustness of ML-based anomaly detection methods in
safety-critical CPS against two types of accidental and malicious input
perturbations, generated using a Gaussian-based noise model and the Fast
Gradient Sign Method (FGSM). We test the hypothesis of whether integrating the
domain knowledge (e.g., on unsafe system behavior) with the ML models can
improve the robustness of anomaly detection without sacrificing accuracy and
transparency. Experimental results with two case studies of Artificial Pancreas
Systems (APS) for diabetes management show that ML-based safety monitors
trained with domain knowledge can reduce on average up to 54.2% of robustness
error and keep the average F1 scores high while improving transparency.

### Title: Learned Monocular Depth Priors in Visual-Inertial Initialization
* Paper ID: 2204.09171v1
* Paper URL: [http://arxiv.org/abs/2204.09171v1](http://arxiv.org/abs/2204.09171v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Visual-inertial odometry (VIO) is the pose estimation backbone for most AR/VR
and autonomous robotic systems today, in both academia and industry. However,
these systems are highly sensitive to the initialization of key parameters such
as sensor biases, gravity direction, and metric scale. In practical scenarios
where high-parallax or variable acceleration assumptions are rarely met (e.g.
hovering aerial robot, smartphone AR user not gesticulating with phone),
classical visual-inertial initialization formulations often become
ill-conditioned and/or fail to meaningfully converge. In this paper we target
visual-inertial initialization specifically for these low-excitation scenarios
critical to in-the-wild usage. We propose to circumvent the limitations of
classical visual-inertial structure-from-motion (SfM) initialization by
incorporating a new learning-based measurement as a higher-level input. We
leverage learned monocular depth images (mono-depth) to constrain the relative
depth of features, and upgrade the mono-depth to metric scale by jointly
optimizing for its scale and shift. Our experiments show a significant
improvement in problem conditioning compared to a classical formulation for
visual-inertial initialization, and demonstrate significant accuracy and
robustness improvements relative to the state-of-the-art on public benchmarks,
particularly under motion-restricted scenarios. We further extend this
improvement to implementation within an existing odometry system to illustrate
the impact of our improved initialization method on resulting tracking
trajectories.

