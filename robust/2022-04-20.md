# robust

## 04-20

### Title: A warm super-Neptune around the G-dwarf star TOI-1710 revealed with TESS, SOPHIE and HARPS-N
* Paper ID: 2204.08984v1
* Paper URL: [http://arxiv.org/abs/2204.08984v1](http://arxiv.org/abs/2204.08984v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: We report the discovery and characterization of the transiting extrasolar
planet TOI-1710$\:$b. It was first identified as a promising candidate by the
Transiting Exoplanet Survey Satellite (TESS). Its planetary nature was then
established with SOPHIE and HARPS-N spectroscopic observations via the RV
method. The stellar parameters for the host star are derived from the spectra
and a joint Markov chain Monte-Carlo (MCMC) adjustment of the spectral energy
distribution and evolutionary tracks of TOI-1710. A joint MCMC analysis of the
TESS light curve and the RV evolution allows us to determine the planetary
system properties. From our analysis, TOI-1710$\:$b is found to be a massive
warm super-Neptune ($M_{\rm p}=28.3\:\pm\:4.7\:{\rm M}_{\rm Earth}$ and $R_{\rm
p}=5.34\:\pm\:0.11\:{\rm R}_{\rm Earth}$) orbiting a G5V dwarf star ($T_{\rm
eff}=5665\pm~55\mathrm{K}$) on a nearly circular 24.3-day orbit
($e=0.16\:\pm\:0.08$). The orbital period of this planet is close to the
estimated rotation period of its host star $P_{\rm
rot}=22.5\pm2.0~\mathrm{days}$ and it has a low Keplerian semi-amplitude
$K=6.4\pm1.0~\mathrm{m\:s^{-1}}$; we thus performed additional analyses to show
the robustness of the retrieved planetary parameters. With a low bulk density
of $1.03\pm0.23~\mathrm{g\:cm^{-3}}$ and orbiting a bright host star ($J=8.3$,
$V=9.6$), TOI-1710$\:$b is one of the best targets in this mass-radius range
(near the Neptunian desert) for atmospheric characterization via transmission
spectroscopy, a key measurement in constraining planet formation and
evolutionary models of sub-Jovian planets.

### Title: Real-Time Face Recognition System
* Paper ID: 2204.08978v1
* Paper URL: [http://arxiv.org/abs/2204.08978v1](http://arxiv.org/abs/2204.08978v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Over the past few decades, interest in algorithms for face recognition has
been growing rapidly and has even surpassed human-level performance. Despite
their accomplishments, their practical integration with a real-time
performance-hungry system is not feasible due to high computational costs. So
in this paper, we explore the recent, fast, and accurate face recognition
system that can be easily integrated with real-time devices, and tested the
algorithms on robot hardware platforms to confirm their robustness and speed.

### Title: Two dimensional LiMgAs; a novel Topological Quantum Catalyst for Hydrogen Evolution Reaction
* Paper ID: 2204.08926v1
* Paper URL: [http://arxiv.org/abs/2204.08926v1](http://arxiv.org/abs/2204.08926v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Quantum materials such as Topological Insulators (TI) have been promising due
to diverse applications of their robust surface/edge states in the bulk (3D)
and two-dimensional (2D) regime. Such conducting surface states in 3D systems,
host "\textit{electron bath}" which are known to facilitate catalysis. However,
the analogous effects in 2D scenarios wherein, conducting helical edge states
giving rise to Fermionic accumulation has been scarcely addressed. Using
density functional theory based \textit{first-principles} calculations, we
demonstrate that, the conducting edge states in 2D TI such as LiMgAs can be
exploited to facilitate excellent catalytic response towards Hydrogen evolution
reactions. The Gibbs free energy in such cases was found to be as low as
$-$0.02 eV which is quite superior as compared to other materials reported in
literature. The concept presented herein can be extended to other well known 2D
TI and used to realise novel topological quantum catalysts for ultra-high
performance and efficient catalytic applications.

### Title: Highly Tunable and Strong Bound Exciton in MoSi2N4 via Strain Engineering
* Paper ID: 2204.08911v1
* Paper URL: [http://arxiv.org/abs/2204.08911v1](http://arxiv.org/abs/2204.08911v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Motivated by the recently synthesized layered material MoSi2N4, we
investigated excitonic response of quasiparticle of monolayer MoSi2N4 by using
G0W0 and Bethe-Salpeter equation (BSE) calculations. With a dually sandwiched
structure consisting of a central MoN2 layer analogue of 2H-MoS2 capped with
silicon-nitrogen (SiN) honeycomb outer layers, MoSi2N4 possesses frontier
orbitals confined at the central MoN2 layer with similar sub-valley at K-point
as 2H-MoS2. The valley splitting (~130 meV) due to the spin-orbital coupling
(SOC) gives rise to a doublet in the spectrum. Excitons in MoSi2N4 shows a
strong binding energy up to 0.95 eV with the optical bandgap of 2.44 eV. Both
electronic and optical gaps are highly sensitive to tensile strains and become
redshift albeit a marginal change of exciton binding energy. With the
protection of capped SiN layers, quantum confined excitons in MoSi2N4 without
the need of additional passivation layer like BN would provide a bright new
platform for robust emission with partially screened disturbance from
environment.

### Title: Photorealistic Monocular 3D Reconstruction of Humans Wearing Clothing
* Paper ID: 2204.08906v1
* Paper URL: [http://arxiv.org/abs/2204.08906v1](http://arxiv.org/abs/2204.08906v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: We present PHORHUM, a novel, end-to-end trainable, deep neural network
methodology for photorealistic 3D human reconstruction given just a monocular
RGB image. Our pixel-aligned method estimates detailed 3D geometry and, for the
first time, the unshaded surface color together with the scene illumination.
Observing that 3D supervision alone is not sufficient for high fidelity color
reconstruction, we introduce patch-based rendering losses that enable reliable
color reconstruction on visible parts of the human, and detailed and plausible
color estimation for the non-visible parts. Moreover, our method specifically
addresses methodological and practical limitations of prior work in terms of
representing geometry, albedo, and illumination effects, in an end-to-end model
where factors can be effectively disentangled. In extensive experiments, we
demonstrate the versatility and robustness of our approach. Our
state-of-the-art results validate the method qualitatively and for different
metrics, for both geometric and color reconstruction.

### Title: The Coming Decades of Quantum Simulation
* Paper ID: 2204.08905v1
* Paper URL: [http://arxiv.org/abs/2204.08905v1](http://arxiv.org/abs/2204.08905v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Contemporary quantum technologies face major difficulties in fault tolerant
quantum computing with error correction, and focus instead on various shades of
quantum simulation (Noisy Intermediate Scale Quantum, NISQ) devices, analogue
and digital quantum simulators and quantum annealers. There is a clear need and
quest for such systems that, without necessarily simulating quantum dynamics of
some physical systems, can generate massive, controllable, robust, entangled,
and superposition states. This will, in particular, allow the control of
decoherence, enabling the use of these states for quantum communications (e.g.
to achieve efficient transfer of information in a safer and quicker way),
quantum metrology, sensing and diagnostics (e.g. to precisely measure phase
shifts of light fields, or to diagnose quantum materials). In this Chapter we
present a vision of the golden future of quantum simulators in the decades to
come.

### Title: Efficient Monte Carlo Method for Integral Fractional Laplacian in Multiple Dimensions
* Paper ID: 2204.08860v1
* Paper URL: [http://arxiv.org/abs/2204.08860v1](http://arxiv.org/abs/2204.08860v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: In this paper, we develop a Monte Carlo method for solving PDEs involving an
integral fractional Laplacian (IFL) in multiple dimensions. We first construct
a new Feynman-Kac representation based on the Green function for the fractional
Laplacian operator on the unit ball in arbitrary dimensions. Inspired by the
"walk-on-spheres" algorithm proposed in [24], we extend our algorithm for
solving fractional PDEs in the complex domain. Then, we can compute the
expectation of a multi-dimensional random variable with a known density
function to obtain the numerical solution efficiently. The proposed algorithm
finds it remarkably efficient in solving fractional PDEs: it only needs to
evaluate the integrals of expectation form over a series of inside ball tangent
boundaries with the known Green function. Moreover, we carry out the error
estimates of the proposed method for the $n$-dimensional unit ball. Finally,
ample numerical results are presented to demonstrate the robustness and
effectiveness of this approach for fractional PDEs in unit disk and complex
domains, and even in ten-dimensional unit balls.

### Title: Robust electronic and tunable magnetic states in Sm$ _{2} $NiMnO$ _{6} $ ferromagnetic insulator
* Paper ID: 2204.08843v1
* Paper URL: [http://arxiv.org/abs/2204.08843v1](http://arxiv.org/abs/2204.08843v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Ferromagnetic insulators (FM-Is) are the materials of interest for new
generation quantum electronic applications. Here, we have investigated the
physical observables depicting FM-I ground states in epitaxial Sm$ _{2} $NiMnO$
_{6} $ (SNMO) double perovskite thin films fabricated under different
conditions to realize different level of Ni/Mn anti-site disorders (ASDs). The
presence of ASDs immensely influence the characteristic magnetic and anisotropy
behaviors in SNMO system by introducing short scale antiferromagnetic
interactions in predominant long range FM ordered host matrix. Charge
disproportion between cation sites in form of $ Ni^{2+}+Mn^{4+} \longrightarrow
Ni^{3+}+Mn^{3+} $, causes mixed valency in both Ni and Mn species, which is
found insensitive to ASD concentrations. Temperature dependent photo emission,
photo absorption measurements duly combined with cluster model configuration
interaction simulations, suggest that the eigenstates of Ni and Mn cations can
be satisfactorily described as a linear combination of the unscreened $ d^{n} $
and screened $ d^{n+1} \underline{L} $ ($ \underline{L} $: O 2\textit{p} hole)
states. The electronic structure across the Fermi level (E$ _{F} $) exhibits
closely spaced Ni $ 3d $, Mn $ 3d $ and O $ 2p $ states. From occupied and
unoccupied bands, estimated values of the Coulomb repulsion energy ($ U $) and
ligand to metal charge transfer energy ($ \Delta $), indicate charge transfer
insulating nature, where remarkable modification in Ni/Mn $ 3d $ - O $ 2p $
hybridization takes place across the FM transition temperature. Existence of
ASD broadens the Ni, Mn $ 3d $ spectral features, whereas spectral positions
are found to be unaltered. Hereby, present work demonstrates SNMO thin film as
a FM-I system, where FM state can be tuned by manipulating ASD in the crystal
structure, while I state remains intact.

### Title: A Convolutional-Attentional Neural Framework for Structure-Aware Performance-Score Synchronization
* Paper ID: 2204.08822v1
* Paper URL: [http://arxiv.org/abs/2204.08822v1](http://arxiv.org/abs/2204.08822v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Performance-score synchronization is an integral task in signal processing,
which entails generating an accurate mapping between an audio recording of a
performance and the corresponding musical score. Traditional synchronization
methods compute alignment using knowledge-driven and stochastic approaches, and
are typically unable to generalize well to different domains and modalities. We
present a novel data-driven method for structure-aware performance-score
synchronization. We propose a convolutional-attentional architecture trained
with a custom loss based on time-series divergence. We conduct experiments for
the audio-to-MIDI and audio-to-image alignment tasks pertained to different
score modalities. We validate the effectiveness of our method via ablation
studies and comparisons with state-of-the-art alignment approaches. We
demonstrate that our approach outperforms previous synchronization methods for
a variety of test settings across score modalities and acoustic conditions. Our
method is also robust to structural differences between the performance and
score sequences, which is a common limitation of standard alignment approaches.

### Title: An Efficient Domain-Incremental Learning Approach to Drive in All Weather Conditions
* Paper ID: 2204.08817v1
* Paper URL: [http://arxiv.org/abs/2204.08817v1](http://arxiv.org/abs/2204.08817v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Although deep neural networks enable impressive visual perception performance
for autonomous driving, their robustness to varying weather conditions still
requires attention. When adapting these models for changed environments, such
as different weather conditions, they are prone to forgetting previously
learned information. This catastrophic forgetting is typically addressed via
incremental learning approaches which usually re-train the model by either
keeping a memory bank of training samples or keeping a copy of the entire model
or model parameters for each scenario. While these approaches show impressive
results, they can be prone to scalability issues and their applicability for
autonomous driving in all weather conditions has not been shown. In this paper
we propose DISC -- Domain Incremental through Statistical Correction -- a
simple online zero-forgetting approach which can incrementally learn new tasks
(i.e weather conditions) without requiring re-training or expensive memory
banks. The only information we store for each task are the statistical
parameters as we categorize each domain by the change in first and second order
statistics. Thus, as each task arrives, we simply 'plug and play' the
statistical vectors for the corresponding task into the model and it
immediately starts to perform well on that task. We show the efficacy of our
approach by testing it for object detection in a challenging domain-incremental
autonomous driving scenario where we encounter different adverse weather
conditions, such as heavy rain, fog, and snow.

### Title: Radio Galaxy Zoo: Using semi-supervised learning to leverage large unlabelled data-sets for radio galaxy classification under data-set shift
* Paper ID: 2204.08816v1
* Paper URL: [http://arxiv.org/abs/2204.08816v1](http://arxiv.org/abs/2204.08816v1)
* Updated Date: 2022-04-19
* Code URL: [https://github.com/inigoval/fixmatch](https://github.com/inigoval/fixmatch)
* Summary: In this work we examine the classification accuracy and robustness of a
state-of-the-art semi-supervised learning (SSL) algorithm applied to the
morphological classification of radio galaxies. We test if SSL with fewer
labels can achieve test accuracies comparable to the supervised
state-of-the-art and whether this holds when incorporating previously unseen
data. We find that for the radio galaxy classification problem considered, SSL
provides additional regularisation and outperforms the baseline test accuracy.
However, in contrast to model performance metrics reported on computer science
benchmarking data-sets, we find that improvement is limited to a narrow range
of label volumes, with performance falling off rapidly at low label volumes.
Additionally, we show that SSL does not improve model calibration, regardless
of whether classification is improved. Moreover, we find that when different
underlying catalogues drawn from the same radio survey are used to provide the
labelled and unlabelled data-sets required for SSL, a significant drop in
classification performance is observered, highlighting the difficulty of
applying SSL techniques under dataset shift. We show that a class-imbalanced
unlabelled data pool negatively affects performance through prior probability
shift, which we suggest may explain this performance drop, and that using the
Frechet Distance between labelled and unlabelled data-sets as a measure of
data-set shift can provide a prediction of model performance, but that for
typical radio galaxy data-sets with labelled sample volumes of O(1000), the
sample variance associated with this technique is high and the technique is in
general not sufficiently robust to replace a train-test cycle.

### Title: The Interplay between Quantum Contextuality and Wigner Negativity
* Paper ID: 2204.08782v1
* Paper URL: [http://arxiv.org/abs/2204.08782v1](http://arxiv.org/abs/2204.08782v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: The use of quantum information in technology promises to supersede the
so-called classical devices used nowadays. Understanding what features are
inherently non-classical is crucial for reaching better-than-classical
performance. This thesis focuses on two nonclassical behaviours: quantum
contextuality and Wigner negativity. The former is a notion superseding
nonlocality that can be exhibited by quantum systems. To date, it has mostly
been studied in discrete-variable scenarios. In those scenarios, contextuality
has been shown to be necessary and sufficient for advantages in some cases. On
the other hand, negativity of the Wigner function is another unsettling
non-classical feature of quantum states that originates from phase-space
formulation in continuous-variable quantum optics. Continuous-variable
scenarios offer promising candidates for implementing quantum computations.
Wigner negativity is known to be a necessary resource for quantum speedup with
continuous variables. However contextuality has been little understood and
studied in continuous-variable scenarios.
  We first set out a robust framework for properly treating contextuality in
continuous variables. We also quantify contextuality in such scenarios by using
tools from infinite-dimensional optimisation theory. Building upon this, we
show that Wigner negativity is equivalent to contextuality in continuous
variables with respect to Pauli measurements thus establishing a
continuous-variable analogue of a celebrated result by Howard et al. We then
introduce experimentally-friendly witnesses for Wigner negativity of single
mode and multimode quantum states, based on fidelities with Fock states, using
again tools from infinite-dimensional optimisation theory. We further extend
the range of previously known discrete-variable results linking contextuality
and advantage into a new territory of information retrieval.

### Title: Incorporating Semi-Supervised and Positive-Unlabeled Learning for Boosting Full Reference Image Quality Assessment
* Paper ID: 2204.08763v1
* Paper URL: [http://arxiv.org/abs/2204.08763v1](http://arxiv.org/abs/2204.08763v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Full-reference (FR) image quality assessment (IQA) evaluates the visual
quality of a distorted image by measuring its perceptual difference with
pristine-quality reference, and has been widely used in low-level vision tasks.
Pairwise labeled data with mean opinion score (MOS) are required in training
FR-IQA model, but is time-consuming and cumbersome to collect. In contrast,
unlabeled data can be easily collected from an image degradation or restoration
process, making it encouraging to exploit unlabeled training data to boost
FR-IQA performance. Moreover, due to the distribution inconsistency between
labeled and unlabeled data, outliers may occur in unlabeled data, further
increasing the training difficulty. In this paper, we suggest to incorporate
semi-supervised and positive-unlabeled (PU) learning for exploiting unlabeled
data while mitigating the adverse effect of outliers. Particularly, by treating
all labeled data as positive samples, PU learning is leveraged to identify
negative samples (i.e., outliers) from unlabeled data. Semi-supervised learning
(SSL) is further deployed to exploit positive unlabeled data by dynamically
generating pseudo-MOS. We adopt a dual-branch network including reference and
distortion branches. Furthermore, spatial attention is introduced in the
reference branch to concentrate more on the informative regions, and sliced
Wasserstein distance is used for robust difference map computation to address
the misalignment issues caused by images recovered by GAN models. Extensive
experiments show that our method performs favorably against state-of-the-arts
on the benchmark datasets PIPAL, KADID-10k, TID2013, LIVE and CSIQ.

### Title: Flat bubble regime and laminar plasma flow in a plasma wake field accelerator
* Paper ID: 2204.08756v1
* Paper URL: [http://arxiv.org/abs/2204.08756v1](http://arxiv.org/abs/2204.08756v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: A simple 2D model of the bubble formation in a plasma wakefield accelerator
is developed and investigated. It is shown that in the case of a flat driver
the bubble may consist of two parts that correspond to two different types of
the plasma flow: a laminar flow where plasma electron streams do not cross and
a two-stream (turbulent) flow. The laminar flow turns out to be robust to the
symmetry breaking. Building-of of the developed model we demonstrate that in
the case of the laminar flow and non-relativistic plasma electrons the
transverse wake field is absent inside the bubble even in the case of a
transversely nonuniform plasma.

### Title: Probabilistic guarantees on the objective value for the scenario approach via sensitivity analysis
* Paper ID: 2204.08733v1
* Paper URL: [http://arxiv.org/abs/2204.08733v1](http://arxiv.org/abs/2204.08733v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: This paper is concerned with objective value performance of the scenario
approach for robust convex optimization. A novel method is proposed to derive
probabilistic bounds for the objective value from scenario programs with a
finite number of samples. This method relies on a max-min reformulation and the
concept of complexity of robust optimization problems. With additional
continuity and regularity conditions, via sensitivity analysis, we also provide
explicit bounds which outperform an existing result in the literature. To
illustrate the improvements of our results, we also provide a numerical
example.

### Title: Jacobian Ensembles Improve Robustness Trade-offs to Adversarial Attacks
* Paper ID: 2204.08726v1
* Paper URL: [http://arxiv.org/abs/2204.08726v1](http://arxiv.org/abs/2204.08726v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Deep neural networks have become an integral part of our software
infrastructure and are being deployed in many widely-used and safety-critical
applications. However, their integration into many systems also brings with it
the vulnerability to test time attacks in the form of Universal Adversarial
Perturbations (UAPs). UAPs are a class of perturbations that when applied to
any input causes model misclassification. Although there is an ongoing effort
to defend models against these adversarial attacks, it is often difficult to
reconcile the trade-offs in model accuracy and robustness to adversarial
attacks. Jacobian regularization has been shown to improve the robustness of
models against UAPs, whilst model ensembles have been widely adopted to improve
both predictive performance and model robustness. In this work, we propose a
novel approach, Jacobian Ensembles-a combination of Jacobian regularization and
model ensembles to significantly increase the robustness against UAPs whilst
maintaining or improving model accuracy. Our results show that Jacobian
Ensembles achieves previously unseen levels of accuracy and robustness, greatly
improving over previous methods that tend to skew towards only either accuracy
or robustness.

### Title: Adaptive Conductance Control
* Paper ID: 2204.08711v1
* Paper URL: [http://arxiv.org/abs/2204.08711v1](http://arxiv.org/abs/2204.08711v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Neuromodulation is central to the adaptation and robustness of animal nervous
systems. This paper explores the classical paradigm of indirect adaptive
control to design neuromodulatory controllers in conductance-based neuronal
models. The adaptive control of maximal conductance parameters is shown to
provide a methodology aligned with the central concepts of neuromodulation in
physiology and of impedance control in robotics.

### Title: Software Engineering Approaches for TinyML based IoT Embedded Vision: A Systematic Literature Review
* Paper ID: 2204.08702v1
* Paper URL: [http://arxiv.org/abs/2204.08702v1](http://arxiv.org/abs/2204.08702v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Internet of Things (IoT) has catapulted human ability to control our
environments through ubiquitous sensing, communication, computation, and
actuation. Over the past few years, IoT has joined forces with Machine Learning
(ML) to embed deep intelligence at the far edge. TinyML (Tiny Machine Learning)
has enabled the deployment of ML models for embedded vision on extremely lean
edge hardware, bringing the power of IoT and ML together. However, TinyML
powered embedded vision applications are still in a nascent stage, and they are
just starting to scale to widespread real-world IoT deployment. To harness the
true potential of IoT and ML, it is necessary to provide product developers
with robust, easy-to-use software engineering (SE) frameworks and best
practices that are customized for the unique challenges faced in TinyML
engineering. Through this systematic literature review, we aggregated the key
challenges reported by TinyML developers and identified state-of-art SE
approaches in large-scale Computer Vision, Machine Learning, and Embedded
Systems that can help address key challenges in TinyML based IoT embedded
vision. In summary, our study draws synergies between SE expertise that
embedded systems developers and ML developers have independently developed to
help address the unique challenges in the engineering of TinyML based IoT
embedded vision.

### Title: Generating Authentic Adversarial Examples beyond Meaning-preserving with Doubly Round-trip Translation
* Paper ID: 2204.08689v1
* Paper URL: [http://arxiv.org/abs/2204.08689v1](http://arxiv.org/abs/2204.08689v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Generating adversarial examples for Neural Machine Translation (NMT) with
single Round-Trip Translation (RTT) has achieved promising results by releasing
the meaning-preserving restriction. However, a potential pitfall for this
approach is that we cannot decide whether the generated examples are
adversarial to the target NMT model or the auxiliary backward one, as the
reconstruction error through the RTT can be related to either. To remedy this
problem, we propose a new criterion for NMT adversarial examples based on the
Doubly Round-Trip Translation (DRTT). Specifically, apart from the
source-target-source RTT, we also consider the target-source-target one, which
is utilized to pick out the authentic adversarial examples for the target NMT
model. Additionally, to enhance the robustness of the NMT model, we introduce
the masked language models to construct bilingual adversarial pairs based on
DRTT, which are used to train the NMT model directly. Extensive experiments on
both the clean and noisy test sets (including the artificial and natural noise)
show that our approach substantially improves the robustness of NMT models.

### Title: Audio-Visual Wake Word Spotting System For MISP Challenge 2021
* Paper ID: 2204.08686v1
* Paper URL: [http://arxiv.org/abs/2204.08686v1](http://arxiv.org/abs/2204.08686v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: This paper presents the details of our system designed for the Task 1 of
Multimodal Information Based Speech Processing (MISP) Challenge 2021. The
purpose of Task 1 is to leverage both audio and video information to improve
the environmental robustness of far-field wake word spotting. In the proposed
system, firstly, we take advantage of speech enhancement algorithms such as
beamforming and weighted prediction error (WPE) to address the multi-microphone
conversational audio. Secondly, several data augmentation techniques are
applied to simulate a more realistic far-field scenario. For the video
information, the provided region of interest (ROI) is used to obtain visual
representation. Then the multi-layer CNN is proposed to learn audio and visual
representations, and these representations are fed into our two-branch
attention-based network which can be employed for fusion, such as transformer
and conformed. The focal loss is used to fine-tune the model and improve the
performance significantly. Finally, multiple trained models are integrated by
casting vote to achieve our final 0.091 score.

### Title: A generalized echo squeezing protocol with near-Heisenberg limit sensitivity and strong robustness against excess noise and variation in squeezing parameter
* Paper ID: 2204.08681v1
* Paper URL: [http://arxiv.org/abs/2204.08681v1](http://arxiv.org/abs/2204.08681v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: We present a generalized echo squeezing protocol (GESP) as a generalization
of the Schr\"odinger cat state protocol (SCSP) with the value of the squeezing
parameter being an arbitrary number rather than pi/2. We show analytically that
over a broad range of the squeezing parameter the sensitivity reaches the
Heisenberg limit within a factor of root-2. For a large number of particles, N,
this plateau interval is almost the whole range from zero to pi/2, and the
sensitivity is independent of the parity of N. Therefore, it is possible to
operate a sensor over wide interval of the squeezing parameter without changing
the sensitivity. This is to be contrasted with the conventional echo squeezing
protocol (CESP) which only works for a very small interval of the squeezing
parameter. We also show that, in contrast to the CESP, the sensitivity of the
GESP is close to the quantum Cram\'er-Rao bound over the whole range of the
squeezing parameter, indicating that the phase shift information is
near-optimally extracted. We find that the enhancement in sensitivity in the
case of the GESP is due to a combination of two parameters: the phase
magnification (PMF) and the noise amplification factor (NAF). As the value of
the squeezing parameter increases, both PMF and NAF increase, while keeping the
ratio of PMF/NAF essentially constant, yielding a net enhancement of
sensitivity that at the Heisenberg limit within a factor of root-2 over the
whole plateau interval. An important consequence of this behavior is that the
robustness of the GESP against excess noise easily exceeds that of the CESP for
a broad range of values of the squeezing parameter. As such, in the context of
an experimental study, it should be possible to achieve a net enhancement in
sensitivity higher than that for the CESP, under typical conditions where the
excess noise exceeds the unsqueezed quantum projection noise.

### Title: Learning Forward Dynamics Model and Informed Trajectory Sampler for Safe Quadruped Navigation
* Paper ID: 2204.08647v1
* Paper URL: [http://arxiv.org/abs/2204.08647v1](http://arxiv.org/abs/2204.08647v1)
* Updated Date: 2022-04-19
* Code URL: [https://github.com/awesomericky/complex-env-navigation](https://github.com/awesomericky/complex-env-navigation)
* Summary: For autonomous quadruped robot navigation in various complex environments, a
typical SOTA system is composed of four main modules -- mapper, global planner,
local planner, and command-tracking controller -- in a hierarchical manner. In
this paper, we build a robust and safe local planner which is designed to
generate a velocity plan to track a coarsely planned path from the global
planner. Previous works used waypoint-based methods (e.g.
Proportional-Differential control and pure pursuit) which simplify the path
tracking problem to local point-goal navigation. However, they suffer from
frequent collisions in geometrically complex and narrow environments because of
two reasons; the global planner uses a coarse and inaccurate model and the
local planner is unable to track the global plan sufficiently well. Currently,
deep learning methods are an appealing alternative because they can learn
safety and path feasibility from experience more accurately. However, existing
deep learning methods are not capable of planning for a long horizon. In this
work, we propose a learning-based fully autonomous navigation framework
composed of three innovative elements: a learned forward dynamics model (FDM),
an online sampling-based model-predictive controller, and an informed
trajectory sampler (ITS). Using our framework, a quadruped robot can
autonomously navigate in various complex environments without a collision and
generate a smoother command plan compared to the baseline method. Furthermore,
our method can reactively handle unexpected obstacles on the planned path and
avoid them. Project page
https://awesomericky.github.io/projects/FDM_ITS_navigation/.

### Title: Asymptotic Independence of the Quadratic form and Maximum of Independent Random Variables with Applications to High-Dimensional Tests
* Paper ID: 2204.08628v1
* Paper URL: [http://arxiv.org/abs/2204.08628v1](http://arxiv.org/abs/2204.08628v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: This paper establishes the asymptotic independence between the quadratic form
and maximum of a sequence of independent random variables. Based on this
theoretical result, we find the asymptotic joint distribution for the quadratic
form and maximum, which can be applied into the high-dimensional testing
problems. By combining the sum-type test and the max-type test, we propose the
Fisher's combination tests for the one-sample mean test and two-sample mean
test. Under this novel general framework, several strong assumptions in
existing literature have been relaxed. Monte Carlo simulation has been done
which shows that our proposed tests are strongly robust to both sparse and
dense data.

### Title: Poisons that are learned faster are more effective
* Paper ID: 2204.08615v1
* Paper URL: [http://arxiv.org/abs/2204.08615v1](http://arxiv.org/abs/2204.08615v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Imperceptible poisoning attacks on entire datasets have recently been touted
as methods for protecting data privacy. However, among a number of defenses
preventing the practical use of these techniques, early-stopping stands out as
a simple, yet effective defense. To gauge poisons' vulnerability to
early-stopping, we benchmark error-minimizing, error-maximizing, and synthetic
poisons in terms of peak test accuracy over 100 epochs and make a number of
surprising observations. First, we find that poisons that reach a low training
loss faster have lower peak test accuracy. Second, we find that a current
state-of-the-art error-maximizing poison is 7 times less effective when poison
training is stopped at epoch 8. Third, we find that stronger, more transferable
adversarial attacks do not make stronger poisons. We advocate for evaluating
poisons in terms of peak test accuracy.

### Title: Self-Supervised Equivariant Learning for Oriented Keypoint Detection
* Paper ID: 2204.08613v1
* Paper URL: [http://arxiv.org/abs/2204.08613v1](http://arxiv.org/abs/2204.08613v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Detecting robust keypoints from an image is an integral part of many computer
vision problems, and the characteristic orientation and scale of keypoints play
an important role for keypoint description and matching. Existing
learning-based methods for keypoint detection rely on standard
translation-equivariant CNNs but often fail to detect reliable keypoints
against geometric variations. To learn to detect robust oriented keypoints, we
introduce a self-supervised learning framework using rotation-equivariant CNNs.
We propose a dense orientation alignment loss by an image pair generated by
synthetic transformations for training a histogram-based orientation map. Our
method outperforms the previous methods on an image matching benchmark and a
camera pose estimation benchmark.

### Title: Metamorphic Testing-based Adversarial Attack to Fool Deepfake Detectors
* Paper ID: 2204.08612v1
* Paper URL: [http://arxiv.org/abs/2204.08612v1](http://arxiv.org/abs/2204.08612v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Deepfakes utilise Artificial Intelligence (AI) techniques to create synthetic
media where the likeness of one person is replaced with another. There are
growing concerns that deepfakes can be maliciously used to create misleading
and harmful digital contents. As deepfakes become more common, there is a dire
need for deepfake detection technology to help spot deepfake media. Present
deepfake detection models are able to achieve outstanding accuracy (>90%).
However, most of them are limited to within-dataset scenario, where the same
dataset is used for training and testing. Most models do not generalise well
enough in cross-dataset scenario, where models are tested on unseen datasets
from another source. Furthermore, state-of-the-art deepfake detection models
rely on neural network-based classification models that are known to be
vulnerable to adversarial attacks. Motivated by the need for a robust deepfake
detection model, this study adapts metamorphic testing (MT) principles to help
identify potential factors that could influence the robustness of the examined
model, while overcoming the test oracle problem in this domain. Metamorphic
testing is specifically chosen as the testing technique as it fits our demand
to address learning-based system testing with probabilistic outcomes from
largely black-box components, based on potentially large input domains. We
performed our evaluations on MesoInception-4 and TwoStreamNet models, which are
the state-of-the-art deepfake detection models. This study identified makeup
application as an adversarial attack that could fool deepfake detectors. Our
experimental results demonstrate that both the MesoInception-4 and TwoStreamNet
models degrade in their performance by up to 30\% when the input data is
perturbed with makeup.

### Title: Is the Contralateral Delay Activity (CDA) a robust neural correlate for Visual Working Memory (VWM) tasks? A reproducibility study
* Paper ID: 2204.08578v1
* Paper URL: [http://arxiv.org/abs/2204.08578v1](http://arxiv.org/abs/2204.08578v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Visual working memory (VWM) allows us to actively store, update and
manipulate visual information surrounding us. While the underlying neural
mechanisms of VWM remain unclear, contralateral delay activity (CDA), a
sustained negativity over the hemisphere contralateral to the positions of
visual items to be remembered, is often used to study VWM. To investigate if
the CDA is a robust neural correlate for VWM tasks, we reproduced eight
CDA-related studies with a publicly accessible EEG dataset. We used the raw EEG
data from these eight studies and analyzed all of them with the same basic
pipeline to extract CDA. We were able to reproduce the results from all the
studies and show that with a basic automated EEG pipeline we can extract a
clear CDA signal. We share insights from the trends observed across the studies
and raise some questions about the CDA decay and the CDA during the recall
phase, which surprisingly, none of the eight studies did address. Finally, we
also provide reproducibility recommendations based on our experience and
challenges in reproducing these studies.

### Title: Expert-Calibrated Learning for Online Optimization with Switching Costs
* Paper ID: 2204.08572v1
* Paper URL: [http://arxiv.org/abs/2204.08572v1](http://arxiv.org/abs/2204.08572v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: We study online convex optimization with switching costs, a practically
important but also extremely challenging problem due to the lack of complete
offline information. By tapping into the power of machine learning (ML) based
optimizers, ML-augmented online algorithms (also referred to as expert
calibration in this paper) have been emerging as state of the art, with
provable worst-case performance guarantees. Nonetheless, by using the standard
practice of training an ML model as a standalone optimizer and plugging it into
an ML-augmented algorithm, the average cost performance can be even worse than
purely using ML predictions. In order to address the "how to learn" challenge,
we propose EC-L2O (expert-calibrated learning to optimize), which trains an
ML-based optimizer by explicitly taking into account the downstream expert
calibrator. To accomplish this, we propose a new differentiable expert
calibrator that generalizes regularized online balanced descent and offers a
provably better competitive ratio than pure ML predictions when the prediction
error is large. For training, our loss function is a weighted sum of two
different losses -- one minimizing the average ML prediction error for better
robustness, and the other one minimizing the post-calibration average cost. We
also provide theoretical analysis for EC-L2O, highlighting that expert
calibration can be even beneficial for the average cost performance and that
the high-percentile tail ratio of the cost achieved by EC-L2O to that of the
offline optimal oracle (i.e., tail cost ratio) can be bounded. Finally, we test
EC-L2O by running simulations for sustainable datacenter demand response. Our
results demonstrate that EC-L2O can empirically achieve a lower average cost as
well as a lower competitive ratio than the existing baseline algorithms.

### Title: A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability
* Paper ID: 2204.08570v1
* Paper URL: [http://arxiv.org/abs/2204.08570v1](http://arxiv.org/abs/2204.08570v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Graph Neural Networks (GNNs) have made rapid developments in the recent
years. Due to their great ability in modeling graph-structured data, GNNs are
vastly used in various applications, including high-stakes scenarios such as
financial analysis, traffic predictions, and drug discovery. Despite their
great potential in benefiting humans in the real world, recent study shows that
GNNs can leak private information, are vulnerable to adversarial attacks, can
inherit and magnify societal bias from training data and lack interpretability,
which have risk of causing unintentional harm to the users and society. For
example, existing works demonstrate that attackers can fool the GNNs to give
the outcome they desire with unnoticeable perturbation on training graph. GNNs
trained on social networks may embed the discrimination in their decision
process, strengthening the undesirable societal bias. Consequently, trustworthy
GNNs in various aspects are emerging to prevent the harm from GNN models and
increase the users' trust in GNNs. In this paper, we give a comprehensive
survey of GNNs in the computational aspects of privacy, robustness, fairness,
and explainability. For each aspect, we give the taxonomy of the related
methods and formulate the general frameworks for the multiple categories of
trustworthy GNNs. We also discuss the future research directions of each aspect
and connections between these aspects to help achieve trustworthiness.

### Title: PIDGeuN: Graph Neural Network-Enabled Transient Dynamics Prediction of Networked Microgrids Through Full-Field Measurement
* Paper ID: 2204.08557v1
* Paper URL: [http://arxiv.org/abs/2204.08557v1](http://arxiv.org/abs/2204.08557v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: A Physics-Informed Dynamic Graph Neural Network (PIDGeuN) is presented to
accurately, efficiently and robustly predict the nonlinear transient dynamics
of microgrids in the presence of disturbances. The graph-based architecture of
PIDGeuN provides a natural representation of the microgrid topology. Using only
the state information that is practically measurable, PIDGeuN employs a time
delay embedding formulation to fully reproduce the system dynamics, avoiding
the dependency of conventional methods on internal dynamic states such as
controllers. Based on a judiciously designed message passing mechanism, the
PIDGeuN incorporates two physics-informed techniques to improve its prediction
performance, including a physics-data-infusion approach to determining the
inter-dependencies between buses, and a loss term to respect the known physical
law of the power system, i.e., the Kirchhoff's law, to ensure the feasibility
of the model prediction. Extensive tests show that PIDGeuN can provide accurate
and robust prediction of transient dynamics for nonlinear microgrids over a
long-term time period. Therefore, the PIDGeuN offers a potent tool for the
modeling of large scale networked microgrids (NMs), with potential applications
to predictive or preventive control in real time applications for the stable
and resilient operations of NMs.

### Title: Topological order and entanglement dynamics in the measurement-only XZZX quantum code
* Paper ID: 2204.08489v1
* Paper URL: [http://arxiv.org/abs/2204.08489v1](http://arxiv.org/abs/2204.08489v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: We examine the dynamics of a $(1+1)$-dimensional measurement-only circuit
defined by the stabilizers of the [[5,1,3]] quantum error correcting code
interrupted by single-qubit Pauli measurements. The code corrects arbitrary
single-qubit errors and it stabilizes an area law entangled state with a $D_2 =
\mathbb{Z}_2 \times \mathbb{Z}_2$ symmetry protected topological (SPT) order,
as well as a symmetry breaking (SB) order from a two-fold bulk degeneracy. The
Pauli measurements break the topological order and induce a phase transition
into a trivial area law phase. Allowing more than one type of Pauli measurement
increases the measurement-induced frustration, and the SPT and SB order can be
broken either simultaneously or separately at nonzero measurement rate. This
yields a rich phase diagram and unanticipated critical behavior at the phase
transitions. Although the correlation length exponent $\nu=\tfrac43$ and the
dynamical critical exponent $z=1$ are consistent with bond percolation, the
prefactor of the logarithmic entanglement growth may take non-integer multiples
of the percolation value. Remarkably, we identify a robust transient scaling
regime for the purification dynamics of $L$ qubits. It reveals a modified
dynamical critical exponent $z^*\neq z$, which is observable up to times $t\sim
L^{z^*}$ and is reminiscent of the relaxation of critical systems into a
prethermal state.

### Title: Observed Extra Mixing Trends in Red Giants are Reproduced by the Reduced Density Ratio in Thermohaline Zones
* Paper ID: 2204.08487v1
* Paper URL: [http://arxiv.org/abs/2204.08487v1](http://arxiv.org/abs/2204.08487v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Observations show an almost ubiquitous presence of extra mixing in low-mass
upper giant branch stars. The most commonly invoked explanation for this is the
thermohaline instability. One dimensional stellar evolution models include
prescriptions for thermohaline mixing, but our ability to make direct
comparisons between models and observations has thus far been limited. Here, we
propose a new framework to facilitate direct comparison: Using carbon to
nitrogen measurements from the SDSS-IV APOGEE survey as a probe of mixing and a
fluid parameter known as the reduced density ratio from one dimensional stellar
evolution programs, we compare the observed amount of extra mixing on the upper
giant branch to predicted trends from three-dimensional fluid dynamics
simulations. By applying this method, we are able to place empirical
constraints on the efficiency of mixing across a range of masses and
metallicities. We find that the observed amount of extra mixing is strongly
correlated with the reduced density ratio and that trends between reduced
density ratio and fundamental stellar parameters are robust across choices for
modeling prescription. We show that stars with available mixing data tend to
have relatively low density ratios, which should inform the regimes selected
for future simulation efforts. Finally, we show that there is increased mixing
at low values of the reduced density ratio, which is consistent with current
hydrodynamical models of the thermohaline instability. The introduction of this
framework sets a new standard for theoretical modeling efforts, as validation
for not only the amount of extra mixing, but trends between the degree of extra
mixing and fundamental stellar parameters is now possible.

### Title: Efficient reverse engineering of one-qubit filter functions with dynamical invariants
* Paper ID: 2204.08457v1
* Paper URL: [http://arxiv.org/abs/2204.08457v1](http://arxiv.org/abs/2204.08457v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: We derive an integral expression for the filter-transfer function of an
arbitrary one-qubit gate through the use of dynamical invariant theory and
Hamiltonian reverse engineering. We use this result to define a cost functional
which can be efficiently optimized to produce one-qubit control pulses that are
robust against specified frequency bands of the noise power spectral density.
We demonstrate the utility of our result by generating optimal control pulses
that are designed to suppress broadband detuning and pulse amplitude noise. We
report an order of magnitude improvement in gate fidelity in comparison with
known composite pulse sequences. More broadly, we also use the same theoretical
framework to prove the robustness of nonadiabatic geometric quantum gates under
specific error models and control constraints.

### Title: Robust, Nonparametric, Efficient Decomposition of Spectral Peaks under Distortion and Interference
* Paper ID: 2204.08411v1
* Paper URL: [http://arxiv.org/abs/2204.08411v1](http://arxiv.org/abs/2204.08411v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: We propose a decomposition method for the spectral peaks in an observed
frequency spectrum, which is efficiently acquired by utilizing the Fast Fourier
Transform. In contrast to the traditional methods of waveform fitting on the
spectrum, we optimize the problem from a more robust perspective. We model the
peaks in spectrum as pseudo-symmetric functions, where the only constraint is a
nonincreasing behavior around a central frequency when the distance increases.
Our approach is more robust against arbitrary distortion, interference and
noise on the spectrum that may be caused by an observation system. The time
complexity of our method is linear, i.e., $O(N)$ per extracted spectral peak.
Moreover, the decomposed spectral peaks show a pseudo-orthogonal behavior,
where they conform to a power preserving equality.

### Title: Non-Markovian random walks characterize network robustness to nonlocal cascades
* Paper ID: 2204.08407v1
* Paper URL: [http://arxiv.org/abs/2204.08407v1](http://arxiv.org/abs/2204.08407v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Localized perturbations in a real-world network have the potential to trigger
cascade failures at the whole system level, hindering its operations and
functions. Standard approaches analytically tackling this problem are mostly
based either on static descriptions, such as percolation, or on models where
the failure evolves through first-neighbor connections, crucially failing to
capture the nonlocal behavior typical of real cascades. We introduce a
dynamical model that maps the failure propagation across the network to a
self-avoiding random walk that, at each step, has a probability to perform
nonlocal jumps toward operational systems' units. Despite the inherent
non-Markovian nature of the process, we are able to characterize the critical
behavior of the system out of equilibrium, as well as the stopping time
distribution of the cascades. Our numerical experiments on synthetic and
empirical biological and transportation networks are in excellent agreement
with theoretical expectation, demonstrating the ability of our framework to
quantify the vulnerability to nonlocal cascade failures of complex systems with
interconnected structure.

### Title: Rank Based Tests for High Dimensional White Noise
* Paper ID: 2204.08402v1
* Paper URL: [http://arxiv.org/abs/2204.08402v1](http://arxiv.org/abs/2204.08402v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: The development of high-dimensional white noise test is important in both
statistical theories and applications, where the dimension of the time series
can be comparable to or exceed the length of the time series. This paper
proposes several distribution-free tests using the rank based statistics for
testing the high-dimensional white noise, which are robust to the heavy tails
and do not quire the finite-order moment assumptions for the sample
distributions. Three families of rank based tests are analyzed in this paper,
including the simple linear rank statistics, non-degenerate U-statistics and
degenerate U-statistics. The asymptotic null distributions and rate optimality
are established for each family of these tests. Among these tests, the test
based on degenerate U-statistics can also detect the non-linear and
non-monotone relationships in the autocorrelations. Moreover, this is the first
result on the asymptotic distributions of rank correlation statistics which
allowing for the cross-sectional dependence in high dimensional data.

### Title: Detecting Deepfakes with Self-Blended Images
* Paper ID: 2204.08376v1
* Paper URL: [http://arxiv.org/abs/2204.08376v1](http://arxiv.org/abs/2204.08376v1)
* Updated Date: 2022-04-18
* Code URL: [https://github.com/mapooon/selfblendedimages](https://github.com/mapooon/selfblendedimages)
* Summary: In this paper, we present novel synthetic training data called self-blended
images (SBIs) to detect deepfakes. SBIs are generated by blending pseudo source
and target images from single pristine images, reproducing common forgery
artifacts (e.g., blending boundaries and statistical inconsistencies between
source and target images). The key idea behind SBIs is that more general and
hardly recognizable fake samples encourage classifiers to learn generic and
robust representations without overfitting to manipulation-specific artifacts.
We compare our approach with state-of-the-art methods on FF++, CDF, DFD, DFDC,
DFDCP, and FFIW datasets by following the standard cross-dataset and
cross-manipulation protocols. Extensive experiments show that our method
improves the model generalization to unknown manipulations and scenes. In
particular, on DFDC and DFDCP where existing methods suffer from the domain gap
between the training and test sets, our approach outperforms the baseline by
4.90% and 11.78% points in the cross-dataset evaluation, respectively.

### Title: Detecting, Tracking and Counting Motorcycle Rider Traffic Violations on Unconstrained Roads
* Paper ID: 2204.08364v1
* Paper URL: [http://arxiv.org/abs/2204.08364v1](http://arxiv.org/abs/2204.08364v1)
* Updated Date: 2022-04-18
* Code URL: [https://github.com/ihubdata-mobility/public-motorcycle-violations](https://github.com/ihubdata-mobility/public-motorcycle-violations)
* Summary: In many Asian countries with unconstrained road traffic conditions, driving
violations such as not wearing helmets and triple-riding are a significant
source of fatalities involving motorcycles. Identifying and penalizing such
riders is vital in curbing road accidents and improving citizens' safety. With
this motivation, we propose an approach for detecting, tracking, and counting
motorcycle riding violations in videos taken from a vehicle-mounted dashboard
camera. We employ a curriculum learning-based object detector to better tackle
challenging scenarios such as occlusions. We introduce a novel trapezium-shaped
object boundary representation to increase robustness and tackle the
rider-motorcycle association. We also introduce an amodal regressor that
generates bounding boxes for the occluded riders. Experimental results on a
large-scale unconstrained driving dataset demonstrate the superiority of our
approach compared to existing approaches and other ablative variants.

### Title: MHSCNet: A Multimodal Hierarchical Shot-aware Convolutional Network for Video Summarization
* Paper ID: 2204.08352v2
* Paper URL: [http://arxiv.org/abs/2204.08352v2](http://arxiv.org/abs/2204.08352v2)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Video summarization intends to produce a concise video summary by effectively
capturing and combining the most informative parts of the whole content.
Existing approaches for video summarization regard the task as a frame-wise
keyframe selection problem and generally construct the frame-wise
representation by combining the long-range temporal dependency with the
unimodal or bimodal information. However, the optimal video summaries need to
reflect the most valuable keyframe with its own information, and one with
semantic power of the whole content. Thus, it is critical to construct a more
powerful and robust frame-wise representation and predict the frame-level
importance score in a fair and comprehensive manner. To tackle the above
issues, we propose a multimodal hierarchical shot-aware convolutional network,
denoted as MHSCNet, to enhance the frame-wise representation via combining the
comprehensive available multimodal information. Specifically, we design a
hierarchical ShotConv network to incorporate the adaptive shot-aware
frame-level representation by considering the short-range and long-range
temporal dependency. Based on the learned shot-aware representations, MHSCNet
can predict the frame-level importance score in the local and global view of
the video. Extensive experiments on two standard video summarization datasets
demonstrate that our proposed method consistently outperforms state-of-the-art
baselines. Source code will be made publicly available.

### Title: Predictive analytics for appointment bookings
* Paper ID: 2204.08475v1
* Paper URL: [http://arxiv.org/abs/2204.08475v1](http://arxiv.org/abs/2204.08475v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: One of the service providers in the financial service sector, who provide
premium service to the customers, wanted to harness the power of data analytics
as data mining can uncover valuable insights for better decision making.
Therefore, the author aimed to use predictive analytics to discover crucial
factors that will affect the customers' showing up for their appointment and
booking the service. The first model predicts whether a customer will show up
for the meeting, while the second model indicates whether a customer will book
a premium service. Both models produce accurate results with more than a 75%
accuracy rate, thus providing a more robust model for implementation than gut
feeling and intuition. Finally, this paper offers a framework for resource
planning using the predicted demand.

### Title: Tracking monocular camera pose and deformation for SLAM inside the human body
* Paper ID: 2204.08309v1
* Paper URL: [http://arxiv.org/abs/2204.08309v1](http://arxiv.org/abs/2204.08309v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Monocular SLAM in deformable scenes will open the way to multiple medical
applications like computer-assisted navigation in endoscopy, automatic drug
delivery or autonomous robotic surgery. In this paper we propose a novel method
to simultaneously track the camera pose and the 3D scene deformation, without
any assumption about environment topology or shape. The method uses an
illumination-invariant photometric method to track image features and estimates
camera motion and deformation combining reprojection error with spatial and
temporal regularization of deformations. Our results in simulated colonoscopies
show the method's accuracy and robustness in complex scenes under increasing
levels of deformation. Our qualitative results in human colonoscopies from
Endomapper dataset show that the method is able to successfully cope with the
challenges of real endoscopies: deformations, low texture and strong
illumination changes. We also compare with previous tracking methods in simpler
scenarios from Hamlyn dataset where we obtain competitive performance, without
needing any topological assumption.

### Title: StepGame: A New Benchmark for Robust Multi-Hop Spatial Reasoning in Texts
* Paper ID: 2204.08292v1
* Paper URL: [http://arxiv.org/abs/2204.08292v1](http://arxiv.org/abs/2204.08292v1)
* Updated Date: 2022-04-18
* Code URL: [https://github.com/ZhengxiangShi/StepGame](https://github.com/ZhengxiangShi/StepGame)
* Summary: Inferring spatial relations in natural language is a crucial ability an
intelligent system should possess. The bAbI dataset tries to capture tasks
relevant to this domain (task 17 and 19). However, these tasks have several
limitations. Most importantly, they are limited to fixed expressions, they are
limited in the number of reasoning steps required to solve them, and they fail
to test the robustness of models to input that contains irrelevant or redundant
information. In this paper, we present a new Question-Answering dataset called
StepGame for robust multi-hop spatial reasoning in texts. Our experiments
demonstrate that state-of-the-art models on the bAbI dataset struggle on the
StepGame dataset. Moreover, we propose a Tensor-Product based Memory-Augmented
Neural Network (TP-MANN) specialized for spatial reasoning tasks. Experimental
results on both datasets show that our model outperforms all the baselines with
superior generalization and robustness performance.

### Title: Modx: Binary Level Partial Imported Third-Party Library Detection through Program Modularization and Semantic Matching
* Paper ID: 2204.08237v1
* Paper URL: [http://arxiv.org/abs/2204.08237v1](http://arxiv.org/abs/2204.08237v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: With the rapid growth of software, using third-party libraries (TPLs) has
become increasingly popular. The prosperity of the library usage has provided
the software engineers with handful of methods to facilitate and boost the
program development. Unfortunately, it also poses great challenges as it
becomes much more difficult to manage the large volume of libraries. Researches
and studies have been proposed to detect and understand the TPLs in the
software. However, most existing approaches rely on syntactic features, which
are not robust when these features are changed or deliberately hidden by the
adversarial parties. Moreover, these approaches typically model each of the
imported libraries as a whole, therefore, cannot be applied to scenarios where
the host software only partially uses the library code segments.
  To detect both fully and partially imported TPLs at the semantic level, we
propose ModX, a framework that leverages novel program modularization
techniques to decompose the program into finegrained functionality-based
modules. By extracting both syntactic and semantic features, it measures the
distance between modules to detect similar library module reuse in the program.
Experimental results show that ModX outperforms other modularization tools by
distinguishing more coherent program modules with 353% higher module quality
scores and beats other TPL detection tools with on average 17% better in
precision and 8% better in recall.

### Title: The Devil is in the Frequency: Geminated Gestalt Autoencoder for Self-Supervised Visual Pre-Training
* Paper ID: 2204.08227v1
* Paper URL: [http://arxiv.org/abs/2204.08227v1](http://arxiv.org/abs/2204.08227v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: The self-supervised Masked Image Modeling (MIM) schema, following
"mask-and-reconstruct" pipeline of recovering contents from masked image, has
recently captured the increasing interest in the multimedia community, owing to
the excellent ability of learning visual representation from unlabeled data.
Aiming at learning representations with high semantics abstracted, a group of
works attempts to reconstruct non-semantic pixels with large-ratio masking
strategy, which may suffer from "over-smoothing" problem, while others directly
infuse semantics into targets in off-line way requiring extra data. Different
from them, we shift the perspective to the Fourier domain which naturally has
global perspective and present a new Masked Image Modeling (MIM), termed
Geminated Gestalt Autoencoder (Ge$^2$-AE) for visual pre-training.
Specifically, we equip our model with geminated decoders in charge of
reconstructing image contents from both pixel and frequency space, where each
other serves as not only the complementation but also the reciprocal
constraints. Through this way, more robust representations can be learned in
the pre-trained encoders, of which the effectiveness is confirmed by the
juxtaposing experimental results on downstream recognition tasks. We also
conduct several quantitative and qualitative experiments to investigate the
learning behavior of our method. To our best knowledge, this is the first MIM
work to solve the visual pre-training through the lens of frequency domain.

### Title: Sardino: Ultra-Fast Dynamic Ensemble for Secure Visual Sensing at Mobile Edge
* Paper ID: 2204.08189v1
* Paper URL: [http://arxiv.org/abs/2204.08189v1](http://arxiv.org/abs/2204.08189v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Adversarial example attack endangers the mobile edge systems such as vehicles
and drones that adopt deep neural networks for visual sensing. This paper
presents {\em Sardino}, an active and dynamic defense approach that renews the
inference ensemble at run time to develop security against the adaptive
adversary who tries to exfiltrate the ensemble and construct the corresponding
effective adversarial examples. By applying consistency check and data fusion
on the ensemble's predictions, Sardino can detect and thwart adversarial
inputs. Compared with the training-based ensemble renewal, we use HyperNet to
achieve {\em one million times} acceleration and per-frame ensemble renewal
that presents the highest level of difficulty to the prerequisite exfiltration
attacks. Moreover, the robustness of the renewed ensembles against adversarial
examples is enhanced with adversarial learning for the HyperNet. We design a
run-time planner that maximizes the ensemble size in favor of security while
maintaining the processing frame rate. Beyond adversarial examples, Sardino can
also address the issue of out-of-distribution inputs effectively. This paper
presents extensive evaluation of Sardino's performance in counteracting
adversarial examples and applies it to build a real-time car-borne traffic sign
recognition system. Live on-road tests show the built system's effectiveness in
maintaining frame rate and detecting out-of-distribution inputs due to the
false positives of a preceding YOLO-based traffic sign detector.

### Title: A Taxonomy of Error Sources in HPC I/O Machine Learning Models
* Paper ID: 2204.08180v1
* Paper URL: [http://arxiv.org/abs/2204.08180v1](http://arxiv.org/abs/2204.08180v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: I/O efficiency is crucial to productivity in scientific computing, but the
increasing complexity of the system and the applications makes it difficult for
practitioners to understand and optimize I/O behavior at scale. Data-driven
machine learning-based I/O throughput models offer a solution: they can be used
to identify bottlenecks, automate I/O tuning, or optimize job scheduling with
minimal human intervention. Unfortunately, current state-of-the-art I/O models
are not robust enough for production use and underperform after being deployed.
  We analyze multiple years of application, scheduler, and storage system logs
on two leadership-class HPC platforms to understand why I/O models underperform
in practice. We propose a taxonomy consisting of five categories of I/O
modeling errors: poor application and system modeling, inadequate dataset
coverage, I/O contention, and I/O noise. We develop litmus tests to quantify
each category, allowing researchers to narrow down failure modes, enhance I/O
throughput models, and improve future generations of HPC logging and analysis
tools.

### Title: TABi: Type-Aware Bi-Encoders for Open-Domain Entity Retrieval
* Paper ID: 2204.08173v1
* Paper URL: [http://arxiv.org/abs/2204.08173v1](http://arxiv.org/abs/2204.08173v1)
* Updated Date: 2022-04-18
* Code URL: [https://github.com/hazyresearch/tabi](https://github.com/hazyresearch/tabi)
* Summary: Entity retrieval--retrieving information about entity mentions in a query--is
a key step in open-domain tasks, such as question answering or fact checking.
However, state-of-the-art entity retrievers struggle to retrieve rare entities
for ambiguous mentions due to biases towards popular entities. Incorporating
knowledge graph types during training could help overcome popularity biases,
but there are several challenges: (1) existing type-based retrieval methods
require mention boundaries as input, but open-domain tasks run on unstructured
text, (2) type-based methods should not compromise overall performance, and (3)
type-based methods should be robust to noisy and missing types. In this work,
we introduce TABi, a method to jointly train bi-encoders on knowledge graph
types and unstructured text for entity retrieval for open-domain tasks. TABi
leverages a type-enforced contrastive loss to encourage entities and queries of
similar types to be close in the embedding space. TABi improves retrieval of
rare entities on the Ambiguous Entity Retrieval (AmbER) sets, while maintaining
strong overall retrieval performance on open-domain tasks in the KILT benchmark
compared to state-of-the-art retrievers. TABi is also robust to incomplete type
systems, improving rare entity retrieval over baselines with only 5% type
coverage of the training dataset. We make our code publicly available at
https://github.com/HazyResearch/tabi.

### Title: Robust End-to-end Speaker Diarization with Generic Neural Clustering
* Paper ID: 2204.08164v1
* Paper URL: [http://arxiv.org/abs/2204.08164v1](http://arxiv.org/abs/2204.08164v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: End-to-end speaker diarization approaches have shown exceptional performance
over the traditional modular approaches. To further improve the performance of
the end-to-end speaker diarization for real speech recordings, recently works
have been proposed which integrate unsupervised clustering algorithms with the
end-to-end neural diarization models. However, these methods have a number of
drawbacks: 1) The unsupervised clustering algorithms cannot leverage the
supervision from the available datasets; 2) The K-means-based unsupervised
algorithms that are explored often suffer from the constraint violation
problem; 3) There is unavoidable mismatch between the supervised training and
the unsupervised inference. In this paper, a robust generic neural clustering
approach is proposed that can be integrated with any chunk-level predictor to
accomplish a fully supervised end-to-end speaker diarization model. Also, by
leveraging the sequence modelling ability of a recurrent neural network, the
proposed neural clustering approach can dynamically estimate the number of
speakers during inference. Experimental show that when integrating an
attractor-based chunk-level predictor, the proposed neural clustering approach
can yield better Diarization Error Rate (DER) than the constrained
K-means-based clustering approaches under the mismatched conditions.

### Title: Multi-scale Anomaly Detection for Big Time Series of Industrial Sensors
* Paper ID: 2204.08159v1
* Paper URL: [http://arxiv.org/abs/2204.08159v1](http://arxiv.org/abs/2204.08159v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Given a multivariate big time series, can we detect anomalies as soon as they
occur? Many existing works detect anomalies by learning how much a time series
deviates away from what it should be in the reconstruction framework. However,
most models have to cut the big time series into small pieces empirically since
optimization algorithms cannot afford such a long series. The question is
raised: do such cuts pollute the inherent semantic segments, like incorrect
punctuation in sentences? Therefore, we propose a reconstruction-based anomaly
detection method, MissGAN, iteratively learning to decode and encode naturally
smooth time series in coarse segments, and finding out a finer segment from
low-dimensional representations based on HMM. As a result, learning from
multi-scale segments, MissGAN can reconstruct a meaningful and robust time
series, with the help of adversarial regularization and extra conditional
states. MissGAN does not need labels or only needs labels of normal instances,
making it widely applicable. Experiments on industrial datasets of real water
network sensors show our MissGAN outperforms the baselines with scalability.
Besides, we use a case study on the CMU Motion dataset to demonstrate that our
model can well distinguish unexpected gestures from a given conditional motion.

### Title: Detect Rumors in Microblog Posts for Low-Resource Domains via Adversarial Contrastive Learning
* Paper ID: 2204.08143v2
* Paper URL: [http://arxiv.org/abs/2204.08143v2](http://arxiv.org/abs/2204.08143v2)
* Updated Date: 2022-04-19
* Code URL: [https://github.com/daniellin97/aclr4rumor-naacl2022](https://github.com/daniellin97/aclr4rumor-naacl2022)
* Summary: Massive false rumors emerging along with breaking news or trending topics
severely hinder the truth. Existing rumor detection approaches achieve
promising performance on the yesterday's news, since there is enough corpus
collected from the same domain for model training. However, they are poor at
detecting rumors about unforeseen events especially those propagated in
different languages due to the lack of training data and prior knowledge (i.e.,
low-resource regimes). In this paper, we propose an adversarial contrastive
learning framework to detect rumors by adapting the features learned from
well-resourced rumor data to that of the low-resourced. Our model explicitly
overcomes the restriction of domain and/or language usage via language
alignment and a novel supervised contrastive training paradigm. Moreover, we
develop an adversarial augmentation mechanism to further enhance the robustness
of low-resource rumor representation. Extensive experiments conducted on two
low-resource datasets collected from real-world microblog platforms demonstrate
that our framework achieves much better performance than state-of-the-art
methods and exhibits a superior capacity for detecting rumors at early stages.

### Title: Optimal Power Flow in Four-Wire Distribution Networks: Formulation and Benchmarking
* Paper ID: 2204.08126v1
* Paper URL: [http://arxiv.org/abs/2204.08126v1](http://arxiv.org/abs/2204.08126v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: In recent years, several applications have been proposed in the context of
distribution networks. Many of these can be formulated as an optimal power flow
problem, a mathematical optimization program which includes a model of the
steady-state physics of the electricity network. If the network loading is
balanced and the lines are transposed, the network model can be simplified to a
single-phase equivalent model. However, these assumptions do not apply to
low-voltage distribution networks, so the network model should model the
effects of phase unbalance correctly. In many parts of the world, the
low-voltage distribution network has four conductors, i.e. three phases and a
neutral. This paper develops OPF formulations for such networks, including
transformers, shunts and voltage-dependent loads, in two variable spaces, i.e.
current-voltage and power-voltage, and compares them for robustness and
scalability. A case study across 128 low-voltage networks also quantifies the
modelling error introduced by Kron reductions and its impact on the solve time.
This work highlights the advantages of formulations in current-voltage
variables over power-voltage, for four-wire networks.

### Title: Testing synchrotron models and frequency resolution in BINGO 21 cm simulated maps using GNILC
* Paper ID: 2204.08112v1
* Paper URL: [http://arxiv.org/abs/2204.08112v1](http://arxiv.org/abs/2204.08112v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: To recover the 21 cm hydrogen line, it is essential to separate the
cosmological signal from the much stronger foreground contributions at radio
frequencies. The BINGO radio telescope is designed to measure the 21 cm line
and detect BAOs using the intensity mapping technique. This work analyses the
performance of the GNILC method, combined with a power spectrum debiasing
procedure. The method was applied to a simulated BINGO mission, building upon
previous work from the collaboration. It compares two different synchrotron
emission models and different instrumental configurations, in addition to the
combination with ancillary data to optimize both the foreground removal and
recovery of the 21 cm signal across the full BINGO frequency band, as well as
to determine an optimal number of frequency bands for the signal recovery. We
have produced foreground emissions maps using the Planck Sky Model, the
cosmological Hi emission maps are generated using the FLASK package and thermal
noise maps are created according to the instrumental setup. We apply the GNILC
method to the simulated sky maps to separate the Hi plus thermal noise
contribution and, through a debiasing procedure, recover an estimate of the
noiseless 21 cm power spectrum. We found a near optimal reconstruction of the
Hi signal using a 80 bins configuration, which resulted in a power spectrum
reconstruction average error over all frequencies of 3%. Furthermore, our tests
showed that GNILC is robust against different synchrotron emission models.
Finally, adding an extra channel with CBASS foregrounds information, we reduced
the estimation error of the 21 cm signal. The optimisation of our previous
work, producing a configuration with an optimal number of channels for binning
the data, impacts greatly the decisions regarding BINGO hardware configuration
before commissioning.

