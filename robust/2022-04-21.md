### Title: An Efficient Domain-Incremental Learning Approach to Drive in All Weather Conditions
* Paper ID: 2204.08817v2
* Paper URL: [http://arxiv.org/abs/2204.08817v2](http://arxiv.org/abs/2204.08817v2)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Although deep neural networks enable impressive visual perception performance
for autonomous driving, their robustness to varying weather conditions still
requires attention. When adapting these models for changed environments, such
as different weather conditions, they are prone to forgetting previously
learned information. This catastrophic forgetting is typically addressed via
incremental learning approaches which usually re-train the model by either
keeping a memory bank of training samples or keeping a copy of the entire model
or model parameters for each scenario. While these approaches show impressive
results, they can be prone to scalability issues and their applicability for
autonomous driving in all weather conditions has not been shown. In this paper
we propose DISC -- Domain Incremental through Statistical Correction -- a
simple online zero-forgetting approach which can incrementally learn new tasks
(i.e weather conditions) without requiring re-training or expensive memory
banks. The only information we store for each task are the statistical
parameters as we categorize each domain by the change in first and second order
statistics. Thus, as each task arrives, we simply 'plug and play' the
statistical vectors for the corresponding task into the model and it
immediately starts to perform well on that task. We show the efficacy of our
approach by testing it for object detection in a challenging domain-incremental
autonomous driving scenario where we encounter different adverse weather
conditions, such as heavy rain, fog, and snow.

### Title: Radio Galaxy Zoo: Using semi-supervised learning to leverage large unlabelled data-sets for radio galaxy classification under data-set shift
* Paper ID: 2204.08816v3
* Paper URL: [http://arxiv.org/abs/2204.08816v3](http://arxiv.org/abs/2204.08816v3)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/inigoval/fixmatch](https://github.com/inigoval/fixmatch)
* Summary: In this work we examine the classification accuracy and robustness of a
state-of-the-art semi-supervised learning (SSL) algorithm applied to the
morphological classification of radio galaxies. We test if SSL with fewer
labels can achieve test accuracies comparable to the supervised
state-of-the-art and whether this holds when incorporating previously unseen
data. We find that for the radio galaxy classification problem considered, SSL
provides additional regularisation and outperforms the baseline test accuracy.
However, in contrast to model performance metrics reported on computer science
benchmarking data-sets, we find that improvement is limited to a narrow range
of label volumes, with performance falling off rapidly at low label volumes.
Additionally, we show that SSL does not improve model calibration, regardless
of whether classification is improved. Moreover, we find that when different
underlying catalogues drawn from the same radio survey are used to provide the
labelled and unlabelled data-sets required for SSL, a significant drop in
classification performance is observered, highlighting the difficulty of
applying SSL techniques under dataset shift. We show that a class-imbalanced
unlabelled data pool negatively affects performance through prior probability
shift, which we suggest may explain this performance drop, and that using the
Frechet Distance between labelled and unlabelled data-sets as a measure of
data-set shift can provide a prediction of model performance, but that for
typical radio galaxy data-sets with labelled sample volumes of O(1000), the
sample variance associated with this technique is high and the technique is in
general not sufficiently robust to replace a train-test cycle.

### Title: Learning Forward Dynamics Model and Informed Trajectory Sampler for Safe Quadruped Navigation
* Paper ID: 2204.08647v3
* Paper URL: [http://arxiv.org/abs/2204.08647v3](http://arxiv.org/abs/2204.08647v3)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/awesomericky/complex-env-navigation](https://github.com/awesomericky/complex-env-navigation)
* Summary: For autonomous quadruped robot navigation in various complex environments, a
typical SOTA system is composed of four main modules -- mapper, global planner,
local planner, and command-tracking controller -- in a hierarchical manner. In
this paper, we build a robust and safe local planner which is designed to
generate a velocity plan to track a coarsely planned path from the global
planner. Previous works used waypoint-based methods (e.g.
Proportional-Differential control and pure pursuit) which simplify the path
tracking problem to local point-goal navigation. However, they suffer from
frequent collisions in geometrically complex and narrow environments because of
two reasons; the global planner uses a coarse and inaccurate model and the
local planner is unable to track the global plan sufficiently well. Currently,
deep learning methods are an appealing alternative because they can learn
safety and path feasibility from experience more accurately. However, existing
deep learning methods are not capable of planning for a long horizon. In this
work, we propose a learning-based fully autonomous navigation framework
composed of three innovative elements: a learned forward dynamics model (FDM),
an online sampling-based model-predictive controller, and an informed
trajectory sampler (ITS). Using our framework, a quadruped robot can
autonomously navigate in various complex environments without a collision and
generate a smoother command plan compared to the baseline method. Furthermore,
our method can reactively handle unexpected obstacles on the planned path and
avoid them. Project page
https://awesomericky.github.io/projects/FDM_ITS_navigation/.

### Title: SelfD: Self-Learning Large-Scale Driving Policies From the Web
* Paper ID: 2204.10320v1
* Paper URL: [http://arxiv.org/abs/2204.10320v1](http://arxiv.org/abs/2204.10320v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Effectively utilizing the vast amounts of ego-centric navigation data that is
freely available on the internet can advance generalized intelligent systems,
i.e., to robustly scale across perspectives, platforms, environmental
conditions, scenarios, and geographical locations. However, it is difficult to
directly leverage such large amounts of unlabeled and highly diverse data for
complex 3D reasoning and planning tasks. Consequently, researchers have
primarily focused on its use for various auxiliary pixel- and image-level
computer vision tasks that do not consider an ultimate navigational objective.
In this work, we introduce SelfD, a framework for learning scalable driving by
utilizing large amounts of online monocular images. Our key idea is to leverage
iterative semi-supervised training when learning imitative agents from
unlabeled data. To handle unconstrained viewpoints, scenes, and camera
parameters, we train an image-based model that directly learns to plan in the
Bird's Eye View (BEV) space. Next, we use unlabeled data to augment the
decision-making knowledge and robustness of an initially trained model via
self-training. In particular, we propose a pseudo-labeling step which enables
making full use of highly diverse demonstration data through "hypothetical"
planning-based data augmentation. We employ a large dataset of publicly
available YouTube videos to train SelfD and comprehensively analyze its
generalization benefits across challenging navigation scenarios. Without
requiring any additional data collection or annotation efforts, SelfD
demonstrates consistent improvements (by up to 24%) in driving performance
evaluation on nuScenes, Argoverse, Waymo, and CARLA.

### Title: Adversarial Contrastive Learning by Permuting Cluster Assignments
* Paper ID: 2204.10314v1
* Paper URL: [http://arxiv.org/abs/2204.10314v1](http://arxiv.org/abs/2204.10314v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Contrastive learning has gained popularity as an effective self-supervised
representation learning technique. Several research directions improve
traditional contrastive approaches, e.g., prototypical contrastive methods
better capture the semantic similarity among instances and reduce the
computational burden by considering cluster prototypes or cluster assignments,
while adversarial instance-wise contrastive methods improve robustness against
a variety of attacks. To the best of our knowledge, no prior work jointly
considers robustness, cluster-wise semantic similarity and computational
efficiency. In this work, we propose SwARo, an adversarial contrastive
framework that incorporates cluster assignment permutations to generate
representative adversarial samples. We evaluate SwARo on multiple benchmark
datasets and against various white-box and black-box attacks, obtaining
consistent improvements over state-of-the-art baselines.

### Title: Unsupervised Human Action Recognition with Skeletal Graph Laplacian and Self-Supervised Viewpoints Invariance
* Paper ID: 2204.10312v1
* Paper URL: [http://arxiv.org/abs/2204.10312v1](http://arxiv.org/abs/2204.10312v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/iit-pavis/uhar_skeletal_laplacian](https://github.com/iit-pavis/uhar_skeletal_laplacian)
* Summary: This paper presents a novel end-to-end method for the problem of
skeleton-based unsupervised human action recognition. We propose a new
architecture with a convolutional autoencoder that uses graph Laplacian
regularization to model the skeletal geometry across the temporal dynamics of
actions. Our approach is robust towards viewpoint variations by including a
self-supervised gradient reverse layer that ensures generalization across
camera views. The proposed method is validated on NTU-60 and NTU-120
large-scale datasets in which it outperforms all prior unsupervised
skeleton-based approaches on the cross-subject, cross-view, and cross-setup
protocols. Although unsupervised, our learnable representation allows our
method even to surpass a few supervised skeleton-based action recognition
methods. The code is available in:
www.github.com/IIT-PAVIS/UHAR_Skeletal_Laplacian

### Title: Layered Complex Networks as Fluctuation Amplifiers
* Paper ID: 2204.10251v1
* Paper URL: [http://arxiv.org/abs/2204.10251v1](http://arxiv.org/abs/2204.10251v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: In complex networked systems theory, an important question is how to evaluate
the system robustness to external perturbations. With this task in mind, I
investigate the propagation of noise in a multi-layer networked systems. I find
that, for a two layer network, noise originally injected in one layer can be
strongly amplified in the other layer, depending on how well-connected are the
complex networks in each layer and on how much the eigenmodes of their
Laplacian matrices overlap. These results allow to predict potentially harmful
conditions for the system and its sub-networks, where the level of fluctuations
is important, and how to avoid them.

### Title: The Silent Problem -- Machine Learning Model Failure -- How to Diagnose and Fix Ailing Machine Learning Models
* Paper ID: 2204.10227v1
* Paper URL: [http://arxiv.org/abs/2204.10227v1](http://arxiv.org/abs/2204.10227v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The COVID-19 pandemic has dramatically changed how healthcare is delivered to
patients, how patients interact with healthcare providers, and how healthcare
information is disseminated to both healthcare providers and patients.
Analytical models that were trained and tested pre-pandemic may no longer be
performing up to expectations, providing unreliable and irrelevant learning
(ML) models given that ML depends on the basic principle that what happened in
the past are likely to repeat in the future. ML faced to two important
degradation principles, concept drift, when the underlying properties and
characteristics of the variables change and data drift, when the data
distributions, probabilities, co-variates, and other variable relationships
change, both of which are prime culprits of model failure. Therefore, detecting
and diagnosing drift in existing models is something that has become an
imperative. And perhaps even more important is a shift in our mindset towards a
conscious recognition that drift is inevitable, and model building must
incorporate intentional resilience, the ability to offset and recover quickly
from failure, and proactive robustness, avoiding failure by developing models
that are less vulnerable to drift and disruption.

### Title: Learning spatiotemporal features from incomplete data for traffic flow prediction using hybrid deep neural networks
* Paper ID: 2204.10222v1
* Paper URL: [http://arxiv.org/abs/2204.10222v1](http://arxiv.org/abs/2204.10222v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Urban traffic flow prediction using data-driven models can play an important
role in route planning and preventing congestion on highways. These methods
utilize data collected from traffic recording stations at different timestamps
to predict the future status of traffic. Hence, data collection, transmission,
storage, and extraction techniques can have a significant impact on the
performance of the traffic flow model. On the other hand, a comprehensive
database can provide the opportunity for using complex, yet reliable predictive
models such as deep learning methods. However, most of these methods have
difficulties in handling missing values and outliers. This study focuses on
hybrid deep neural networks to predict traffic flow in the California Freeway
Performance Measurement System (PeMS) with missing values. The proposed
networks are based on a combination of recurrent neural networks (RNNs) to
consider the temporal dependencies in the data recorded in each station and
convolutional neural networks (CNNs) to take the spatial correlations in the
adjacent stations into account. Various architecture configurations with series
and parallel connections are considered based on RNNs and CNNs, and several
prevalent data imputation techniques are used to examine the robustness of the
hybrid networks to missing values. A comprehensive analysis performed on two
different datasets from PeMS indicates that the proposed series-parallel hybrid
network with the mean imputation technique achieves the lowest error in
predicting the traffic flow and is robust to missing values up until 21%
missing ratio in both complete and incomplete training data scenarios when
applied to an incomplete test data.

### Title: System-size dependence of the charged-particle pseudorapidity density at $\sqrt{s_{\rm NN}} = 5.02$ TeV for pp, p-Pb, and Pb-Pb collisions
* Paper ID: 2204.10210v1
* Paper URL: [http://arxiv.org/abs/2204.10210v1](http://arxiv.org/abs/2204.10210v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: We present and compare the charged-particle pseudorapidity densities for pp,
p-Pb, and Pb-Pb collisions at $\sqrt{s_{\rm NN}} = 5.02$ TeV measured over a
wide pseudorapidity range (${-3.5 <\eta <5}$), using ALICE at the Large Hadron
Collider. The distributions for p-Pb and Pb-Pb collisions are determined as a
function of the centrality of the collisions, while results from pp collisions
are reported for inelastic events with at least one charged particle at
midrapidity. The charged-particle pseudorapidity densities are, under simple
and robust assumptions, transformed to charged-particle rapidity densities.
This allows for the calculation and the presentation of the evolution of the
width of the rapidity distributions and of a lower bound on the Bjorken energy
density, as a function of the number of participants in all three collision
systems. We find a decreasing width of the particle production, and roughly a
ten fold increase in the energy density, as the system size grows.

### Title: BTranspose: Bottleneck Transformers for Human Pose Estimation with Self-Supervised Pre-Training
* Paper ID: 2204.10209v1
* Paper URL: [http://arxiv.org/abs/2204.10209v1](http://arxiv.org/abs/2204.10209v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The task of 2D human pose estimation is challenging as the number of
keypoints is typically large (~ 17) and this necessitates the use of robust
neural network architectures and training pipelines that can capture the
relevant features from the input image. These features are then aggregated to
make accurate heatmap predictions from which the final keypoints of human body
parts can be inferred. Many papers in literature use CNN-based architectures
for the backbone, and/or combine it with a transformer, after which the
features are aggregated to make the final keypoint predictions [1]. In this
paper, we consider the recently proposed Bottleneck Transformers [2], which
combine CNN and multi-head self attention (MHSA) layers effectively, and we
integrate it with a Transformer encoder and apply it to the task of 2D human
pose estimation. We consider different backbone architectures and pre-train
them using the DINO self-supervised learning method [3], this pre-training is
found to improve the overall prediction accuracy. We call our model BTranspose,
and experiments show that on the COCO validation set, our model achieves an AP
of 76.4, which is competitive with other methods such as [1] and has fewer
network parameters. Furthermore, we also present the dependencies of the final
predicted keypoints on both the MHSA block and the Transformer encoder layers,
providing clues on the image sub-regions the network attends to at the mid and
high levels.

### Title: A case for using rotation invariant features in state of the art feature matchers
* Paper ID: 2204.10144v1
* Paper URL: [http://arxiv.org/abs/2204.10144v1](http://arxiv.org/abs/2204.10144v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/georg-bn/se2-loftr](https://github.com/georg-bn/se2-loftr)
* Summary: The aim of this paper is to demonstrate that a state of the art feature
matcher (LoFTR) can be made more robust to rotations by simply replacing the
backbone CNN with a steerable CNN which is equivariant to translations and
image rotations. It is experimentally shown that this boost is obtained without
reducing performance on ordinary illumination and viewpoint matching sequences.

### Title: Toward Fast, Flexible, and Robust Low-Light Image Enhancement
* Paper ID: 2204.10137v1
* Paper URL: [http://arxiv.org/abs/2204.10137v1](http://arxiv.org/abs/2204.10137v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/vis-opt-group/sci](https://github.com/vis-opt-group/sci)
* Summary: Existing low-light image enhancement techniques are mostly not only difficult
to deal with both visual quality and computational efficiency but also commonly
invalid in unknown complex scenarios. In this paper, we develop a new
Self-Calibrated Illumination (SCI) learning framework for fast, flexible, and
robust brightening images in real-world low-light scenarios. To be specific, we
establish a cascaded illumination learning process with weight sharing to
handle this task. Considering the computational burden of the cascaded pattern,
we construct the self-calibrated module which realizes the convergence between
results of each stage, producing the gains that only use the single basic block
for inference (yet has not been exploited in previous works), which drastically
diminishes computation cost. We then define the unsupervised training loss to
elevate the model capability that can adapt to general scenes. Further, we make
comprehensive explorations to excavate SCI's inherent properties (lacking in
existing works) including operation-insensitive adaptability (acquiring stable
performance under the settings of different simple operations) and
model-irrelevant generality (can be applied to illumination-based existing
works to improve performance). Finally, plenty of experiments and ablation
studies fully indicate our superiority in both quality and efficiency.
Applications on low-light face detection and nighttime semantic segmentation
fully reveal the latent practical values for SCI. The source code is available
at https://github.com/vis-opt-group/SCI.

### Title: Fast iterative regularization by reusing data
* Paper ID: 2204.10131v1
* Paper URL: [http://arxiv.org/abs/2204.10131v1](http://arxiv.org/abs/2204.10131v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Discrete inverse problems correspond to solving a system of equations in a
stable way with respect to noise in the data. A typical approach to enforce
uniqueness and select a meaningful solution is to introduce a regularizer.
While for most applications the regularizer is convex, in many cases it is not
smooth nor strongly convex. In this paper, we propose and study two new
iterative regularization methods, based on a primal-dual algorithm, to solve
inverse problems efficiently. Our analysis, in the noise free case, provides
convergence rates for the Lagrangian and the feasibility gap. In the noisy
case, it provides stability bounds and early-stopping rules with theoretical
guarantees. The main novelty of our work is the exploitation of some a priori
knowledge about the solution set, i.e. redundant information. More precisely we
show that the linear systems can be used more than once along the iteration.
Despite the simplicity of the idea, we show that this procedure brings
surprising advantages in the numerical applications. We discuss various
approaches to take advantage of redundant information, that are at the same
time consistent with our assumptions and flexible in the implementation.
Finally, we illustrate our theoretical findings with numerical simulations for
robust sparse recovery and image reconstruction through total variation. We
confirm the efficiency of the proposed procedures, comparing the results with
state-of-the-art methods.

### Title: Working memory inspired hierarchical video decomposition with transformative representations
* Paper ID: 2204.10105v1
* Paper URL: [http://arxiv.org/abs/2204.10105v1](http://arxiv.org/abs/2204.10105v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Video decomposition is very important to extract moving foreground objects
from complex backgrounds in computer vision, machine learning, and medical
imaging, e.g., extracting moving contrast-filled vessels from the complex and
noisy backgrounds of X-ray coronary angiography (XCA). However, the challenges
caused by dynamic backgrounds, overlapping heterogeneous environments and
complex noises still exist in video decomposition. To solve these problems,
this study is the first to introduce a flexible visual working memory model in
video decomposition tasks to provide interpretable and high-performance
hierarchical deep architecture, integrating the transformative representations
between sensory and control layers from the perspective of visual and cognitive
neuroscience. Specifically, robust PCA unrolling networks acting as a
structure-regularized sensor layer decompose XCA into sparse/low-rank
structured representations to separate moving contrast-filled vessels from
noisy and complex backgrounds. Then, patch recurrent convolutional LSTM
networks with a backprojection module embody unstructured random
representations of the control layer in working memory, recurrently projecting
spatiotemporally decomposed nonlocal patches into orthogonal subspaces for
heterogeneous vessel retrieval and interference suppression. This video
decomposition deep architecture effectively restores the heterogeneous profiles
of intensity and the geometries of moving objects against the complex
background interferences. Experiments show that the proposed method
significantly outperforms state-of-the-art methods in accurate moving
contrast-filled vessel extraction with excellent flexibility and computational
efficiency.

### Title: Detecting Topology Attacks against Graph Neural Networks
* Paper ID: 2204.10072v1
* Paper URL: [http://arxiv.org/abs/2204.10072v1](http://arxiv.org/abs/2204.10072v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Graph neural networks (GNNs) have been widely used in many real applications,
and recent studies have revealed their vulnerabilities against topology
attacks. To address this issue, existing efforts have mainly been dedicated to
improving the robustness of GNNs, while little attention has been paid to the
detection of such attacks. In this work, we study the victim node detection
problem under topology attacks against GNNs. Our approach is built upon the key
observation rooted in the intrinsic message passing nature of GNNs. That is,
the neighborhood of a victim node tends to have two competing group forces,
pushing the node classification results towards the original label and the
targeted label, respectively. Based on this observation, we propose to detect
victim nodes by deliberately designing an effective measurement of the
neighborhood variance for each node. Extensive experimental results on four
real-world datasets and five existing topology attacks show the effectiveness
and efficiency of the proposed detection approach.

### Title: Robustness of Machine Learning Models Beyond Adversarial Attacks
* Paper ID: 2204.10046v1
* Paper URL: [http://arxiv.org/abs/2204.10046v1](http://arxiv.org/abs/2204.10046v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Correctly quantifying the robustness of machine learning models is a central
aspect in judging their suitability for specific tasks, and thus, ultimately,
for generating trust in the models. We show that the widely used concept of
adversarial robustness and closely related metrics based on counterfactuals are
not necessarily valid metrics for determining the robustness of ML models
against perturbations that occur "naturally", outside specific adversarial
attack scenarios. Additionally, we argue that generic robustness metrics in
principle are insufficient for determining real-world-robustness. Instead we
propose a flexible approach that models possible perturbations in input data
individually for each application. This is then combined with a probabilistic
approach that computes the likelihood that a real-world perturbation will
change a prediction, thus giving quantitative information of the robustness of
the trained machine learning model. The method does not require access to the
internals of the classifier and thus in principle works for any black-box
model. It is, however, based on Monte-Carlo sampling and thus only suited for
input spaces with small dimensions. We illustrate our approach on two dataset,
as well as on analytically solvable cases. Finally, we discuss ideas on how
real-world robustness could be computed or estimated in high-dimensional input
spaces.

### Title: DropMessage: Unifying Random Dropping for Graph Neural Networks
* Paper ID: 2204.10037v1
* Paper URL: [http://arxiv.org/abs/2204.10037v1](http://arxiv.org/abs/2204.10037v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Graph Neural Networks (GNNs) are powerful tools for graph representation
learning. Despite their rapid development, GNNs also faces some challenges,
such as over-fitting, over-smoothing, and non-robustness. Previous works
indicate that these problems can be alleviated by random dropping methods,
which integrate noises into models by randomly masking parts of the input.
However, some open-ended problems of random dropping on GNNs remain to solve.
First, it is challenging to find a universal method that are suitable for all
cases considering the divergence of different datasets and models. Second,
random noises introduced to GNNs cause the incomplete coverage of parameters
and unstable training process. In this paper, we propose a novel random
dropping method called DropMessage, which performs dropping operations directly
on the message matrix and can be applied to any message-passing GNNs.
Furthermore, we elaborate the superiority of DropMessage: it stabilizes the
training process by reducing sample variance; it keeps information diversity
from the perspective of information theory, which makes it a theoretical upper
bound of other methods. Also, we unify existing random dropping methods into
our framework and analyze their effects on GNNs. To evaluate our proposed
method, we conduct experiments that aims for multiple tasks on five public
datasets and two industrial datasets with various backbone models. The
experimental results show that DropMessage has both advantages of effectiveness
and generalization.

### Title: Stability, Linear Convergence, and Robustness of the Wang-Elia Algorithm for Distributed Consensus Optimization
* Paper ID: 2204.10030v1
* Paper URL: [http://arxiv.org/abs/2204.10030v1](http://arxiv.org/abs/2204.10030v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: We revisit an algorithm for distributed consensus optimization proposed in
2010 by J. Wang and N. Elia. By means of a Lyapunov-based analysis, we prove
input-to-state stability of the algorithm relative to a closed invariant set
composed of optimal equilibria and with respect to perturbations affecting the
algorithm's dynamics. In the absence of perturbations, this result implies
linear convergence of the local estimates and Lyapunov stability of the optimal
steady state. Moreover, we unveil fundamental connections with the well-known
Gradient Tracking and with distributed integral control. Overall, our results
suggest that a control theoretic approach can have a considerable impact on
(distributed) optimization, especially when robustness is considered.

### Title: Is Neuron Coverage Needed to Make Person Detection More Robust?
* Paper ID: 2204.10027v1
* Paper URL: [http://arxiv.org/abs/2204.10027v1](http://arxiv.org/abs/2204.10027v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The growing use of deep neural networks (DNNs) in safety- and
security-critical areas like autonomous driving raises the need for their
systematic testing. Coverage-guided testing (CGT) is an approach that applies
mutation or fuzzing according to a predefined coverage metric to find inputs
that cause misbehavior. With the introduction of a neuron coverage metric, CGT
has also recently been applied to DNNs. In this work, we apply CGT to the task
of person detection in crowded scenes. The proposed pipeline uses YOLOv3 for
person detection and includes finding DNN bugs via sampling and mutation, and
subsequent DNN retraining on the updated training set. To be a bug, we require
a mutated image to cause a significant performance drop compared to a clean
input. In accordance with the CGT, we also consider an additional requirement
of increased coverage in the bug definition. In order to explore several types
of robustness, our approach includes natural image transformations,
corruptions, and adversarial examples generated with the Daedalus attack. The
proposed framework has uncovered several thousand cases of incorrect DNN
behavior. The relative change in mAP performance of the retrained models
reached on average between 26.21\% and 64.24\% for different robustness types.
However, we have found no evidence that the investigated coverage metrics can
be advantageously used to improve robustness.

### Title: DGECN: A Depth-Guided Edge Convolutional Network for End-to-End 6D Pose Estimation
* Paper ID: 2204.09983v1
* Paper URL: [http://arxiv.org/abs/2204.09983v1](http://arxiv.org/abs/2204.09983v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Monocular 6D pose estimation is a fundamental task in computer vision.
Existing works often adopt a two-stage pipeline by establishing correspondences
and utilizing a RANSAC algorithm to calculate 6 degrees-of-freedom (6DoF) pose.
Recent works try to integrate differentiable RANSAC algorithms to achieve an
end-to-end 6D pose estimation. However, most of them hardly consider the
geometric features in 3D space, and ignore the topology cues when performing
differentiable RANSAC algorithms. To this end, we proposed a Depth-Guided Edge
Convolutional Network (DGECN) for 6D pose estimation task. We have made efforts
from the following three aspects: 1) We take advantages ofestimated depth
information to guide both the correspondences-extraction process and the
cascaded differentiable RANSAC algorithm with geometric information. 2)We
leverage the uncertainty ofthe estimated depth map to improve accuracy and
robustness ofthe output 6D pose. 3) We propose a differentiable
Perspective-n-Point(PnP) algorithm via edge convolution to explore the topology
relations between 2D-3D correspondences. Experiments demonstrate that our
proposed network outperforms current works on both effectiveness and
efficiency.

### Title: Domain Invariant Model with Graph Convolutional Network for Mammogram Classification
* Paper ID: 2204.09954v1
* Paper URL: [http://arxiv.org/abs/2204.09954v1](http://arxiv.org/abs/2204.09954v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Due to its safety-critical property, the image-based diagnosis is desired to
achieve robustness on out-of-distribution (OOD) samples. A natural way towards
this goal is capturing only clinically disease-related features, which is
composed of macroscopic attributes (e.g., margins, shapes) and microscopic
image-based features (e.g., textures) of lesion-related areas. However, such
disease-related features are often interweaved with data-dependent (but disease
irrelevant) biases during learning, disabling the OOD generalization. To
resolve this problem, we propose a novel framework, namely Domain Invariant
Model with Graph Convolutional Network (DIM-GCN), which only exploits invariant
disease-related features from multiple domains. Specifically, we first propose
a Bayesian network, which explicitly decomposes the latent variables into
disease-related and other disease-irrelevant parts that are provable to be
disentangled from each other. Guided by this, we reformulate the objective
function based on Variational Auto-Encoder, in which the encoder in each domain
has two branches: the domain-independent and -dependent ones, which
respectively encode disease-related and -irrelevant features. To better capture
the macroscopic features, we leverage the observed clinical attributes as a
goal for reconstruction, via Graph Convolutional Network (GCN). Finally, we
only implement the disease-related features for prediction. The effectiveness
and utility of our method are demonstrated by the superior OOD generalization
performance over others on mammogram benign/malignant diagnosis.

### Title: SPIKE: Secure and Private Investigation of the Kidney Exchange problem
* Paper ID: 2204.09937v1
* Paper URL: [http://arxiv.org/abs/2204.09937v1](http://arxiv.org/abs/2204.09937v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Background: The kidney exchange problem (KEP) addresses the matching of
patients in need for a replacement organ with compatible living donors. Ideally
many medical institutions should participate in a matching program to increase
the chance for successful matches. However, to fulfill legal requirements
current systems use complicated policy-based data protection mechanisms that
effectively exclude smaller medical facilities to participate. Employing secure
multi-party computation (MPC) techniques provides a technical way to satisfy
data protection requirements for highly sensitive personal health information
while simultaneously reducing the regulatory burdens.
  Results: We have designed, implemented, and benchmarked SPIKE, a secure
MPC-based privacy-preserving KEP which computes a solution by finding matching
donor-recipient pairs in a graph structure. SPIKE matches 40 pairs in cycles of
length 2 in less than 4 minutes and outperforms the previous state-of-the-art
protocol by a factor of 400x in runtime while providing medically more robust
solutions.
  Conclusions: We show how to solve the KEP in a robust and privacy-preserving
manner achieving practical performance. The usage of MPC techniques fulfills
many data protection requirements on a technical level, allowing smaller health
care providers to directly participate in a kidney exchange with reduced legal
processes.

### Title: MAP-SNN: Mapping Spike Activities with Multiplicity, Adaptability, and Plasticity into Bio-Plausible Spiking Neural Networks
* Paper ID: 2204.09893v1
* Paper URL: [http://arxiv.org/abs/2204.09893v1](http://arxiv.org/abs/2204.09893v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Spiking Neural Network (SNN) is considered more biologically realistic and
power-efficient as it imitates the fundamental mechanism of the human brain.
Recently, backpropagation (BP) based SNN learning algorithms that utilize deep
learning frameworks have achieved good performance. However,
bio-interpretability is partially neglected in those BP-based algorithms.
Toward bio-plausible BP-based SNNs, we consider three properties in modeling
spike activities: Multiplicity, Adaptability, and Plasticity (MAP). In terms of
multiplicity, we propose a Multiple-Spike Pattern (MSP) with multiple spike
transmission to strengthen model robustness in discrete time-iteration. To
realize adaptability, we adopt Spike Frequency Adaption (SFA) under MSP to
decrease spike activities for improved efficiency. For plasticity, we propose a
trainable convolutional synapse that models spike response current to enhance
the diversity of spiking neurons for temporal feature extraction. The proposed
SNN model achieves competitive performances on neuromorphic datasets: N-MNIST
and SHD. Furthermore, experimental results demonstrate that the proposed three
aspects are significant to iterative robustness, spike efficiency, and temporal
feature extraction capability of spike activities. In summary, this work
proposes a feasible scheme for bio-inspired spike activities with MAP, offering
a new neuromorphic perspective to embed biological characteristics into spiking
neural networks.

### Title: Pixel2Mesh++: 3D Mesh Generation and Refinement from Multi-View Images
* Paper ID: 2204.09866v1
* Paper URL: [http://arxiv.org/abs/2204.09866v1](http://arxiv.org/abs/2204.09866v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: We study the problem of shape generation in 3D mesh representation from a
small number of color images with or without camera poses. While many previous
works learn to hallucinate the shape directly from priors, we adopt to further
improve the shape quality by leveraging cross-view information with a graph
convolution network. Instead of building a direct mapping function from images
to 3D shape, our model learns to predict series of deformations to improve a
coarse shape iteratively. Inspired by traditional multiple view geometry
methods, our network samples nearby area around the initial mesh's vertex
locations and reasons an optimal deformation using perceptual feature
statistics built from multiple input images. Extensive experiments show that
our model produces accurate 3D shapes that are not only visually plausible from
the input perspectives, but also well aligned to arbitrary viewpoints. With the
help of physically driven architecture, our model also exhibits generalization
capability across different semantic categories, and the number of input
images. Model analysis experiments show that our model is robust to the quality
of the initial mesh and the error of camera pose, and can be combined with a
differentiable renderer for test-time optimization.

### Title: A Masked Image Reconstruction Network for Document-level Relation Extraction
* Paper ID: 2204.09851v1
* Paper URL: [http://arxiv.org/abs/2204.09851v1](http://arxiv.org/abs/2204.09851v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Document-level relation extraction aims to extract relations among entities
within a document. Compared with its sentence-level counterpart, Document-level
relation extraction requires inference over multiple sentences to extract
complex relational triples. Previous research normally complete reasoning
through information propagation on the mention-level or entity-level
document-graphs, regardless of the correlations between the relationships. In
this paper, we propose a novel Document-level Relation Extraction model based
on a Masked Image Reconstruction network (DRE-MIR), which models inference as a
masked image reconstruction problem to capture the correlations between
relationships. Specifically, we first leverage an encoder module to get the
features of entities and construct the entity-pair matrix based on the
features. After that, we look on the entity-pair matrix as an image and then
randomly mask it and restore it through an inference module to capture the
correlations between the relationships. We evaluate our model on three public
document-level relation extraction datasets, i.e. DocRED, CDR, and GDA.
Experimental results demonstrate that our model achieves state-of-the-art
performance on these three datasets and has excellent robustness against the
noises during the inference process.

### Title: Weakly Aligned Feature Fusion for Multimodal Object Detection
* Paper ID: 2204.09848v1
* Paper URL: [http://arxiv.org/abs/2204.09848v1](http://arxiv.org/abs/2204.09848v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: To achieve accurate and robust object detection in the real-world scenario,
various forms of images are incorporated, such as color, thermal, and depth.
However, multimodal data often suffer from the position shift problem, i.e.,
the image pair is not strictly aligned, making one object has different
positions in different modalities. For the deep learning method, this problem
makes it difficult to fuse multimodal features and puzzles the convolutional
neural network (CNN) training. In this article, we propose a general multimodal
detector named aligned region CNN (AR-CNN) to tackle the position shift
problem. First, a region feature (RF) alignment module with adjacent similarity
constraint is designed to consistently predict the position shift between two
modalities and adaptively align the cross-modal RFs. Second, we propose a novel
region of interest (RoI) jitter strategy to improve the robustness to
unexpected shift patterns. Third, we present a new multimodal feature fusion
method that selects the more reliable feature and suppresses the less useful
one via feature reweighting. In addition, by locating bounding boxes in both
modalities and building their relationships, we provide novel multimodal
labeling named KAIST-Paired. Extensive experiments on 2-D and 3-D object
detection, RGB-T, and RGB-D datasets demonstrate the effectiveness and
robustness of our method.

### Title: Coronagraph Experiment on Dark-hole Control by Speckle Area Nulling Method
* Paper ID: 2204.09834v1
* Paper URL: [http://arxiv.org/abs/2204.09834v1](http://arxiv.org/abs/2204.09834v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: In high-contrast imaging optical systems for direct observation of planets
outside our solar system, adaptive optics with an accuracy of lambda/10,000
root mean square is required to reduce the speckle noise down to 1e-10 level in
addition to the nulling coronagraph which eliminate the diffracted light. We
developed the speckle area nulling (SAN) method as a new dark-hole control
algorithm which is capable of controlling speckle electric field in a wide area
quickly, in spite of an extension of speckle nulling, and is robust not relying
upon an optical model. We conducted a validation experiment for the SAN method
with a monochromatic light and succeeded in reducing the intensity of areal
speckles by 4.4e-2.

