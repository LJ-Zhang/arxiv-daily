### Title: Decentralized Distributed Learning with Privacy-Preserving Data Synthesis
* Paper ID: 2206.10048v1
* Paper URL: [http://arxiv.org/abs/2206.10048v1](http://arxiv.org/abs/2206.10048v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: In the medical field, multi-center collaborations are often sought to yield
more generalizable findings by leveraging the heterogeneity of patient and
clinical data. However, recent privacy regulations hinder the possibility to
share data, and consequently, to come up with machine learning-based solutions
that support diagnosis and prognosis. Federated learning (FL) aims at
sidestepping this limitation by bringing AI-based solutions to data owners and
only sharing local AI models, or parts thereof, that need then to be
aggregated. However, most of the existing federated learning solutions are
still at their infancy and show several shortcomings, from the lack of a
reliable and effective aggregation scheme able to retain the knowledge learned
locally to weak privacy preservation as real data may be reconstructed from
model updates. Furthermore, the majority of these approaches, especially those
dealing with medical data, relies on a centralized distributed learning
strategy that poses robustness, scalability and trust issues. In this paper we
present a decentralized distributed method that, exploiting concepts from
experience replay and generative adversarial research, effectively integrates
features from local nodes, providing models able to generalize across multiple
datasets while maintaining privacy. The proposed approach is tested on two
tasks - tuberculosis and melanoma classification - using multiple datasets in
order to simulate realistic non-i.i.d. data scenarios. Results show that our
approach achieves performance comparable to both standard (non-federated)
learning and federated methods in their centralized (thus, more favourable)
formulation.

### Title: Arnold Tongues in Area-Preserving Maps
* Paper ID: 2206.10040v1
* Paper URL: [http://arxiv.org/abs/2206.10040v1](http://arxiv.org/abs/2206.10040v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: In the early 60's J. B. Keller and D. Levy discovered a fundamental property:
the instability tongues in Mathieu-type equations lose sharpness with the
addition of higher-frequency harmonics in the Mathieu potentials. 20 years
later V. Arnold rediscovered a similar phenomenon on sharpness of Arnold
tongues in circle maps (and rediscovered the result of Keller and Levy). In
this paper we find a third class of objects where a similarly flavored behavior
takes place: area-preserving maps of the cylinder. Speaking loosely, we show
that periodic orbits of standard maps are extra fragile with respect to added
drift (i.e. non-exactness) if the potential of the map is a trigonometric
polynomial. That is, higher-frequency harmonics make periodic orbits more
robust with respect to ``drift". The observation was motivated by the study of
traveling waves in the discretized sine-Gordon equation which in turn models a
wide variety of physical systems.

### Title: Spin Torque Generated by Valley Hall Effect in WSe2
* Paper ID: 2206.09998v1
* Paper URL: [http://arxiv.org/abs/2206.09998v1](http://arxiv.org/abs/2206.09998v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Monolayer transition metal dichalcogenides are promising materials for
spintronics due to their robust spin-valley locked valence states, enabling
efficient charge-to-spin conversion via valley Hall effect with non-equilibrium
spins possessing long spin diffusion lengths of hundreds of nanometers. In this
work, we show that the injection of a pure valley current, induced by valley
Hall effect in a WSe2 monolayer, imparts a spin torque on the magnetization of
an overlaid Fe or CoFe in a tunneling structure. The torque efficiency is found
to be comparable to that in conventional perpendicular magnetic tunnel
junctions and can be further optimized with valley Hall angle in WSe2. The
valley nature of the spin torque gives rise to out-of-plane damping-like
torques in a current-in-plane configuration, vanishing charge transport
perpendicular-to-the-plane as well as torque efficiency tunable through gating.

### Title: Noise Estimation in Gaussian Process Regression
* Paper ID: 2206.09976v1
* Paper URL: [http://arxiv.org/abs/2206.09976v1](http://arxiv.org/abs/2206.09976v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: We develop a computational procedure to estimate the covariance
hyperparameters for semiparametric Gaussian process regression models with
additive noise. Namely, the presented method can be used to efficiently
estimate the variance of the correlated error, and the variance of the noise
based on maximizing a marginal likelihood function. Our method involves
suitably reducing the dimensionality of the hyperparameter space to simplify
the estimation procedure to a univariate root-finding problem. Moreover, we
derive bounds and asymptotes of the marginal likelihood function and its
derivatives, which are useful to narrowing the initial range of the
hyperparameter search. Using numerical examples, we demonstrate the
computational advantages and robustness of the presented approach compared to
traditional parameter optimization.

### Title: Two-sided Robustly Testable Codes
* Paper ID: 2206.09973v1
* Paper URL: [http://arxiv.org/abs/2206.09973v1](http://arxiv.org/abs/2206.09973v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: We show that the tensor product of two random linear codes is robustly
testable with high probability. This implies that one can obtain pairs of
linear codes such that their product and the product of their dual codes are
simultaneously robustly testable. Such two-sided robustly testable codes (with
a much weaker form of robustness) were the key ingredient in the recent
constructions of asymptotically good quantum LDPC codes, which ensured their
linear minimum distance. We hope that the existence of such codes with a
stronger form of robustness, shown here, can be used to simplify the proofs and
provide better distance bounds in these constructions. We also give new very
simple examples of non-robustly testable codes. We show that if the
parity-checks of two codes are mutually orthogonal, then their product is not
robustly testable. In particular, this implies that the product of a code with
its dual code is not robustly testable. We also study a property of a
collection of linear codes called product-expansion, which can be viewed as a
coboundary expansion of the cochain complex naturally associated with the
product of these codes. We show that this property is related with the robust
testability and the agreement testability of the products of codes.

### Title: Analytical study of gravitational lensing in Kerr-Newman black-bounce spacetime
* Paper ID: 2206.09954v1
* Paper URL: [http://arxiv.org/abs/2206.09954v1](http://arxiv.org/abs/2206.09954v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: We investigate the equatorial deflection angle of light rays propagating in
Kerr-Newman black-bounce spacetime. Furthermore, we analyze the light ray
trajectories and derive a closed-form formula for deflection angle in terms of
elliptic integrals. The deflection angle increases with the decrease of charge
and regularisation parameter for a particular impact parameter. We also study
the strong field limit of the deflection angle. Using this strong deflection
angle formula and lens equation, we find the radius of the first Einstein ring
and study its dependence on the charge and the regularisation parameter. We
demonstrate that the charge has a robust effect on the size of the Einstein
rings, but the effect of the regularization parameter on the ring size is
negligible. These results directly affect the observational appearance of the
Kerr-Newman black-bounce.

### Title: A Dense Representation Framework for Lexical and Semantic Matching
* Paper ID: 2206.09912v1
* Paper URL: [http://arxiv.org/abs/2206.09912v1](http://arxiv.org/abs/2206.09912v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Lexical and semantic matching capture different successful approaches to text
retrieval and the fusion of their results has proven to be more effective and
robust than either alone. Prior work performs hybrid retrieval by conducting
lexical and semantic text matching using different systems (e.g., Lucene and
Faiss, respectively) and then fusing their model outputs. In contrast, our work
integrates lexical representations with dense semantic representations by
densifying high-dimensional lexical representations into what we call
low-dimensional dense lexical representations (DLRs). Our experiments show that
DLRs can effectively approximate the original lexical representations,
preserving effectiveness while improving query latency. Furthermore, we can
combine dense lexical and semantic representations to generate dense hybrid
representations (DHRs) that are more flexible and yield faster retrieval
compared to existing hybrid techniques. Finally, we explore {\it jointly}
training lexical and semantic representations in a single model and empirically
show that the resulting DHRs are able to combine the advantages of each
individual component. Our best DHR model is competitive with state-of-the-art
single-vector and multi-vector dense retrievers in both in-domain and zero-shot
evaluation settings. Furthermore, our model is both faster and requires smaller
indexes, making our dense representation framework an attractive approach to
text retrieval. Our code is available at https://github.com/castorini/dhr.

### Title: Achieving Dexterous Bidirectional Interaction in Uncertain Conditions for Medical Robotics
* Paper ID: 2206.09906v1
* Paper URL: [http://arxiv.org/abs/2206.09906v1](http://arxiv.org/abs/2206.09906v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Medical robotics can help improve and extend the reach of healthcare
services. A major challenge for medical robots is the complex physical
interaction between the robot and the patients which is required to be safe.
This work presents the preliminary evaluation of a recently introduced control
architecture based on the Fractal Impedance Control (FIC) in medical
applications. The deployed FIC architecture is robust to delay between the
master and the replica robots. It can switch online between an admittance and
impedance behaviour, and it is robust to interaction with unstructured
environments. Our experiments analyse three scenarios: teleoperated surgery,
rehabilitation, and remote ultrasound scan. The experiments did not require any
adjustment of the robot tuning, which is essential in medical applications
where the operators do not have an engineering background required to tune the
controller. Our results show that is possible to teleoperate the robot to cut
using a scalpel, do an ultrasound scan, and perform remote occupational
therapy. However, our experiments also highlighted the need for a better robots
embodiment to precisely control the system in 3D dynamic tasks.

### Title: Only Tails Matter: Average-Case Universality and Robustness in the Convex Regime
* Paper ID: 2206.09901v1
* Paper URL: [http://arxiv.org/abs/2206.09901v1](http://arxiv.org/abs/2206.09901v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: The recently developed average-case analysis of optimization methods allows a
more fine-grained and representative convergence analysis than usual worst-case
results. In exchange, this analysis requires a more precise hypothesis over the
data generating process, namely assuming knowledge of the expected spectral
distribution (ESD) of the random matrix associated with the problem. This work
shows that the concentration of eigenvalues near the edges of the ESD
determines a problem's asymptotic average complexity. This a priori information
on this concentration is a more grounded assumption than complete knowledge of
the ESD. This approximate concentration is effectively a middle ground between
the coarseness of the worst-case scenario convergence and the restrictive
previous average-case analysis. We also introduce the Generalized Chebyshev
method, asymptotically optimal under a hypothesis on this concentration and
globally optimal when the ESD follows a Beta distribution. We compare its
performance to classical optimization algorithms, such as gradient descent or
Nesterov's scheme, and we show that, in the average-case context, Nesterov's
method is universally nearly optimal asymptotically.

### Title: Understanding Robust Learning through the Lens of Representation Similarities
* Paper ID: 2206.09868v1
* Paper URL: [http://arxiv.org/abs/2206.09868v1](http://arxiv.org/abs/2206.09868v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Representation learning, i.e. the generation of representations useful for
downstream applications, is a task of fundamental importance that underlies
much of the success of deep neural networks (DNNs). Recently, robustness to
adversarial examples has emerged as a desirable property for DNNs, spurring the
development of robust training methods that account for adversarial examples.
In this paper, we aim to understand how the properties of representations
learned by robust training differ from those obtained from standard, non-robust
training. This is critical to diagnosing numerous salient pitfalls in robust
networks, such as, degradation of performance on benign inputs, poor
generalization of robustness, and increase in over-fitting. We utilize a
powerful set of tools known as representation similarity metrics, across three
vision datasets, to obtain layer-wise comparisons between robust and non-robust
DNNs with different architectures, training procedures and adversarial
constraints. Our experiments highlight hitherto unseen properties of robust
representations that we posit underlie the behavioral differences of robust
networks. We discover a lack of specialization in robust networks'
representations along with a disappearance of `block structure'. We also find
overfitting during robust training largely impacts deeper layers. These, along
with other findings, suggest ways forward for the design and training of better
robust networks.

### Title: Delocalization-localization dynamical phase transition of random walks on graphs
* Paper ID: 2206.09866v1
* Paper URL: [http://arxiv.org/abs/2206.09866v1](http://arxiv.org/abs/2206.09866v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: We consider random walks evolving on two models of connected and undirected
graphs and study the exact large deviations of a local dynamical observable. We
prove, in the thermodynamic limit, that this observable undergoes a first-order
dynamical phase transition (DPT). This is interpreted as a `co-existence' of
paths in the fluctuations that visit the highly connected bulk of the graph
(delocalization) and paths that visit the boundary (localization). The methods
we used also allow us to characterize analytically the scaling function that
describes the finite size crossover between the localized and delocalized
regimes. Remarkably, we also show that the DPT is robust with respect to a
change in the graph topology, which only plays a role in the crossover regime.
All results support the view that a first-order DPT may also appear in random
walks on infinite-size random graphs.

### Title: Environmental dependence of the molecular cloud lifecycle in 54 main sequence galaxies
* Paper ID: 2206.09857v1
* Paper URL: [http://arxiv.org/abs/2206.09857v1](http://arxiv.org/abs/2206.09857v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: The processes of star formation and feedback, which regulate the cycle of
matter between gas and stars on the scales of giant molecular clouds (GMCs;
$\sim$100pc), play a major role in governing galaxy evolution. Measuring the
time-scales of GMC evolution is important to identify and characterise the
specific physical mechanisms that drive this transition. By applying a robust
statistical method to high-resolution CO and narrow-band H$\alpha$ imaging from
the PHANGS survey, we systematically measure the evolutionary timeline from
molecular clouds to exposed young stellar regions on GMC scales, across an
unprecedented sample of 54 star-forming main-sequence galaxies. We find that
clouds live for about $1{-}3$ GMC turbulence crossing times ($5{-}30$Myr) and
are efficiently dispersed by stellar feedback within $1{-}5$Myr once the
star-forming region becomes partially exposed, resulting in integrated star
formation efficiencies of $1{-}8$%. These ranges reflect physical
galaxy-to-galaxy variation. In order to evaluate whether galactic environment
influences GMC evolution, we correlate our measurements with average properties
of the GMCs and their local galactic environment. We find several strong
correlations that can be physically understood, revealing a quantitative link
between galactic-scale environmental properties and the small-scale GMC
evolution. Notably, the measured CO-visible cloud lifetimes become shorter with
decreasing galaxy mass, most likely due to the increasing presence of CO-dark
molecular gas in such environment. Our results represent a first step towards a
comprehensive picture of cloud assembly and dispersal, which will further
require extension and refinement with tracers of the atomic gas, dust, and
deeply-embedded stellar populations.

### Title: Practical Deepfake Detection: Vulnerabilities in Global Contexts
* Paper ID: 2206.09842v1
* Paper URL: [http://arxiv.org/abs/2206.09842v1](http://arxiv.org/abs/2206.09842v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Recent advances in deep learning have enabled realistic digital alterations
to videos, known as deepfakes. This technology raises important societal
concerns regarding disinformation and authenticity, galvanizing the development
of numerous deepfake detection algorithms. At the same time, there are
significant differences between training data and in-the-wild video data, which
may undermine their practical efficacy. We simulate data corruption techniques
and examine the performance of a state-of-the-art deepfake detection algorithm
on corrupted variants of the FaceForensics++ dataset.
  While deepfake detection models are robust against video corruptions that
align with training-time augmentations, we find that they remain vulnerable to
video corruptions that simulate decreases in video quality. Indeed, in the
controversial case of the video of Gabonese President Bongo's new year address,
the algorithm, which confidently authenticates the original video, judges
highly corrupted variants of the video to be fake. Our work opens up both
technical and ethical avenues of exploration into practical deepfake detection
in global contexts.

### Title: Higher-Dimensional Topological Insulators in Pure Diffusion Systems
* Paper ID: 2206.09837v1
* Paper URL: [http://arxiv.org/abs/2206.09837v1](http://arxiv.org/abs/2206.09837v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Compared with one dimension, topological insulators (TIs) in higher
dimensions contain more unexpected boundary states, such as higher-order
topological insulators (HOTIs) that the conventional bulk-boundary
correspondence cannot describe. Thanks to the form similarity between the
Schr\"{o}dinger equation and the wave equation, research on HOTIs has been
extended from condensed matter to classical wave systems. Unfortunately, it is
still challenging to uncover HOTIs in pure diffusion systems because of the
essential difference between diffusion and wave. Here, we construct
higher-dimensional heat diffusion models based on sphere-rod structures to
reveal purely diffusive HOTIs. Starting from two dimensions, we demonstrate
diffusive second-order TIs with zero-dimensional corner states and
one-dimensional edge states. Unlike Hermitian wave systems, these diffusive
boundary states feature the anti-Hermitian dissipative nature and have
different decay rates from the bulk states. We further present two-dimensional
anisotropic TIs and three-dimensional third-order TIs. Our results open a new
gate for diffusive topological states and provide a distinct mechanism for
robust boundary heat regulation.

### Title: Deep representation of EEG data from Spatio-Spectral Feature Images
* Paper ID: 2206.09807v1
* Paper URL: [http://arxiv.org/abs/2206.09807v1](http://arxiv.org/abs/2206.09807v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Unlike conventional data such as natural images, audio and speech, raw
multi-channel Electroencephalogram (EEG) data are difficult to interpret.
Modern deep neural networks have shown promising results in EEG studies,
however finding robust invariant representations of EEG data across subjects
remains a challenge, due to differences in brain folding structures. Thus,
invariant representations of EEG data would be desirable to improve our
understanding of the brain activity and to use them effectively during transfer
learning. In this paper, we propose an approach to learn deep representations
of EEG data by exploiting spatial relationships between recording electrodes
and encoding them in a Spatio-Spectral Feature Images. We use multi-channel EEG
signals from the PhyAAt dataset for auditory tasks and train a Convolutional
Neural Network (CNN) on 25 subjects individually. Afterwards, we generate the
input patterns that activate deep neurons across all the subjects. The
generated pattern can be seen as a map of the brain activity in different
spatial regions. Our analysis reveals the existence of specific brain regions
related to different tasks. Low-level features focusing on larger regions and
high-level features focusing on a smaller and very specific cluster of regions
are also identified. Interestingly, similar patterns are found across different
subjects although the activities appear in different regions. Our analysis also
reveals common brain regions across subjects, which can be used as generalized
representations. Our proposed approach allows us to find more interpretable
representations of EEG data, which can further be used for effective transfer
learning.

### Title: Statistical Inference for Large-dimensional Tensor Factor Model by Weighted/Unweighted Projection
* Paper ID: 2206.09800v1
* Paper URL: [http://arxiv.org/abs/2206.09800v1](http://arxiv.org/abs/2206.09800v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Tensor Factor Models (TFM) are appealing dimension reduction tools for
high-order large-dimensional time series, and have wide applications in
economics, finance and medical imaging. Two types of TFM have been proposed in
the literature, essentially based on the Tucker or CP decomposition of tensors.
In this paper, we propose a projection estimator for the Tucker-decomposition
based TFM, and provide its least-square interpretation which parallels to the
least-square interpretation of the Principal Component Analysis (PCA) for the
vector factor model. The projection technique simultaneously reduce the
dimensionality and the magnitudes of the idiosyncratic error matrix, thus
leading to an increase of signal-to-noise ratio. We derive a faster convergence
rate of the projection estimator than that of the naive PCA-based estimator,
under mild conditions which allow the idiosyncratic noise to have weak
cross-correlations and weak autocorrelations. Further motivated by the
least-squares interpretation, we propose a robust version by utilizing a
Huber-loss function, which leads to an iterative weighted projection technique.
Extensive numerical studies are conducted to investigate the empirical
performance of the proposed (weighted) projection estimator relative to the
sate-of-the-art ones. The simulation results shows that the projection
estimator performs better than the non-projection estimators, and the weighted
projection estimator performs much better than the existing ones in the
heavy-tailed case. We are still working on the theoretical analysis of the
weighted projection estimator.

### Title: Cosmic rays probed by H$_2$ rovibrational lines: Is chemical modeling important to understand JWST H$_2$ observations?
* Paper ID: 2206.09780v1
* Paper URL: [http://arxiv.org/abs/2206.09780v1](http://arxiv.org/abs/2206.09780v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Context: It has been proposed that H$_2$near-infrared lines may be excited by
cosmic rays and allow for a determination of the cosmic-ray ionization rate in
dense gas. One-dimensional models show that measuring both the H$_2$gas column
density and H$_2$line intensity enables a constraint on the cosmic-ray
ionization rate as well as the spectral slope of low-energy cosmic-ray protons
in the interstellar medium (ISM). Aims: We aim to investigate the impact of
certain assumptions regarding the H$_2$chemical models and ISM density
distributions on the emission of cosmic-ray induced H$_2$emission lines. This
is of particular importance for utilizing observations of these lines with the
James Webb Space Telescope to constrain the cosmic-ray ionization rate.
Methods: We compare the predicted emission from cosmic-ray induced,
ro-vibrationally excited H$_2$emission lines for different one- and
three-dimensional models with varying assumptions on the gas chemistry and
density distribution. Results: We find that the model predictions of the
H$_2$line intensities for the (1-0)S(0), (1-0)Q(2), (1-0)O(2) and (1-0)O(4)
transitions at 2.22, 2.41, 2.63 and 3.00 $\mu$m, respectively, are relatively
independent of the astro-chemical model and the gas density distribution when
compared against the H$_2$column density, making them robust tracer of the
cosmic-ray ionization rate. Conclusions: We recommend the use of ro-vibrational
H$_2$line emission in combination with estimation of the cloud's H$_2$column
density, to constrain the ionization rate and the spectrum of low energy
cosmic-rays.

### Title: Test-time image-to-image translation ensembling improves out-of-distribution generalization in histopathology
* Paper ID: 2206.09769v1
* Paper URL: [http://arxiv.org/abs/2206.09769v1](http://arxiv.org/abs/2206.09769v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Histopathology whole slide images (WSIs) can reveal significant
inter-hospital variability such as illumination, color or optical artifacts.
These variations, caused by the use of different scanning protocols across
medical centers (staining, scanner), can strongly harm algorithms
generalization on unseen protocols. This motivates development of new methods
to limit such drop of performances. In this paper, to enhance robustness on
unseen target protocols, we propose a new test-time data augmentation based on
multi domain image-to-image translation. It allows to project images from
unseen protocol into each source domain before classifying them and ensembling
the predictions. This test-time augmentation method results in a significant
boost of performances for domain generalization. To demonstrate its
effectiveness, our method has been evaluated on 2 different histopathology
tasks where it outperforms conventional domain generalization, standard H&E
specific color augmentation/normalization and standard test-time augmentation
techniques. Our code is publicly available at
https://gitlab.com/vitadx/articles/test-time-i2i-translation-ensembling.

### Title: Data Fusion for Radio Frequency SLAM with Robust Sampling
* Paper ID: 2206.09746v1
* Paper URL: [http://arxiv.org/abs/2206.09746v1](http://arxiv.org/abs/2206.09746v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Precise indoor localization remains a challenging problem for a variety of
essential applications. A promising approach to address this problem is to
exchange radio signals between mobile agents and static physical anchors (PAs)
that bounce off flat surfaces in the indoor environment. Radio frequency
simultaneous localization and mapping (RF-SLAM) methods can be used to jointly
estimates the time-varying location of agents as well as the static locations
of the flat surfaces. Recent work on RF-SLAM methods has shown that each
surface can be efficiently represented by a single master virtual anchor (MVA).
The measurement model related to this MVA-based RF-SLAM method is highly
nonlinear. Thus, Bayesian estimation relies on sampling-based techniques. The
original MVA-based RF-SLAM method employs conventional "bootstrap" sampling. In
challenging scenarios it was observed that the original method might converge
to incorrect MVA positions corresponding to local maxima. In this paper, we
introduce MVA-based RF-SLAM with an improved sampling technique that succeeds
in the aforementioned challenging scenarios. Our simulation results demonstrate
significant performance advantages.

### Title: A Safe Control Architecture Based on Robust Model Predictive Control for Autonomous Driving
* Paper ID: 2206.09735v1
* Paper URL: [http://arxiv.org/abs/2206.09735v1](http://arxiv.org/abs/2206.09735v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: This paper proposes a Robust Safe Control Architecture (RSCA) for
safe-decision making. The system to be controlled is a vehicle in the presence
of bounded disturbances. The RSCA consists of two parts: a Supervisor MPC and a
Controller MPC. Both the Supervisor and the Controller are tube MPCs (TMPCs).
The Supervisor MPC provides a safety certificate for an operating controller
and a backup control input in every step. After an unsafe action by the
operating controller is predicted, the Controller MPC takes over the system. In
this paper, a method for the computation of a terminal set is proposed, which
is robust against changes in road curvature and forces the vehicle to reach a
safe reference. Moreover, two important proofs are provided in this paper.
First, it is shown that the backup control input is safe to be applied to the
system to lead the vehicle to a safe state. Next, the recursive feasibility of
the RSCA is proven. By simulating some obstacle avoidance scenarios, the
effectiveness of the proposed RSCA is confirmed.

### Title: Square wave generation in vertical external-cavity Kerr-Gires-Tournois interferometers
* Paper ID: 2206.09656v1
* Paper URL: [http://arxiv.org/abs/2206.09656v1](http://arxiv.org/abs/2206.09656v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: We study theoretically the mechanisms of square-wave (SW) formation in
vertical external-cavity Kerr-Gires-Tournois interferometers in presence of
anti-resonant injection. We provide simple analytical approximations for their
plateau intensities and for the conditions of their emergence. We demonstrate
that SWs may appear via a homoclinic snaking scenario, leading to the formation
of complex-shaped multistable SW solutions. The resulting SWs can host
localized structures and robust bound-states.

### Title: Beyond IID: data-driven decision-making in heterogeneous environments
* Paper ID: 2206.09642v1
* Paper URL: [http://arxiv.org/abs/2206.09642v1](http://arxiv.org/abs/2206.09642v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: In this work, we study data-driven decision-making and depart from the
classical identically and independently distributed (i.i.d.) assumption. We
present a new framework in which historical samples are generated from unknown
and different distributions, which we dub heterogeneous environments. These
distributions are assumed to lie in a heterogeneity ball with known radius and
centered around the (also) unknown future (out-of-sample) distribution on which
the performance of a decision will be evaluated. We quantify the asymptotic
worst-case regret that is achievable by central data-driven policies such as
Sample Average Approximation, but also by rate-optimal ones, as a function of
the radius of the heterogeneity ball. Our work shows that the type of
achievable performance varies considerably across different combinations of
problem classes and notions of heterogeneity. We demonstrate the versatility of
our framework by comparing achievable guarantees for the heterogeneous version
of widely studied data-driven problems such as pricing, ski-rental, and
newsvendor. En route, we establish a new connection between data-driven
decision-making and distributionally robust optimization.

### Title: Classical Splitting of Parametrized Quantum Circuits
* Paper ID: 2206.09641v1
* Paper URL: [http://arxiv.org/abs/2206.09641v1](http://arxiv.org/abs/2206.09641v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Barren plateaus appear to be a major obstacle to using variational quantum
algorithms to simulate large-scale quantum systems or replace traditional
machine learning algorithms. They can be caused by multiple factors such as
expressivity, entanglement, locality of observables, or even hardware noise. We
propose classical splitting of ans\"atze or parametrized quantum circuits to
avoid barren plateaus. Classical splitting is realized by splitting an $N$
qubit ansatz to multiple ans\"atze that consists of $\mathcal{O}(\log N)$
qubits. We show that such an ansatz can be used to avoid barren plateaus. We
support our results with numerical experiments and perform binary
classification on classical and quantum datasets. Then, we propose an extension
of the ansatz that is compatible with variational quantum simulations. Finally,
we discuss a speed-up for gradient-based optimization and hardware
implementation, robustness against noise and parallelization, making classical
splitting an ideal tool for noisy intermediate scale quantum (NISQ)
applications.

### Title: Diversified Adversarial Attacks based on Conjugate Gradient Method
* Paper ID: 2206.09628v1
* Paper URL: [http://arxiv.org/abs/2206.09628v1](http://arxiv.org/abs/2206.09628v1)
* Updated Date: 2022-06-20
* Code URL: [https://github.com/yamamura-k/ACG](https://github.com/yamamura-k/ACG)
* Summary: Deep learning models are vulnerable to adversarial examples, and adversarial
attacks used to generate such examples have attracted considerable research
interest. Although existing methods based on the steepest descent have achieved
high attack success rates, ill-conditioned problems occasionally reduce their
performance. To address this limitation, we utilize the conjugate gradient (CG)
method, which is effective for this type of problem, and propose a novel attack
algorithm inspired by the CG method, named the Auto Conjugate Gradient (ACG)
attack. The results of large-scale evaluation experiments conducted on the
latest robust models show that, for most models, ACG was able to find more
adversarial examples with fewer iterations than the existing SOTA algorithm
Auto-PGD (APGD). We investigated the difference in search performance between
ACG and APGD in terms of diversification and intensification, and define a
measure called Diversity Index (DI) to quantify the degree of diversity. From
the analysis of the diversity using this index, we show that the more diverse
search of the proposed method remarkably improves its attack success rate.

### Title: Degeneracy in epilepsy: Multiple Routes to Hyperexcitable Brain Circuits and their Repair
* Paper ID: 2206.09621v1
* Paper URL: [http://arxiv.org/abs/2206.09621v1](http://arxiv.org/abs/2206.09621v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Developing effective therapies against epilepsy remains a challenge. The
complex and multifaceted nature of this disease still fuels controversies about
its origin. In this perspective article, we argue that conflicting hypotheses
can be reconciled by taking into account the degeneracy of the brain, which
manifests in multiple routes leading to similar function or dysfunction. We
exemplify degeneracy at three different levels, ranging from the cellular to
the network and systems level. First, at the cellular level, we describe the
relevance of ion channel degeneracy for epilepsy and discuss its interplay with
dendritic morphology. Second, at the network level, we provide examples for the
degeneracy of synaptic and intrinsic neuronal properties that supports the
robustness of neuronal networks but also leads to diverse responses to
ictogenic and epileptogenic perturbations. Third, at the system level, we
provide examples for degeneracy in the intricate interactions between the
immune and nervous system. Finally, we show that computational approaches
including multiscale and so called population neural circuit models help
disentangle the complex web of physiological and pathological adaptations. Such
models may contribute to identifying the best personalized multitarget
strategies for directing the system towards a physiological state.

### Title: Examining the Robustness of Spiking Neural Networks on Non-ideal Memristive Crossbars
* Paper ID: 2206.09599v1
* Paper URL: [http://arxiv.org/abs/2206.09599v1](http://arxiv.org/abs/2206.09599v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Spiking Neural Networks (SNNs) have recently emerged as the low-power
alternative to Artificial Neural Networks (ANNs) owing to their asynchronous,
sparse, and binary information processing. To improve the energy-efficiency and
throughput, SNNs can be implemented on memristive crossbars where
Multiply-and-Accumulate (MAC) operations are realized in the analog domain
using emerging Non-Volatile-Memory (NVM) devices. Despite the compatibility of
SNNs with memristive crossbars, there is little attention to study on the
effect of intrinsic crossbar non-idealities and stochasticity on the
performance of SNNs. In this paper, we conduct a comprehensive analysis of the
robustness of SNNs on non-ideal crossbars. We examine SNNs trained via learning
algorithms such as, surrogate gradient and ANN-SNN conversion. Our results show
that repetitive crossbar computations across multiple time-steps induce error
accumulation, resulting in a huge performance drop during SNN inference. We
further show that SNNs trained with a smaller number of time-steps achieve
better accuracy when deployed on memristive crossbars.

### Title: Chiral current in Floquet cavity-magnonics
* Paper ID: 2206.09540v1
* Paper URL: [http://arxiv.org/abs/2206.09540v1](http://arxiv.org/abs/2206.09540v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Floquet engineering could induce complex collective behaviour and interesting
synthetic gauge-field in quantum many-body systems through temporal modulation
of system parameters by periodic drives. Using a Floquet drive on frequencies
of the magnon modes, we realize a chiral state-transfer in a hybrid
photon-magnon system. The time-reversal symmetry is broken in such a promising
platform for coherent information processing. The cavity-photon mode is
adiabatically eliminated in the large-detuning regime and the magnon modes
under conditional longitudinal drives can be indirectly coupled to each other
with a phase-modulated interaction. The effective Hamiltonian is then used to
generate chiral currents in a circular loop, whose dynamics is evaluated to
measure the symmetry of the system Hamiltonian. Beyond the dynamics in the
manifold with a limited number of excitations, our protocol applies to the
continuous-variable systems with arbitrary initial states. In addition, it is
found to be robust against the systematic errors in the photon-magnon coupling
strength and Kerr nonlinearity.

### Title: Hands-on Wireless Sensing with Wi-Fi: A Tutorial
* Paper ID: 2206.09532v1
* Paper URL: [http://arxiv.org/abs/2206.09532v1](http://arxiv.org/abs/2206.09532v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: With the rapid development of wireless communication technology, wireless
access points (AP) and internet of things (IoT) devices have been widely
deployed in our surroundings. Various types of wireless signals (e.g., Wi-Fi,
LoRa, LTE) are filling out our living and working spaces. Previous researches
reveal the fact that radio waves are modulated by the spatial structure during
the propagation process (e.g., reflection, diffraction, and scattering) and
superimposed on the receiver. This observation allows us to reconstruct the
surrounding environment based on received wireless signals, called "wireless
sensing". Wireless sensing is an emerging technology that enables a wide range
of applications, such as gesture recognition for human-computer interaction,
vital signs monitoring for health care, and intrusion detection for security
management. Compared with other sensing paradigms, such as vision-based and
IMU-based sensing, wireless sensing solutions have unique advantages such as
high coverage, pervasiveness, low cost, and robustness under adverse light and
texture scenarios. Besides, wireless sensing solutions are generally
lightweight in terms of both computation overhead and device size. This
tutorial takes Wi-Fi sensing as an example. It introduces both the theoretical
principles and the code implementation of data collection, signal processing,
features extraction, and model design. In addition, this tutorial highlights
state-of-the-art deep learning models (e.g., CNN, RNN, and adversarial learning
models) and their applications in wireless sensing systems. We hope this
tutorial will help people in other research fields to break into wireless
sensing research and learn more about its theories, designs, and implementation
skills, promoting prosperity in the wireless sensing research field.

### Title: Optimal design for on-farm strip trials -- systematic or randomised?
* Paper ID: 2206.09528v1
* Paper URL: [http://arxiv.org/abs/2206.09528v1](http://arxiv.org/abs/2206.09528v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: There is no doubt on the importance of randomisation in agricultural
experiments by agronomists and biometricians. Even when agronomists extend the
experimentation from small trials to large on-farm trials, randomised designs
predominate over systematic designs. However, the situation may change
depending on the objective of the on-farm experiments (OFE). If the goal of OFE
is obtaining a smooth map showing the optimal level of a controllable input
across a grid made by rows and columns covering the whole field, a systematic
design should be preferred over a randomised design in terms of robustness and
reliability. With the novel geographically weighted regression (GWR) for OFE
and simulation studies, we conclude that, for large OFE strip trials, the
difference between randomised designs and systematic designs are not
significant if a linear model of treatments is fitted or if the spatial
variation is not taken into account. But for a quadratic model, systematic
designs are superior to randomised designs.

### Title: Robust One Round Federated Learning with Predictive Space Bayesian Inference
* Paper ID: 2206.09526v1
* Paper URL: [http://arxiv.org/abs/2206.09526v1](http://arxiv.org/abs/2206.09526v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Making predictions robust is an important challenge. A separate challenge in
federated learning (FL) is to reduce the number of communication rounds,
particularly since doing so reduces performance in heterogeneous data settings.
To tackle both issues, we take a Bayesian perspective on the problem of
learning a global model. We show how the global predictive posterior can be
approximated using client predictive posteriors. This is unlike other works
which aggregate the local model space posteriors into the global model space
posterior, and are susceptible to high approximation errors due to the
posterior's high dimensional multimodal nature. In contrast, our method
performs the aggregation on the predictive posteriors, which are typically
easier to approximate owing to the low-dimensionality of the output space. We
present an algorithm based on this idea, which performs MCMC sampling at each
client to obtain an estimate of the local posterior, and then aggregates these
in one round to obtain a global ensemble model. Through empirical evaluation on
several classification and regression tasks, we show that despite using one
round of communication, the method is competitive with other FL techniques, and
outperforms them on heterogeneous settings. The code is publicly available at
https://github.com/hasanmohsin/FedPredSpace_1Round.

