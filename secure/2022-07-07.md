### Title: Training Transformers Together
* Paper ID: 2207.03481v1
* Paper URL: [http://arxiv.org/abs/2207.03481v1](http://arxiv.org/abs/2207.03481v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LG', 'cs.DC']
* Code URL: [https://github.com/learning-at-home/hivemind](https://github.com/learning-at-home/hivemind)
* Summary: The infrastructure necessary for training state-of-the-art models is becoming
overly expensive, which makes training such models affordable only to large
corporations and institutions. Recent work proposes several methods for
training such models collaboratively, i.e., by pooling together hardware from
many independent parties and training a shared model over the Internet. In this
demonstration, we collaboratively trained a text-to-image transformer similar
to OpenAI DALL-E. We invited the viewers to join the ongoing training run,
showing them instructions on how to contribute using the available hardware. We
explained how to address the engineering challenges associated with such a
training run (slow communication, limited memory, uneven performance between
devices, and security concerns) and discussed how the viewers can set up
collaborative training runs themselves. Finally, we show that the resulting
model generates images of reasonable quality on a number of prompts.

### Title: Differentially Private Stochastic Linear Bandits: (Almost) for Free
* Paper ID: 2207.03445v1
* Paper URL: [http://arxiv.org/abs/2207.03445v1](http://arxiv.org/abs/2207.03445v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LG', 'cs.CR']
* Code URL: null
* Summary: In this paper, we propose differentially private algorithms for the problem
of stochastic linear bandits in the central, local and shuffled models. In the
central model, we achieve almost the same regret as the optimal non-private
algorithms, which means we get privacy for free. In particular, we achieve a
regret of $\tilde{O}(\sqrt{T}+\frac{1}{\epsilon})$ matching the known lower
bound for private linear bandits, while the best previously known algorithm
achieves $\tilde{O}(\frac{1}{\epsilon}\sqrt{T})$. In the local case, we achieve
a regret of $\tilde{O}(\frac{1}{\epsilon}{\sqrt{T}})$ which matches the
non-private regret for constant $\epsilon$, but suffers a regret penalty when
$\epsilon$ is small. In the shuffled model, we also achieve regret of
$\tilde{O}(\sqrt{T}+\frac{1}{\epsilon})$ %for small $\epsilon$ as in the
central case, while the best previously known algorithm suffers a regret of
$\tilde{O}(\frac{1}{\epsilon}{T^{3/5}})$. Our numerical evaluation validates
our theoretical results.

### Title: HE-PEx: Efficient Machine Learning under Homomorphic Encryption using Pruning, Permutation and Expansion
* Paper ID: 2207.03384v1
* Paper URL: [http://arxiv.org/abs/2207.03384v1](http://arxiv.org/abs/2207.03384v1)
* Updated Date: 2022-07-07
* Categories: ['cs.CR', 'cs.LG']
* Code URL: null
* Summary: Privacy-preserving neural network (NN) inference solutions have recently
gained significant traction with several solutions that provide different
latency-bandwidth trade-offs. Of these, many rely on homomorphic encryption
(HE), a method of performing computations over encrypted data. However, HE
operations even with state-of-the-art schemes are still considerably slow
compared to their plaintext counterparts. Pruning the parameters of a NN model
is a well-known approach to improving inference latency. However, pruning
methods that are useful in the plaintext context may lend nearly negligible
improvement in the HE case, as has also been demonstrated in recent work.
  In this work, we propose a novel set of pruning methods that reduce the
latency and memory requirement, thus bringing the effectiveness of plaintext
pruning methods to HE. Crucially, our proposal employs two key techniques, viz.
permutation and expansion of the packed model weights, that enable pruning
significantly more ciphertexts and recuperating most of the accuracy loss,
respectively. We demonstrate the advantage of our method on fully connected
layers where the weights are packed using a recently proposed packing technique
called tile tensors, which allows executing deep NN inference in a
non-interactive mode. We evaluate our methods on various autoencoder
architectures and demonstrate that for a small mean-square reconstruction loss
of 1.5*10^{-5} on MNIST, we reduce the memory requirement and latency of
HE-enabled inference by 60%.

### Title: On Session Typing, Probabilistic Polynomial Time, and Cryptographic Experiments (Long Version)
* Paper ID: 2207.03360v1
* Paper URL: [http://arxiv.org/abs/2207.03360v1](http://arxiv.org/abs/2207.03360v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LO', 'cs.CR']
* Code URL: null
* Summary: A system of session types is introduced as induced by a Curry Howard
correspondence applied to Bounded Linear Logic, and then extending the thus
obtained type system with probabilistic choices and ground types. The obtained
system satisfies the expected properties, like subject reduction and progress,
but also unexpected ones, like a polynomial bound on the time needed to reduce
processes. This makes the system suitable for modelling experiments and proofs
from the so-called computational model of cryptography.

### Title: A Methodology to Support Automatic Cyber Risk Assessment Review
* Paper ID: 2207.03269v1
* Paper URL: [http://arxiv.org/abs/2207.03269v1](http://arxiv.org/abs/2207.03269v1)
* Updated Date: 2022-07-07
* Categories: ['cs.CR']
* Code URL: null
* Summary: Cyber risk assessment is a fundamental activity for enhancing the protection
of an organization, identifying and evaluating the exposure to cyber threats.
Currently, this activity is carried out mainly manually and the identification
and correct quantification of risks deeply depend on the experience and
confidence of the human assessor. As a consequence, the process is not
completely objective and two parallel assessments of the same situation may
lead to different results. This paper takes a step in the direction of reducing
the degree of subjectivity by proposing a methodology to support risk assessors
with an automatic review of the produced assessment. Our methodology starts
from a controls-based assessment performed using well-known cybersecurity
frameworks (e.g., ISO 27001, NIST) and maps security controls over
infrastructural aspects that can be assessed automatically (e.g., ICT devices,
organization policies). Exploiting this mapping, the methodology suggests how
to identify controls needing revision. The approach has been validated through
a case study from the healthcare domain and a set of statistical analyses.

### Title: Local Inversion of maps: Black box Cryptanalysis
* Paper ID: 2207.03247v1
* Paper URL: [http://arxiv.org/abs/2207.03247v1](http://arxiv.org/abs/2207.03247v1)
* Updated Date: 2022-07-07
* Categories: ['cs.CR', '11T30, 11T30', 'F.2.1; E.3; I.1.0; I.1.1']
* Code URL: null
* Summary: This paper is a short summery of results announced in a previous paper on a
new universal method for Cryptanalysis which uses a Black Box linear algebra
approach to computation of local inversion of nonlinear maps in finite fields.
It is shown that one local inverse $x$ of the map equation $y=F(x)$ can be
computed by using the minimal polynomial of the sequence $y(k)$ defined by
iterates (or recursion) $y(k+1)=F(y(k))$ with $y(0)=y$ when the sequence is
periodic. This is the only solution in the periodic orbit of the map $F$.
Further, when the degree of the minimal polynomial is of polynomial order in
number of bits of the input of $F$ (called low complexity case), the solution
can be computed in polynomial time. The method of computation only uses the
forward computations $F(y)$ for given $y$ which is why this is called a Black
Box approach. Application of this approach is then shown for cryptanalysis of
several maps arising in cryptographic primitives. It is shown how in the low
complexity cases maps defined by block and stream ciphers can be inverted to
find the symmetric key under known plaintext attack. Then it is shown how RSA
map can be inverted to find the plaintext as well as an equivalent private key
to break the RSA algorithm without factoring the modulus. Finally it is shown
that the discrete log computation in finite field and elliptic curves can be
formulated as a local inversion problem and the low complexity cases can be
solved in polynomial time.

### Title: Towards Immediate Feedback for Security Relevant Code in Development Environments
* Paper ID: 2207.03225v1
* Paper URL: [http://arxiv.org/abs/2207.03225v1](http://arxiv.org/abs/2207.03225v1)
* Updated Date: 2022-07-07
* Categories: ['cs.SE', 'cs.CR']
* Code URL: null
* Summary: Nowadays, the correct use of cryptography libraries is essential to ensure
the necessary information security in different kinds of applications. A common
practice in software development is the use of static application security
testing (SAST) tools to analyze code regarding security vulnerabilities. Most
of these tools are designed to run separately from development environments.
Their results are extensive lists of security notifications, which software
developers have to inspect manually in a time-consuming follow-up step. To
support developers in their tasks of developing secure code, we present an
approach for providing them with continuous immediate feedback of SAST tools in
integrated development environments (IDEs). Our approach also considers the
understandability of security notifications and aims for a user-centered
approach that leverages developers' feedback to build an adaptive system
tailored to each individual developer.

### Title: Privacy-Preserving Synthetic Educational Data Generation
* Paper ID: 2207.03202v1
* Paper URL: [http://arxiv.org/abs/2207.03202v1](http://arxiv.org/abs/2207.03202v1)
* Updated Date: 2022-07-07
* Categories: ['cs.CY', 'cs.AI', 'cs.CR', 'cs.LG']
* Code URL: [https://github.com/akulen/privgen](https://github.com/akulen/privgen)
* Summary: Institutions collect massive learning traces but they may not disclose it for
privacy issues. Synthetic data generation opens new opportunities for research
in education. In this paper we present a generative model for educational data
that can preserve the privacy of participants, and an evaluation framework for
comparing synthetic data generators. We show how naive pseudonymization can
lead to re-identification threats and suggest techniques to guarantee privacy.
We evaluate our method on existing massive educational open datasets.

