### Title: BliMe: Verifiably Secure Outsourced Computation with Hardware-Enforced Taint Tracking
* Paper ID: 2204.09649v1
* Paper URL: [http://arxiv.org/abs/2204.09649v1](http://arxiv.org/abs/2204.09649v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: We present Blinded Memory (BliMe), a way to realize efficient and secure
outsourced computation. BliMe consists of a novel and minimal set of ISA
extensions that uses taint tracking to ensure the confidentiality of sensitive
(client) data even in the presence of server malware, run-time attacks, and
side-channel attacks. To secure outsourced computation, the BliMe extensions
can be used together with an attestable, fixed-function trusted execution
environment (TEE) and an encryption engine that provides atomic
decrypt-and-taint and encrypt-and-untaint operations. The TEE engages in an
attestation and key agreement protocol with the client. It provides the
resulting client-specific keys to the encryption engine. Clients rely on remote
attestation to ensure that their data will always be protected by BliMe's taint
tracking policy after decryption. We provide a machine-checked security proof
and an FPGA implementation (BliMe-Ibex) of BliMe's taint tracking policy. We
show that BliMe-Ibex does not reduce performance relative to the unmodified
core, and incurs only minor increases in resource consumption in terms of power
($<2\%$), LUTs ($<1\%$), and registers ($<3\%$).

### Title: Detecting Unintended Memorization in Language-Model-Fused ASR
* Paper ID: 2204.09606v1
* Paper URL: [http://arxiv.org/abs/2204.09606v1](http://arxiv.org/abs/2204.09606v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: End-to-end (E2E) models are often being accompanied by language models (LMs)
via shallow fusion for boosting their overall quality as well as recognition of
rare words. At the same time, several prior works show that LMs are susceptible
to unintentionally memorizing rare or unique sequences in the training data. In
this work, we design a framework for detecting memorization of random textual
sequences (which we call canaries) in the LM training data when one has only
black-box (query) access to LM-fused speech recognizer, as opposed to direct
access to the LM. On a production-grade Conformer RNN-T E2E model fused with a
Transformer LM, we show that detecting memorization of singly-occurring
canaries from the LM training data of 300M examples is possible. Motivated to
protect privacy, we also show that such memorization gets significantly reduced
by per-example gradient-clipped LM training without compromising overall
quality.

### Title: Digging into Primary Financial Market: Challenges and Opportunities of Adopting Blockchain
* Paper ID: 2204.09544v1
* Paper URL: [http://arxiv.org/abs/2204.09544v1](http://arxiv.org/abs/2204.09544v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Since the emergence of blockchain technology, its application in the
financial market has always been an area of focus and exploration by all
parties. With the characteristics of anonymity, trust, tamper-proof, etc.,
blockchain technology can effectively solve some problems faced by the
financial market, such as trust issues and information asymmetry issues. To
deeply understand the application scenarios of blockchain in the financial
market, the issue of securities issuance and trading in the primary market is a
problem that must be studied clearly. We conducted an empirical study to
investigate the main difficulties faced by primary market participants in their
business practices and the potential challenges of the deepening application of
blockchain technology in the primary market. We adopted a hybrid method
combining interviews (qualitative methods) and surveys (quantitative methods)
to conduct this research in two stages. In the first stage, we interview 15
major primary market participants with different backgrounds and expertise. In
the second phase, we conducted a verification survey of 54 primary market
practitioners to confirm various insights from the interviews, including
challenges and desired improvements. Our interviews and survey results revealed
several significant challenges facing blockchain applications in the primary
market: complex due diligence, mismatch, and difficult monitoring. On this
basis, we believe that our future research can focus on some aspects of these
challenges.

### Title: A Comprehensive Study of Accelerating IPv6 Deployment
* Paper ID: 2204.09539v1
* Paper URL: [http://arxiv.org/abs/2204.09539v1](http://arxiv.org/abs/2204.09539v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Since the lack of IPv6 network development, China is currently accelerating
IPv6 deployment. In this scenario, traffic and network structure show a huge
shift. However, due to the long-term prosperity, we are ignorant of the
problems behind such outbreak of traffic and performance improvement events in
accelerating deployment. IPv6 development in some regions will still face
similar challenges in the future. To contribute to solving this problem, in
this paper, we produce a new measurement framework and implement a 5-month
passive measurement on the IPv6 network during the accelerating deployment in
China. We combine 6 global-scale datasets to form the normal status of IPv6
network, which is against to the accelerating status formed by the passive
traffic. Moreover, we compare with the traffic during World IPv6 Day 2011 and
Launch 2012 to discuss the common nature of accelerating deployment. Finally,
the results indicate that the IPv6 accelerating deployment is often accompanied
by an unbalanced network status. It exposes unresolved security issues
including the challenge of user privacy and inappropriate access methods.
According to the investigation, we point the future IPv6 development after
accelerating deployment.

### Title: Backdooring Explainable Machine Learning
* Paper ID: 2204.09498v1
* Paper URL: [http://arxiv.org/abs/2204.09498v1](http://arxiv.org/abs/2204.09498v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Explainable machine learning holds great potential for analyzing and
understanding learning-based systems. These methods can, however, be
manipulated to present unfaithful explanations, giving rise to powerful and
stealthy adversaries. In this paper, we demonstrate blinding attacks that can
fully disguise an ongoing attack against the machine learning model. Similar to
neural backdoors, we modify the model's prediction upon trigger presence but
simultaneously also fool the provided explanation. This enables an adversary to
hide the presence of the trigger or point the explanation to entirely different
portions of the input, throwing a red herring. We analyze different
manifestations of such attacks for different explanation types in the image
domain, before we resume to conduct a red-herring attack against malware
classification.

### Title: SiamHAN: IPv6 Address Correlation Attacks on TLS Encrypted Traffic via Siamese Heterogeneous Graph Attention Network
* Paper ID: 2204.09465v1
* Paper URL: [http://arxiv.org/abs/2204.09465v1](http://arxiv.org/abs/2204.09465v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Unlike IPv4 addresses, which are typically masked by a NAT, IPv6 addresses
could easily be correlated with user activity, endangering their privacy.
Mitigations to address this privacy concern have been deployed, making existing
approaches for address-to-user correlation unreliable. This work demonstrates
that an adversary could still correlate IPv6 addresses with users accurately,
even with these protection mechanisms. To do this, we propose an IPv6 address
correlation model - SiamHAN. The model uses a Siamese Heterogeneous Graph
Attention Network to measure whether two IPv6 client addresses belong to the
same user even if the user's traffic is protected by TLS encryption. Using a
large real-world dataset, we show that, for the tasks of tracking target users
and discovering unique users, the state-of-the-art techniques could achieve
only 85% and 60% accuracy, respectively. However, SiamHAN exhibits 99% and 88%
accuracy.

### Title: Sheaf semantics of termination-insensitive noninterference
* Paper ID: 2204.09421v1
* Paper URL: [http://arxiv.org/abs/2204.09421v1](http://arxiv.org/abs/2204.09421v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: We propose a new sheaf semantics for secure information flow over a space of
abstract behaviors, based on synthetic domain theory: security classes are
open/closed partitions, types are sheaves, and redaction of sensitive
information corresponds to restricting a sheaf to a closed subspace. Our
security-aware computational model satisfies termination-insensitive
noninterference automatically, and therefore constitutes an intrinsic
alternative to state of the art extrinsic/relational models of noninterference.
Our semantics is the latest application of Sterling and Harper's recent
re-interpretation of phase distinctions and noninterference in programming
languages in terms of Artin gluing and topos-theoretic open/closed modalities.
Prior applications include parametricity for ML modules, the proof of
normalization for cubical type theory by Sterling and Angiuli, and the
cost-aware logical framework of Niu et al. In this paper we employ the phase
distinction perspective twice: first to reconstruct the syntax and semantics of
secure information flow as a lattice of phase distinctions between "higher" and
"lower" security, and second to verify the computational adequacy of our sheaf
semantics vis-\`a-vis an extension of Abadi et al.'s dependency core calculus
with a construct for declassifying termination channels.

### Title: Case-Aware Adversarial Training
* Paper ID: 2204.09398v1
* Paper URL: [http://arxiv.org/abs/2204.09398v1](http://arxiv.org/abs/2204.09398v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: The neural network (NN) becomes one of the most heated type of models in
various signal processing applications. However, NNs are extremely vulnerable
to adversarial examples (AEs). To defend AEs, adversarial training (AT) is
believed to be the most effective method while due to the intensive
computation, AT is limited to be applied in most applications. In this paper,
to resolve the problem, we design a generic and efficient AT improvement
scheme, namely case-aware adversarial training (CAT). Specifically, the
intuition stems from the fact that a very limited part of informative samples
can contribute to most of model performance. Alternatively, if only the most
informative AEs are used in AT, we can lower the computation complexity of AT
significantly as maintaining the defense effect. To achieve this, CAT achieves
two breakthroughs. First, a method to estimate the information degree of
adversarial examples is proposed for AE filtering. Second, to further enrich
the information that the NN can obtain from AEs, CAT involves a weight
estimation and class-level balancing based sampling strategy to increase the
diversity of AT at each iteration. Extensive experiments show that CAT is
faster than vanilla AT by up to 3x while achieving competitive defense effect.

### Title: Adversarial Scratches: Deployable Attacks to CNN Classifiers
* Paper ID: 2204.09397v1
* Paper URL: [http://arxiv.org/abs/2204.09397v1](http://arxiv.org/abs/2204.09397v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: A growing body of work has shown that deep neural networks are susceptible to
adversarial examples. These take the form of small perturbations applied to the
model's input which lead to incorrect predictions. Unfortunately, most
literature focuses on visually imperceivable perturbations to be applied to
digital images that often are, by design, impossible to be deployed to physical
targets. We present Adversarial Scratches: a novel L0 black-box attack, which
takes the form of scratches in images, and which possesses much greater
deployability than other state-of-the-art attacks. Adversarial Scratches
leverage B\'ezier Curves to reduce the dimension of the search space and
possibly constrain the attack to a specific location. We test Adversarial
Scratches in several scenarios, including a publicly available API and images
of traffic signs. Results show that, often, our attack achieves higher fooling
rate than other deployable state-of-the-art methods, while requiring
significantly fewer queries and modifying very few pixels.

### Title: Runtime Prevention of Deserialization Attacks
* Paper ID: 2204.09388v1
* Paper URL: [http://arxiv.org/abs/2204.09388v1](http://arxiv.org/abs/2204.09388v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Untrusted deserialization exploits, where a serialised object graph is used
to achieve denial-of-service or arbitrary code execution, have become so
prominent that they were introduced in the 2017 OWASP Top 10. In this paper, we
present a novel and lightweight approach for runtime prevention of
deserialization attacks using Markov chains. The intuition behind our work is
that the features and ordering of classes in malicious object graphs make them
distinguishable from benign ones. Preliminary results indeed show that our
approach achieves an F1-score of 0.94 on a dataset of 264 serialised payloads,
collected from an industrial Java EE application server and a repository of
deserialization exploits.

### Title: Exploring Widevine for Fun and Profit
* Paper ID: 2204.09298v1
* Paper URL: [http://arxiv.org/abs/2204.09298v1](http://arxiv.org/abs/2204.09298v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: For years, Digital Right Management (DRM) systems have been used as the go-to
solution for media content protection against piracy. With the growing
consumption of content using Over-the-Top platforms, such as Netflix or Prime
Video, DRMs have been deployed on numerous devices considered as potential
hostile environments. In this paper, we focus on the most widespread solution,
the closed-source Widevine DRM. Installed on billions of devices, Widevine
relies on cryptographic operations to protect content. Our work presents a
study of Widevine internals on Android, mapping its distinct components and
bringing out its different cryptographic keys involved in content decryption.
We provide a structural view of Widevine as a protocol with its complete key
ladder. Based on our insights, we develop WideXtractor, a tool based on Frida
to trace Widevine function calls and intercept messages for inspection. Using
this tool, we analyze Netflix usage of Widevine as a proof-of-concept, and
raised privacy concerns on user-tracking. In addition, we leverage our
knowledge to bypass the obfuscation of Android Widevine software-only version,
namely L3, and recover its Root-of-Trust.

### Title: The Danger of Small Anonymity Sets in Privacy-Preserving Payment Systems
* Paper ID: 2204.09282v1
* Paper URL: [http://arxiv.org/abs/2204.09282v1](http://arxiv.org/abs/2204.09282v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Unlike suggested during their early years of existence, Bitcoin and similar
cryptocurrencies in fact offer significantly less privacy as compared to
traditional banking. A myriad of privacy-enhancing extensions to those
cryptocurrencies as well as several clean-slate privacy-protecting
cryptocurrencies have been proposed in turn. To convey a better understanding
of the protection of popular design decisions, we investigate expected
anonymity set sizes in an initial simulation study. The large variation of
expected transaction values yields soberingly small effective anonymity sets
for protocols that leak transaction values. We hence examine the effect of
preliminary, intuitive strategies for merging groups of payments into larger
anonymity sets, for instance by choosing from pre-specified value classes. The
results hold promise, as they indeed induce larger anonymity sets at
comparatively low cost, depending on the corresponding strategy

### Title: Causality-based Neural Network Repair
* Paper ID: 2204.09274v1
* Paper URL: [http://arxiv.org/abs/2204.09274v1](http://arxiv.org/abs/2204.09274v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Neural networks have had discernible achievements in a wide range of
applications. The wide-spread adoption also raises the concern of their
dependability and reliability. Similar to traditional decision-making programs,
neural networks can have defects that need to be repaired. The defects may
cause unsafe behaviors, raise security concerns or unjust societal impacts. In
this work, we address the problem of repairing a neural network for desirable
properties such as fairness and the absence of backdoor. The goal is to
construct a neural network that satisfies the property by (minimally) adjusting
the given neural network's parameters (i.e., weights). Specifically, we propose
CARE (\textbf{CA}usality-based \textbf{RE}pair), a causality-based neural
network repair technique that 1) performs causality-based fault localization to
identify the `guilty' neurons and 2) optimizes the parameters of the identified
neurons to reduce the misbehavior. We have empirically evaluated CARE on
various tasks such as backdoor removal, neural network repair for fairness and
safety properties. Our experiment results show that CARE is able to repair all
neural networks efficiently and effectively. For fairness repair tasks, CARE
successfully improves fairness by $61.91\%$ on average. For backdoor removal
tasks, CARE reduces the attack success rate from over $98\%$ to less than
$1\%$. For safety property repair tasks, CARE reduces the property violation
rate to less than $1\%$. Results also show that thanks to the causality-based
fault localization, CARE's repair focuses on the misbehavior and preserves the
accuracy of the neural networks.

### Title: Refinement on spectral Turán's theorem
* Paper ID: 2204.09194v1
* Paper URL: [http://arxiv.org/abs/2204.09194v1](http://arxiv.org/abs/2204.09194v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: A well-known result in extremal spectral graph theory, known as Nosal's
theorem, states that if $G$ is a triangle-free graph on $n$ vertices, then
$\lambda (G) \le \lambda (K_{\lfloor \frac{n}{2}\rfloor, \lceil \frac{n}{2}
\rceil })$, equality holds if and only if $G=K_{\lfloor \frac{n}{2}\rfloor,
\lceil \frac{n}{2} \rceil }$. Nikiforov [Linear Algebra Appl. 427 (2007)]
extended Nosal's theorem to $K_{r+1}$-free graphs for every integer $r\ge 2$.
This is now known as the spectral Tur\'{a}n theorem. Recently, Lin, Ning and Wu
[Combin. Probab. Comput. 30 (2021)] proved a refinement on Nosal's theorem for
non-bipartite triangle-free graphs. In this paper, we provide alternative
proofs for both the result of Nikiforov and the result of Lin, Ning and Wu.
Moreover, our new proof can allow us to extend the later result to
non-$r$-partite $K_{r+1}$-free graphs. Our result refines the theorem of
Nikiforov and it also can be viewed as a spectral version of a theorem of
Brouwer.

### Title: Robustness Testing of Data and Knowledge Driven Anomaly Detection in Cyber-Physical Systems
* Paper ID: 2204.09183v1
* Paper URL: [http://arxiv.org/abs/2204.09183v1](http://arxiv.org/abs/2204.09183v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: The growing complexity of Cyber-Physical Systems (CPS) and challenges in
ensuring safety and security have led to the increasing use of deep learning
methods for accurate and scalable anomaly detection. However, machine learning
(ML) models often suffer from low performance in predicting unexpected data and
are vulnerable to accidental or malicious perturbations. Although robustness
testing of deep learning models has been extensively explored in applications
such as image classification and speech recognition, less attention has been
paid to ML-driven safety monitoring in CPS. This paper presents the preliminary
results on evaluating the robustness of ML-based anomaly detection methods in
safety-critical CPS against two types of accidental and malicious input
perturbations, generated using a Gaussian-based noise model and the Fast
Gradient Sign Method (FGSM). We test the hypothesis of whether integrating the
domain knowledge (e.g., on unsafe system behavior) with the ML models can
improve the robustness of anomaly detection without sacrificing accuracy and
transparency. Experimental results with two case studies of Artificial Pancreas
Systems (APS) for diabetes management show that ML-based safety monitors
trained with domain knowledge can reduce on average up to 54.2% of robustness
error and keep the average F1 scores high while improving transparency.

### Title: Private measures, random walks, and synthetic data
* Paper ID: 2204.09167v1
* Paper URL: [http://arxiv.org/abs/2204.09167v1](http://arxiv.org/abs/2204.09167v1)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Differential privacy is a mathematical concept that provides an
information-theoretic security guarantee. While differential privacy has
emerged as a de facto standard for guaranteeing privacy in data sharing, the
known mechanisms to achieve it come with some serious limitations. Utility
guarantees are usually provided only for a fixed, a priori specified set of
queries. Moreover, there are no utility guarantees for more complex - but very
common - machine learning tasks such as clustering or classification. In this
paper we overcome some of these limitations. Working with metric privacy, a
powerful generalization of differential privacy, we develop a polynomial-time
algorithm that creates a private measure from a data set. This private measure
allows us to efficiently construct private synthetic data that are accurate for
a wide range of statistical analysis tools. Moreover, we prove an
asymptotically sharp min-max result for private measures and synthetic data for
general compact metric spaces. A key ingredient in our construction is a new
superregular random walk, whose joint distribution of steps is as regular as
that of independent random variables, yet which deviates from the origin
logarithmicaly slowly.

### Title: STPA-driven Multilevel Runtime Monitoring for In-time Hazard Detection
* Paper ID: 2204.08999v2
* Paper URL: [http://arxiv.org/abs/2204.08999v2](http://arxiv.org/abs/2204.08999v2)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: Runtime verification or runtime monitoring equips safety-critical
cyber-physical systems to augment design assurance measures and ensure
operational safety and security. Cyber-physical systems have interaction
failures, attack surfaces, and attack vectors resulting in unanticipated
hazards and loss scenarios. These interaction failures pose challenges to
runtime verification regarding monitoring specifications and monitoring
placements for in-time detection of hazards. We develop a well-formed workflow
model that connects system theoretic process analysis, commonly referred to as
STPA, hazard causation information to lower-level runtime monitoring to detect
hazards at the operational phase. Specifically, our model follows the DepDevOps
paradigm to provide evidence and insights to runtime monitoring on what to
monitor, where to monitor, and the monitoring context. We demonstrate and
evaluate the value of multilevel monitors by injecting hazards on an autonomous
emergency braking system model.

### Title: Audio Deep Fake Detection System with Neural Stitching for ADD 2022
* Paper ID: 2204.08720v2
* Paper URL: [http://arxiv.org/abs/2204.08720v2](http://arxiv.org/abs/2204.08720v2)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: This paper describes our best system and methodology for ADD 2022: The First
Audio Deep Synthesis Detection Challenge\cite{Yi2022ADD}. The very same system
was used for both two rounds of evaluation in Track 3.2 with a similar training
methodology. The first round of Track 3.2 data is generated from
Text-to-Speech(TTS) or voice conversion (VC) algorithms, while the second round
of data consists of generated fake audio from other participants in Track 3.1,
aiming to spoof our systems. Our systems use a standard 34-layer ResNet, with
multi-head attention pooling \cite{india2019self} to learn the discriminative
embedding for fake audio and spoof detection. We further utilize neural
stitching to boost the model's generalization capability in order to perform
equally well in different tasks, and more details will be explained in the
following sessions. The experiments show that our proposed method outperforms
all other systems with a 10.1% equal error rate(EER) in Track 3.2.

### Title: Time Domain Adversarial Voice Conversion for ADD 2022
* Paper ID: 2204.08692v2
* Paper URL: [http://arxiv.org/abs/2204.08692v2](http://arxiv.org/abs/2204.08692v2)
* Updated Date: 2022-04-20
* Code URL: null
* Summary: In this paper, we describe our speech generation system for the first Audio
Deep Synthesis Detection Challenge (ADD 2022). Firstly, we build an any-to-many
voice conversion (VC) system to convert source speech with arbitrary language
content into the target speaker%u2019s fake speech. Then the converted speech
generated from VC is post-processed in the time domain to improve the deception
ability. The experimental results show that our system has adversarial ability
against anti-spoofing detectors with a little compromise in audio quality and
speaker similarity. This system ranks top in Track 3.1 in the ADD 2022, showing
that our method could also gain good generalization ability against different
detectors.

