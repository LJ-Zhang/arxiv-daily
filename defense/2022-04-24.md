### Title: Eliminating Backdoor Triggers for Deep Neural Networks Using Attention Relation Graph Distillation
* Paper ID: 2204.09975v2
* Paper URL: [http://arxiv.org/abs/2204.09975v2](http://arxiv.org/abs/2204.09975v2)
* Updated Date: 2022-04-24
* Code URL: [https://github.com/BililiCode/ARGD](https://github.com/BililiCode/ARGD)
* Summary: Due to the prosperity of Artificial Intelligence (AI) techniques, more and
more backdoors are designed by adversaries to attack Deep Neural Networks
(DNNs).Although the state-of-the-art method Neural Attention Distillation (NAD)
can effectively erase backdoor triggers from DNNs, it still suffers from
non-negligible Attack Success Rate (ASR) together with lowered classification
ACCuracy (ACC), since NAD focuses on backdoor defense using attention features
(i.e., attention maps) of the same order. In this paper, we introduce a novel
backdoor defense framework named Attention Relation Graph Distillation (ARGD),
which fully explores the correlation among attention features with different
orders using our proposed Attention Relation Graphs (ARGs). Based on the
alignment of ARGs between both teacher and student models during knowledge
distillation, ARGD can eradicate more backdoor triggers than NAD. Comprehensive
experimental results show that, against six latest backdoor attacks, ARGD
outperforms NAD by up to 94.85% reduction in ASR, while ACC can be improved by
up to 3.23%.

