### Title: MemFHE: End-to-End Computing with Fully Homomorphic Encryption in Memory
* Paper ID: 2204.12557v1
* Paper URL: [http://arxiv.org/abs/2204.12557v1](http://arxiv.org/abs/2204.12557v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: The increasing amount of data and the growing complexity of problems has
resulted in an ever-growing reliance on cloud computing. However, many
applications, most notably in healthcare, finance or defense, demand security
and privacy which today's solutions cannot fully address. Fully homomorphic
encryption (FHE) elevates the bar of today's solutions by adding
confidentiality of data during processing. It allows computation on fully
encrypted data without the need for decryption, thus fully preserving privacy.
To enable processing encrypted data at usable levels of classic security, e.g.,
128-bit, the encryption procedure introduces noticeable data size expansion -
the ciphertext is much bigger than the native aggregate of native data types.
In this paper, we present MemFHE which is the first accelerator of both client
and server for the latest Ring-GSW (Gentry, Sahai, and Waters) based
homomorphic encryption schemes using Processing In Memory (PIM). PIM alleviates
the data movement issues with large FHE encrypted data, while providing in-situ
execution and extensive parallelism needed for FHE's polynomial operations.
While the client-PIM can homomorphically encrypt and decrypt data, the
server-PIM can process homomorphically encrypted data without decryption.
MemFHE's server-PIM is pipelined and is designed to provide flexible
bootstrapping, allowing two encryption techniques and various FHE
security-levels based on the application requirements. We evaluate MemFHE for
various security-levels and compare it with state-of-the-art CPU
implementations for Ring-GSW based FHE. MemFHE is up to 20kx (265x) faster than
CPU (GPU) for FHE arithmetic operations and provides on average 2007x higher
throughput than the state-of-the-art while implementing neural networks with
FHE.

### Title: Enhancing Privacy against Inversion Attacks in Federated Learning by using Mixing Gradients Strategies
* Paper ID: 2204.12495v1
* Paper URL: [http://arxiv.org/abs/2204.12495v1](http://arxiv.org/abs/2204.12495v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Federated learning reduces the risk of information leakage, but remains
vulnerable to attacks. We investigate how several neural network design
decisions can defend against gradients inversion attacks. We show that
overlapping gradients provides numerical resistance to gradient inversion on
the highly vulnerable dense layer. Specifically, we propose to leverage
batching to maximise mixing of gradients by choosing an appropriate loss
function and drawing identical labels. We show that otherwise it is possible to
directly recover all vectors in a mini-batch without any numerical optimisation
due to the de-mixing nature of the cross entropy loss. To accurately assess
data recovery, we introduce an absolute variation distance (AVD) metric for
information leakage in images, derived from total variation. In contrast to
standard metrics, e.g. Mean Squared Error or Structural Similarity Index, AVD
offers a continuous metric for extracting information in noisy images. Finally,
our empirical results on information recovery from various inversion attacks
and training performance supports our defense strategies. These strategies are
also shown to be useful for deep convolutional neural networks such as LeNET
for image recognition. We hope that this study will help guide the development
of further strategies that achieve a trustful federation policy.

