### Title: Semantics-Depth-Symbiosis: Deeply Coupled Semi-Supervised Learning of Semantics and Depth
* Paper ID: 2206.10562v1
* Paper URL: [http://arxiv.org/abs/2206.10562v1](http://arxiv.org/abs/2206.10562v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Multi-task learning (MTL) paradigm focuses on jointly learning two or more
tasks, aiming for significant improvement w.r.t model's generalizability,
performance, and training/inference memory footprint. The aforementioned
benefits become ever so indispensable in the case of joint training for
vision-related {\bf dense} prediction tasks. In this work, we tackle the MTL
problem of two dense tasks, \ie, semantic segmentation and depth estimation,
and present a novel attention module called Cross-Channel Attention Module
({CCAM}), which facilitates effective feature sharing along each channel
between the two tasks, leading to mutual performance gain with a negligible
increase in trainable parameters. In a true symbiotic spirit, we then formulate
a novel data augmentation for the semantic segmentation task using predicted
depth called {AffineMix}, and a simple depth augmentation using predicted
semantics called {ColorAug}. Finally, we validate the performance gain of the
proposed method on the Cityscapes dataset, which helps us achieve
state-of-the-art results for a semi-supervised joint model based on depth and
semantic segmentation.

### Title: Multi-UAV Planning for Cooperative Wildfire Coverage and Tracking with Quality-of-Service Guarantees
* Paper ID: 2206.10544v1
* Paper URL: [http://arxiv.org/abs/2206.10544v1](http://arxiv.org/abs/2206.10544v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: In recent years, teams of robot and Unmanned Aerial Vehicles (UAVs) have been
commissioned by researchers to enable accurate, online wildfire coverage and
tracking. While the majority of prior work focuses on the coordination and
control of such multi-robot systems, to date, these UAV teams have not been
given the ability to reason about a fire's track (i.e., location and
propagation dynamics) to provide performance guarantee over a time horizon.
Motivated by the problem of aerial wildfire monitoring, we propose a predictive
framework which enables cooperation in multi-UAV teams towards collaborative
field coverage and fire tracking with probabilistic performance guarantee. Our
approach enables UAVs to infer the latent fire propagation dynamics for
time-extended coordination in safety-critical conditions. We derive a set of
novel, analytical temporal, and tracking-error bounds to enable the UAV-team to
distribute their limited resources and cover the entire fire area according to
the case-specific estimated states and provide a probabilistic performance
guarantee. Our results are not limited to the aerial wildfire monitoring
case-study and are generally applicable to problems, such as search-and-rescue,
target tracking and border patrol. We evaluate our approach in simulation and
provide demonstrations of the proposed framework on a physical multi-robot
testbed to account for real robot dynamics and restrictions. Our quantitative
evaluations validate the performance of our method accumulating 7.5x and 9.0x
smaller tracking-error than state-of-the-art model-based and reinforcement
learning benchmarks, respectively.

### Title: Reconfigurable Elastic Metamaterials: Engineering Dispersion with Meccano$^{\text{TM}}$
* Paper ID: 2206.10487v1
* Paper URL: [http://arxiv.org/abs/2206.10487v1](http://arxiv.org/abs/2206.10487v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: We design, simulate and experimentally characterise a reconfigurable elastic
metamaterial with beyond-nearest-neighbour (BNN) coupling. The structure is
composed from the popular British model construction system,
Meccano$^{\text{TM}}$. The Meccano$^{\text{TM}}$ metamaterial supports
backwards waves with opposite directions of phase and group velocities. We
experimentally verify three distinct configurations and acoustically infer
their spatial vibration spectra.

### Title: An Automatic and Efficient BERT Pruning for Edge AI Systems
* Paper ID: 2206.10461v1
* Paper URL: [http://arxiv.org/abs/2206.10461v1](http://arxiv.org/abs/2206.10461v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: With the yearning for deep learning democratization, there are increasing
demands to implement Transformer-based natural language processing (NLP) models
on resource-constrained devices for low-latency and high accuracy. Existing
BERT pruning methods require domain experts to heuristically handcraft
hyperparameters to strike a balance among model size, latency, and accuracy. In
this work, we propose AE-BERT, an automatic and efficient BERT pruning
framework with efficient evaluation to select a "good" sub-network candidate
(with high accuracy) given the overall pruning ratio constraints. Our proposed
method requires no human experts experience and achieves a better accuracy
performance on many NLP tasks. Our experimental results on General Language
Understanding Evaluation (GLUE) benchmark show that AE-BERT outperforms the
state-of-the-art (SOTA) hand-crafted pruning methods on BERT$_{\mathrm{BASE}}$.
On QNLI and RTE, we obtain 75\% and 42.8\% more overall pruning ratio while
achieving higher accuracy. On MRPC, we obtain a 4.6 higher score than the SOTA
at the same overall pruning ratio of 0.5. On STS-B, we can achieve a 40\%
higher pruning ratio with a very small loss in Spearman correlation compared to
SOTA hand-crafted pruning methods. Experimental results also show that after
model compression, the inference time of a single BERT$_{\mathrm{BASE}}$
encoder on Xilinx Alveo U200 FPGA board has a 1.83$\times$ speedup compared to
Intel(R) Xeon(R) Gold 5218 (2.30GHz) CPU, which shows the reasonableness of
deploying the proposed method generated subnets of BERT$_{\mathrm{BASE}}$ model
on computation restricted devices.

### Title: Transformer-Based Multi-modal Proposal and Re-Rank for Wikipedia Image-Caption Matching
* Paper ID: 2206.10436v1
* Paper URL: [http://arxiv.org/abs/2206.10436v1](http://arxiv.org/abs/2206.10436v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: With the increased accessibility of web and online encyclopedias, the amount
of data to manage is constantly increasing. In Wikipedia, for example, there
are millions of pages written in multiple languages. These pages contain images
that often lack the textual context, remaining conceptually floating and
therefore harder to find and manage. In this work, we present the system we
designed for participating in the Wikipedia Image-Caption Matching challenge on
Kaggle, whose objective is to use data associated with images (URLs and visual
data) to find the correct caption among a large pool of available ones. A
system able to perform this task would improve the accessibility and
completeness of multimedia content on large online encyclopedias. Specifically,
we propose a cascade of two models, both powered by the recent Transformer
model, able to efficiently and effectively infer a relevance score between the
query image data and the captions. We verify through extensive experimentation
that the proposed two-model approach is an effective way to handle a large pool
of images and captions while maintaining bounded the overall computational
complexity at inference time. Our approach achieves remarkable results,
obtaining a normalized Discounted Cumulative Gain (nDCG) value of 0.53 on the
private leaderboard of the Kaggle challenge.

### Title: Graphical Join: A New Physical Join Algorithm for RDBMSs
* Paper ID: 2206.10435v1
* Paper URL: [http://arxiv.org/abs/2206.10435v1](http://arxiv.org/abs/2206.10435v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Join operations (especially n-way, many-to-many joins) are known to be time-
and resource-consuming. At large scales, with respect to table and join-result
sizes, current state of the art approaches (including both binary-join plans
which use Nested-loop/Hash/Sort-merge Join algorithms or, alternatively,
worst-case optimal join algorithms (WOJAs)), may even fail to produce any
answer given reasonable resource and time constraints. In this work, we
introduce a new approach for n-way equi-join processing, the Graphical Join
(GJ). The key idea is two-fold: First, to map the physical join computation
problem to PGMs and introduce tweaked inference algorithms which can compute a
Run-Length Encoding (RLE) based join-result summary, entailing all statistics
necessary to materialize the join result. Second, and most importantly, to show
that a join algorithm, like GJ, which produces the above join-result summary
and then desummarizes it, can introduce large performance benefits in time and
space. Comprehensive experimentation is undertaken with join queries from the
JOB, TPCDS, and lastFM datasets, comparing GJ against PostgresQL and MonetDB
and a state of the art WOJA implemented within the Umbra system. The results
for in-memory join computation show performance improvements up to 64X, 388X,
and 6X faster than PostgreSQL, MonetDB and Umbra, respectively. For on-disk
join computation, GJ is faster than PostgreSQL, MonetDB and Umbra by up to
820X, 717X and 165X, respectively. Furthermore, GJ space needs are up to
21,488X, 38,333X, and 78,750X smaller than PostgresQL, MonetDB, and Umbra,
respectively.

### Title: Route to Time and Time to Route: Travel Time Estimation from Sparse Trajectories
* Paper ID: 2206.10418v1
* Paper URL: [http://arxiv.org/abs/2206.10418v1](http://arxiv.org/abs/2206.10418v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Due to the rapid development of Internet of Things (IoT) technologies, many
online web apps (e.g., Google Map and Uber) estimate the travel time of
trajectory data collected by mobile devices. However, in reality, complex
factors, such as network communication and energy constraints, make multiple
trajectories collected at a low sampling rate. In this case, this paper aims to
resolve the problem of travel time estimation (TTE) and route recovery in
sparse scenarios, which often leads to the uncertain label of travel time and
route between continuously sampled GPS points. We formulate this problem as an
inexact supervision problem in which the training data has coarsely grained
labels and jointly solve the tasks of TTE and route recovery. And we argue that
both two tasks are complementary to each other in the model-learning procedure
and hold such a relation: more precise travel time can lead to better inference
for routes, in turn, resulting in a more accurate time estimation). Based on
this assumption, we propose an EM algorithm to alternatively estimate the
travel time of inferred route through weak supervision in E step and retrieve
the route based on estimated travel time in M step for sparse trajectories. We
conducted experiments on three real-world trajectory datasets and demonstrated
the effectiveness of the proposed method.

### Title: Multilayer Block Models for Exploratory Analysis of Computer Event Logs
* Paper ID: 2206.10413v1
* Paper URL: [http://arxiv.org/abs/2206.10413v1](http://arxiv.org/abs/2206.10413v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: We investigate a graph-based approach to exploratory data analysis in the
context of network security monitoring. Given a possibly large batch of event
logs describing ongoing activity, we first represent these events as a
bipartite multiplex graph. We then apply a model-based biclustering algorithm
to extract relevant clusters of entities and interactions between these
clusters, thereby providing a simplified situational picture. We illustrate
this methodology through two case studies addressing network flow records and
authentication logs, respectively. In both cases, the inferred clusters reveal
the functional roles of entities as well as relevant behavioral patterns.
Displaying interactions between these clusters also helps uncover malicious
activity. Our code is available at
https://github.com/cl-anssi/MultilayerBlockModels.

### Title: Parameter estimation for a linear parabolic SPDE model in two space dimensions with a small noise
* Paper ID: 2206.10363v1
* Paper URL: [http://arxiv.org/abs/2206.10363v1](http://arxiv.org/abs/2206.10363v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: We study parameter estimation for a linear parabolic second-order stochastic
partial differential equation (SPDE) in two space dimensions with a small
dispersion parameter using high frequency data with respect to time and space.
We set two types of $Q$-Wiener processes as a driving noise. We provide minimum
contrast estimators of the coefficient parameters of the SPDE appearing in the
coordinate process of the SPDE based on the thinned data in space, and
approximate the coordinate process based on the thinned data in time. Moreover,
we propose an estimator of the drift parameter using the fact that the
coordinate process is the Ornstein-Uhlenbeck process and statistical inference
for diffusion processes with a small noise.

### Title: Deep Active Latent Surfaces for Medical Geometries
* Paper ID: 2206.10241v1
* Paper URL: [http://arxiv.org/abs/2206.10241v1](http://arxiv.org/abs/2206.10241v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Shape priors have long been known to be effective when reconstructing 3D
shapes from noisy or incomplete data. When using a deep-learning based shape
representation, this often involves learning a latent representation, which can
be either in the form of a single global vector or of multiple local ones. The
latter allows more flexibility but is prone to overfitting. In this paper, we
advocate a hybrid approach representing shapes in terms of 3D meshes with a
separate latent vector at each vertex. During training the latent vectors are
constrained to have the same value, which avoids overfitting. For inference,
the latent vectors are updated independently while imposing spatial
regularization constraints. We show that this gives us both flexibility and
generalization capabilities, which we demonstrate on several medical image
processing tasks.

### Title: Topological Inference of the Conley Index
* Paper ID: 2206.10198v1
* Paper URL: [http://arxiv.org/abs/2206.10198v1](http://arxiv.org/abs/2206.10198v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: The Conley index of an isolated invariant set is a fundamental object in the
study of dynamical systems. Here we consider smooth functions on closed
submanifolds of Euclidean space and describe a framework for inferring the
Conley index of any compact, connected isolated critical set of such a function
with high confidence from a sufficiently large finite point sample. The main
construction of this paper is a specific index pair which is local to the
critical set in question. We establish that these index pairs have positive
reach and hence admit a sampling theory for robust homology inference. This
allows us to estimate the Conley index, and as a direct consequence, we are
also able to estimate the Morse index of any critical point of a Morse function
using finitely many local evaluations.

### Title: $L_p$-norm spherical copulas
* Paper ID: 2206.10180v1
* Paper URL: [http://arxiv.org/abs/2206.10180v1](http://arxiv.org/abs/2206.10180v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: In this paper we study $L_p$-norm spherical copulas for arbitrary $p \in
[1,\infty]$ and arbitrary dimensions. The study is motivated by a conjecture
that these distributions lead to a sharp bound for the value of a certain
generalized mean difference. We fully characterize conditions for existence and
uniqueness of $L_p$-norm spherical copulas. Explicit formulas for their
densities and correlation coefficients are derived and the distribution of the
radial part is determined. Moreover, statistical inference and efficient
simulation are considered.

### Title: Efficient Inference of Spatially-varying Gaussian Markov Random Fields with Applications in Gene Regulatory Networks
* Paper ID: 2206.10174v1
* Paper URL: [http://arxiv.org/abs/2206.10174v1](http://arxiv.org/abs/2206.10174v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: In this paper, we study the problem of inferring spatially-varying Gaussian
Markov random fields (SV-GMRF) where the goal is to learn a network of sparse,
context-specific GMRFs representing network relationships between genes. An
important application of SV-GMRFs is in inference of gene regulatory networks
from spatially-resolved transcriptomics datasets. The current work on inference
of SV-GMRFs are based on the regularized maximum likelihood estimation (MLE)
and suffer from overwhelmingly high computational cost due to their highly
nonlinear nature. To alleviate this challenge, we propose a simple and
efficient optimization problem in lieu of MLE that comes equipped with strong
statistical and computational guarantees. Our proposed optimization problem is
extremely efficient in practice: we can solve instances of SV-GMRFs with more
than 2 million variables in less than 2 minutes. We apply the developed
framework to study how gene regulatory networks in Glioblastoma are spatially
rewired within tissue, and identify prominent activity of the transcription
factor HES4 and ribosomal proteins as characterizing the gene expression
network in the tumor peri-vascular niche that is known to harbor treatment
resistant stem cells.

### Title: Statistical inference of lead-lag at various timescales between asynchronous time series from p-values of transfer entropy
* Paper ID: 2206.10173v1
* Paper URL: [http://arxiv.org/abs/2206.10173v1](http://arxiv.org/abs/2206.10173v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Symbolic transfer entropy is a powerful non-parametric tool to detect
lead-lag between time series. Because a closed expression of the distribution
of Transfer Entropy is not known for finite-size samples, statistical testing
is often performed with bootstraps whose slowness prevents the inference of
large lead-lag networks between long time series. On the other hand, the
asymptotic distribution of Transfer Entropy between two time series is known.
In this work, we derive the asymptotic distribution of the test for one time
series having a larger Transfer Entropy than another one on a target time
series. We then measure the convergence speed of both tests in the small sample
size limits via benchmarks. We then introduce Transfer Entropy between
time-shifted time series, which allows to measure the timescale at which
information transfer is maximal and vanishes. We finally apply these methods to
tick-by-tick price changes of several hundreds of stocks, yielding non-trivial
statistically validated networks.

### Title: The Solar Minimum Eclipse of 2019 July 2: II. The First Absolute Brightness Measurements and MHD Model Predictions of Fe X, XI and XIV out to 3.4 Rs
* Paper ID: 2206.10106v1
* Paper URL: [http://arxiv.org/abs/2206.10106v1](http://arxiv.org/abs/2206.10106v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: We present the spatially resolved absolute brightness of the Fe X, Fe XI and
Fe XIV visible coronal emission lines from 1.08 to 3.4 $R_\odot$, observed
during the 2019 July 2 total solar eclipse (TSE). The morphology of the corona
was typical of solar minimum, with a dipole field dominance showcased by large
polar coronal holes and a broad equatorial streamer belt. The Fe XI line is
found to be the brightest, followed by Fe X and Fe XIV (in disk $B_\odot$
units). All lines had brightness variations between streamers and coronal
holes, where Fe XIV exhibited the largest variation. However, Fe X remained
surprisingly uniform with latitude. The Fe line brightnesses are used to infer
the relative ionic abundances and line of sight averaged electron temperature
($T_e$) throughout the corona, yielding values from 1.25 - 1.4 MK in coronal
holes up to 1.65 MK in the core of streamers. The line brightnesses and
inferred $T_e$ values are then quantitatively compared to the PSI
Magnetohydrodynamic model prediction for this TSE. The MHD model predicted the
Fe lines rather well in general, while the forward modeled line ratios slightly
underestimated the observationally inferred $T_e$ within 5 to 10 % averaged
over the entire corona. Larger discrepancies in the polar coronal holes may
point to insufficient heating and/or other limitations in the approach. These
comparisons highlight the importance of TSE observations for constraining
models of the corona and solar wind formation.

### Title: Bypass Network for Semantics Driven Image Paragraph Captioning
* Paper ID: 2206.10059v1
* Paper URL: [http://arxiv.org/abs/2206.10059v1](http://arxiv.org/abs/2206.10059v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Image paragraph captioning aims to describe a given image with a sequence of
coherent sentences. Most existing methods model the coherence through the topic
transition that dynamically infers a topic vector from preceding sentences.
However, these methods still suffer from immediate or delayed repetitions in
generated paragraphs because (i) the entanglement of syntax and semantics
distracts the topic vector from attending pertinent visual regions; (ii) there
are few constraints or rewards for learning long-range transitions. In this
paper, we propose a bypass network that separately models semantics and
linguistic syntax of preceding sentences. Specifically, the proposed model
consists of two main modules, i.e. a topic transition module and a sentence
generation module. The former takes previous semantic vectors as queries and
applies attention mechanism on regional features to acquire the next topic
vector, which reduces immediate repetition by eliminating linguistics. The
latter decodes the topic vector and the preceding syntax state to produce the
following sentence. To further reduce delayed repetition in generated
paragraphs, we devise a replacement-based reward for the REINFORCE training.
Comprehensive experiments on the widely used benchmark demonstrate the
superiority of the proposed model over the state of the art for coherence while
maintaining high accuracy.

