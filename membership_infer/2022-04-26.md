### Title: Zero-Touch Network on Industrial IoT: An End-to-End Machine Learning Approach
* Paper ID: 2204.12605v1
* Paper URL: [http://arxiv.org/abs/2204.12605v1](http://arxiv.org/abs/2204.12605v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Industry 4.0-enabled smart factory is expected to realize the next revolution
for manufacturers. Although artificial intelligence (AI) technologies have
improved productivity, current use cases belong to small-scale and single-task
operations. To unbound the potential of smart factory, this paper develops
zero-touch network systems for intelligent manufacturing and facilitates
distributed AI applications in both training and inferring stages in a
large-scale manner. The open radio access network (O-RAN) architecture is first
introduced for the zero-touch platform to enable globally controlling
communications and computation infrastructure capability in the field. The
designed serverless framework allows intelligent and efficient learning
assignments and resource allocations. Hence, requested learning tasks can be
assigned to appropriate robots, and the underlying infrastructure can be used
to support the learning tasks without expert knowledge. Moreover, due to the
proposed network system's flexibility, powerful AI-enabled networking
algorithms can be utilized to ensure service-level agreements and superior
performances for factory workloads. Finally, three open research directions of
backward compatibility, end-to-end enhancements, and cybersecurity are
discussed for zero-touch smart factory.

### Title: A cloud-cloud collision in Sgr B2? 3D simulations meet SiO observations
* Paper ID: 2204.12603v1
* Paper URL: [http://arxiv.org/abs/2204.12603v1](http://arxiv.org/abs/2204.12603v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: We compare the properties of shocked gas in Sgr B2 with maps obtained from 3D
simulations of a collision between two fractal clouds. In agreement with
$^{13}$CO(1-0) observations, our simulations show that a cloud-cloud collision
produces a region with a highly turbulent density substructure with an average
$N_{\rm H2}\gtrsim 5\times10^{22}\,\rm cm^{-2}$. Similarly, our numerical
multi-channel shock study shows that colliding clouds are efficient at
producing internal shocks with velocities of $5-50\,\rm km\,s^{-1}$ and Mach
numbers of $\sim4-40$, which are needed to explain the $\sim 10^{-9}$ SiO
abundances inferred from our SiO(2-1) IRAM observations of Sgr B2. Overall, we
find that both the density structure and the shocked gas morphology in Sgr B2
are consistent with a $\lesssim 0.5\,\rm Myr$-old cloud-cloud collision.
High-velocity shocks are produced during the early stages of the collision and
can ignite star formation, while moderate- and low-velocity shocks are
important over longer time-scales and can explain the extended SiO emission in
Sgr B2.

### Title: Correcting motion induced fluorescence artifacts in two-channel neural imaging
* Paper ID: 2204.12595v1
* Paper URL: [http://arxiv.org/abs/2204.12595v1](http://arxiv.org/abs/2204.12595v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Imaging neural activity in a behaving animal presents unique challenges in
part because motion from an animal's movement creates artifacts in fluorescence
intensity time-series that are difficult to distinguish from neural signals of
interest. One approach to mitigating these artifacts is to image two channels;
one that captures an activity-dependent fluorophore, such as GCaMP, and another
that captures an activity-independent fluorophore such as RFP. Because the
activity-independent channel contains the same motion artifacts as the
activity-dependent channel, but no neural signals, the two together can be used
to remove the artifacts. Existing approaches for this correction, such as
taking the ratio of the two channels, do not account for channel independent
noise in the measured fluorescence. Moreover, no systematic comparison has been
made of existing approaches that use two-channel signals. Here, we present
Two-channel Motion Artifact Correction (TMAC), a method which seeks to remove
artifacts by specifying a generative model of the fluorescence of the two
channels as a function of motion artifact, neural activity, and noise. We
further present a novel method for evaluating ground-truth performance of
motion correction algorithms by comparing the decodability of behavior from two
types of neural recordings; a recording that had both an activity-dependent
fluorophore (GCaMP and RFP) and a recording where both fluorophores were
activity-independent (GFP and RFP). A successful motion-correction method
should decode behavior from the first type of recording, but not the second. We
use this metric to systematically compare five methods for removing motion
artifacts from fluorescent time traces. We decode locomotion from a GCaMP
expressing animal 15x more accurately on average than from control when using
TMAC inferred activity and outperform all other methods of motion correction
tested.

### Title: AccMPEG: Optimizing Video Encoding for Video Analytics
* Paper ID: 2204.12534v1
* Paper URL: [http://arxiv.org/abs/2204.12534v1](http://arxiv.org/abs/2204.12534v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: With more videos being recorded by edge sensors (cameras) and analyzed by
computer-vision deep neural nets (DNNs), a new breed of video streaming systems
has emerged, with the goal to compress and stream videos to remote servers in
real time while preserving enough information to allow highly accurate
inference by the server-side DNNs. An ideal design of the video streaming
system should simultaneously meet three key requirements: (1) low latency of
encoding and streaming, (2) high accuracy of server-side DNNs, and (3) low
compute overheads on the camera. Unfortunately, despite many recent efforts,
such video streaming system has hitherto been elusive, especially when serving
advanced vision tasks such as object detection or semantic segmentation. This
paper presents AccMPEG, a new video encoding and streaming system that meets
all the three requirements. The key is to learn how much the encoding quality
at each (16x16) macroblock can influence the server-side DNN accuracy, which we
call accuracy gradient. Our insight is that these macroblock-level accuracy
gradient can be inferred with sufficient precision by feeding the video frames
through a cheap model. AccMPEG provides a suite of techniques that, given a new
server-side DNN, can quickly create a cheap model to infer the accuracy
gradient on any new frame in near realtime. Our extensive evaluation of AccMPEG
on two types of edge devices (one Intel Xeon Silver 4100 CPU or NVIDIA Jetson
Nano) and three vision tasks (six recent pre-trained DNNs) shows that AccMPEG
(with the same camera-side compute resources) can reduce the end-to-end
inference delay by 10-43% without hurting accuracy compared to the
state-of-the-art baselines

### Title: Detailed properties of gravitational-wave mergers from flyby perturbations of wide binary black holes in the field
* Paper ID: 2204.12506v1
* Paper URL: [http://arxiv.org/abs/2204.12506v1](http://arxiv.org/abs/2204.12506v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Wide black hole binaries (wide-BBHs; $\geqslant 10^3$ AU) in the field can be
perturbed by random stellar flybys that excite their eccentricities. Once a
wide binary is driven to a sufficiently small pericenter approach,
gravitational wave (GW) emission becomes significant, and the binary inspirals
and merges. In our previous study, using simplified models for wide-BBHs, we
found that successive flybys lead to significant merger fractions of wide-BBHs
in less than Hubble time, making the flyby perturbation mechanism a relevant
contributor to the production rate of GW-sources. However, the exact rates and
detailed properties of the resulting GW sources depend on the wide binary
progenitors. In this paper we use detailed population synthesis models for the
initial wide-BBH population, considering several populations corresponding to
different natal-kick models and metallicities, and then follow the wide-BBHs
evolution due to flyby perturbations and GW-emission. We show that the
cumulative effect of flybys is conductive for the production of GW sources in
non-negligible rates of $1-20$ Gpc$^{-3}$ yr$^{-1}$, which are sensitive to the
natal kicks model. Such rates are relevant to the observationally inferred
rate. Our models, now derived from detailed population of binaries, provide the
detailed properties of the produced GW-sources, including mass-functions and
delay times. The GW mergers are circularized when enter the aLIGO band; have a
preference for high velocity dispersion host galaxies (in particular
ellipticals); have a relatively uniform delay-time distribution; and likely
have mildly correlated (less than isolated evolution channels and more than
dynamical channels) prograde spin-spin and spin-orbits.

### Title: Federated Progressive Sparsification (Purge, Merge, Tune)+
* Paper ID: 2204.12430v1
* Paper URL: [http://arxiv.org/abs/2204.12430v1](http://arxiv.org/abs/2204.12430v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: To improve federated training of neural networks, we develop FedSparsify, a
sparsification strategy based on progressive weight magnitude pruning. Our
method has several benefits. First, since the size of the network becomes
increasingly smaller, computation and communication costs during training are
reduced. Second, the models are incrementally constrained to a smaller set of
parameters, which facilitates alignment/merging of the local models and
improved learning performance at high sparsification rates. Third, the final
sparsified model is significantly smaller, which improves inference efficiency
and optimizes operations latency during encrypted communication. We show
experimentally that FedSparsify learns a subnetwork of both high sparsity and
learning performance. Our sparse models can reach a tenth of the size of the
original model with the same or better accuracy compared to existing pruning
and nonpruning baselines.

### Title: Bifrost: End-to-End Evaluation and Optimization of Reconfigurable DNN Accelerators
* Paper ID: 2204.12418v1
* Paper URL: [http://arxiv.org/abs/2204.12418v1](http://arxiv.org/abs/2204.12418v1)
* Updated Date: 2022-04-26
* Code URL: [https://github.com/giclab/bifrost](https://github.com/giclab/bifrost)
* Summary: Reconfigurable accelerators for deep neural networks (DNNs) promise to
improve performance such as inference latency. STONNE is the first
cycle-accurate simulator for reconfigurable DNN inference accelerators which
allows for the exploration of accelerator designs and configuration space.
However, preparing models for evaluation and exploring configuration space in
STONNE is a manual developer-timeconsuming process, which is a barrier for
research. This paper introduces Bifrost, an end-to-end framework for the
evaluation and optimization of reconfigurable DNN inference accelerators.
Bifrost operates as a frontend for STONNE and leverages the TVM deep learning
compiler stack to parse models and automate offloading of accelerated
computations. We discuss Bifrost's advantages over STONNE and other tools, and
evaluate the MAERI and SIGMA architectures using Bifrost. Additionally, Bifrost
introduces a module leveraging AutoTVM to efficiently explore accelerator
designs and dataflow mapping space to optimize performance. This is
demonstrated by tuning the MAERI architecture and generating efficient dataflow
mappings for AlexNet, obtaining an average speedup of $50\times$ for the
convolutional layers and $11\times$ for the fully connected layers. Our code is
available at www.github.com/gicLAB/bifrost.

### Title: Knowledge Transfer in Engineering Fleets: Hierarchical Bayesian Modelling for Multi-Task Learning
* Paper ID: 2204.12404v1
* Paper URL: [http://arxiv.org/abs/2204.12404v1](http://arxiv.org/abs/2204.12404v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: We propose a population-level analysis to address issues of data sparsity
when building predictive models of engineering infrastructure. By sharing
information between similar assets, hierarchical Bayesian modelling is used to
improve the survival analysis of a truck fleet (hazard curves) and power
prediction in a wind farm (power curves). In each example, a set of correlated
functions are learnt over the asset fleet, in a combined inference, to learn a
population model. Parameter estimation is improved when sub-fleets of assets
are allowed to share correlated information at different levels in the
hierarchy. In turn, groups with incomplete data automatically borrow
statistical strength from those that are data-rich. The correlations can be
inspected to inform which assets share information for which effect (i.e.
parameter).

### Title: Linear-response approach to critical quantum many-body systems
* Paper ID: 2204.12335v1
* Paper URL: [http://arxiv.org/abs/2204.12335v1](http://arxiv.org/abs/2204.12335v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: The characterization of quantum critical phenomena is pivotal for the
understanding and harnessing of quantum many-body physics. However, their
complexity makes the inference of such fundamental processes difficult. Thus,
efficient and experimentally non-demanding methods for their diagnosis are
strongly desired. Here, we introduce a general scheme, based on the combination
of finite-size scaling and the linear response of a given observable to a
time-dependent perturbation, to efficiently extract the energy gaps to the
lowest excited states of the system, and thus infer its dynamical critical
exponents. Remarkably, the scheme is able to tackle both integrable and
non-integrable models, prepared away from their ground states. It thus holds
the potential to embody a valuable diagnostic tool for experimentally
significant problems in quantum many-body physics.

### Title: Designing Perceptual Puzzles by Differentiating Probabilistic Programs
* Paper ID: 2204.12301v1
* Paper URL: [http://arxiv.org/abs/2204.12301v1](http://arxiv.org/abs/2204.12301v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: We design new visual illusions by finding "adversarial examples" for
principled models of human perception -- specifically, for probabilistic
models, which treat vision as Bayesian inference. To perform this search
efficiently, we design a differentiable probabilistic programming language,
whose API exposes MCMC inference as a first-class differentiable function. We
demonstrate our method by automatically creating illusions for three features
of human vision: color constancy, size constancy, and face perception.

### Title: Optimal Network Membership Estimation Under Severe Degree Heterogeneity
* Paper ID: 2204.12087v1
* Paper URL: [http://arxiv.org/abs/2204.12087v1](http://arxiv.org/abs/2204.12087v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Real networks often have severe degree heterogeneity. We are interested in
studying the effect of degree heterogeneity on estimation of the underlying
community structure. We consider the degree-corrected mixed membership model
(DCMM) for a symmetric network with $n$ nodes and $K$ communities, where each
node $i$ has a degree parameter $\theta_i$ and a mixed membership vector
$\pi_i$. The level of degree heterogeneity is captured by $F_n(\cdot)$ -- the
empirical distribution associated with $n$ (scaled) degree parameters. We first
show that the optimal rate of convergence for the $\ell^1$-loss of estimating
$\pi_i$'s depends on an integral with respect to $F_n(\cdot)$. We call a method
$\textit{optimally adaptive to degree heterogeneity}$ (in short, optimally
adaptive) if it attains the optimal rate for arbitrary $F_n(\cdot)$.
Unfortunately, none of the existing methods satisfy this requirement. We
propose a new spectral method that is optimally adaptive, the core idea behind
which is using a pre-PCA normalization to yield the optimal signal-to-noise
ratio simultaneously at all entries of each leading empirical eigenvector. As
one technical contribution, we derive a new row-wise large-deviation bound for
eigenvectors of the regularized graph Laplacian.

### Title: Treating Crowdsourcing as Examination: How to Score Tasks and Online Workers?
* Paper ID: 2204.13065v1
* Paper URL: [http://arxiv.org/abs/2204.13065v1](http://arxiv.org/abs/2204.13065v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Crowdsourcing is an online outsourcing mode which can solve the current
machine learning algorithm's urge need for massive labeled data. Requester
posts tasks on crowdsourcing platforms, which employ online workers over the
Internet to complete tasks, then aggregate and return results to requester. How
to model the interaction between different types of workers and tasks is a hot
spot. In this paper, we try to model workers as four types based on their
ability: expert, normal worker, sloppy worker and spammer, and divide tasks
into hard, medium and easy task according to their difficulty. We believe that
even experts struggle with difficult tasks while sloppy workers can get easy
tasks right, and spammers always give out wrong answers deliberately. So, good
examination tasks should have moderate degree of difficulty and
discriminability to score workers more objectively. Thus, we first score
workers' ability mainly on the medium difficult tasks, then reducing the weight
of answers from sloppy workers and modifying the answers from spammers when
inferring the tasks' ground truth. A probability graph model is adopted to
simulate the task execution process, and an iterative method is adopted to
calculate and update the ground truth, the ability of workers and the
difficulty of the task successively. We verify the rightness and effectiveness
of our algorithm both in simulated and real crowdsourcing scenes.

### Title: Know Thy Student: Interactive Learning with Gaussian Processes
* Paper ID: 2204.12072v1
* Paper URL: [http://arxiv.org/abs/2204.12072v1](http://arxiv.org/abs/2204.12072v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Learning often involves interaction between multiple agents. Human
teacher-student settings best illustrate how interactions result in efficient
knowledge passing where the teacher constructs a curriculum based on their
students' abilities. Prior work in machine teaching studies how the teacher
should construct optimal teaching datasets assuming the teacher knows
everything about the student. However, in the real world, the teacher doesn't
have complete information about the student. The teacher must interact and
diagnose the student, before teaching. Our work proposes a simple diagnosis
algorithm which uses Gaussian processes for inferring student-related
information, before constructing a teaching dataset. We apply this to two
settings. One is where the student learns from scratch and the teacher must
figure out the student's learning algorithm parameters, eg. the regularization
parameters in ridge regression or support vector machines. Two is where the
student has partially explored the environment and the teacher must figure out
the important areas the student has not explored; we study this in the offline
reinforcement learning setting where the teacher must provide demonstrations to
the student and avoid sending redundant trajectories. Our experiments highlight
the importance of diagosing before teaching and demonstrate how students can
learn more efficiently with the help of an interactive teacher. We conclude by
outlining where diagnosing combined with teaching would be more desirable than
passive learning.

### Title: Pretraining Chinese BERT for Detecting Word Insertion and Deletion Errors
* Paper ID: 2204.12052v1
* Paper URL: [http://arxiv.org/abs/2204.12052v1](http://arxiv.org/abs/2204.12052v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Chinese BERT models achieve remarkable progress in dealing with grammatical
errors of word substitution. However, they fail to handle word insertion and
deletion because BERT assumes the existence of a word at each position. To
address this, we present a simple and effective Chinese pretrained model. The
basic idea is to enable the model to determine whether a word exists at a
particular position. We achieve this by introducing a special token
\texttt{[null]}, the prediction of which stands for the non-existence of a
word. In the training stage, we design pretraining tasks such that the model
learns to predict \texttt{[null]} and real words jointly given the surrounding
context. In the inference stage, the model readily detects whether a word
should be inserted or deleted with the standard masked language modeling
function. We further create an evaluation dataset to foster research on word
insertion and deletion. It includes human-annotated corrections for 7,726
erroneous sentences. Results show that existing Chinese BERT performs poorly on
detecting insertion and deletion errors. Our approach significantly improves
the F1 scores from 24.1\% to 78.1\% for word insertion and from 26.5\% to
68.5\% for word deletion, respectively.

### Title: Causal Reasoning with Spatial-temporal Representation Learning: A Prospective Study
* Paper ID: 2204.12037v1
* Paper URL: [http://arxiv.org/abs/2204.12037v1](http://arxiv.org/abs/2204.12037v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Spatial-temporal representation learning is ubiquitous in various real-world
applications, including visual comprehension, video understanding, multi-modal
analysis, human-computer interaction, and urban computing. Due to the emergence
of huge amounts of multi-modal heterogeneous spatial/temporal/spatial-temporal
data in big data era, the existing visual methods rely heavily on large-scale
data annotations and supervised learning to learn a powerful big model.
However, the lack of interpretability, robustness, and out-of-distribution
generalization are becoming the bottleneck problems of these models, which
hinders the progress of interpretable and reliable artificial intelligence. The
majority of the existing methods are based on correlation learning with the
assumption that the data are independent and identically distributed, which
lack an unified guidance and analysis about why modern spatial-temporal
representation learning methods have limited interpretability and easily
collapse into dataset bias. Inspired by the strong inference ability of
human-level agents, recent years have therefore witnessed great effort in
developing causal reasoning paradigms to realize robust representation and
model learning with good interpretability. In this paper, we conduct a
comprehensive review of existing causal reasoning methods for spatial-temporal
representation learning, covering fundamental theories, models, and datasets.
The limitations of current methods and datasets are also discussed. Moreover,
we propose some primary challenges, opportunities, and future research
directions for benchmarking causal reasoning algorithms in spatial-temporal
representation learning.

