### Title: Adaptive Noisy Data Augmentation for Regularized Estimation and Inference in Generalized Linear Models
* Paper ID: 2204.08574v1
* Paper URL: [http://arxiv.org/abs/2204.08574v1](http://arxiv.org/abs/2204.08574v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: We propose the AdaPtive Noise Augmentation (PANDA) procedure to regularize
the estimation and inference of generalized linear models (GLMs). PANDA
iteratively optimizes the objective function given noise augmented data until
convergence to obtain the regularized model estimates. The augmented noises are
designed to achieve various regularization effects, including $l_0$, bridge
(lasso and ridge included), elastic net, adaptive lasso, and SCAD, as well as
group lasso and fused ridge. We examine the tail bound of the noise-augmented
loss function and establish the almost sure convergence of the noise-augmented
loss function and its minimizer to the expected penalized loss function and its
minimizer, respectively. We derive the asymptotic distributions for the
regularized parameters, based on which, inferences can be obtained
simultaneously with variable selection. PANDA exhibits ensemble learning
behaviors that help further decrease the generalization error. Computationally,
PANDA is easy to code, leveraging existing software for implementing GLMs,
without resorting to complicated optimization techniques. We demonstrate the
superior or similar performance of PANDA against the existing approaches of the
same type of regularizers in simulated and real-life data. We show that the
inferences through PANDA achieve nominal or near-nominal coverage and are far
more efficient compared to a popular existing post-selection procedure.

### Title: Imagination-Augmented Natural Language Understanding
* Paper ID: 2204.08535v1
* Paper URL: [http://arxiv.org/abs/2204.08535v1](http://arxiv.org/abs/2204.08535v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Human brains integrate linguistic and perceptual information simultaneously
to understand natural language, and hold the critical ability to render
imaginations. Such abilities enable us to construct new abstract concepts or
concrete objects, and are essential in involving practical knowledge to solve
problems in low-resource scenarios. However, most existing methods for Natural
Language Understanding (NLU) are mainly focused on textual signals. They do not
simulate human visual imagination ability, which hinders models from inferring
and learning efficiently from limited data samples. Therefore, we introduce an
Imagination-Augmented Cross-modal Encoder (iACE) to solve natural language
understanding tasks from a novel learning perspective -- imagination-augmented
cross-modal understanding. iACE enables visual imagination with external
knowledge transferred from the powerful generative and pre-trained
vision-and-language models. Extensive experiments on GLUE and SWAG show that
iACE achieves consistent improvement over visually-supervised pre-trained
models. More importantly, results in extreme and normal few-shot settings
validate the effectiveness of iACE in low-resource natural language
understanding circumstances.

### Title: How large are the monomers of dust aggregates in planet-forming disks?: Insights from quantitative optical and near-infrared polarimetry
* Paper ID: 2204.08506v1
* Paper URL: [http://arxiv.org/abs/2204.08506v1](http://arxiv.org/abs/2204.08506v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Context: The size of the constituent particles (monomers) of dust aggregates
is one of the most uncertain parameters directly affecting collisional growth
of aggregates in planet-forming disks. Despite its importance, the monomer size
has not yet been meaningfully constrained by disk observations. Aims: We
attempt to derive the monomer size from optical and near-infrared (IR)
polarimetric observations of planet-forming disks. Methods: We perform a
comprehensive parameter survey on the degree of linear polarization of light
scattered by dust aggregates, using an exact numerical method called the
$T$-matrix method. We investigate the effect of the monomer size, aggregate
size, porosity, and composition on the degree of polarization. The obtained
results are then compared with observed polarization fractions of several
planet-forming disks at optical and near-IR wavelengths. Results: It is shown
that the degree of polarization of aggregates depends sensitively on the
monomer size unless the monomer size parameter is smaller than one or two.
Comparing the simulation results with the disk observations, we find that the
monomer radius is no greater than $0.4~\mu$m. The inferred monomer size is
therefore similar to subunit sizes of the solar system dust aggregates and the
maximum size of interstellar grains. Conclusions: Optical and near-IR
quantitative polarimetry will provide observational grounds on the initial
conditions for dust coagulation and thereby planetesimal formation in
planet-forming disks.

### Title: Neural Space-filling Curves
* Paper ID: 2204.08453v1
* Paper URL: [http://arxiv.org/abs/2204.08453v1](http://arxiv.org/abs/2204.08453v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: We present Neural Space-filling Curves (SFCs), a data-driven approach to
infer a context-based scan order for a set of images. Linear ordering of pixels
forms the basis for many applications such as video scrambling, compression,
and auto-regressive models that are used in generative modeling for images.
Existing algorithms resort to a fixed scanning algorithm such as Raster scan or
Hilbert scan. Instead, our work learns a spatially coherent linear ordering of
pixels from the dataset of images using a graph-based neural network. The
resulting Neural SFC is optimized for an objective suitable for the downstream
task when the image is traversed along with the scan line order. We show the
advantage of using Neural SFCs in downstream applications such as image
compression. Code and additional results will be made available at
https://hywang66.github.io/publication/neuralsfc.

### Title: Constraining runaway dilaton models using joint gravitational-wave and electromagnetic observations
* Paper ID: 2204.08445v1
* Paper URL: [http://arxiv.org/abs/2204.08445v1](http://arxiv.org/abs/2204.08445v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: With the advent of gravitational-wave astronomy it has now been possible to
constrain modified theories of gravity that were invoked to explain the dark
energy. In a class of dilaton models, distances to cosmic sources inferred from
electromagnetic and gravitational wave observations would differ due to the
presence of a friction term. In such theories, the ratio of the Newton's
constant to the fine structure constant varies with time. In this paper we
explore the degree to which it will be possible to test such models. If
collocated sources (e.g. supernovae and binary neutron star mergers), but not
necessarily multimessengers, can be identified by electromagnetic telescopes
and gravitational-wave detectors one can probe if light and gravitational
radiation are subject to the same laws of propagation over cosmological
distances. This helps in constraining the variation of Newton's constant
relative to fine-structure constant. The next generation of gravitational wave
detectors, such as the Cosmic Explorer and Einstein Telescope, in tandem with
the Vera Rubin Observatory and gamma ray observatories such as the Fermi Space
Observatory will be able to detect or constrain such variations at the level of
a few parts in 100. We apply this method to GW170817 with distances inferred by
the LIGO and Virgo detectors and the observed Kilonova.

### Title: Temporally Efficient Vision Transformer for Video Instance Segmentation
* Paper ID: 2204.08412v1
* Paper URL: [http://arxiv.org/abs/2204.08412v1](http://arxiv.org/abs/2204.08412v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Recently vision transformer has achieved tremendous success on image-level
visual recognition tasks. To effectively and efficiently model the crucial
temporal information within a video clip, we propose a Temporally Efficient
Vision Transformer (TeViT) for video instance segmentation (VIS). Different
from previous transformer-based VIS methods, TeViT is nearly convolution-free,
which contains a transformer backbone and a query-based video instance
segmentation head. In the backbone stage, we propose a nearly parameter-free
messenger shift mechanism for early temporal context fusion. In the head
stages, we propose a parameter-shared spatiotemporal query interaction
mechanism to build the one-to-one correspondence between video instances and
queries. Thus, TeViT fully utilizes both framelevel and instance-level temporal
context information and obtains strong temporal modeling capacity with
negligible extra computational cost. On three widely adopted VIS benchmarks,
i.e., YouTube-VIS-2019, YouTube-VIS-2021, and OVIS, TeViT obtains
state-of-the-art results and maintains high inference speed, e.g., 46.6 AP with
68.9 FPS on YouTube-VIS-2019. Code is available at
https://github.com/hustvl/TeViT.

### Title: Dynamic Network Adaptation at Inference
* Paper ID: 2204.08400v1
* Paper URL: [http://arxiv.org/abs/2204.08400v1](http://arxiv.org/abs/2204.08400v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Machine learning (ML) inference is a real-time workload that must comply with
strict Service Level Objectives (SLOs), including latency and accuracy targets.
Unfortunately, ensuring that SLOs are not violated in inference-serving systems
is challenging due to inherent model accuracy-latency tradeoffs, SLO diversity
across and within application domains, evolution of SLOs over time,
unpredictable query patterns, and co-location interference. In this paper, we
observe that neural networks exhibit high degrees of per-input activation
sparsity during inference. . Thus, we propose SLO-Aware Neural Networks which
dynamically drop out nodes per-inference query, thereby tuning the amount of
computation performed, according to specified SLO optimization targets and
machine utilization. SLO-Aware Neural Networks achieve average speedups of
$1.3-56.7\times$ with little to no accuracy loss (less than 0.3%). When
accuracy constrained, SLO-Aware Neural Networks are able to serve a range of
accuracy targets at low latency with the same trained model. When latency
constrained, SLO-Aware Neural Networks can proactively alleviate latency
degradation from co-location interference while maintaining high accuracy to
meet latency constraints.

### Title: Fast and Memory-Efficient Network Towards Efficient Image Super-Resolution
* Paper ID: 2204.08397v1
* Paper URL: [http://arxiv.org/abs/2204.08397v1](http://arxiv.org/abs/2204.08397v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Runtime and memory consumption are two important aspects for efficient image
super-resolution (EISR) models to be deployed on resource-constrained devices.
Recent advances in EISR exploit distillation and aggregation strategies with
plenty of channel split and concatenation operations to make full use of
limited hierarchical features. In contrast, sequential network operations avoid
frequently accessing preceding states and extra nodes, and thus are beneficial
to reducing the memory consumption and runtime overhead. Following this idea,
we design our lightweight network backbone by mainly stacking multiple highly
optimized convolution and activation layers and decreasing the usage of feature
fusion. We propose a novel sequential attention branch, where every pixel is
assigned an important factor according to local and global contexts, to enhance
high-frequency details. In addition, we tailor the residual block for EISR and
propose an enhanced residual block (ERB) to further accelerate the network
inference. Finally, combining all the above techniques, we construct a fast and
memory-efficient network (FMEN) and its small version FMEN-S, which runs 33%
faster and reduces 74% memory consumption compared with the state-of-the-art
EISR model: E-RFDN, the champion in AIM 2020 efficient super-resolution
challenge. Besides, FMEN-S achieves the lowest memory consumption and the
second shortest runtime in NTIRE 2022 challenge on efficient super-resolution.
Code is available at https://github.com/NJU-Jet/FMEN.

### Title: StableMoE: Stable Routing Strategy for Mixture of Experts
* Paper ID: 2204.08396v1
* Paper URL: [http://arxiv.org/abs/2204.08396v1](http://arxiv.org/abs/2204.08396v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: The Mixture-of-Experts (MoE) technique can scale up the model size of
Transformers with an affordable computational overhead. We point out that
existing learning-to-route MoE methods suffer from the routing fluctuation
issue, i.e., the target expert of the same input may change along with
training, but only one expert will be activated for the input during inference.
The routing fluctuation tends to harm sample efficiency because the same input
updates different experts but only one is finally used. In this paper, we
propose StableMoE with two training stages to address the routing fluctuation
problem. In the first training stage, we learn a balanced and cohesive routing
strategy and distill it into a lightweight router decoupled from the backbone
model. In the second training stage, we utilize the distilled router to
determine the token-to-expert assignment and freeze it for a stable routing
strategy. We validate our method on language modeling and multilingual machine
translation. The results show that StableMoE outperforms existing MoE methods
in terms of both convergence speed and performance.

### Title: Inference for Cluster Randomized Experiments with Non-ignorable Cluster Sizes
* Paper ID: 2204.08356v1
* Paper URL: [http://arxiv.org/abs/2204.08356v1](http://arxiv.org/abs/2204.08356v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: This paper considers the problem of inference in cluster randomized
experiments when cluster sizes are non-ignorable. Here, by a cluster randomized
experiment, we mean one in which treatment is assigned at the level of the
cluster; by non-ignorable cluster sizes we mean that "large" clusters and
"small" clusters may be heterogeneous, and, in particular, the effects of the
treatment may vary across clusters of differing sizes. In order to permit this
sort of flexibility, we consider a sampling framework in which cluster sizes
themselves are random. In this way, our analysis departs from earlier analyses
of cluster randomized experiments in which cluster sizes are treated as
non-random. We distinguish between two different parameters of interest: the
equally-weighted cluster-level average treatment effect, and the size-weighted
cluster-level average treatment effect. For each parameter, we provide methods
for inference in an asymptotic framework where the number of clusters tends to
infinity and treatment is assigned using simple random sampling. We
additionally permit the experimenter to sample only a subset of the units
within each cluster rather than the entire cluster and demonstrate the
implications of such sampling for some commonly used estimators. A small
simulation study shows the practical relevance of our theoretical results.

### Title: Using Statistical Emulation and Knowledge of Grain-Surface Diffusion for Bayesian Inference of Reaction Rate Parameters: An Application to a Glycine Network
* Paper ID: 2204.08347v1
* Paper URL: [http://arxiv.org/abs/2204.08347v1](http://arxiv.org/abs/2204.08347v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: There exists much uncertainty surrounding interstellar grain-surface
chemistry. One of the major reaction mechanisms is grain-surface diffusion for
which the the binding energy parameter for each species needs to be known.
However, these values vary significantly across the literature which can lead
to debate as to whether or not a particular reaction takes place via diffusion.
In this work we employ Bayesian inference to use available ice abundances to
estimate the reaction rates of the reactions in a chemical network that
produces glycine. Using this we estimate the binding energy of a variety of
important species in the network, by assuming that the reactions take place via
diffusion. We use our understanding of the diffusion mechanism to reduce the
dimensionality of the inference problem from 49 to 14, by demonstrating that
reactions can be separated into classes. This dimensionality reduction makes
the problem computationally feasible. A neural network statistical emulator is
used to also help accelerate the Bayesian inference process substantially.
  The binding energies of most of the diffusive species of interest are found
to match some of the disparate literature values, with the exceptions of atomic
and diatomic hydrogen. The discrepancies with these two species are related to
limitations of the physical and chemical model. However, the use of a dummy
reaction of the form H + X -> HX is found to somewhat reduce the discrepancy
with the binding energy of atomic hydrogen. Using the inferred binding energies
in the full gas-grain version of UCLCHEM results in almost all the molecular
abundances being recovered.

### Title: StepGame: A New Benchmark for Robust Multi-Hop Spatial Reasoning in Texts
* Paper ID: 2204.08292v1
* Paper URL: [http://arxiv.org/abs/2204.08292v1](http://arxiv.org/abs/2204.08292v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Inferring spatial relations in natural language is a crucial ability an
intelligent system should possess. The bAbI dataset tries to capture tasks
relevant to this domain (task 17 and 19). However, these tasks have several
limitations. Most importantly, they are limited to fixed expressions, they are
limited in the number of reasoning steps required to solve them, and they fail
to test the robustness of models to input that contains irrelevant or redundant
information. In this paper, we present a new Question-Answering dataset called
StepGame for robust multi-hop spatial reasoning in texts. Our experiments
demonstrate that state-of-the-art models on the bAbI dataset struggle on the
StepGame dataset. Moreover, we propose a Tensor-Product based Memory-Augmented
Neural Network (TP-MANN) specialized for spatial reasoning tasks. Experimental
results on both datasets show that our model outperforms all the baselines with
superior generalization and robustness performance.

### Title: Precursors of fatty alcohols in the ISM: Discovery of n-propanol
* Paper ID: 2204.08267v1
* Paper URL: [http://arxiv.org/abs/2204.08267v1](http://arxiv.org/abs/2204.08267v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Theories on the origins of life propose that early cell membranes were
synthesized from amphiphilic molecules simpler than phospholipids such as fatty
alcohols. The discovery in the interstellar medium (ISM) of ethanolamine, the
simplest phospholipid head group, raises the question whether simple
amphiphilic molecules are also synthesized in space. We investigate whether
precursors of fatty alcohols are present in the ISM. For this, we have carried
out a spectral survey at 7, 3, 2 and 1 mm toward the Giant Molecular Cloud
G+0.693-0.027 located in the Galactic Center using the IRAM 30m and Yebes 40m
telescopes. Here, we report the detection in the ISM of the primary alcohol
n-propanol (in both conformers Ga-n-C3H7OH and Aa-n-C3H7OH), a precursor of
fatty alcohols. The derived column densities of n-propanol are (5.5+-0.4)x10^13
cm^-2 for the Ga conformer and (3.4+-0.3)x10^13 cm^-2 for the Aa conformer,
which imply molecular abundances of (4.1+-0.3)x10^-10 for Ga-n-C3H7OH and of
(2.5+-0.2)x10^-10 for Aa-n-C3H7OH. We also searched for the AGa conformer of
n-butanol (AGa-n-C4H9OH) without success yielding an upper limit to its
abundance of <4.1x10^-11. The inferred CH3OH:C2H5OH:C3H7OH:C4H9OH abundance
ratios go as 1:0.04:0.006:<0.0004 toward G+0.693-0.027, i.e. they decrease
roughly by one order of magnitude for increasing complexity. We also report the
detection of both syn and anti conformers of vinyl alcohol, with column
densities of (1.11+-0.08)x10^14 cm^-2 and (1.3+-0.4)x10^13 cm^-2, and
abundances of (8.2+-0.6)x10^-10 and (9.6+-3.0)x10^-11, respectively. The
detection of n-propanol, together with the recent discovery of ethanolamine in
the ISM, opens the possibility that precursors of lipids according to theories
of the origin of life, could have been brought to Earth from outer space.

### Title: High-resolution ALMA observations of transition disk candidates in Lupus
* Paper ID: 2204.08225v1
* Paper URL: [http://arxiv.org/abs/2204.08225v1](http://arxiv.org/abs/2204.08225v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Transition disks with small inner dust cavities are interesting targets for
the study of disk clearing mechanisms. Such disks have been identified through
a deficit in the infrared part of their SED, but spatially resolved millimeter
imaging is required to confirm the presence of an inner dust cavity. We use
high-resolution ALMA observations of 30 mas resolution in Band 6 continuum and
$^{12}$CO 2--1 emission of 10 transition disk candidates in the Lupus star
forming region, in order to confirm the presence of inner dust cavities and
infer the responsible mechanism. The continuum data are analyzed using
visibility modeling and the SEDs are compared with radiative transfer models.
Out of the six transition disk candidates selected from their SED, only one
disk revealed an inner dust cavity of 4 au in radius. Three of the other disks
are highly inclined, which limits the detectability of an inner dust cavity but
it is also demonstrated to be the possible cause for the infrared deficit in
their SED. The two remaining SED-selected disks are very compact, with dust
radii of only $\sim$3 au. From the four candidates selected from low-resolution
images, three new transition disks with large inner cavities $>$20 au are
identified, bringing the total number of transition disks with large cavities
in Lupus to 13. SED-selected transition disks with small cavities are biased
towards highly inclined and compact disks, which casts doubt on the use of
their occurrence rates in estimating dispersal timescales of photoevaporation.
Using newly derived disk dust masses and radii, we re-evaluate the
size-luminosity and $M_{\rm dust}-M_{\rm star}$ relations. These relations can
be understood if the bright disks are dominated by disks with substructure
whereas faint disks are dominated by drift-dominated disks. (Abridged)

### Title: Sardino: Ultra-Fast Dynamic Ensemble for Secure Visual Sensing at Mobile Edge
* Paper ID: 2204.08189v1
* Paper URL: [http://arxiv.org/abs/2204.08189v1](http://arxiv.org/abs/2204.08189v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Adversarial example attack endangers the mobile edge systems such as vehicles
and drones that adopt deep neural networks for visual sensing. This paper
presents {\em Sardino}, an active and dynamic defense approach that renews the
inference ensemble at run time to develop security against the adaptive
adversary who tries to exfiltrate the ensemble and construct the corresponding
effective adversarial examples. By applying consistency check and data fusion
on the ensemble's predictions, Sardino can detect and thwart adversarial
inputs. Compared with the training-based ensemble renewal, we use HyperNet to
achieve {\em one million times} acceleration and per-frame ensemble renewal
that presents the highest level of difficulty to the prerequisite exfiltration
attacks. Moreover, the robustness of the renewed ensembles against adversarial
examples is enhanced with adversarial learning for the HyperNet. We design a
run-time planner that maximizes the ensemble size in favor of security while
maintaining the processing frame rate. Beyond adversarial examples, Sardino can
also address the issue of out-of-distribution inputs effectively. This paper
presents extensive evaluation of Sardino's performance in counteracting
adversarial examples and applies it to build a real-time car-borne traffic sign
recognition system. Live on-road tests show the built system's effectiveness in
maintaining frame rate and detecting out-of-distribution inputs due to the
false positives of a preceding YOLO-based traffic sign detector.

### Title: Robust End-to-end Speaker Diarization with Generic Neural Clustering
* Paper ID: 2204.08164v1
* Paper URL: [http://arxiv.org/abs/2204.08164v1](http://arxiv.org/abs/2204.08164v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: End-to-end speaker diarization approaches have shown exceptional performance
over the traditional modular approaches. To further improve the performance of
the end-to-end speaker diarization for real speech recordings, recently works
have been proposed which integrate unsupervised clustering algorithms with the
end-to-end neural diarization models. However, these methods have a number of
drawbacks: 1) The unsupervised clustering algorithms cannot leverage the
supervision from the available datasets; 2) The K-means-based unsupervised
algorithms that are explored often suffer from the constraint violation
problem; 3) There is unavoidable mismatch between the supervised training and
the unsupervised inference. In this paper, a robust generic neural clustering
approach is proposed that can be integrated with any chunk-level predictor to
accomplish a fully supervised end-to-end speaker diarization model. Also, by
leveraging the sequence modelling ability of a recurrent neural network, the
proposed neural clustering approach can dynamically estimate the number of
speakers during inference. Experimental show that when integrating an
attractor-based chunk-level predictor, the proposed neural clustering approach
can yield better Diarization Error Rate (DER) than the constrained
K-means-based clustering approaches under the mismatched conditions.

### Title: BSAL: A Framework of Bi-component Structure and Attribute Learning for Link Prediction
* Paper ID: 2204.09508v1
* Paper URL: [http://arxiv.org/abs/2204.09508v1](http://arxiv.org/abs/2204.09508v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Given the ubiquitous existence of graph-structured data, learning the
representations of nodes for the downstream tasks ranging from node
classification, link prediction to graph classification is of crucial
importance. Regarding missing link inference of diverse networks, we revisit
the link prediction techniques and identify the importance of both the
structural and attribute information. However, the available techniques either
heavily count on the network topology which is spurious in practice or cannot
integrate graph topology and features properly. To bridge the gap, we propose a
bicomponent structural and attribute learning framework (BSAL) that is designed
to adaptively leverage information from topology and feature spaces.
Specifically, BSAL constructs a semantic topology via the node attributes and
then gets the embeddings regarding the semantic view, which provides a flexible
and easy-to-implement solution to adaptively incorporate the information
carried by the node attributes. Then the semantic embedding together with
topology embedding is fused together using an attention mechanism for the final
prediction. Extensive experiments show the superior performance of our proposal
and it significantly outperforms baselines on diverse research benchmarks.

