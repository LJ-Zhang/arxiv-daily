### Title: Adversarial Contrastive Learning by Permuting Cluster Assignments
* Paper ID: 2204.10314v1
* Paper URL: [http://arxiv.org/abs/2204.10314v1](http://arxiv.org/abs/2204.10314v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Contrastive learning has gained popularity as an effective self-supervised
representation learning technique. Several research directions improve
traditional contrastive approaches, e.g., prototypical contrastive methods
better capture the semantic similarity among instances and reduce the
computational burden by considering cluster prototypes or cluster assignments,
while adversarial instance-wise contrastive methods improve robustness against
a variety of attacks. To the best of our knowledge, no prior work jointly
considers robustness, cluster-wise semantic similarity and computational
efficiency. In this work, we propose SwARo, an adversarial contrastive
framework that incorporates cluster assignment permutations to generate
representative adversarial samples. We evaluate SwARo on multiple benchmark
datasets and against various white-box and black-box attacks, obtaining
consistent improvements over state-of-the-art baselines.

### Title: A novel two-party semiquantum key distribution protocol based on GHZ-like states
* Paper ID: 2204.10088v1
* Paper URL: [http://arxiv.org/abs/2204.10088v1](http://arxiv.org/abs/2204.10088v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: In this paper, we propose a novel two-party semiquantum key distribution
(SQKD) protocol by only employing one kind of GHZ-like state. The proposed SQKD
protocol can create a private key shared between one quantum party with
unlimited quantum abilities and one classical party with limited quantum
abilities without the existence of a third party. The proposed SQKD protocol
doesn't need the Hadamard gate or quantum entanglement swapping. Detailed
security analysis turns out that the proposed SQKD protocol can resist various
famous attacks from an outside eavesdropper, such as the Trojan horse attacks,
the entangle-measure attack, the double CNOT attacks, the measure-resend attack
and the intercept-resend attack.

### Title: Detecting Topology Attacks against Graph Neural Networks
* Paper ID: 2204.10072v1
* Paper URL: [http://arxiv.org/abs/2204.10072v1](http://arxiv.org/abs/2204.10072v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Graph neural networks (GNNs) have been widely used in many real applications,
and recent studies have revealed their vulnerabilities against topology
attacks. To address this issue, existing efforts have mainly been dedicated to
improving the robustness of GNNs, while little attention has been paid to the
detection of such attacks. In this work, we study the victim node detection
problem under topology attacks against GNNs. Our approach is built upon the key
observation rooted in the intrinsic message passing nature of GNNs. That is,
the neighborhood of a victim node tends to have two competing group forces,
pushing the node classification results towards the original label and the
targeted label, respectively. Based on this observation, we propose to detect
victim nodes by deliberately designing an effective measurement of the
neighborhood variance for each node. Extensive experimental results on four
real-world datasets and five existing topology attacks show the effectiveness
and efficiency of the proposed detection approach.

### Title: Robustness of Machine Learning Models Beyond Adversarial Attacks
* Paper ID: 2204.10046v1
* Paper URL: [http://arxiv.org/abs/2204.10046v1](http://arxiv.org/abs/2204.10046v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Correctly quantifying the robustness of machine learning models is a central
aspect in judging their suitability for specific tasks, and thus, ultimately,
for generating trust in the models. We show that the widely used concept of
adversarial robustness and closely related metrics based on counterfactuals are
not necessarily valid metrics for determining the robustness of ML models
against perturbations that occur "naturally", outside specific adversarial
attack scenarios. Additionally, we argue that generic robustness metrics in
principle are insufficient for determining real-world-robustness. Instead we
propose a flexible approach that models possible perturbations in input data
individually for each application. This is then combined with a probabilistic
approach that computes the likelihood that a real-world perturbation will
change a prediction, thus giving quantitative information of the robustness of
the trained machine learning model. The method does not require access to the
internals of the classifier and thus in principle works for any black-box
model. It is, however, based on Monte-Carlo sampling and thus only suited for
input spaces with small dimensions. We illustrate our approach on two dataset,
as well as on analytically solvable cases. Finally, we discuss ideas on how
real-world robustness could be computed or estimated in high-dimensional input
spaces.

### Title: Is Neuron Coverage Needed to Make Person Detection More Robust?
* Paper ID: 2204.10027v1
* Paper URL: [http://arxiv.org/abs/2204.10027v1](http://arxiv.org/abs/2204.10027v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The growing use of deep neural networks (DNNs) in safety- and
security-critical areas like autonomous driving raises the need for their
systematic testing. Coverage-guided testing (CGT) is an approach that applies
mutation or fuzzing according to a predefined coverage metric to find inputs
that cause misbehavior. With the introduction of a neuron coverage metric, CGT
has also recently been applied to DNNs. In this work, we apply CGT to the task
of person detection in crowded scenes. The proposed pipeline uses YOLOv3 for
person detection and includes finding DNN bugs via sampling and mutation, and
subsequent DNN retraining on the updated training set. To be a bug, we require
a mutated image to cause a significant performance drop compared to a clean
input. In accordance with the CGT, we also consider an additional requirement
of increased coverage in the bug definition. In order to explore several types
of robustness, our approach includes natural image transformations,
corruptions, and adversarial examples generated with the Daedalus attack. The
proposed framework has uncovered several thousand cases of incorrect DNN
behavior. The relative change in mAP performance of the retrained models
reached on average between 26.21\% and 64.24\% for different robustness types.
However, we have found no evidence that the investigated coverage metrics can
be advantageously used to improve robustness.

### Title: Baseline Systems for the First Spoofing-Aware Speaker Verification Challenge: Score and Embedding Fusion
* Paper ID: 2204.09976v1
* Paper URL: [http://arxiv.org/abs/2204.09976v1](http://arxiv.org/abs/2204.09976v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Deep learning has brought impressive progress in the study of both automatic
speaker verification (ASV) and spoofing countermeasures (CM). Although
solutions are mutually dependent, they have typically evolved as standalone
sub-systems whereby CM solutions are usually designed for a fixed ASV system.
The work reported in this paper aims to gauge the improvements in reliability
that can be gained from their closer integration. Results derived using the
popular ASVspoof2019 dataset indicate that the equal error rate (EER) of a
state-of-the-art ASV system degrades from 1.63% to 23.83% when the evaluation
protocol is extended with spoofed trials.%subjected to spoofing attacks.
However, even the straightforward integration of ASV and CM systems in the form
of score-sum and deep neural network-based fusion strategies reduce the EER to
1.71% and 6.37%, respectively. The new Spoofing-Aware Speaker Verification
(SASV) challenge has been formed to encourage greater attention to the
integration of ASV and CM systems as well as to provide a means to benchmark
different solutions.

### Title: Eliminating Backdoor Triggers for Deep Neural Networks Using Attention Relation Graph Distillation
* Paper ID: 2204.09975v1
* Paper URL: [http://arxiv.org/abs/2204.09975v1](http://arxiv.org/abs/2204.09975v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Due to the prosperity of Artificial Intelligence (AI) techniques, more and
more backdoors are designed by adversaries to attack Deep Neural Networks
(DNNs).Although the state-of-the-art method Neural Attention Distillation (NAD)
can effectively erase backdoor triggers from DNNs, it still suffers from
non-negligible Attack Success Rate (ASR) together with lowered classification
ACCuracy (ACC), since NAD focuses on backdoor defense using attention features
(i.e., attention maps) of the same order. In this paper, we introduce a novel
backdoor defense framework named Attention Relation Graph Distillation (ARGD),
which fully explores the correlation among attention features with different
orders using our proposed Attention Relation Graphs (ARGs). Based on the
alignment of ARGs between both teacher and student models during knowledge
distillation, ARGD can eradicate more backdoor triggers than NAD. Comprehensive
experimental results show that, against six latest backdoor attacks, ARGD
outperforms NAD by up to 94.85% reduction in ASR, while ACC can be improved by
up to 3.23%.

### Title: Hybrid Cloud-Edge Collaborative Data Anomaly Detection in Industrial Sensor Networks
* Paper ID: 2204.09942v1
* Paper URL: [http://arxiv.org/abs/2204.09942v1](http://arxiv.org/abs/2204.09942v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Industrial control systems (ICSs) are facing increasing cyber-physical
attacks that can cause catastrophes in the physical system. Efficient anomaly
detection models in the industrial sensor networks are essential for enhancing
ICS reliability and security, due to the sensor data is related to the
operational state of the ICS. Considering the limited availability of computing
resources, this paper proposes a hybrid anomaly detection approach in
cloud-edge collaboration industrial sensor networks. The hybrid approach
consists of sensor data detection models deployed at the edges and a sensor
data analysis model deployed in the cloud. The sensor data detection model
based on Gaussian and Bayesian algorithms can detect the anomalous sensor data
in real-time and upload them to the cloud for further analysis, filtering the
normal sensor data and reducing traffic load. The sensor data analysis model
based on Graph convolutional network, Residual algorithm and Long short-term
memory network (GCRL) can effectively extract the spatial and temporal features
and then identify the attack precisely. The proposed hybrid anomaly detection
approach is evaluated using a benchmark dataset and baseline anomaly detection
models. The experimental results show that the proposed approach can achieve an
overall 11.19% increase in Recall and an impressive 14.29% improvement in
F1-score, compared with the existing models.

### Title: Fast AdvProp
* Paper ID: 2204.09838v1
* Paper URL: [http://arxiv.org/abs/2204.09838v1](http://arxiv.org/abs/2204.09838v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/meijieru/fast_advprop](https://github.com/meijieru/fast_advprop)
* Summary: Adversarial Propagation (AdvProp) is an effective way to improve recognition
models, leveraging adversarial examples. Nonetheless, AdvProp suffers from the
extremely slow training speed, mainly because: a) extra forward and backward
passes are required for generating adversarial examples; b) both original
samples and their adversarial counterparts are used for training (i.e.,
2$\times$ data). In this paper, we introduce Fast AdvProp, which aggressively
revamps AdvProp's costly training components, rendering the method nearly as
cheap as the vanilla training. Specifically, our modifications in Fast AdvProp
are guided by the hypothesis that disentangled learning with adversarial
examples is the key for performance improvements, while other training recipes
(e.g., paired clean and adversarial training samples, multi-step adversarial
attackers) could be largely simplified.
  Our empirical results show that, compared to the vanilla training baseline,
Fast AdvProp is able to further model performance on a spectrum of visual
benchmarks, without incurring extra training cost. Additionally, our ablations
find Fast AdvProp scales better if larger models are used, is compatible with
existing data augmentation methods (i.e., Mixup and CutMix), and can be easily
adapted to other recognition tasks like object detection. The code is available
here: https://github.com/meijieru/fast_advprop.

### Title: An Information-theoretical Secured Byzantine-fault Tolerance Consensus in Quantum Key Distribution Network
* Paper ID: 2204.09832v1
* Paper URL: [http://arxiv.org/abs/2204.09832v1](http://arxiv.org/abs/2204.09832v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Quantum key distribution (QKD) networks is expected to provide
information-theoretical secured (ITS) communication over long distances. QKD
networks based trusted relay architecture are now the most widely used scheme
in practice. However, it is an unrealistic assumption that all relays are fully
trustable in complex networks. In the past, only a few studies have
theoretically analyzed the case of passive eavesdropping attack by dishonest
relays and corresponding defense method. However, we have found that active
attacks by dishonest relays can be more threatening. With the consideration of
passive and active attacks, we treat dishonest relays as Byzantine nodes and
analyzes the upper limit of Byzantine nodes that the QKD network can
accommodate. In this paper, we propose an ITS Byzantine-fault tolerance (BFT)
QKD network scheme to achieve end-to-end key distribution based on
point-to-point QKD links. To ensure consistency and provide BFT ability in the
QKD network, we design an ITSBFT-consensus protocol for this network scheme. To
ensure the information-theoretic security of consensus, we design a temporary
signature scheme based on point-to-point QKD link keys. To prevent Byzantine
nodes from disrupting the execution process of key distribution, we design an
end-to-end key distribution scheme combined with consensus. We theoretically
analyze proposed ITSBFT-QKD network scheme from four aspects: QKD key
distribution security, temporary signature security, consensus security, and
leader election fairness. The simulation result proved the feasibility and
demonstrate the performance.

### Title: Block Hunter: Federated Learning for Cyber Threat Hunting in Blockchain-based IIoT Networks
* Paper ID: 2204.09829v1
* Paper URL: [http://arxiv.org/abs/2204.09829v1](http://arxiv.org/abs/2204.09829v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Nowadays, blockchain-based technologies are being developed in various
industries to improve data security. In the context of the Industrial Internet
of Things (IIoT), a chain-based network is one of the most notable applications
of blockchain technology. IIoT devices have become increasingly prevalent in
our digital world, especially in support of developing smart factories.
Although blockchain is a powerful tool, it is vulnerable to cyber attacks.
Detecting anomalies in blockchain-based IIoT networks in smart factories is
crucial in protecting networks and systems from unexpected attacks. In this
paper, we use Federated Learning (FL) to build a threat hunting framework
called Block Hunter to automatically hunt for attacks in blockchain-based IIoT
networks. Block Hunter utilizes a cluster-based architecture for anomaly
detection combined with several machine learning models in a federated
environment. To the best of our knowledge, Block Hunter is the first federated
threat hunting model in IIoT networks that identifies anomalous behavior while
preserving privacy. Our results prove the efficiency of the Block Hunter in
detecting anomalous activities with high accuracy and minimum required
bandwidth.

