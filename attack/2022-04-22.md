### Title: Noncooperative Herding With Control Barrier Functions: Theory and Experiments
* Paper ID: 2204.10945v1
* Paper URL: [http://arxiv.org/abs/2204.10945v1](http://arxiv.org/abs/2204.10945v1)
* Updated Date: 2022-04-22
* Code URL: null
* Summary: In this paper, we consider the problem of protecting a high-value unit from
inadvertent attack by a group of agents using defending robots. Specifically,
we develop a control strategy for the defending agents that we call "dog
robots" to prevent a flock of "sheep agents" from breaching a protected zone.
We take recourse to control barrier functions to pose this problem and exploit
the interaction dynamics between the sheep and dogs to find dogs' velocities
that result in the sheep getting repelled from the zone. We solve a QP
reactively that incorporates the defending constraints to compute the desired
velocities for all dogs. Owing to this, our proposed framework is composable
\textit{i.e.} it allows for simultaneous inclusion of multiple protected zones
in the constraints on dog robots' velocities. We provide a theoretical proof of
feasibility of our strategy for the one dog/one sheep case. Additionally, we
provide empirical results of two dogs defending the protected zone from upto
ten sheep averaged over a hundred simulations and report high success rates. We
also demonstrate this algorithm experimentally on non-holonomic robots. Videos
of these results are available at https://tinyurl.com/4dj2kjwx.

### Title: Baxos: Backing off for Robust and Efficient Consensus
* Paper ID: 2204.10934v1
* Paper URL: [http://arxiv.org/abs/2204.10934v1](http://arxiv.org/abs/2204.10934v1)
* Updated Date: 2022-04-22
* Code URL: null
* Summary: Leader-based consensus algorithms are vulnerable to liveness and performance
downgrade attacks. We explore the possibility of replacing leader election in
Multi-Paxos with random exponential backoff (REB), a simpler approach that
requires minimum modifications to the two phase Synod Paxos and achieves better
resiliency under attacks. We propose Baxos, a new resilient consensus protocol
that leverages a random exponential backoff scheme as a replacement for leader
election in consensus algorithms. Our backoff scheme addresses the common
challenges of random exponential backoff such as scalability and robustness to
changing wide area latency. We extensively evaluate Baxos to illustrate its
performance and robustness against two liveness and performance downgrade
attacks using an implementation running on Amazon EC2 in a wide area network
and a combination of a micro benchmark and YCSB-A workload on Redis. Our
results show that Baxos offers more robustness to liveness and performance
downgrade attacks than leader-based consensus protocols. Baxos outperforms
Multi-Paxos and Raft up to 185% in throughput under liveness and performance
downgrade attacks under worst case contention scenarios where each replica
proposes requests concurrently while only incurring a 7% reduction on the
maximum throughput in the synchronous attack-free scenario.

### Title: A Tale of Two Models: Constructing Evasive Attacks on Edge Models
* Paper ID: 2204.10933v1
* Paper URL: [http://arxiv.org/abs/2204.10933v1](http://arxiv.org/abs/2204.10933v1)
* Updated Date: 2022-04-22
* Code URL: null
* Summary: Full-precision deep learning models are typically too large or costly to
deploy on edge devices. To accommodate to the limited hardware resources,
models are adapted to the edge using various edge-adaptation techniques, such
as quantization and pruning. While such techniques may have a negligible impact
on top-line accuracy, the adapted models exhibit subtle differences in output
compared to the original model from which they are derived. In this paper, we
introduce a new evasive attack, DIVA, that exploits these differences in edge
adaptation, by adding adversarial noise to input data that maximizes the output
difference between the original and adapted model. Such an attack is
particularly dangerous, because the malicious input will trick the adapted
model running on the edge, but will be virtually undetectable by the original
model, which typically serves as the authoritative model version, used for
validation, debugging and retraining. We compare DIVA to a state-of-the-art
attack, PGD, and show that DIVA is only 1.7-3.6% worse on attacking the adapted
model but 1.9-4.2 times more likely not to be detected by the the original
model under a whitebox and semi-blackbox setting, compared to PGD.

### Title: How Sampling Impacts the Robustness of Stochastic Neural Networks
* Paper ID: 2204.10839v1
* Paper URL: [http://arxiv.org/abs/2204.10839v1](http://arxiv.org/abs/2204.10839v1)
* Updated Date: 2022-04-22
* Code URL: null
* Summary: Stochastic neural networks (SNNs) are random functions and predictions are
gained by averaging over multiple realizations of this random function.
Consequently, an adversarial attack is calculated based on one set of samples
and applied to the prediction defined by another set of samples. In this paper
we analyze robustness in this setting by deriving a sufficient condition for
the given prediction process to be robust against the calculated attack. This
allows us to identify the factors that lead to an increased robustness of SNNs
and helps to explain the impact of the variance and the amount of samples.
Among other things, our theoretical analysis gives insights into (i) why
increasing the amount of samples drawn for the estimation of adversarial
examples increases the attack's strength, (ii) why decreasing sample size
during inference hardly influences the robustness, and (iii) why a higher
prediction variance between realizations relates to a higher robustness. We
verify the validity of our theoretical findings by an extensive empirical
analysis.

### Title: Unknown Face Presentation Attack Detection via Localised Learning of Multiple Kernels
* Paper ID: 2204.10675v1
* Paper URL: [http://arxiv.org/abs/2204.10675v1](http://arxiv.org/abs/2204.10675v1)
* Updated Date: 2022-04-22
* Code URL: null
* Summary: The paper studies face spoofing, a.k.a. presentation attack detection (PAD)
in the demanding scenarios of unknown types of attack. While earlier studies
have revealed the benefits of ensemble methods, and in particular, a multiple
kernel learning approach to the problem, one limitation of such techniques is
that they typically treat the entire observation space similarly and ignore any
variability and local structure inherent to the data. This work studies this
aspect of the face presentation attack detection problem in relation to
multiple kernel learning in a one-class setting to benefit from intrinsic local
structure in bona fide face samples. More concretely, inspired by the success
of the one-class Fisher null formalism, we formulate a convex localised
multiple kernel learning algorithm by imposing a joint matrix-norm constraint
on the collection of local kernel weights and infer locally adaptive weights
for zero-shot one-class unseen attack detection.
  We present a theoretical study of the proposed localised MKL algorithm using
Rademacher complexities to characterise its generalisation capability and
demonstrate the advantages of the proposed technique over some other options.
An assessment of the proposed approach on general object image datasets
illustrates its efficacy for abnormality and novelty detection while the
results of the experiments on face PAD datasets verifies its potential in
detecting unknown/unseen face presentation attacks.

### Title: Enhancing the Transferability via Feature-Momentum Adversarial Attack
* Paper ID: 2204.10606v1
* Paper URL: [http://arxiv.org/abs/2204.10606v1](http://arxiv.org/abs/2204.10606v1)
* Updated Date: 2022-04-22
* Code URL: null
* Summary: Transferable adversarial attack has drawn increasing attention due to their
practical threaten to real-world applications. In particular, the feature-level
adversarial attack is one recent branch that can enhance the transferability
via disturbing the intermediate features. The existing methods usually create a
guidance map for features, where the value indicates the importance of the
corresponding feature element and then employs an iterative algorithm to
disrupt the features accordingly. However, the guidance map is fixed in
existing methods, which can not consistently reflect the behavior of networks
as the image is changed during iteration. In this paper, we describe a new
method called Feature-Momentum Adversarial Attack (FMAA) to further improve
transferability. The key idea of our method is that we estimate a guidance map
dynamically at each iteration using momentum to effectively disturb the
category-relevant features. Extensive experiments demonstrate that our method
significantly outperforms other state-of-the-art methods by a large margin on
different target models.

### Title: BliMe: Verifiably Secure Outsourced Computation with Hardware-Enforced Taint Tracking
* Paper ID: 2204.09649v2
* Paper URL: [http://arxiv.org/abs/2204.09649v2](http://arxiv.org/abs/2204.09649v2)
* Updated Date: 2022-04-22
* Code URL: null
* Summary: We present Blinded Memory (BliMe), a way to realize efficient and secure
outsourced computation. BliMe consists of a novel and minimal set of ISA
extensions that uses taint tracking to ensure the confidentiality of sensitive
(client) data even in the presence of server malware, run-time attacks, and
side-channel attacks.
  To secure outsourced computation, the BliMe extensions can be used together
with an attestable, fixed-function trusted execution environment (TEE) and an
encryption engine that provides atomic decrypt-and-taint and
encrypt-and-untaint operations. The TEE engages in an attestation and key
agreement protocol with the client. It provides the resulting client-specific
keys to the encryption engine. Clients rely on remote attestation to ensure
that their data will always be protected by BliMe's taint tracking policy after
decryption.
  We provide a machine-checked security proof and an FPGA implementation
(BliMe-Ibex) of BliMe's taint tracking policy. We show that BliMe-Ibex does not
reduce performance relative to the unmodified core, and incurs only minor
increases in resource consumption in terms of power (${\approx}2.1\%$), LUTs
(${\approx}1.0\%$), and registers (${\approx}2.3\%$).

