### Title: Securing the Future Internet of Things with Post-Quantum Cryptography
* Paper ID: 2206.10473v1
* Paper URL: [http://arxiv.org/abs/2206.10473v1](http://arxiv.org/abs/2206.10473v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Traditional and lightweight cryptography primitives and protocols are
insecure against quantum attacks. Thus, a real-time application using
traditional or lightweight cryptography primitives and protocols does not
ensure full-proof security. Post-quantum Cryptography is important for the
Internet of Things (IoT) due to its security against Quantum attacks. This
paper offers a broad literature analysis of post-quantum cryptography for IoT
networks, including the challenges and research directions to adopt in
real-time applications. The work draws focus towards post-quantum cryptosystems
that are useful for resource-constraint devices. Further, those quantum attacks
are surveyed, which may occur over traditional and lightweight cryptographic
primitives.

### Title: The Privacy Onion Effect: Memorization is Relative
* Paper ID: 2206.10469v1
* Paper URL: [http://arxiv.org/abs/2206.10469v1](http://arxiv.org/abs/2206.10469v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Machine learning models trained on private datasets have been shown to leak
their private data. While recent work has found that the average data point is
rarely leaked, the outlier samples are frequently subject to memorization and,
consequently, privacy leakage. We demonstrate and analyse an Onion Effect of
memorization: removing the "layer" of outlier points that are most vulnerable
to a privacy attack exposes a new layer of previously-safe points to the same
attack. We perform several experiments to study this effect, and understand why
it occurs. The existence of this effect has various consequences. For example,
it suggests that proposals to defend against memorization without training with
rigorous privacy guarantees are unlikely to be effective. Further, it suggests
that privacy-enhancing technologies such as machine unlearning could actually
harm the privacy of other users.

### Title: Using EBGAN for Anomaly Intrusion Detection
* Paper ID: 2206.10400v1
* Paper URL: [http://arxiv.org/abs/2206.10400v1](http://arxiv.org/abs/2206.10400v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: As an active network security protection scheme, intrusion detection system
(IDS) undertakes the important responsibility of detecting network attacks in
the form of malicious network traffic. Intrusion detection technology is an
important part of IDS. At present, many scholars have carried out extensive
research on intrusion detection technology. However, developing an efficient
intrusion detection method for massive network traffic data is still difficult.
Since Generative Adversarial Networks (GANs) have powerful modeling
capabilities for complex high-dimensional data, they provide new ideas for
addressing this problem. In this paper, we put forward an EBGAN-based intrusion
detection method, IDS-EBGAN, that classifies network records as normal traffic
or malicious traffic. The generator in IDS-EBGAN is responsible for converting
the original malicious network traffic in the training set into adversarial
malicious examples. This is because we want to use adversarial learning to
improve the ability of discriminator to detect malicious traffic. At the same
time, the discriminator adopts Autoencoder model. During testing, IDS-EBGAN
uses reconstruction error of discriminator to classify traffic records.

### Title: Identification of Attack Paths Using Kill Chain and Attack Graphs
* Paper ID: 2206.10272v1
* Paper URL: [http://arxiv.org/abs/2206.10272v1](http://arxiv.org/abs/2206.10272v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: The ever-evolving capabilities of cyber attackers force security
administrators to focus on the early identification of emerging threats.
Targeted cyber attacks usually consist of several phases, from initial
reconnaissance of the network environment to final impact on objectives. This
paper investigates the identification of multi-step cyber threat scenarios
using kill chain and attack graphs. Kill chain and attack graphs are threat
modeling concepts that enable determining weak security defense points. We
propose a novel kill chain attack graph that merges kill chain and attack
graphs together. This approach determines possible chains of attacker's actions
and their materialization within the protected network. The graph generation
uses a categorization of threats according to violated security properties. The
graph allows determining the kill chain phase the administrator should focus on
and applicable countermeasures to mitigate possible cyber threats. We
implemented the proposed approach for a predefined range of cyber threats,
especially vulnerability exploitation and network threats. The approach was
validated on a real-world use case. Publicly available implementation contains
a proof-of-concept kill chain attack graph generator.

### Title: Certifiably Robust Policy Learning against Adversarial Communication in Multi-agent Systems
* Paper ID: 2206.10158v1
* Paper URL: [http://arxiv.org/abs/2206.10158v1](http://arxiv.org/abs/2206.10158v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Communication is important in many multi-agent reinforcement learning (MARL)
problems for agents to share information and make good decisions. However, when
deploying trained communicative agents in a real-world application where noise
and potential attackers exist, the safety of communication-based policies
becomes a severe issue that is underexplored. Specifically, if communication
messages are manipulated by malicious attackers, agents relying on
untrustworthy communication may take unsafe actions that lead to catastrophic
consequences. Therefore, it is crucial to ensure that agents will not be misled
by corrupted communication, while still benefiting from benign communication.
In this work, we consider an environment with $N$ agents, where the attacker
may arbitrarily change the communication from any $C<\frac{N-1}{2}$ agents to a
victim agent. For this strong threat model, we propose a certifiable defense by
constructing a message-ensemble policy that aggregates multiple randomly
ablated message sets. Theoretical analysis shows that this message-ensemble
policy can utilize benign communication while being certifiably robust to
adversarial communication, regardless of the attacking algorithm. Experiments
in multiple environments verify that our defense significantly improves the
robustness of trained policies against various types of attacks.

### Title: ProML: A Decentralised Platform for Provenance Management of Machine Learning Software Systems
* Paper ID: 2206.10110v1
* Paper URL: [http://arxiv.org/abs/2206.10110v1](http://arxiv.org/abs/2206.10110v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Large-scale Machine Learning (ML) based Software Systems are increasingly
developed by distributed teams situated in different trust domains. Insider
threats can launch attacks from any domain to compromise ML assets (models and
datasets). Therefore, practitioners require information about how and by whom
ML assets were developed to assess their quality attributes such as security,
safety, and fairness. Unfortunately, it is challenging for ML teams to access
and reconstruct such historical information of ML assets (ML provenance)
because it is generally fragmented across distributed ML teams and threatened
by the same adversaries that attack ML assets. This paper proposes ProML, a
decentralised platform that leverages blockchain and smart contracts to empower
distributed ML teams to jointly manage a single source of truth about
circulated ML assets' provenance without relying on a third party, which is
vulnerable to insider threats and presents a single point of failure. We
propose a novel architectural approach called Artefact-as-a-State-Machine to
leverage blockchain transactions and smart contracts for managing ML provenance
information and introduce a user-driven provenance capturing mechanism to
integrate existing scripts and tools to ProML without compromising
participants' control over their assets and toolchains. We evaluate the
performance and overheads of ProML by benchmarking a proof-of-concept system on
a global blockchain. Furthermore, we assessed ProML's security against a threat
model of a distributed ML workflow.

### Title: Mechanism Design Approaches to Blockchain Consensus
* Paper ID: 2206.10065v1
* Paper URL: [http://arxiv.org/abs/2206.10065v1](http://arxiv.org/abs/2206.10065v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Blockchain consensus is a state whereby each node in a network agrees on the
current state of the blockchain. Existing protocols achieve consensus via a
contest or voting procedure to select one node as a dictator to propose new
blocks. However, this procedure can still lead to potential attacks that make
consensus harder to achieve or lead to coordination issues if multiple,
competing chains (i.e., forks) are created with the potential that an
untruthful fork might be selected. We explore the potential for mechanisms to
be used to achieve consensus that are triggered when there is a dispute
impeding consensus. Using the feature that nodes stake tokens in proof of stake
(POS) protocols, we construct revelation mechanisms in which the unique
(subgame perfect) equilibrium involves validating nodes propose truthful blocks
using only the information that exists amongst all nodes. We construct
operationally and computationally simple mechanisms under both Byzantine Fault
Tolerance and a Longest Chain Rule, and discuss their robustness to attacks.
Our perspective is that the use of simple mechanisms is an unexplored area of
blockchain consensus and has the potential to mitigate known trade-offs and
enhance scalability.

