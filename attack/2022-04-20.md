# attack

## 04-20

### Title: Cascading traffic jamming in a two-dimensional Motter and Lai model
* Paper ID: 2204.09011v1
* Paper URL: [http://arxiv.org/abs/2204.09011v1](http://arxiv.org/abs/2204.09011v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: We study the cascading traffic jamming on a two-dimensional random geometric
graph using the Motter and Lai model. The traffic jam is caused by a localized
attack incapacitating circular region or a line of a certain size, as well as a
dispersed attack on an equal number of randomly selected nodes. We investigate
if there is a critical size of the attack above which the network becomes
completely jammed due to cascading jamming, and how this critical size depends
on the average degree $\langle k\rangle$ of the graph, on the number of nodes
$N$ in the system, and the tolerance parameter $\alpha$ of the Motter and Lai
model.

### Title: STPA-driven Multilevel Runtime Monitoring for In-time Hazard Detection
* Paper ID: 2204.08999v1
* Paper URL: [http://arxiv.org/abs/2204.08999v1](http://arxiv.org/abs/2204.08999v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Runtime verification or runtime monitoring equips safety-critical
cyber-physical systems to augment design assurance measures and ensure
operational safety and security. Cyber-physical systems have interaction
failures, attack surfaces, and attack vectors resulting in unanticipated
hazards and loss scenarios. These interaction failures pose challenges to
runtime verification regarding monitoring specifications and monitoring
placements for in-time detection of hazards. We develop a well-formed workflow
model that connects system theoretic process analysis, commonly referred to as
STPA, hazard causation information to lower-level runtime monitoring to detect
hazards at the operational phase. Specifically, our model follows the DepDevOps
paradigm to provide evidence and insights to runtime monitoring on what to
monitor, where to monitor, and the monitoring context. We demonstrate and
evaluate the value of multilevel monitors by injecting hazards on an autonomous
emergency braking system model.

### Title: Disappeared Command: Spoofing Attack On Automatic Speech Recognition Systems with Sound Masking
* Paper ID: 2204.08977v1
* Paper URL: [http://arxiv.org/abs/2204.08977v1](http://arxiv.org/abs/2204.08977v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: The development of deep learning technology has greatly promoted the
performance improvement of automatic speech recognition (ASR) technology, which
has demonstrated an ability comparable to human hearing in many tasks. Voice
interfaces are becoming more and more widely used as input for many
applications and smart devices. However, existing research has shown that DNN
is easily disturbed by slight disturbances and makes false recognition, which
is extremely dangerous for intelligent voice applications controlled by voice.

### Title: Seculator: A Fast and Secure Neural Processing Unit
* Paper ID: 2204.08951v1
* Paper URL: [http://arxiv.org/abs/2204.08951v1](http://arxiv.org/abs/2204.08951v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Securing deep neural networks (DNNs) is a problem of significant interest
since an ML model incorporates high-quality intellectual property, features of
data sets painstakingly collated by mechanical turks, and novel methods of
training on large cluster computers. Sadly, attacks to extract model parameters
are on the rise, and thus designers are being forced to create architectures
for securing such models. State-of-the-art proposals in this field take the
deterministic memory access patterns of such networks into cognizance (albeit
partially), group a set of memory blocks into a tile, and maintain state at the
level of tiles (to reduce storage space). For providing integrity guarantees
(tamper avoidance), they don't propose any significant optimizations, and still
maintain block-level state.
  We observe that it is possible to exploit the deterministic memory access
patterns of DNNs even further, and maintain state information for only the
current tile and current layer, which may comprise a large number of tiles.
This reduces the storage space, reduces the number of memory accesses,
increases performance, and simplifies the design without sacrificing any
security guarantees. The key techniques in our proposed accelerator
architecture, Seculator, are to encode memory access patterns to create a small
HW-based tile version number generator for a given layer, and to store
layer-level MACs. We completely eliminate the need for having a MAC cache and a
tile version number store (as used in related work). We show that using
intelligently-designed mathematical operations, these structures are not
required. By reducing such overheads, we show a speedup of 16% over the closest
competing work.

### Title: Model Checking Strategic Abilities in Information-sharing Systems
* Paper ID: 2204.08896v1
* Paper URL: [http://arxiv.org/abs/2204.08896v1](http://arxiv.org/abs/2204.08896v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: We introduce a subclass of concurrent game structures (CGS) with imperfect
information in which agents are endowed with private data-sharing capabilities.
Importantly, our CGSs are such that it is still decidable to model-check these
CGSs against a relevant fragment of ATL. These systems can be thought as a
generalisation of architectures allowing information forks, in the sense that,
in the initial states of the system, we allow information forks from agents
outside a given set A to agents inside this A. For this reason, together with
the fact that the communication in our models underpins a specialised form of
broadcast, we call our formalism A-cast systems. To underline, the fragment of
ATL for which we show the model-checking problem to be decidable over A-cast is
a large and significant one; it expresses coalitions over agents in any subset
of the set A. Indeed, as we show, our systems and this ATL fragments can encode
security problems that are notoriously hard to express faithfully:
terrorist-fraud attacks in identity schemes.

### Title: Event-triggered Approximate Byzantine Consensus with Multi-hop Communication
* Paper ID: 2204.08883v1
* Paper URL: [http://arxiv.org/abs/2204.08883v1](http://arxiv.org/abs/2204.08883v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: In this paper, we consider a resilient consensus problem for the multi-agent
network where some of the agents are subject to Byzantine attacks and may
transmit erroneous state values to their neighbors. In particular, we develop
an event-triggered update rule to tackle this problem as well as reduce the
communication for each agent. Our approach is based on the mean subsequence
reduced (MSR) algorithm with agents being capable to communicate with multi-hop
neighbors. Since delays are critical in such an environment, we provide
necessary graph conditions for the proposed algorithm to perform well with
delays in the communication. We highlight that through multi-hop communication,
the network connectivity can be reduced especially in comparison with the
common onehop communication case. Lastly, we show the effectiveness of the
proposed algorithm by a numerical example.

### Title: CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution
* Paper ID: 2204.08742v1
* Paper URL: [http://arxiv.org/abs/2204.08742v1](http://arxiv.org/abs/2204.08742v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: The migration of computation to the cloud has raised privacy concerns as
sensitive data becomes vulnerable to attacks since they need to be decrypted
for processing. Fully Homomorphic Encryption (FHE) mitigates this issue as it
enables meaningful computations to be performed directly on encrypted data.
Nevertheless, FHE is orders of magnitude slower than unencrypted computation,
which hinders its practicality and adoption. Therefore, improving FHE
performance is essential for its real world deployment. In this paper, we
present a year-long effort to design, implement, fabricate, and post-silicon
validate a hardware accelerator for Fully Homomorphic Encryption dubbed CoFHEE.
With a design area of $12mm^2$, CoFHEE aims to improve performance of
ciphertext multiplications, the most demanding arithmetic FHE operation, by
accelerating several primitive operations on polynomials, such as polynomial
additions and subtractions, Hadamard product, and Number Theoretic Transform.
CoFHEE supports polynomial degrees of up to $n = 2^{14}$ with a maximum
coefficient sizes of 128 bits, while it is capable of performing ciphertext
multiplications entirely on chip for $n \leq 2^{13}$. CoFHEE is fabricated in
55nm CMOS technology and achieves 250 MHz with our custom-built low-power
digital PLL design. In addition, our chip includes two communication interfaces
to the host machine: UART and SPI. This manuscript presents all steps and
design techniques in the ASIC development process, ranging from RTL design to
fabrication and validation. We evaluate our chip with performance and power
experiments and compare it against state-of-the-art software implementations
and other ASIC designs. Developed RTL files are available in an open-source
repository.

### Title: Jacobian Ensembles Improve Robustness Trade-offs to Adversarial Attacks
* Paper ID: 2204.08726v1
* Paper URL: [http://arxiv.org/abs/2204.08726v1](http://arxiv.org/abs/2204.08726v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Deep neural networks have become an integral part of our software
infrastructure and are being deployed in many widely-used and safety-critical
applications. However, their integration into many systems also brings with it
the vulnerability to test time attacks in the form of Universal Adversarial
Perturbations (UAPs). UAPs are a class of perturbations that when applied to
any input causes model misclassification. Although there is an ongoing effort
to defend models against these adversarial attacks, it is often difficult to
reconcile the trade-offs in model accuracy and robustness to adversarial
attacks. Jacobian regularization has been shown to improve the robustness of
models against UAPs, whilst model ensembles have been widely adopted to improve
both predictive performance and model robustness. In this work, we propose a
novel approach, Jacobian Ensembles-a combination of Jacobian regularization and
model ensembles to significantly increase the robustness against UAPs whilst
maintaining or improving model accuracy. Our results show that Jacobian
Ensembles achieves previously unseen levels of accuracy and robustness, greatly
improving over previous methods that tend to skew towards only either accuracy
or robustness.

### Title: Topology and geometry of data manifold in deep learning
* Paper ID: 2204.08624v1
* Paper URL: [http://arxiv.org/abs/2204.08624v1](http://arxiv.org/abs/2204.08624v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Despite significant advances in the field of deep learning in applications to
various fields, explaining the inner processes of deep learning models remains
an important and open question. The purpose of this article is to describe and
substantiate the geometric and topological view of the learning process of
neural networks. Our attention is focused on the internal representation of
neural networks and on the dynamics of changes in the topology and geometry of
the data manifold on different layers. We also propose a method for assessing
the generalizing ability of neural networks based on topological descriptors.
In this paper, we use the concepts of topological data analysis and intrinsic
dimension, and we present a wide range of experiments on different datasets and
different configurations of convolutional neural network architectures. In
addition, we consider the issue of the geometry of adversarial attacks in the
classification task and spoofing attacks on face recognition systems. Our work
is a contribution to the development of an important area of explainable and
interpretable AI through the example of computer vision.

### Title: Poisons that are learned faster are more effective
* Paper ID: 2204.08615v1
* Paper URL: [http://arxiv.org/abs/2204.08615v1](http://arxiv.org/abs/2204.08615v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Imperceptible poisoning attacks on entire datasets have recently been touted
as methods for protecting data privacy. However, among a number of defenses
preventing the practical use of these techniques, early-stopping stands out as
a simple, yet effective defense. To gauge poisons' vulnerability to
early-stopping, we benchmark error-minimizing, error-maximizing, and synthetic
poisons in terms of peak test accuracy over 100 epochs and make a number of
surprising observations. First, we find that poisons that reach a low training
loss faster have lower peak test accuracy. Second, we find that a current
state-of-the-art error-maximizing poison is 7 times less effective when poison
training is stopped at epoch 8. Third, we find that stronger, more transferable
adversarial attacks do not make stronger poisons. We advocate for evaluating
poisons in terms of peak test accuracy.

### Title: Metamorphic Testing-based Adversarial Attack to Fool Deepfake Detectors
* Paper ID: 2204.08612v1
* Paper URL: [http://arxiv.org/abs/2204.08612v1](http://arxiv.org/abs/2204.08612v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Deepfakes utilise Artificial Intelligence (AI) techniques to create synthetic
media where the likeness of one person is replaced with another. There are
growing concerns that deepfakes can be maliciously used to create misleading
and harmful digital contents. As deepfakes become more common, there is a dire
need for deepfake detection technology to help spot deepfake media. Present
deepfake detection models are able to achieve outstanding accuracy (>90%).
However, most of them are limited to within-dataset scenario, where the same
dataset is used for training and testing. Most models do not generalise well
enough in cross-dataset scenario, where models are tested on unseen datasets
from another source. Furthermore, state-of-the-art deepfake detection models
rely on neural network-based classification models that are known to be
vulnerable to adversarial attacks. Motivated by the need for a robust deepfake
detection model, this study adapts metamorphic testing (MT) principles to help
identify potential factors that could influence the robustness of the examined
model, while overcoming the test oracle problem in this domain. Metamorphic
testing is specifically chosen as the testing technique as it fits our demand
to address learning-based system testing with probabilistic outcomes from
largely black-box components, based on potentially large input domains. We
performed our evaluations on MesoInception-4 and TwoStreamNet models, which are
the state-of-the-art deepfake detection models. This study identified makeup
application as an adversarial attack that could fool deepfake detectors. Our
experimental results demonstrate that both the MesoInception-4 and TwoStreamNet
models degrade in their performance by up to 30\% when the input data is
perturbed with makeup.

### Title: Context-Auditor: Context-sensitive Content Injection Mitigation
* Paper ID: 2204.08592v1
* Paper URL: [http://arxiv.org/abs/2204.08592v1](http://arxiv.org/abs/2204.08592v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Cross-site scripting (XSS) is the most common vulnerability class in web
applications over the last decade. Much research attention has focused on
building exploit mitigation defenses for this problem, but no technique
provides adequate protection in the face of advanced attacks. One technique
that bypasses XSS mitigations is the scriptless attack: a content injection
technique that uses (among other options) CSS and HTML injection to infiltrate
data. In studying this technique and others, we realized that the common
property among the exploitation of all content injection vulnerabilities,
including not just XSS and scriptless attacks, but also command injections and
several others, is an unintended context switch in the victim program's parsing
engine that is caused by untrusted user input.
  In this paper, we propose Context-Auditor, a novel technique that leverages
this insight to identify content injection vulnerabilities ranging from XSS to
scriptless attacks and command injections. We implemented Context-Auditor as a
general solution to content injection exploit detection problem in the form of
a flexible, stand-alone detection module. We deployed instances of
Context-Auditor as (1) a browser plugin, (2) a web proxy (3) a web server
plugin, and (4) as a wrapper around potentially-injectable system endpoints.
Because Context-Auditor targets the root cause of content injection
exploitation (and, more specifically for the purpose of our prototype, XSS
exploitation, scriptless exploitation, and command injection), our evaluation
results demonstrate that Context-Auditor can identify and block content
injection exploits that modern defenses cannot while maintaining low throughput
overhead and avoiding false positives.

### Title: Automatic Hardware Trojan Insertion using Machine Learning
* Paper ID: 2204.08580v1
* Paper URL: [http://arxiv.org/abs/2204.08580v1](http://arxiv.org/abs/2204.08580v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Due to the current horizontal business model that promotes increasing
reliance on untrusted third-party Intellectual Properties (IPs), CAD tools, and
design facilities, hardware Trojan attacks have become a serious threat to the
semiconductor industry. Development of effective countermeasures against
hardware Trojan attacks requires: (1) fast and reliable exploration of the
viable Trojan attack space for a given design and (2) a suite of high-quality
Trojan-inserted benchmarks that meet specific standards. The latter has become
essential for the development and evaluation of design/verification solutions
to achieve quantifiable assurance against Trojan attacks. While existing static
benchmarks provide a baseline for comparing different countermeasures, they
only enumerate a limited number of handcrafted Trojans from the complete Trojan
design space. To accomplish these dual objectives, in this paper, we present
MIMIC, a novel AI-guided framework for automatic Trojan insertion, which can
create a large population of valid Trojans for a given design by mimicking the
properties of a small set of known Trojans. While there exist tools to
automatically insert Trojan instances using fixed Trojan templates, they cannot
analyze known Trojan attacks for creating new instances that accurately capture
the threat model. MIMIC works in two major steps: (1) it analyzes structural
and functional features of existing Trojan populations in a multi-dimensional
space to train machine learning models and generate a large number of "virtual
Trojans" of the given design, (2) next, it binds them into the design by
matching their functional/structural properties with suitable nets of the
internal logic structure. We have developed a complete tool flow for MIMIC,
extensively evaluated the framework by exploring several use-cases, and
quantified its effectiveness to demonstrate highly promising results.

### Title: Collusion-resistant fingerprinting of parallel content channels
* Paper ID: 2204.08575v1
* Paper URL: [http://arxiv.org/abs/2204.08575v1](http://arxiv.org/abs/2204.08575v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: The fingerprinting game is analysed when the coalition size $k$ is known to
the tracer, but the colluders can distribute themselves across $L$ TV channels.
The collusion channel is introduced and the extra degrees of freedom for the
coalition are made manifest in our formulation. We introduce a payoff
functional that is analogous to the single TV channel case, and is conjectured
to be closely related to the fingerprinting capacity. For the binary alphabet
case under the marking assumption, and the restriction of access to one TV
channel per person per segment, we derive the asymptotic behavior of the payoff
functional. We find that the value of the maximin game for our payoff is
asymptotically equal to $L^2/k^2 2 \ln 2$, with optimal strategy for the tracer
being the arcsine distribution, and for the coalition being the interleaving
attack across all TV channels, as well as assigning an equal number of
colluders across the $L$ TV channels.

### Title: A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability
* Paper ID: 2204.08570v1
* Paper URL: [http://arxiv.org/abs/2204.08570v1](http://arxiv.org/abs/2204.08570v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Graph Neural Networks (GNNs) have made rapid developments in the recent
years. Due to their great ability in modeling graph-structured data, GNNs are
vastly used in various applications, including high-stakes scenarios such as
financial analysis, traffic predictions, and drug discovery. Despite their
great potential in benefiting humans in the real world, recent study shows that
GNNs can leak private information, are vulnerable to adversarial attacks, can
inherit and magnify societal bias from training data and lack interpretability,
which have risk of causing unintentional harm to the users and society. For
example, existing works demonstrate that attackers can fool the GNNs to give
the outcome they desire with unnoticeable perturbation on training graph. GNNs
trained on social networks may embed the discrimination in their decision
process, strengthening the undesirable societal bias. Consequently, trustworthy
GNNs in various aspects are emerging to prevent the harm from GNN models and
increase the users' trust in GNNs. In this paper, we give a comprehensive
survey of GNNs in the computational aspects of privacy, robustness, fairness,
and explainability. For each aspect, we give the taxonomy of the related
methods and formulate the general frameworks for the multiple categories of
trustworthy GNNs. We also discuss the future research directions of each aspect
and connections between these aspects to help achieve trustworthiness.

### Title: Optimal Layered Defense For Site Protection
* Paper ID: 2204.08961v1
* Paper URL: [http://arxiv.org/abs/2204.08961v1](http://arxiv.org/abs/2204.08961v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: We present a model for layered security with applications to the protection
of sites such as stadiums or large gathering places. We formulate the problem
as one of maximizing the capture of illegal contraband. The objective function
is indefinite and only limited information can be gained when the problem is
solved by standard convex optimization methods. In order to solve the model, we
develop a dynamic programming approach, and study its convergence properties.
Additionally, we formulate a version of the problem aimed at addressing
intelligent adversaries who can adjust their direction of attack as they
observe changes in the site security. Furthermore, we also develop a method for
the solution of the latter model. Finally, we perform computational experiments
to demonstrate the use of our methods.

### Title: Sardino: Ultra-Fast Dynamic Ensemble for Secure Visual Sensing at Mobile Edge
* Paper ID: 2204.08189v1
* Paper URL: [http://arxiv.org/abs/2204.08189v1](http://arxiv.org/abs/2204.08189v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Adversarial example attack endangers the mobile edge systems such as vehicles
and drones that adopt deep neural networks for visual sensing. This paper
presents {\em Sardino}, an active and dynamic defense approach that renews the
inference ensemble at run time to develop security against the adaptive
adversary who tries to exfiltrate the ensemble and construct the corresponding
effective adversarial examples. By applying consistency check and data fusion
on the ensemble's predictions, Sardino can detect and thwart adversarial
inputs. Compared with the training-based ensemble renewal, we use HyperNet to
achieve {\em one million times} acceleration and per-frame ensemble renewal
that presents the highest level of difficulty to the prerequisite exfiltration
attacks. Moreover, the robustness of the renewed ensembles against adversarial
examples is enhanced with adversarial learning for the HyperNet. We design a
run-time planner that maximizes the ensemble size in favor of security while
maintaining the processing frame rate. Beyond adversarial examples, Sardino can
also address the issue of out-of-distribution inputs effectively. This paper
presents extensive evaluation of Sardino's performance in counteracting
adversarial examples and applies it to build a real-time car-borne traffic sign
recognition system. Live on-road tests show the built system's effectiveness in
maintaining frame rate and detecting out-of-distribution inputs due to the
false positives of a preceding YOLO-based traffic sign detector.

### Title: Securing Signal-free Intersections against Strategic Jamming Attacks: A Macroscopic Approach
* Paper ID: 2204.08187v1
* Paper URL: [http://arxiv.org/abs/2204.08187v1](http://arxiv.org/abs/2204.08187v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: We consider the security-by-design of a signal-free intersection for
connected and autonomous vehicles in the face of strategic jamming attacks. We
use a fluid model to characterize macroscopic traffic flow through the
intersection, where the saturation rate is derived from a vehicle coordination
algorithm. We model jamming attacks as sudden increase in communication latency
induced on vehicle-to-infrastructure connectivity; such latency triggers the
safety mode for vehicle coordination and thus reduces the intersection
saturation rate. A strategic attacker selects the attacking rate, while a
system operator selects key design parameters, either the saturation rate or
the recovery rate. Both players' actions induce technological costs and jointly
determine the mean travel delay. By analyzing the equilibrium of the security
game, we study the preferable level of investment in the intersection's nominal
discharging capability or recovery capability, for balance between
hardware/infrastructure cost and security-by-design.

