### Title: An Improved Authentication Scheme for BLE Devices with no I/O Capabilities
* Paper ID: 2204.13640v1
* Paper URL: [http://arxiv.org/abs/2204.13640v1](http://arxiv.org/abs/2204.13640v1)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: Bluetooth Low Energy (BLE) devices have become very popular because of their
Low energy consumption and hence a prolonged battery life. They are being used
in smart wearable devices, smart home automation system, beacons and many more
areas. BLE uses pairing mechanisms to achieve a level of peer entity
authentication as well as encryption. Although, there are a set of pairing
mechanisms available but BLE devices having no keyboard or display mechanism
(and hence using the Just Works pairing) are still vulnerable. In this paper,
we propose and implement, a light-weight digital certificate based
authentication mechanism for the BLE devices making use of Just Works model.
The proposed model is an add-on to the already existing pairing mechanism and
therefore can be easily incorporated in the existing BLE stack. To counter the
existing Man-in-The-Middle attack scenario in Just Works pairing (device
spoofing), our proposed model allows the client and peripheral to make use of
the popular Public Key Infrastructure (PKI) to establish peer entity
authentication and a secure cryptographic tunnel for communication. We have
also developed a lightweight BLE profiled digital certificate containing the
bare minimum fields required for resource constrained devices, which
significantly reduces the memory (about 90\% reduction) and energy consumption.
We have experimentally evaluated the energy consumption of the device using the
proposed pairing mechanism to demonstrate that the model can be easily deployed
with less changes to the power requirements of the chips. The model has been
formally verified using automatic verification tool for protocol testing.

### Title: Death By A Thousand COTS: Disrupting Satellite Communications using Low Earth Orbit Constellations
* Paper ID: 2204.13514v1
* Paper URL: [http://arxiv.org/abs/2204.13514v1](http://arxiv.org/abs/2204.13514v1)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: Satellites in Geostationary Orbit (GEO) provide a number of commercial,
government, and military services around the world, offering everything from
surveillance and monitoring to video calls and internet access. However a
dramatic lowering of the cost-per-kilogram to space has led to a recent
explosion in real and planned constellations in Low Earth Orbit (LEO) of
smaller satellites. These constellations are managed remotely and it is
important to consider a scenario in which an attacker gains control over the
constituent satellites. In this paper we aim to understand what damage this
attacker could cause, using the satellites to generate interference. To ground
our analysis, we simulate a number of existing and planned LEO constellations
against an example GEO constellation, and evaluate the relative effectiveness
of each. Our model shows that with conservative power estimates, both current
and planned constellations could disrupt GEO satellite services at every
groundstation considered, with effectiveness varying considerably between
locations. We analyse different patterns of interference, how they reflect the
structures of the constellations creating them, and how effective they might be
against a number of legitimate services. We found that real-time usage (e.g.
calls, streaming) would be most affected, with 3 constellation designs able to
generate thousands of outages of 30 seconds or longer over the course of the
day across all groundstations.

### Title: FieldFuzz: Enabling vulnerability discovery in Industrial Control Systems supply chain using stateful system-level fuzzing
* Paper ID: 2204.13499v1
* Paper URL: [http://arxiv.org/abs/2204.13499v1](http://arxiv.org/abs/2204.13499v1)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: With the advent of the fourth industrial revolution, Programmable Logic
Controllers (PLCs) used as field devices, have been growing in their
sophistication, offering extensive smart features, such as remote connectivity,
support for standardized cryptography, and visualization. Such computational
platforms incorporate components from various sources (vendor, platform
provider, open-source), bringing along their associated vulnerabilities. This,
combined with the increase in reliance on the Industrial Internet of Things
(IIoT) devices for automation and feedback, has opened previously airtight
networks to remote attacks. Furthermore, modern PLCs often employ commodity
software such as Linux on ARM, further expanding the threat surface towards
traditional vulnerabilities. Security analysis of Operational Technology (OT)
software, specifically, the control runtime and IEC applications, remains
relatively unexplored due to its proprietary nature. In this work, we implement
FieldFuzz, a methodology for discovering supply chain vulnerabilities in every
PLC component using stateful black-box fuzzing without the requirement of a
real device. FieldFuzz has been built using the Codesys v3 protocol, making it
applicable to at least 80 industrial device vendors ranging from over 400
devices. Fuzzing campaigns uncovered multiple vulnerabilities, leading to three
reported CVE IDs. To study the cross-platform applicability of FieldFuzz, we
reproduce the findings on a diverse set of Industrial Control System (ICS)
devices, showing a significant improvement over the state-of-the-art.

### Title: Morphing Attack Potential
* Paper ID: 2204.13374v1
* Paper URL: [http://arxiv.org/abs/2204.13374v1](http://arxiv.org/abs/2204.13374v1)
* Updated Date: 2022-04-28
* Code URL: [https://github.com/matteoferrara/morphing-attack-potential](https://github.com/matteoferrara/morphing-attack-potential)
* Summary: In security systems the risk assessment in the sense of common criteria
testing is a very relevant topic; this requires quantifying the attack
potential in terms of the expertise of the attacker, his knowledge about the
target and access to equipment. Contrary to those attacks, the recently
revealed morphing attacks against Face Recognition Systems (FRSs) can not be
assessed by any of the above criteria. But not all morphing techniques pose the
same risk for an operational face recognition system. This paper introduces
with the Morphing Attack Potential (MAP) a consistent methodology, that can
quantify the risk, which a certain morphing attack creates.

### Title: The Effect of Preferences in Abstract Argumentation Under a Claim-Centric View
* Paper ID: 2204.13305v1
* Paper URL: [http://arxiv.org/abs/2204.13305v1](http://arxiv.org/abs/2204.13305v1)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: In this paper, we study the effect of preferences in abstract argumentation
under a claim-centric perspective. Recent work has revealed that semantical and
computational properties can change when reasoning is performed on claim-level
rather than on the argument-level, while under certain natural restrictions
(arguments with the same claims have the same outgoing attacks) these
properties are conserved. We now investigate these effects when, in addition,
preferences have to be taken into account and consider four prominent
reductions to handle preferences between arguments. As we shall see, these
reductions give rise to different classes of claim-augmented argumentation
frameworks, and behave differently in terms of semantic properties and
computational complexity. This strengthens the view that the actual choice for
handling preferences has to be taken with care.

### Title: Shielding Federated Learning: Robust Aggregation with Adaptive Client Selection
* Paper ID: 2204.13256v1
* Paper URL: [http://arxiv.org/abs/2204.13256v1](http://arxiv.org/abs/2204.13256v1)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: Federated learning (FL) enables multiple clients to collaboratively train an
accurate global model while protecting clients' data privacy. However, FL is
susceptible to Byzantine attacks from malicious participants. Although the
problem has gained significant attention, existing defenses have several flaws:
the server irrationally chooses malicious clients for aggregation even after
they have been detected in previous rounds; the defenses perform ineffectively
against sybil attacks or in the heterogeneous data setting.
  To overcome these issues, we propose MAB-RFL, a new method for robust
aggregation in FL. By modelling the client selection as an extended multi-armed
bandit (MAB) problem, we propose an adaptive client selection strategy to
choose honest clients that are more likely to contribute high-quality updates.
We then propose two approaches to identify malicious updates from sybil and
non-sybil attacks, based on which rewards for each client selection decision
can be accurately evaluated to discourage malicious behaviors. MAB-RFL achieves
a satisfying balance between exploration and exploitation on the potential
benign clients. Extensive experimental results show that MAB-RFL outperforms
existing defenses in three attack scenarios under different percentages of
attackers.

### Title: Adversarial Fine-tune with Dynamically Regulated Adversary
* Paper ID: 2204.13232v1
* Paper URL: [http://arxiv.org/abs/2204.13232v1](http://arxiv.org/abs/2204.13232v1)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: Adversarial training is an effective method to boost model robustness to
malicious, adversarial attacks. However, such improvement in model robustness
often leads to a significant sacrifice of standard performance on clean images.
In many real-world applications such as health diagnosis and autonomous
surgical robotics, the standard performance is more valued over model
robustness against such extremely malicious attacks. This leads to the
question: To what extent we can boost model robustness without sacrificing
standard performance? This work tackles this problem and proposes a simple yet
effective transfer learning-based adversarial training strategy that
disentangles the negative effects of adversarial samples on model's standard
performance. In addition, we introduce a training-friendly adversarial attack
algorithm, which facilitates the boost of adversarial robustness without
introducing significant training complexity. Extensive experimentation
indicates that the proposed method outperforms previous adversarial training
algorithms towards the target: to improve model robustness while preserving
model's standard performance on clean data.

