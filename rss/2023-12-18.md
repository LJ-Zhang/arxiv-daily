## diffusion
### Title: LatentEditor: Text Driven Local Editing of 3D Scenes. (arXiv:2312.09313v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09313](http://arxiv.org/abs/2312.09313)
* Code URL: [https://github.com/umarkhalidAI/LatentEditor](https://github.com/umarkhalidAI/LatentEditor)
* Copy Paste: `<input type="checkbox">[[2312.09313] LatentEditor: Text Driven Local Editing of 3D Scenes](http://arxiv.org/abs/2312.09313) #diffusion`
* Summary: <p>While neural fields have made significant strides in view synthesis and scene
reconstruction, editing them poses a formidable challenge due to their implicit
encoding of geometry and texture information from multi-view inputs. In this
paper, we introduce \textsc{LatentEditor}, an innovative framework designed to
empower users with the ability to perform precise and locally controlled
editing of neural fields using text prompts. Leveraging denoising diffusion
models, we successfully embed real-world scenes into the latent space,
resulting in a faster and more adaptable NeRF backbone for editing compared to
traditional methods. To enhance editing precision, we introduce a delta score
to calculate the 2D mask in the latent space that serves as a guide for local
modifications while preserving irrelevant regions. Our novel pixel-level
scoring approach harnesses the power of InstructPix2Pix (IP2P) to discern the
disparity between IP2P conditional and unconditional noise predictions in the
latent space. The edited latents conditioned on the 2D masks are then
iteratively updated in the training set to achieve 3D local editing. Our
approach achieves faster editing speeds and superior output quality compared to
existing 3D editing models, bridging the gap between textual instructions and
high-quality 3D scene editing in latent space. We show the superiority of our
approach on four benchmark 3D datasets, LLFF, IN2N, NeRFStudio and NeRF-Art.
</p>

### Title: Single PW takes a shortcut to compound PW in US imaging. (arXiv:2312.09514v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09514](http://arxiv.org/abs/2312.09514)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09514] Single PW takes a shortcut to compound PW in US imaging](http://arxiv.org/abs/2312.09514) #diffusion`
* Summary: <p>Reconstruction of ultrasound (US) images from radio-frequency data can be
conceptualized as a linear inverse problem. Traditional deep learning
approaches, which aim to improve the quality of US images by directly learning
priors, often encounter challenges in generalization. Recently, diffusion-based
generative models have received significant attention within the research
community due to their robust performance in image reconstruction tasks.
However, a limitation of these models is their inherent low speed in generating
image samples from pure Gaussian noise progressively. In this study, we exploit
the inherent similarity between the US images reconstructed from a single plane
wave (PW) and PW compounding PWC). We hypothesize that a single PW can take a
shortcut to reach the diffusion trajectory of PWC, removing the need to begin
with Gaussian noise. By employing an advanced diffusion model, we demonstrate
its effectiveness in US image reconstruction, achieving a substantial reduction
in sampling steps. In-vivo experimental results indicate that our approach can
reduce sampling steps by 60%, while preserving comparable performance metrics
with the conventional diffusion model.
</p>

### Title: CAGE: Controllable Articulation GEneration. (arXiv:2312.09570v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09570](http://arxiv.org/abs/2312.09570)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09570] CAGE: Controllable Articulation GEneration](http://arxiv.org/abs/2312.09570) #diffusion`
* Summary: <p>We address the challenge of generating 3D articulated objects in a
controllable fashion. Currently, modeling articulated 3D objects is either
achieved through laborious manual authoring, or using methods from prior work
that are hard to scale and control directly. We leverage the interplay between
part shape, connectivity, and motion using a denoising diffusion-based method
with attention modules designed to extract correlations between part
attributes. Our method takes an object category label and a part connectivity
graph as input and generates an object's geometry and motion parameters. The
generated objects conform to user-specified constraints on the object category,
part shape, and part articulation. Our experiments show that our method
outperforms the state-of-the-art in articulated object generation, producing
more realistic objects while conforming better to user constraints.
</p>
<p>Video Summary at: <a href="http://youtu.be/cH_rbKbyTpE">this http URL</a>
</p>

### Title: Faster Diffusion: Rethinking the Role of UNet Encoder in Diffusion Models. (arXiv:2312.09608v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09608](http://arxiv.org/abs/2312.09608)
* Code URL: [https://github.com/hutaihang/faster-diffusion](https://github.com/hutaihang/faster-diffusion)
* Copy Paste: `<input type="checkbox">[[2312.09608] Faster Diffusion: Rethinking the Role of UNet Encoder in Diffusion Models](http://arxiv.org/abs/2312.09608) #diffusion`
* Summary: <p>One of the key components within diffusion models is the UNet for noise
prediction. While several works have explored basic properties of the UNet
decoder, its encoder largely remains unexplored. In this work, we conduct the
first comprehensive study of the UNet encoder. We empirically analyze the
encoder features and provide insights to important questions regarding their
changes at the inference process. In particular, we find that encoder features
change gently, whereas the decoder features exhibit substantial variations
across different time-steps. This finding inspired us to omit the encoder at
certain adjacent time-steps and reuse cyclically the encoder features in the
previous time-steps for the decoder. Further based on this observation, we
introduce a simple yet effective encoder propagation scheme to accelerate the
diffusion sampling for a diverse set of tasks. By benefiting from our
propagation scheme, we are able to perform in parallel the decoder at certain
adjacent time-steps. Additionally, we introduce a prior noise injection method
to improve the texture details in the generated image. Besides the standard
text-to-image task, we also validate our approach on other tasks:
text-to-video, personalized generation and reference-guided generation. Without
utilizing any knowledge distillation technique, our approach accelerates both
the Stable Diffusion (SD) and the DeepFloyd-IF models sampling by 41$\%$ and
24$\%$ respectively, while maintaining high-quality generation performance. Our
code is available in
\href{https://github.com/hutaiHang/Faster-Diffusion}{FasterDiffusion}.
</p>

### Title: TF-CLIP: Learning Text-free CLIP for Video-based Person Re-Identification. (arXiv:2312.09627v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09627](http://arxiv.org/abs/2312.09627)
* Code URL: [https://github.com/asuradayuci/tf-clip](https://github.com/asuradayuci/tf-clip)
* Copy Paste: `<input type="checkbox">[[2312.09627] TF-CLIP: Learning Text-free CLIP for Video-based Person Re-Identification](http://arxiv.org/abs/2312.09627) #diffusion`
* Summary: <p>Large-scale language-image pre-trained models (e.g., CLIP) have shown
superior performances on many cross-modal retrieval tasks. However, the problem
of transferring the knowledge learned from such models to video-based person
re-identification (ReID) has barely been explored. In addition, there is a lack
of decent text descriptions in current ReID benchmarks. To address these
issues, in this work, we propose a novel one-stage text-free CLIP-based
learning framework named TF-CLIP for video-based person ReID. More
specifically, we extract the identity-specific sequence feature as the
CLIP-Memory to replace the text feature. Meanwhile, we design a
Sequence-Specific Prompt (SSP) module to update the CLIP-Memory online. To
capture temporal information, we further propose a Temporal Memory Diffusion
(TMD) module, which consists of two key components: Temporal Memory
Construction (TMC) and Memory Diffusion (MD). Technically, TMC allows the
frame-level memories in a sequence to communicate with each other, and to
extract temporal information based on the relations within the sequence. MD
further diffuses the temporal memories to each token in the original features
to obtain more robust sequence features. Extensive experiments demonstrate that
our proposed method shows much better results than other state-of-the-art
methods on MARS, LS-VID and iLIDS-VID. The code is available at
https://github.com/AsuradaYuci/TF-CLIP.
</p>

### Title: Exploring the Feasibility of Generating Realistic 3D Models of Endangered Species Using DreamGaussian: An Analysis of Elevation Angle's Impact on Model Generation. (arXiv:2312.09682v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09682](http://arxiv.org/abs/2312.09682)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09682] Exploring the Feasibility of Generating Realistic 3D Models of Endangered Species Using DreamGaussian: An Analysis of Elevation Angle's Impact on Model Generation](http://arxiv.org/abs/2312.09682) #diffusion`
* Summary: <p>Many species face the threat of extinction. It's important to study these
species and gather information about them as much as possible to preserve
biodiversity. Due to the rarity of endangered species, there is a limited
amount of data available, making it difficult to apply data requiring
generative AI methods to this domain. We aim to study the feasibility of
generating consistent and real-like 3D models of endangered animals using
limited data. Such a phenomenon leads us to utilize zero-shot stable diffusion
models that can generate a 3D model out of a single image of the target
species. This paper investigates the intricate relationship between elevation
angle and the output quality of 3D model generation, focusing on the innovative
approach presented in DreamGaussian. DreamGaussian, a novel framework utilizing
Generative Gaussian Splatting along with novel mesh extraction and refinement
algorithms, serves as the focal point of our study. We conduct a comprehensive
analysis, analyzing the effect of varying elevation angles on DreamGaussian's
ability to reconstruct 3D scenes accurately. Through an empirical evaluation,
we demonstrate how changes in elevation angle impact the generated images'
spatial coherence, structural integrity, and perceptual realism. We observed
that giving a correct elevation angle with the input image significantly
affects the result of the generated 3D model. We hope this study to be
influential for the usability of AI to preserve endangered animals; while the
penultimate aim is to obtain a model that can output biologically consistent 3D
models via small samples, the qualitative interpretation of an existing
state-of-the-art model such as DreamGaussian will be a step forward in our
goal.
</p>

### Title: DreamTalk: When Expressive Talking Head Generation Meets Diffusion Probabilistic Models. (arXiv:2312.09767v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09767](http://arxiv.org/abs/2312.09767)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09767] DreamTalk: When Expressive Talking Head Generation Meets Diffusion Probabilistic Models](http://arxiv.org/abs/2312.09767) #diffusion`
* Summary: <p>Diffusion models have shown remarkable success in a variety of downstream
generative tasks, yet remain under-explored in the important and challenging
expressive talking head generation. In this work, we propose a DreamTalk
framework to fulfill this gap, which employs meticulous design to unlock the
potential of diffusion models in generating expressive talking heads.
Specifically, DreamTalk consists of three crucial components: a denoising
network, a style-aware lip expert, and a style predictor. The diffusion-based
denoising network is able to consistently synthesize high-quality audio-driven
face motions across diverse expressions. To enhance the expressiveness and
accuracy of lip motions, we introduce a style-aware lip expert that can guide
lip-sync while being mindful of the speaking styles. To eliminate the need for
expression reference video or text, an extra diffusion-based style predictor is
utilized to predict the target expression directly from the audio. By this
means, DreamTalk can harness powerful diffusion models to generate expressive
faces effectively and reduce the reliance on expensive style references.
Experimental results demonstrate that DreamTalk is capable of generating
photo-realistic talking faces with diverse speaking styles and achieving
accurate lip motions, surpassing existing state-of-the-art counterparts.
</p>

### Title: Latent Diffusion Models with Image-Derived Annotations for Enhanced AI-Assisted Cancer Diagnosis in Histopathology. (arXiv:2312.09792v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09792](http://arxiv.org/abs/2312.09792)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09792] Latent Diffusion Models with Image-Derived Annotations for Enhanced AI-Assisted Cancer Diagnosis in Histopathology](http://arxiv.org/abs/2312.09792) #diffusion`
* Summary: <p>Artificial Intelligence (AI) based image analysis has an immense potential to
support diagnostic histopathology, including cancer diagnostics. However,
developing supervised AI methods requires large-scale annotated datasets. A
potentially powerful solution is to augment training data with synthetic data.
Latent diffusion models, which can generate high-quality, diverse synthetic
images, are promising. However, the most common implementations rely on
detailed textual descriptions, which are not generally available in this
domain. This work proposes a method that constructs structured textual prompts
from automatically extracted image features. We experiment with the PCam
dataset, composed of tissue patches only loosely annotated as healthy or
cancerous. We show that including image-derived features in the prompt, as
opposed to only healthy and cancerous labels, improves the Fr\'echet Inception
Distance (FID) from 178.8 to 90.2. We also show that pathologists find it
challenging to detect synthetic images, with a median sensitivity/specificity
of 0.55/0.55. Finally, we show that synthetic data effectively trains AI
models.
</p>

### Title: Socio-Economic Deprivation Analysis: Diffusion Maps. (arXiv:2312.09830v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2312.09830](http://arxiv.org/abs/2312.09830)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09830] Socio-Economic Deprivation Analysis: Diffusion Maps](http://arxiv.org/abs/2312.09830) #diffusion`
* Summary: <p>This report proposes a model to predict the location of the most deprived
areas in a city using data from the census. A census data is very high
dimensional and needs to be simplified. We use a novel algorithm to reduce
dimensionality and find patterns: The diffusion map. Features are defined by
eigenvectors of the Laplacian matrix that defines the diffusion map.
Eigenvectors corresponding to the smallest eigenvalues indicate specific
population features. Previous work has found qualitatively that the second most
important dimension for describing the census data in Bristol is linked to
deprivation. In this report, we analyse how good this dimension is as a model
for predicting deprivation by comparing with the recognised measures. The
Pearson correlation coefficient was found to be over 0.7. The top 10 per cent
of deprived areas in the UK which also locate in Bristol are extracted to test
the accuracy of the model. There are 52 most deprived areas, and 38 areas are
correctly identified by comparing to the model. The influence of scores of IMD
domains that do not correlate with the models, Eigenvector 2 entries of
non-deprived OAs and orthogonality of Eigenvectors cause the model to fail the
prediction of 14 deprived areas.
</p>
<p>However, overall, the model shows a high performance to predict the future
deprivation of overall areas where the project considers. This project is
expected to support the government to allocate resources and funding.
</p>

## self-supervised
### Title: CNC-Net: Self-Supervised Learning for CNC Machining Operations. (arXiv:2312.09925v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09925](http://arxiv.org/abs/2312.09925)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09925] CNC-Net: Self-Supervised Learning for CNC Machining Operations](http://arxiv.org/abs/2312.09925) #self-supervised`
* Summary: <p>CNC manufacturing is a process that employs computer numerical control (CNC)
machines to govern the movements of various industrial tools and machinery,
encompassing equipment ranging from grinders and lathes to mills and CNC
routers. However, the reliance on manual CNC programming has become a
bottleneck, and the requirement for expert knowledge can result in significant
costs. Therefore, we introduce a pioneering approach named CNC-Net,
representing the use of deep neural networks (DNNs) to simulate CNC machines
and grasp intricate operations when supplied with raw materials. CNC-Net
constitutes a self-supervised framework that exclusively takes an input 3D
model and subsequently generates the essential operation parameters required by
the CNC machine to construct the object. Our method has the potential to
transformative automation in manufacturing by offering a cost-effective
alternative to the high costs of manual CNC programming while maintaining
exceptional precision in 3D object production. Our experiments underscore the
effectiveness of our CNC-Net in constructing the desired 3D objects through the
utilization of CNC operations. Notably, it excels in preserving finer local
details, exhibiting a marked enhancement in precision compared to the
state-of-the-art 3D CAD reconstruction approaches.
</p>

### Title: Generative Context-aware Fine-tuning of Self-supervised Speech Models. (arXiv:2312.09895v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2312.09895](http://arxiv.org/abs/2312.09895)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09895] Generative Context-aware Fine-tuning of Self-supervised Speech Models](http://arxiv.org/abs/2312.09895) #self-supervised`
* Summary: <p>When performing tasks like automatic speech recognition or spoken language
understanding for a given utterance, access to preceding text or audio provides
contextual information can improve performance. Considering the recent advances
in generative large language models (LLM), we hypothesize that an LLM could
generate useful context information using the preceding text. With appropriate
prompts, LLM could generate a prediction of the next sentence or abstractive
text like titles or topics. In this paper, we study the use of LLM-generated
context information and propose an approach to distill the generated
information during fine-tuning of self-supervised speech models, which we refer
to as generative context-aware fine-tuning. This approach allows the fine-tuned
model to make improved predictions without access to the true surrounding
segments or to the LLM at inference time, while requiring only a very small
additional context module. We evaluate the proposed approach using the SLUE and
Libri-light benchmarks for several downstream tasks: automatic speech
recognition, named entity recognition, and sentiment analysis. The results show
that generative context-aware fine-tuning outperforms a context injection
fine-tuning approach that accesses the ground-truth previous text, and is
competitive with a generative context injection fine-tuning approach that
requires the LLM at inference time.
</p>

## foundation model
### Title: Collaborating Foundation models for Domain Generalized Semantic Segmentation. (arXiv:2312.09788v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09788](http://arxiv.org/abs/2312.09788)
* Code URL: [https://github.com/yasserben/clouds](https://github.com/yasserben/clouds)
* Copy Paste: `<input type="checkbox">[[2312.09788] Collaborating Foundation models for Domain Generalized Semantic Segmentation](http://arxiv.org/abs/2312.09788) #foundation model`
* Summary: <p>Domain Generalized Semantic Segmentation (DGSS) deals with training a model
on a labeled source domain with the aim of generalizing to unseen domains
during inference. Existing DGSS methods typically effectuate robust features by
means of Domain Randomization (DR). Such an approach is often limited as it can
only account for style diversification and not content. In this work, we take
an orthogonal approach to DGSS and propose to use an assembly of CoLlaborative
FOUndation models for Domain Generalized Semantic Segmentation (CLOUDS). In
detail, CLOUDS is a framework that integrates FMs of various kinds: (i) CLIP
backbone for its robust feature representation, (ii) generative models to
diversify the content, thereby covering various modes of the possible target
distribution, and (iii) Segment Anything Model (SAM) for iteratively refining
the predictions of the segmentation model. Extensive experiments show that our
CLOUDS excels in adapting from synthetic to real DGSS benchmarks and under
varying weather conditions, notably outperforming prior methods by 5.6% and
6.7% on averaged miou, respectively. The code is available at :
https://github.com/yasserben/CLOUDS
</p>

### Title: PathoDuet: Foundation Models for Pathological Slide Analysis of H&E and IHC Stains. (arXiv:2312.09894v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09894](http://arxiv.org/abs/2312.09894)
* Code URL: [https://github.com/openmedlab/pathoduet](https://github.com/openmedlab/pathoduet)
* Copy Paste: `<input type="checkbox">[[2312.09894] PathoDuet: Foundation Models for Pathological Slide Analysis of H&E and IHC Stains](http://arxiv.org/abs/2312.09894) #foundation model`
* Summary: <p>Large amounts of digitized histopathological data display a promising future
for developing pathological foundation models via self-supervised learning
methods. Foundation models pretrained with these methods serve as a good basis
for downstream tasks. However, the gap between natural and histopathological
images hinders the direct application of existing methods. In this work, we
present PathoDuet, a series of pretrained models on histopathological images,
and a new self-supervised learning framework in histopathology. The framework
is featured by a newly-introduced pretext token and later task raisers to
explicitly utilize certain relations between images, like multiple
magnifications and multiple stains. Based on this, two pretext tasks,
cross-scale positioning and cross-stain transferring, are designed to pretrain
the model on Hematoxylin and Eosin (H\&amp;E) images and transfer the model to
immunohistochemistry (IHC) images, respectively. To validate the efficacy of
our models, we evaluate the performance over a wide variety of downstream
tasks, including patch-level colorectal cancer subtyping and whole slide image
(WSI)-level classification in H\&amp;E field, together with expression level
prediction of IHC marker and tumor identification in IHC field. The
experimental results show the superiority of our models over most tasks and the
efficacy of proposed pretext tasks. The codes and models are available at
https://github.com/openmedlab/PathoDuet.
</p>

## generative
### Title: Image Deblurring using GAN. (arXiv:2312.09496v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09496](http://arxiv.org/abs/2312.09496)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09496] Image Deblurring using GAN](http://arxiv.org/abs/2312.09496) #generative`
* Summary: <p>In recent years, deep generative models, such as Generative Adversarial
Network (GAN), has grabbed significant attention in the field of computer
vision. This project focuses on the application of GAN in image deblurring with
the aim of generating clearer images from blurry inputs caused by factors such
as motion blur. However, traditional image restoration techniques have
limitations in handling complex blurring patterns. Hence, a GAN-based framework
is proposed as a solution to generate high-quality deblurred images. The
project defines a GAN model in Tensorflow and trains it with GoPRO dataset. The
Generator will intake blur images directly to create fake images to convince
the Discriminator which will receive clear images at the same time and
distinguish between the real image and the fake image. After obtaining the
trained parameters, the model was used to deblur motion-blur images taken in
daily life as well as testing set for validation. The result shows that the
pretrained network of GAN can obtain sharper pixels in image, achieving an
average of 29.3 Peak Signal-to-Noise Ratio (PSNR) and 0.72 Structural
Similarity Assessment (SSIM). This help to effectively address the challenges
posed by image blurring, leading to the generation of visually pleasing and
sharp images. By exploiting the adversarial learning framework, the proposed
approach enhances the potential for real-world applications in image
restoration.
</p>

### Title: Fast Sampling generative model for Ultrasound image reconstruction. (arXiv:2312.09510v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09510](http://arxiv.org/abs/2312.09510)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09510] Fast Sampling generative model for Ultrasound image reconstruction](http://arxiv.org/abs/2312.09510) #generative`
* Summary: <p>Image reconstruction from radio-frequency data is pivotal in ultrafast plane
wave ultrasound imaging. Unlike the conventional delay-and-sum (DAS) technique,
which relies on somewhat imprecise assumptions, deep learning-based methods
perform image reconstruction by training on paired data, leading to a notable
enhancement in image quality. Nevertheless, these strategies often exhibit
limited generalization capabilities. Recently, denoising diffusion models have
become the preferred paradigm for image reconstruction tasks. However, their
reliance on an iterative sampling procedure results in prolonged generation
time. In this paper, we propose a novel sampling framework that concurrently
enforces data consistency of ultrasound signals and data-driven priors. By
leveraging the advanced diffusion model, the generation of high-quality images
is substantially expedited. Experimental evaluations on an in-vivo dataset
indicate that our approach with a single plane wave surpasses DAS with spatial
coherent compounding of 75 plane waves.
</p>

### Title: Style Generation in Robot Calligraphy with Deep Generative Adversarial Networks. (arXiv:2312.09673v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09673](http://arxiv.org/abs/2312.09673)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09673] Style Generation in Robot Calligraphy with Deep Generative Adversarial Networks](http://arxiv.org/abs/2312.09673) #generative`
* Summary: <p>Robot calligraphy is an emerging exploration of artificial intelligence in
the fields of art and education. Traditional calligraphy generation researches
mainly focus on methods such as tool-based image processing, generative models,
and style transfer. Unlike the English alphabet, the number of Chinese
characters is tens of thousands, which leads to difficulties in the generation
of a style consistent Chinese calligraphic font with over 6000 characters. Due
to the lack of high-quality data sets, formal definitions of calligraphy
knowledge, and scientific art evaluation methods, The results generated are
frequently of low quality and falls short of professional-level requirements.
To address the above problem, this paper proposes an automatic calligraphy
generation model based on deep generative adversarial networks (deepGAN) that
can generate style calligraphy fonts with professional standards. The key
highlights of the proposed method include: (1) The datasets use a
high-precision calligraphy synthesis method to ensure its high quality and
sufficient quantity; (2) Professional calligraphers are invited to conduct a
series of Turing tests to evaluate the gap between model generation results and
human artistic level; (3) Experimental results indicate that the proposed model
is the state-of-the-art among current calligraphy generation methods. The
Turing tests and similarity evaluations validate the effectiveness of the
proposed method.
</p>

### Title: GSQA: An End-to-End Model for Generative Spoken Question Answering. (arXiv:2312.09781v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2312.09781](http://arxiv.org/abs/2312.09781)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09781] GSQA: An End-to-End Model for Generative Spoken Question Answering](http://arxiv.org/abs/2312.09781) #generative`
* Summary: <p>In recent advancements in spoken question answering (QA), end-to-end models
have made significant strides. However, previous research has primarily focused
on extractive span selection. While this extractive-based approach is effective
when answers are present directly within the input, it falls short in
addressing abstractive questions, where answers are not directly extracted but
inferred from the given information. To bridge this gap, we introduce the first
end-to-end Generative Spoken Question Answering (GSQA) model that empowers the
system to engage in abstractive reasoning. The challenge in training our GSQA
model lies in the absence of a spoken abstractive QA dataset. We propose using
text models for initialization and leveraging the extractive QA dataset to
transfer knowledge from the text generative model to the spoken generative
model. Experimental results indicate that our model surpasses the previous
extractive model by 3% on extractive QA datasets. Furthermore, the GSQA model
has only been fine-tuned on the spoken extractive QA dataset. Despite not
having seen any spoken abstractive QA data, it can still closely match the
performance of the cascade model. In conclusion, our GSQA model shows the
potential to generalize to a broad spectrum of questions, thus further
expanding spoken question answering capabilities of abstractive QA. Our code is
available at
\href{https://voidful.github.io/GSQA}{https://voidful.github.io/GSQA}
</p>

### Title: A Malware Classification Survey on Adversarial Attacks and Defences. (arXiv:2312.09636v1 [cs.CR])
* Paper URL: [http://arxiv.org/abs/2312.09636](http://arxiv.org/abs/2312.09636)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09636] A Malware Classification Survey on Adversarial Attacks and Defences](http://arxiv.org/abs/2312.09636) #generative`
* Summary: <p>As the number and complexity of malware attacks continue to increase, there
is an urgent need for effective malware detection systems. While deep learning
models are effective at detecting malware, they are vulnerable to adversarial
attacks. Attacks like this can create malicious files that are resistant to
detection, creating a significant cybersecurity risk. Recent research has seen
the development of several adversarial attack and response approaches aiming at
strengthening deep learning models' resilience to such attacks. This survey
study offers an in-depth look at current research in adversarial attack and
defensive strategies for malware classification in cybersecurity. The methods
are classified into four categories: generative models, feature-based
approaches, ensemble methods, and hybrid tactics. The article outlines
cutting-edge procedures within each area, assessing their benefits and
drawbacks. Each topic presents cutting-edge approaches and explores their
advantages and disadvantages. In addition, the study discusses the datasets and
assessment criteria that are often utilized on this subject. Finally, it
identifies open research difficulties and suggests future study options. This
document is a significant resource for malware categorization and cyber
security researchers and practitioners.
</p>

### Title: Unbiasing Enhanced Sampling on a High-dimensional Free Energy Surface with Deep Generative Model. (arXiv:2312.09404v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2312.09404](http://arxiv.org/abs/2312.09404)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09404] Unbiasing Enhanced Sampling on a High-dimensional Free Energy Surface with Deep Generative Model](http://arxiv.org/abs/2312.09404) #generative`
* Summary: <p>Biased enhanced sampling methods utilizing collective variables (CVs) are
powerful tools for sampling conformational ensembles. Due to high intrinsic
dimensions, efficiently generating conformational ensembles for complex systems
requires enhanced sampling on high-dimensional free energy surfaces. While
methods like temperature-accelerated molecular dynamics (TAMD) can adopt many
CVs in a simulation, unbiasing the simulation requires accurate modeling of a
high-dimensional CV probability distribution, which is challenging for
traditional density estimation techniques. Here we propose an unbiasing method
based on the score-based diffusion model, a deep generative learning method
that excels in density estimation across complex data landscapes. We test the
score-based diffusion unbiasing method on TAMD simulations. The results
demonstrate that this unbiasing approach significantly outperforms traditional
unbiasing methods, and can generate accurate unbiased conformational ensembles
for simulations with a number of CVs higher than usual ranges.
</p>

### Title: Automating reward function configuration for drug design. (arXiv:2312.09865v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2312.09865](http://arxiv.org/abs/2312.09865)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09865] Automating reward function configuration for drug design](http://arxiv.org/abs/2312.09865) #generative`
* Summary: <p>Designing reward functions that guide generative molecular design (GMD)
algorithms to desirable areas of chemical space is of critical importance in
AI-driven drug discovery. Traditionally, this has been a manual and error-prone
task; the selection of appropriate computational methods to approximate
biological assays is challenging and the aggregation of computed values into a
single score even more so, leading to potential reliance on trial-and-error
approaches. We propose a novel approach for automated reward configuration that
relies solely on experimental data, mitigating the challenges of manual reward
adjustment on drug discovery projects. Our method achieves this by constructing
a ranking over experimental data based on Pareto dominance over the
multi-objective space, then training a neural network to approximate the reward
function such that rankings determined by the predicted reward correlate with
those determined by the Pareto dominance relation. We validate our method using
two case studies. In the first study we simulate Design-Make-Test-Analyse
(DMTA) cycles by alternating reward function updates and generative runs guided
by that function. We show that the learned function adapts over time to yield
compounds that score highly with respect to evaluation functions taken from the
literature. In the second study we apply our algorithm to historical data from
four real drug discovery projects. We show that our algorithm yields reward
functions that outperform the predictive accuracy of human-defined functions,
achieving an improvement of up to 0.4 in Spearman's correlation against a
ground truth evaluation function that encodes the target drug profile for that
project. Our method provides an efficient data-driven way to configure reward
functions for GMD, and serves as a strong baseline for future research into
transformative approaches for the automation of drug discovery.
</p>

## anomaly
### Title: TAB: Text-Align Anomaly Backbone Model for Industrial Inspection Tasks. (arXiv:2312.09480v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09480](http://arxiv.org/abs/2312.09480)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09480] TAB: Text-Align Anomaly Backbone Model for Industrial Inspection Tasks](http://arxiv.org/abs/2312.09480) #anomaly`
* Summary: <p>In recent years, the focus on anomaly detection and localization in
industrial inspection tasks has intensified. While existing studies have
demonstrated impressive outcomes, they often rely heavily on extensive training
datasets or robust features extracted from pre-trained models trained on
diverse datasets like ImageNet. In this work, we propose a novel framework
leveraging the visual-linguistic CLIP model to adeptly train a backbone model
tailored to the manufacturing domain. Our approach concurrently considers
visual and text-aligned embedding spaces for normal and abnormal conditions.
The resulting pre-trained backbone markedly enhances performance in industrial
downstream tasks, particularly in anomaly detection and localization. Notably,
this improvement is substantiated through experiments conducted on multiple
datasets such as MVTecAD, BTAD, and KSDD2. Furthermore, using our pre-trained
backbone weights allows previous works to achieve superior performance in
few-shot scenarios with less training data. The proposed anomaly backbone
provides a foundation model for more precise anomaly detection and
localization.
</p>

### Title: Entropy Causal Graphs for Multivariate Time Series Anomaly Detection. (arXiv:2312.09478v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2312.09478](http://arxiv.org/abs/2312.09478)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09478] Entropy Causal Graphs for Multivariate Time Series Anomaly Detection](http://arxiv.org/abs/2312.09478) #anomaly`
* Summary: <p>Many multivariate time series anomaly detection frameworks have been proposed
and widely applied. However, most of these frameworks do not consider intrinsic
relationships between variables in multivariate time series data, thus ignoring
the causal relationship among variables and degrading anomaly detection
performance. This work proposes a novel framework called CGAD, an entropy
Causal Graph for multivariate time series Anomaly Detection. CGAD utilizes
transfer entropy to construct graph structures that unveil the underlying
causal relationships among time series data. Weighted graph convolutional
networks combined with causal convolutions are employed to model both the
causal graph structures and the temporal patterns within multivariate time
series data. Furthermore, CGAD applies anomaly scoring, leveraging median
absolute deviation-based normalization to improve the robustness of the anomaly
identification process. Extensive experiments demonstrate that CGAD outperforms
state-of-the-art methods on real-world datasets with a 15% average improvement
based on three different multivariate time series anomaly detection metrics.
</p>

## in-context
## memory
### Title: Continual Adversarial Defense. (arXiv:2312.09481v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09481](http://arxiv.org/abs/2312.09481)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09481] Continual Adversarial Defense](http://arxiv.org/abs/2312.09481) #memory`
* Summary: <p>In response to the rapidly evolving nature of adversarial attacks on a
monthly basis, numerous defenses have been proposed to generalize against as
many known attacks as possible. However, designing a defense method that can
generalize to all types of attacks, including unseen ones, is not realistic
because the environment in which defense systems operate is dynamic and
comprises various unique attacks used by many attackers. The defense system
needs to upgrade itself by utilizing few-shot defense feedback and efficient
memory. Therefore, we propose the first continual adversarial defense (CAD)
framework that adapts to any attacks in a dynamic scenario, where various
attacks emerge stage by stage. In practice, CAD is modeled under four
principles: (1) continual adaptation to new attacks without catastrophic
forgetting, (2) few-shot adaptation, (3) memory-efficient adaptation, and (4)
high accuracy on both clean and adversarial images. We leverage cutting-edge
continual learning, few-shot learning, and ensemble learning techniques to
qualify the principles. Experiments conducted on CIFAR-10 and ImageNet-100
validate the effectiveness of our approach against multiple stages of 10 modern
adversarial attacks and significant improvements over 10 baseline methods. In
particular, CAD is capable of quickly adapting with minimal feedback and a low
cost of defense failure, while maintaining good performance against old
attacks. Our research sheds light on a brand-new paradigm for continual defense
adaptation against dynamic and evolving attacks.
</p>

### Title: LAENeRF: Local Appearance Editing for Neural Radiance Fields. (arXiv:2312.09913v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09913](http://arxiv.org/abs/2312.09913)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09913] LAENeRF: Local Appearance Editing for Neural Radiance Fields](http://arxiv.org/abs/2312.09913) #memory`
* Summary: <p>Due to the omnipresence of Neural Radiance Fields (NeRFs), the interest
towards editable implicit 3D representations has surged over the last years.
However, editing implicit or hybrid representations as used for NeRFs is
difficult due to the entanglement of appearance and geometry encoded in the
model parameters. Despite these challenges, recent research has shown first
promising steps towards photorealistic and non-photorealistic appearance edits.
The main open issues of related work include limited interactivity, a lack of
support for local edits and large memory requirements, rendering them less
useful in practice. We address these limitations with LAENeRF, a unified
framework for photorealistic and non-photorealistic appearance editing of
NeRFs. To tackle local editing, we leverage a voxel grid as starting point for
region selection. We learn a mapping from expected ray terminations to final
output color, which can optionally be supervised by a style loss, resulting in
a framework which can perform photorealistic and non-photorealistic appearance
editing of selected regions. Relying on a single point per ray for our mapping,
we limit memory requirements and enable fast optimization. To guarantee
interactivity, we compose the output color using a set of learned, modifiable
base colors, composed with additive layer mixing. Compared to concurrent work,
LAENeRF enables recoloring and stylization while keeping processing time low.
Furthermore, we demonstrate that our approach surpasses baseline methods both
quantitatively and qualitatively.
</p>

### Title: SlimmeRF: Slimmable Radiance Fields. (arXiv:2312.10034v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.10034](http://arxiv.org/abs/2312.10034)
* Code URL: [https://github.com/shiran-yuan/slimmerf](https://github.com/shiran-yuan/slimmerf)
* Copy Paste: `<input type="checkbox">[[2312.10034] SlimmeRF: Slimmable Radiance Fields](http://arxiv.org/abs/2312.10034) #memory`
* Summary: <p>Neural Radiance Field (NeRF) and its variants have recently emerged as
successful methods for novel view synthesis and 3D scene reconstruction.
However, most current NeRF models either achieve high accuracy using large
model sizes, or achieve high memory-efficiency by trading off accuracy. This
limits the applicable scope of any single model, since high-accuracy models
might not fit in low-memory devices, and memory-efficient models might not
satisfy high-quality requirements. To this end, we present SlimmeRF, a model
that allows for instant test-time trade-offs between model size and accuracy
through slimming, thus making the model simultaneously suitable for scenarios
with different computing budgets. We achieve this through a newly proposed
algorithm named Tensorial Rank Incrementation (TRaIn) which increases the rank
of the model's tensorial representation gradually during training. We also
observe that our model allows for more effective trade-offs in sparse-view
scenarios, at times even achieving higher accuracy after being slimmed. We
credit this to the fact that erroneous information such as floaters tend to be
stored in components corresponding to higher ranks. Our implementation is
available at https://github.com/Shiran-Yuan/SlimmeRF.
</p>

### Title: Point Transformer V3: Simpler, Faster, Stronger. (arXiv:2312.10035v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.10035](http://arxiv.org/abs/2312.10035)
* Code URL: [https://github.com/pointcept/pointtransformerv3](https://github.com/pointcept/pointtransformerv3)
* Copy Paste: `<input type="checkbox">[[2312.10035] Point Transformer V3: Simpler, Faster, Stronger](http://arxiv.org/abs/2312.10035) #memory`
* Summary: <p>This paper is not motivated to seek innovation within the attention
mechanism. Instead, it focuses on overcoming the existing trade-offs between
accuracy and efficiency within the context of point cloud processing,
leveraging the power of scale. Drawing inspiration from recent advances in 3D
large-scale representation learning, we recognize that model performance is
more influenced by scale than by intricate design. Therefore, we present Point
Transformer V3 (PTv3), which prioritizes simplicity and efficiency over the
accuracy of certain mechanisms that are minor to the overall performance after
scaling, such as replacing the precise neighbor search by KNN with an efficient
serialized neighbor mapping of point clouds organized with specific patterns.
This principle enables significant scaling, expanding the receptive field from
16 to 1024 points while remaining efficient (a 3x increase in processing speed
and a 10x improvement in memory efficiency compared with its predecessor,
PTv2). PTv3 attains state-of-the-art results on over 20 downstream tasks that
span both indoor and outdoor scenarios. Further enhanced with multi-dataset
joint training, PTv3 pushes these results to a higher level.
</p>

### Title: DECLASSIFLOW: A Static Analysis for Modeling Non-Speculative Knowledge to Relax Speculative Execution Security Measures (Full Version). (arXiv:2312.09336v1 [cs.CR])
* Paper URL: [http://arxiv.org/abs/2312.09336](http://arxiv.org/abs/2312.09336)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09336] DECLASSIFLOW: A Static Analysis for Modeling Non-Speculative Knowledge to Relax Speculative Execution Security Measures (Full Version)](http://arxiv.org/abs/2312.09336) #memory`
* Summary: <p>Speculative execution attacks undermine the security of constant-time
programming, the standard technique used to prevent microarchitectural side
channels in security-sensitive software such as cryptographic code.
Constant-time code must therefore also deploy a defense against speculative
execution attacks to prevent leakage of secret data stored in memory or the
processor registers. Unfortunately, contemporary defenses, such as speculative
load hardening (SLH), can only satisfy this strong security guarantee at a very
high performance cost.
</p>
<p>This paper proposes DECLASSIFLOW, a static program analysis and protection
framework to efficiently protect constant-time code from speculative leakage.
DECLASSIFLOW models "attacker knowledge" -- data which is inherently
transmitted (or, implicitly declassified) by the code's non-speculative
execution -- and statically removes protection on such data from points in the
program where it is already guaranteed to leak non-speculatively. Overall,
DECLASSIFLOW ensures that data which never leaks during the non-speculative
execution does not leak during speculative execution, but with lower overhead
than conservative protections like SLH.
</p>

### Title: Random resistive memory-based deep extreme point learning machine for unified visual processing. (arXiv:2312.09262v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2312.09262](http://arxiv.org/abs/2312.09262)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09262] Random resistive memory-based deep extreme point learning machine for unified visual processing](http://arxiv.org/abs/2312.09262) #memory`
* Summary: <p>Visual sensors, including 3D LiDAR, neuromorphic DVS sensors, and
conventional frame cameras, are increasingly integrated into edge-side
intelligent machines. Realizing intensive multi-sensory data analysis directly
on edge intelligent machines is crucial for numerous emerging edge
applications, such as augmented and virtual reality and unmanned aerial
vehicles, which necessitates unified data representation, unprecedented
hardware energy efficiency and rapid model training. However, multi-sensory
data are intrinsically heterogeneous, causing significant complexity in the
system development for edge-side intelligent machines. In addition, the
performance of conventional digital hardware is limited by the physically
separated processing and memory units, known as the von Neumann bottleneck, and
the physical limit of transistor scaling, which contributes to the slowdown of
Moore's law. These limitations are further intensified by the tedious training
of models with ever-increasing sizes. We propose a novel hardware-software
co-design, random resistive memory-based deep extreme point learning machine
(DEPLM), that offers efficient unified point set analysis. We show the system's
versatility across various data modalities and two different learning tasks.
Compared to a conventional digital hardware-based system, our co-design system
achieves huge energy efficiency improvements and training cost reduction when
compared to conventional systems. Our random resistive memory-based deep
extreme point learning machine may pave the way for energy-efficient and
training-friendly edge AI across various data modalities and tasks.
</p>

### Title: Exploiting Symmetric Temporally Sparse BPTT for Efficient RNN Training. (arXiv:2312.09391v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2312.09391](http://arxiv.org/abs/2312.09391)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09391] Exploiting Symmetric Temporally Sparse BPTT for Efficient RNN Training](http://arxiv.org/abs/2312.09391) #memory`
* Summary: <p>Recurrent Neural Networks (RNNs) are useful in temporal sequence tasks.
However, training RNNs involves dense matrix multiplications which require
hardware that can support a large number of arithmetic operations and memory
accesses. Implementing online training of RNNs on the edge calls for optimized
algorithms for an efficient deployment on hardware. Inspired by the spiking
neuron model, the Delta RNN exploits temporal sparsity during inference by
skipping over the update of hidden states from those inactivated neurons whose
change of activation across two timesteps is below a defined threshold. This
work describes a training algorithm for Delta RNNs that exploits temporal
sparsity in the backward propagation phase to reduce computational requirements
for training on the edge. Due to the symmetric computation graphs of forward
and backward propagation during training, the gradient computation of
inactivated neurons can be skipped. Results show a reduction of $\sim$80% in
matrix operations for training a 56k parameter Delta LSTM on the Fluent Speech
Commands dataset with negligible accuracy loss. Logic simulations of a hardware
accelerator designed for the training algorithm show 2-10X speedup in matrix
computations for an activation sparsity range of 50%-90%. Additionally, we show
that the proposed Delta RNN training will be useful for online incremental
learning on edge devices with limited computing resources.
</p>

### Title: Sketch and shift: a robust decoder for compressive clustering. (arXiv:2312.09940v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2312.09940](http://arxiv.org/abs/2312.09940)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09940] Sketch and shift: a robust decoder for compressive clustering](http://arxiv.org/abs/2312.09940) #memory`
* Summary: <p>Compressive learning is an emerging approach to drastically reduce the memory
footprint of large-scale learning, by first summarizing a large dataset into a
low-dimensional sketch vector, and then decoding from this sketch the latent
information needed for learning. In light of recent progress on information
preservation guarantees for sketches based on random features, a major
objective is to design easy-to-tune algorithms (called decoders) to robustly
and efficiently extract this information. To address the underlying non-convex
optimization problems, various heuristics have been proposed. In the case of
compressive clustering, the standard heuristic is CL-OMPR, a variant of sliding
Frank-Wolfe. Yet, CL-OMPR is hard to tune, and the examination of its
robustness was overlooked. In this work, we undertake a scrutinized examination
of CL-OMPR to circumvent its limitations. In particular, we show how this
algorithm can fail to recover the clusters even in advantageous scenarios. To
gain insight, we show how the deficiencies of this algorithm can be attributed
to optimization difficulties related to the structure of a correlation function
appearing at core steps of the algorithm. To address these limitations, we
propose an alternative decoder offering substantial improvements over CL-OMPR.
Its design is notably inspired from the mean shift algorithm, a classic
approach to detect the local maxima of kernel density estimators. The proposed
algorithm can extract clustering information from a sketch of the MNIST dataset
that is 10 times smaller than previously.
</p>

### Title: Accelerating Neural Network Training: A Brief Review. (arXiv:2312.10024v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2312.10024](http://arxiv.org/abs/2312.10024)
* Code URL: [https://github.com/sahilnokhwal/annt](https://github.com/sahilnokhwal/annt)
* Copy Paste: `<input type="checkbox">[[2312.10024] Accelerating Neural Network Training: A Brief Review](http://arxiv.org/abs/2312.10024) #memory`
* Summary: <p>The process of training a deep neural network is characterized by significant
time requirements and associated costs. Although researchers have made
considerable progress in this area, further work is still required due to
resource constraints. This study examines innovative approaches to expedite the
training process of deep neural networks (DNN), with specific emphasis on three
state-of-the-art models such as ResNet50, Vision Transformer (ViT), and
EfficientNet. The research utilizes sophisticated methodologies, including
Gradient Accumulation (GA), Automatic Mixed Precision (AMP), and Pin Memory
(PM), in order to optimize performance and accelerate the training procedure.
</p>
<p>The study examines the effects of these methodologies on the DNN models
discussed earlier, assessing their efficacy with regard to training rate and
computational efficacy. The study showcases the efficacy of including GA as a
strategic approach, resulting in a noteworthy decrease in the duration required
for training. This enables the models to converge at a faster pace. The
utilization of AMP enhances the speed of computations by taking advantage of
the advantages offered by lower precision arithmetic while maintaining the
correctness of the model.
</p>
<p>Furthermore, this study investigates the application of Pin Memory as a
strategy to enhance the efficiency of data transmission between the central
processing unit and the graphics processing unit, thereby offering a promising
opportunity for enhancing overall performance. The experimental findings
demonstrate that the combination of these sophisticated methodologies
significantly accelerates the training of DNNs, offering vital insights for
experts seeking to improve the effectiveness of deep learning processes.
</p>

## few-shot
### Title: High-Resolution Maps of Left Atrial Displacements and Strains Estimated with 3D CINE MRI and Unsupervised Neural Networks. (arXiv:2312.09387v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09387](http://arxiv.org/abs/2312.09387)
* Code URL: [https://github.com/cgalaz01/aladdin_cmr_la](https://github.com/cgalaz01/aladdin_cmr_la)
* Copy Paste: `<input type="checkbox">[[2312.09387] High-Resolution Maps of Left Atrial Displacements and Strains Estimated with 3D CINE MRI and Unsupervised Neural Networks](http://arxiv.org/abs/2312.09387) #few-shot`
* Summary: <p>The functional analysis of the left atrium (LA) is important for evaluating
cardiac health and understanding diseases like atrial fibrillation. Cine MRI is
ideally placed for the detailed 3D characterisation of LA motion and
deformation, but it is lacking appropriate acquisition and analysis tools. In
this paper, we present Analysis for Left Atrial Displacements and Deformations
using unsupervIsed neural Networks, \textit{Aladdin}, to automatically and
reliably characterise regional LA deformations from high-resolution 3D Cine
MRI. The tool includes: an online few-shot segmentation network (Aladdin-S), an
online unsupervised image registration network (Aladdin-R), and a strain
calculations pipeline tailored to the LA. We create maps of LA Displacement
Vector Field (DVF) magnitude and LA principal strain values from images of 10
healthy volunteers and 8 patients with cardiovascular disease (CVD). We
additionally create an atlas of these biomarkers using the data from the
healthy volunteers. Aladdin is able to accurately track the LA wall across the
cardiac cycle and characterize its motion and deformation. The overall DVF
magnitude and principal strain values are significantly higher in the healthy
group vs CVD patients: $2.85 \pm 1.59~mm$ and $0.09 \pm 0.05$ vs $1.96 \pm
0.74~mm$ and $0.03 \pm 0.04$, respectively. The time course of these metrics is
also different in the two groups, with a more marked active contraction phase
observed in the healthy cohort. Finally, utilizing the LA atlas allows us to
identify regional deviations from the population distribution that may indicate
focal tissue abnormalities. The proposed tool for the quantification of novel
regional LA deformation biomarkers should have important clinical applications.
The source code, anonymized images, generated maps and atlas are publicly
available: https://github.com/cgalaz01/aladdin_cmr_la.
</p>

### Title: Improving Cross-domain Few-shot Classification with Multilayer Perceptron. (arXiv:2312.09589v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2312.09589](http://arxiv.org/abs/2312.09589)
* Code URL: [https://github.com/BaiShuanghao/CDFSC-MLP](https://github.com/BaiShuanghao/CDFSC-MLP)
* Copy Paste: `<input type="checkbox">[[2312.09589] Improving Cross-domain Few-shot Classification with Multilayer Perceptron](http://arxiv.org/abs/2312.09589) #few-shot`
* Summary: <p>Cross-domain few-shot classification (CDFSC) is a challenging and tough task
due to the significant distribution discrepancies across different domains. To
address this challenge, many approaches aim to learn transferable
representations. Multilayer perceptron (MLP) has shown its capability to learn
transferable representations in various downstream tasks, such as unsupervised
image classification and supervised concept generalization. However, its
potential in the few-shot settings has yet to be comprehensively explored. In
this study, we investigate the potential of MLP to assist in addressing the
challenges of CDFSC. Specifically, we introduce three distinct frameworks
incorporating MLP in accordance with three types of few-shot classification
methods to verify the effectiveness of MLP. We reveal that MLP can
significantly enhance discriminative capabilities and alleviate distribution
shifts, which can be supported by our expensive experiments involving 10
baseline models and 12 benchmark datasets. Furthermore, our method even
compares favorably against other state-of-the-art CDFSC algorithms.
</p>

### Title: Extending Context Window of Large Language Models via Semantic Compression. (arXiv:2312.09571v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2312.09571](http://arxiv.org/abs/2312.09571)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2312.09571] Extending Context Window of Large Language Models via Semantic Compression](http://arxiv.org/abs/2312.09571) #few-shot`
* Summary: <p>Transformer-based Large Language Models (LLMs) often impose limitations on
the length of the text input to ensure the generation of fluent and relevant
responses. This constraint restricts their applicability in scenarios involving
long texts. We propose a novel semantic compression method that enables
generalization to texts that are 6-8 times longer, without incurring
significant computational costs or requiring fine-tuning. Our proposed
framework draws inspiration from source coding in information theory and
employs a pre-trained model to reduce the semantic redundancy of long inputs
before passing them to the LLMs for downstream tasks. Experimental results
demonstrate that our method effectively extends the context window of LLMs
across a range of tasks including question answering, summarization, few-shot
learning, and information retrieval. Furthermore, the proposed semantic
compression method exhibits consistent fluency in text generation while
reducing the associated computational overhead.
</p>

### Title: Grammatical information in BERT sentence embeddings as two-dimensional arrays. (arXiv:2312.09890v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2312.09890](http://arxiv.org/abs/2312.09890)
* Code URL: [https://github.com/clcl-geneva/blm-snfdisentangling](https://github.com/clcl-geneva/blm-snfdisentangling)
* Copy Paste: `<input type="checkbox">[[2312.09890] Grammatical information in BERT sentence embeddings as two-dimensional arrays](http://arxiv.org/abs/2312.09890) #few-shot`
* Summary: <p>Sentence embeddings induced with various transformer architectures encode
much semantic and syntactic information in a distributed manner in a
one-dimensional array. We investigate whether specific grammatical information
can be accessed in these distributed representations. Using data from a task
developed to test rule-like generalizations, our experiments on detecting
subject-verb agreement yield several promising results. First, we show that
while the usual sentence representations encoded as one-dimensional arrays do
not easily support extraction of rule-like regularities, a two-dimensional
reshaping of these vectors allows various learning architectures to access such
information. Next, we show that various architectures can detect patterns in
these two-dimensional reshaped sentence embeddings and successfully learn a
model based on smaller amounts of simpler training data, which performs well on
more complex test data. This indicates that current sentence embeddings contain
information that is regularly distributed, and which can be captured when the
embeddings are reshaped into higher dimensional arrays. Our results cast light
on representations produced by language models and help move towards developing
few-shot learning approaches.
</p>

