## diffusion
### Title: From Pampas to Pixels: Fine-Tuning Diffusion Models for Ga\'ucho Heritage. (arXiv:2401.05520v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05520](http://arxiv.org/abs/2401.05520)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05520] From Pampas to Pixels: Fine-Tuning Diffusion Models for Ga\'ucho Heritage](http://arxiv.org/abs/2401.05520) #diffusion`
* Summary: <p>Generative AI has become pervasive in society, witnessing significant
advancements in various domains. Particularly in the realm of Text-to-Image
(TTI) models, Latent Diffusion Models (LDMs), showcase remarkable capabilities
in generating visual content based on textual prompts. This paper addresses the
potential of LDMs in representing local cultural concepts, historical figures,
and endangered species. In this study, we use the cultural heritage of Rio
Grande do Sul (RS), Brazil, as an illustrative case. Our objective is to
contribute to the broader understanding of how generative models can help to
capture and preserve the cultural and historical identity of regions. The paper
outlines the methodology, including subject selection, dataset creation, and
the fine-tuning process. The results showcase the images generated, alongside
the challenges and feasibility of each concept. In conclusion, this work shows
the power of these models to represent and preserve unique aspects of diverse
regions and communities.
</p>

### Title: Diffusion Priors for Dynamic View Synthesis from Monocular Videos. (arXiv:2401.05583v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05583](http://arxiv.org/abs/2401.05583)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05583] Diffusion Priors for Dynamic View Synthesis from Monocular Videos](http://arxiv.org/abs/2401.05583) #diffusion`
* Summary: <p>Dynamic novel view synthesis aims to capture the temporal evolution of visual
content within videos. Existing methods struggle to distinguishing between
motion and structure, particularly in scenarios where camera poses are either
unknown or constrained compared to object motion. Furthermore, with information
solely from reference images, it is extremely challenging to hallucinate unseen
regions that are occluded or partially observed in the given videos. To address
these issues, we first finetune a pretrained RGB-D diffusion model on the video
frames using a customization technique. Subsequently, we distill the knowledge
from the finetuned model to a 4D representations encompassing both dynamic and
static Neural Radiance Fields (NeRF) components. The proposed pipeline achieves
geometric consistency while preserving the scene identity. We perform thorough
experiments to evaluate the efficacy of the proposed method qualitatively and
quantitatively. Our results demonstrate the robustness and utility of our
approach in challenging cases, further advancing dynamic novel view synthesis.
</p>

### Title: Object-Centric Diffusion for Efficient Video Editing. (arXiv:2401.05735v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05735](http://arxiv.org/abs/2401.05735)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05735] Object-Centric Diffusion for Efficient Video Editing](http://arxiv.org/abs/2401.05735) #diffusion`
* Summary: <p>Diffusion-based video editing have reached impressive quality and can
transform either the global style, local structure, and attributes of given
video inputs, following textual edit prompts. However, such solutions typically
incur heavy memory and computational costs to generate temporally-coherent
frames, either in the form of diffusion inversion and/or cross-frame attention.
In this paper, we conduct an analysis of such inefficiencies, and suggest
simple yet effective modifications that allow significant speed-ups whilst
maintaining quality. Moreover, we introduce Object-Centric Diffusion, coined as
OCD, to further reduce latency by allocating computations more towards
foreground edited regions that are arguably more important for perceptual
quality. We achieve this by two novel proposals: i) Object-Centric Sampling,
decoupling the diffusion steps spent on salient regions or background,
allocating most of the model capacity to the former, and ii) Object-Centric 3D
Token Merging, which reduces cost of cross-frame attention by fusing redundant
tokens in unimportant background regions. Both techniques are readily
applicable to a given video editing model \textit{without} retraining, and can
drastically reduce its memory and computational cost. We evaluate our proposals
on inversion-based and control-signal-based editing pipelines, and show a
latency reduction up to 10x for a comparable synthesis quality.
</p>

### Title: EraseDiff: Erasing Data Influence in Diffusion Models. (arXiv:2401.05779v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05779](http://arxiv.org/abs/2401.05779)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05779] EraseDiff: Erasing Data Influence in Diffusion Models](http://arxiv.org/abs/2401.05779) #diffusion`
* Summary: <p>In response to data protection regulations and the ``right to be forgotten'',
in this work, we introduce an unlearning algorithm for diffusion models. Our
algorithm equips a diffusion model with a mechanism to mitigate the concerns
related to data memorization. To achieve this, we formulate the unlearning
problem as a bi-level optimization problem, wherein the outer objective is to
preserve the utility of the diffusion model on the remaining data. The inner
objective aims to scrub the information associated with forgetting data by
deviating the learnable generative process from the ground-truth denoising
procedure. To solve the resulting bi-level problem, we adopt a first-order
method, having superior practical performance while being vigilant about the
diffusion process and solving a bi-level problem therein. Empirically, we
demonstrate that our algorithm can preserve the model utility, effectiveness,
and efficiency while removing across two widely-used diffusion models and in
both conditional and unconditional image generation scenarios. In our
experiments, we demonstrate the unlearning of classes, attributes, and even a
race from face and object datasets such as UTKFace, CelebA, CelebA-HQ, and
CIFAR10.
</p>

### Title: HiCAST: Highly Customized Arbitrary Style Transfer with Adapter Enhanced Diffusion Models. (arXiv:2401.05870v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05870](http://arxiv.org/abs/2401.05870)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05870] HiCAST: Highly Customized Arbitrary Style Transfer with Adapter Enhanced Diffusion Models](http://arxiv.org/abs/2401.05870) #diffusion`
* Summary: <p>The goal of Arbitrary Style Transfer (AST) is injecting the artistic features
of a style reference into a given image/video. Existing methods usually focus
on pursuing the balance between style and content, whereas ignoring the
significant demand for flexible and customized stylization results and thereby
limiting their practical application. To address this critical issue, a novel
AST approach namely HiCAST is proposed, which is capable of explicitly
customizing the stylization results according to various source of semantic
clues. In the specific, our model is constructed based on Latent Diffusion
Model (LDM) and elaborately designed to absorb content and style instance as
conditions of LDM. It is characterized by introducing of \textit{Style
Adapter}, which allows user to flexibly manipulate the output results by
aligning multi-level style information and intrinsic knowledge in LDM. Lastly,
we further extend our model to perform video AST. A novel learning objective is
leveraged for video diffusion model training, which significantly improve
cross-frame temporal consistency in the premise of maintaining stylization
strength. Qualitative and quantitative comparisons as well as comprehensive
user studies demonstrate that our HiCAST outperforms the existing SoTA methods
in generating visually plausible stylization results.
</p>

### Title: Efficient Image Deblurring Networks based on Diffusion Models. (arXiv:2401.05907v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05907](http://arxiv.org/abs/2401.05907)
* Code URL: [https://github.com/bnm6900030/swintormer](https://github.com/bnm6900030/swintormer)
* Copy Paste: `<input type="checkbox">[[2401.05907] Efficient Image Deblurring Networks based on Diffusion Models](http://arxiv.org/abs/2401.05907) #diffusion`
* Summary: <p>This article introduces a sliding window model for defocus deblurring that
achieves the best performance to date with extremely low memory usage. Named
Swintormer, the method utilizes a diffusion model to generate latent prior
features that assist in restoring more detailed images. It also extends the
sliding window strategy to specialized Transformer blocks for efficient
inference. Additionally, we have further optimized Multiply-Accumulate
operations (Macs). Compared to the currently top-performing GRL method, our
Swintormer model drastically reduces computational complexity from 140.35 GMACs
to 8.02 GMacs, while also improving the Signal-to-Noise Ratio (SNR) for defocus
deblurring from 27.04 dB to 27.07 dB. This new method allows for the processing
of higher resolution images on devices with limited memory, significantly
expanding potential application scenarios. The article concludes with an
ablation study that provides an in-depth analysis of the impact of each network
module on final performance. The source code and model will be available at the
following website: https://github.com/bnm6900030/swintormer.
</p>

### Title: E$^{2}$GAN: Efficient Training of Efficient GANs for Image-to-Image Translation. (arXiv:2401.06127v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.06127](http://arxiv.org/abs/2401.06127)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.06127] E$^{2}$GAN: Efficient Training of Efficient GANs for Image-to-Image Translation](http://arxiv.org/abs/2401.06127) #diffusion`
* Summary: <p>One highly promising direction for enabling flexible real-time on-device
image editing is utilizing data distillation by leveraging large-scale
text-to-image diffusion models, such as Stable Diffusion, to generate paired
datasets used for training generative adversarial networks (GANs). This
approach notably alleviates the stringent requirements typically imposed by
high-end commercial GPUs for performing image editing with diffusion models.
However, unlike text-to-image diffusion models, each distilled GAN is
specialized for a specific image editing task, necessitating costly training
efforts to obtain models for various concepts. In this work, we introduce and
address a novel research direction: can the process of distilling GANs from
diffusion models be made significantly more efficient? To achieve this goal, we
propose a series of innovative techniques. First, we construct a base GAN model
with generalized features, adaptable to different concepts through fine-tuning,
eliminating the need for training from scratch. Second, we identify crucial
layers within the base GAN model and employ Low-Rank Adaptation (LoRA) with a
simple yet effective rank search process, rather than fine-tuning the entire
base model. Third, we investigate the minimal amount of data necessary for
fine-tuning, further reducing the overall training time. Extensive experiments
show that we can efficiently empower GANs with the ability to perform real-time
high-quality image editing on mobile devices with remarkable reduced training
cost and storage for each concept.
</p>

## self-supervised
### Title: Siamese Networks with Soft Labels for Unsupervised Lesion Detection and Patch Pretraining on Screening Mammograms. (arXiv:2401.05570v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05570](http://arxiv.org/abs/2401.05570)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05570] Siamese Networks with Soft Labels for Unsupervised Lesion Detection and Patch Pretraining on Screening Mammograms](http://arxiv.org/abs/2401.05570) #self-supervised`
* Summary: <p>Self-supervised learning has become a popular way to pretrain a deep learning
model and then transfer it to perform downstream tasks. However, most of these
methods are developed on large-scale image datasets that contain natural
objects with clear textures, outlines, and distinct color contrasts. It remains
uncertain whether these methods are equally effective for medical imaging,
where the regions of interest often blend subtly and indistinctly with the
surrounding tissues. In this study, we propose an alternative method that uses
contralateral mammograms to train a neural network to encode similar embeddings
when a pair contains both normal images and different embeddings when a pair
contains normal and abnormal images. Our approach leverages the natural
symmetry of human body as weak labels to learn to distinguish abnormal lesions
from background tissues in a fully unsupervised manner. Our findings suggest
that it's feasible by incorporating soft labels derived from the Euclidean
distances between the embeddings of the image pairs into the Siamese network
loss. Our method demonstrates superior performance in mammogram patch
classification compared to existing self-supervised learning methods. This
approach not only leverages a vast amount of image data effectively but also
minimizes reliance on costly labels, a significant advantage particularly in
the field of medical imaging.
</p>

### Title: HiCMAE: Hierarchical Contrastive Masked Autoencoder for Self-Supervised Audio-Visual Emotion Recognition. (arXiv:2401.05698v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05698](http://arxiv.org/abs/2401.05698)
* Code URL: [https://github.com/sunlicai/hicmae](https://github.com/sunlicai/hicmae)
* Copy Paste: `<input type="checkbox">[[2401.05698] HiCMAE: Hierarchical Contrastive Masked Autoencoder for Self-Supervised Audio-Visual Emotion Recognition](http://arxiv.org/abs/2401.05698) #self-supervised`
* Summary: <p>Audio-Visual Emotion Recognition (AVER) has garnered increasing attention in
recent years for its critical role in creating emotion-ware intelligent
machines. Previous efforts in this area are dominated by the supervised
learning paradigm. Despite significant progress, supervised learning is meeting
its bottleneck due to the longstanding data scarcity issue in AVER. Motivated
by recent advances in self-supervised learning, we propose Hierarchical
Contrastive Masked Autoencoder (HiCMAE), a novel self-supervised framework that
leverages large-scale self-supervised pre-training on vast unlabeled
audio-visual data to promote the advancement of AVER. Following prior arts in
self-supervised audio-visual representation learning, HiCMAE adopts two primary
forms of self-supervision for pre-training, namely masked data modeling and
contrastive learning. Unlike them which focus exclusively on top-layer
representations while neglecting explicit guidance of intermediate layers,
HiCMAE develops a three-pronged strategy to foster hierarchical audio-visual
feature learning and improve the overall quality of learned representations. To
verify the effectiveness of HiCMAE, we conduct extensive experiments on 9
datasets covering both categorical and dimensional AVER tasks. Experimental
results show that our method significantly outperforms state-of-the-art
supervised and self-supervised audio-visual methods, which indicates that
HiCMAE is a powerful audio-visual emotion representation learner. Codes and
models will be publicly available at https://github.com/sunlicai/HiCMAE.
</p>

### Title: Enhancing Essay Scoring with Adversarial Weights Perturbation and Metric-specific AttentionPooling. (arXiv:2401.05433v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2401.05433](http://arxiv.org/abs/2401.05433)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05433] Enhancing Essay Scoring with Adversarial Weights Perturbation and Metric-specific AttentionPooling](http://arxiv.org/abs/2401.05433) #self-supervised`
* Summary: <p>The objective of this study is to improve automated feedback tools designed
for English Language Learners (ELLs) through the utilization of data science
techniques encompassing machine learning, natural language processing, and
educational data analytics. Automated essay scoring (AES) research has made
strides in evaluating written essays, but it often overlooks the specific needs
of English Language Learners (ELLs) in language development. This study
explores the application of BERT-related techniques to enhance the assessment
of ELLs' writing proficiency within AES.
</p>
<p>To address the specific needs of ELLs, we propose the use of DeBERTa, a
state-of-the-art neural language model, for improving automated feedback tools.
DeBERTa, pretrained on large text corpora using self-supervised learning,
learns universal language representations adaptable to various natural language
understanding tasks. The model incorporates several innovative techniques,
including adversarial training through Adversarial Weights Perturbation (AWP)
and Metric-specific AttentionPooling (6 kinds of AP) for each label in the
competition.
</p>
<p>The primary focus of this research is to investigate the impact of
hyperparameters, particularly the adversarial learning rate, on the performance
of the model. By fine-tuning the hyperparameter tuning process, including the
influence of 6AP and AWP, the resulting models can provide more accurate
evaluations of language proficiency and support tailored learning tasks for
ELLs. This work has the potential to significantly benefit ELLs by improving
their English language proficiency and facilitating their educational journey.
</p>

### Title: Learning Performance-Oriented Control Barrier Functions Under Complex Safety Constraints and Limited Actuation. (arXiv:2401.05629v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2401.05629](http://arxiv.org/abs/2401.05629)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05629] Learning Performance-Oriented Control Barrier Functions Under Complex Safety Constraints and Limited Actuation](http://arxiv.org/abs/2401.05629) #self-supervised`
* Summary: <p>Control Barrier Functions (CBFs) provide an elegant framework for designing
safety filters for nonlinear control systems by constraining their trajectories
to an invariant subset of a prespecified safe set. However, the task of finding
a CBF that concurrently maximizes the volume of the resulting control invariant
set while accommodating complex safety constraints, particularly in high
relative degree systems with actuation constraints, continues to pose a
substantial challenge. In this work, we propose a novel self-supervised
learning framework that holistically addresses these hurdles. Given a Boolean
composition of multiple state constraints that define the safe set, our
approach starts with building a single continuously differentiable function
whose 0-superlevel set provides an inner approximation of the safe set. We then
use this function together with a smooth neural network to parameterize the CBF
candidate. Finally, we design a training loss function based on a
Hamilton-Jacobi partial differential equation to train the CBF while enlarging
the volume of the induced control invariant set. We demonstrate the
effectiveness of our approach via numerical experiments.
</p>

## foundation model
### Title: Surgical-DINO: Adapter Learning of Foundation Model for Depth Estimation in Endoscopic Surgery. (arXiv:2401.06013v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.06013](http://arxiv.org/abs/2401.06013)
* Code URL: [https://github.com/beileicui/surgicaldino](https://github.com/beileicui/surgicaldino)
* Copy Paste: `<input type="checkbox">[[2401.06013] Surgical-DINO: Adapter Learning of Foundation Model for Depth Estimation in Endoscopic Surgery](http://arxiv.org/abs/2401.06013) #foundation model`
* Summary: <p>Purpose: Depth estimation in robotic surgery is vital in 3D reconstruction,
surgical navigation and augmented reality visualization. Although the
foundation model exhibits outstanding performance in many vision tasks,
including depth estimation (e.g., DINOv2), recent works observed its
limitations in medical and surgical domain-specific applications. This work
presents a low-ranked adaptation (LoRA) of the foundation model for surgical
depth estimation. Methods: We design a foundation model-based depth estimation
method, referred to as Surgical-DINO, a low-rank adaptation of the DINOv2 for
depth estimation in endoscopic surgery. We build LoRA layers and integrate them
into DINO to adapt with surgery-specific domain knowledge instead of
conventional fine-tuning. During training, we freeze the DINO image encoder,
which shows excellent visual representation capacity, and only optimize the
LoRA layers and depth decoder to integrate features from the surgical scene.
Results: Our model is extensively validated on a MICCAI challenge dataset of
SCARED, which is collected from da Vinci Xi endoscope surgery. We empirically
show that Surgical-DINO significantly outperforms all the state-of-the-art
models in endoscopic depth estimation tasks. The analysis with ablation studies
has shown evidence of the remarkable effect of our LoRA layers and adaptation.
Conclusion: Surgical-DINO shed some light on the successful adaptation of the
foundation models into the surgical domain for depth estimation. There is clear
evidence in the results that zero-shot prediction on pre-trained weights in
computer vision datasets or naive fine-tuning is not sufficient to use the
foundation model in the surgical domain directly. Code is available at
https://github.com/BeileiCui/SurgicalDINO.
</p>

### Title: VI-PANN: Harnessing Transfer Learning and Uncertainty-Aware Variational Inference for Improved Generalization in Audio Pattern Recognition. (arXiv:2401.05531v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2401.05531](http://arxiv.org/abs/2401.05531)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05531] VI-PANN: Harnessing Transfer Learning and Uncertainty-Aware Variational Inference for Improved Generalization in Audio Pattern Recognition](http://arxiv.org/abs/2401.05531) #foundation model`
* Summary: <p>Transfer learning (TL) is an increasingly popular approach to training deep
learning (DL) models that leverages the knowledge gained by training a
foundation model on diverse, large-scale datasets for use on downstream tasks
where less domain- or task-specific data is available. The literature is rich
with TL techniques and applications; however, the bulk of the research makes
use of deterministic DL models which are often uncalibrated and lack the
ability to communicate a measure of epistemic (model) uncertainty in
prediction. Unlike their deterministic counterparts, Bayesian DL (BDL) models
are often well-calibrated, provide access to epistemic uncertainty for a
prediction, and are capable of achieving competitive predictive performance. In
this study, we propose variational inference pre-trained audio neural networks
(VI-PANNs). VI-PANNs are a variational inference variant of the popular
ResNet-54 architecture which are pre-trained on AudioSet, a large-scale audio
event detection dataset. We evaluate the quality of the resulting uncertainty
when transferring knowledge from VI-PANNs to other downstream acoustic
classification tasks using the ESC-50, UrbanSound8K, and DCASE2013 datasets. We
demonstrate, for the first time, that it is possible to transfer calibrated
uncertainty information along with knowledge from upstream tasks to enhance a
model's capability to perform downstream tasks.
</p>

## generative
### Title: Evaluating Data Augmentation Techniques for Coffee Leaf Disease Classification. (arXiv:2401.05768v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05768](http://arxiv.org/abs/2401.05768)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05768] Evaluating Data Augmentation Techniques for Coffee Leaf Disease Classification](http://arxiv.org/abs/2401.05768) #generative`
* Summary: <p>The detection and classification of diseases in Robusta coffee leaves are
essential to ensure that plants are healthy and the crop yield is kept high.
However, this job requires extensive botanical knowledge and much wasted time.
Therefore, this task and others similar to it have been extensively researched
subjects in image classification. Regarding leaf disease classification, most
approaches have used the more popular PlantVillage dataset while completely
disregarding other datasets, like the Robusta Coffee Leaf (RoCoLe) dataset. As
the RoCoLe dataset is imbalanced and does not have many samples, fine-tuning of
pre-trained models and multiple augmentation techniques need to be used. The
current paper uses the RoCoLe dataset and approaches based on deep learning for
classifying coffee leaf diseases from images, incorporating the pix2pix model
for segmentation and cycle-generative adversarial network (CycleGAN) for
augmentation. Our study demonstrates the effectiveness of Transformer-based
models, online augmentations, and CycleGAN augmentation in improving leaf
disease classification. While synthetic data has limitations, it complements
real data, enhancing model performance. These findings contribute to developing
robust techniques for plant disease detection and classification.
</p>

### Title: An attempt to generate new bridge types from latent space of PixelCNN. (arXiv:2401.05964v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2401.05964](http://arxiv.org/abs/2401.05964)
* Code URL: [https://github.com/QQ583304953/Bridge-PixelCNN](https://github.com/QQ583304953/Bridge-PixelCNN)
* Copy Paste: `<input type="checkbox">[[2401.05964] An attempt to generate new bridge types from latent space of PixelCNN](http://arxiv.org/abs/2401.05964) #generative`
* Summary: <p>Try to generate new bridge types using generative artificial intelligence
technology. Using symmetric structured image dataset of three-span beam bridge,
arch bridge, cable-stayed bridge and suspension bridge , based on Python
programming language, TensorFlow and Keras deep learning platform framework ,
PixelCNN is constructed and trained. The model can capture the statistical
structure of the images and calculate the probability distribution of the next
pixel when the previous pixels are given. From the obtained latent space
sampling, new bridge types different from the training dataset can be
generated. PixelCNN can organically combine different structural components on
the basis of human original bridge types, creating new bridge types that have a
certain degree of human original ability. Autoregressive models cannot
understand the meaning of the sequence, while multimodal models combine
regression and autoregressive models to understand the sequence. Multimodal
models should be the way to achieve artificial general intelligence in the
future.
</p>

### Title: GE-AdvGAN: Improving the transferability of adversarial samples by gradient editing-based adversarial generative model. (arXiv:2401.06031v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.06031](http://arxiv.org/abs/2401.06031)
* Code URL: [https://github.com/lmbtough/ge-advgan](https://github.com/lmbtough/ge-advgan)
* Copy Paste: `<input type="checkbox">[[2401.06031] GE-AdvGAN: Improving the transferability of adversarial samples by gradient editing-based adversarial generative model](http://arxiv.org/abs/2401.06031) #generative`
* Summary: <p>Adversarial generative models, such as Generative Adversarial Networks
(GANs), are widely applied for generating various types of data, i.e., images,
text, and audio. Accordingly, its promising performance has led to the
GAN-based adversarial attack methods in the white-box and black-box attack
scenarios. The importance of transferable black-box attacks lies in their
ability to be effective across different models and settings, more closely
aligning with real-world applications. However, it remains challenging to
retain the performance in terms of transferable adversarial examples for such
methods. Meanwhile, we observe that some enhanced gradient-based transferable
adversarial attack algorithms require prolonged time for adversarial sample
generation. Thus, in this work, we propose a novel algorithm named GE-AdvGAN to
enhance the transferability of adversarial samples whilst improving the
algorithm's efficiency. The main approach is via optimising the training
process of the generator parameters. With the functional and characteristic
similarity analysis, we introduce a novel gradient editing (GE) mechanism and
verify its feasibility in generating transferable samples on various models.
Moreover, by exploring the frequency domain information to determine the
gradient editing direction, GE-AdvGAN can generate highly transferable
adversarial samples while minimizing the execution time in comparison to the
state-of-the-art transferable adversarial attack algorithms. The performance of
GE-AdvGAN is comprehensively evaluated by large-scale experiments on different
datasets, which results demonstrate the superiority of our algorithm. The code
for our algorithm is available at: https://github.com/LMBTough/GE-advGAN
</p>

### Title: RAVEN: Rethinking Adversarial Video Generation with Efficient Tri-plane Networks. (arXiv:2401.06035v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.06035](http://arxiv.org/abs/2401.06035)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.06035] RAVEN: Rethinking Adversarial Video Generation with Efficient Tri-plane Networks](http://arxiv.org/abs/2401.06035) #generative`
* Summary: <p>We present a novel unconditional video generative model designed to address
long-term spatial and temporal dependencies. To capture these dependencies, our
approach incorporates a hybrid explicit-implicit tri-plane representation
inspired by 3D-aware generative frameworks developed for three-dimensional
object representation and employs a singular latent code to model an entire
video sequence. Individual video frames are then synthesized from an
intermediate tri-plane representation, which itself is derived from the primary
latent code. This novel strategy reduces computational complexity by a factor
of $2$ as measured in FLOPs. Consequently, our approach facilitates the
efficient and temporally coherent generation of videos. Moreover, our joint
frame modeling approach, in contrast to autoregressive methods, mitigates the
generation of visual artifacts. We further enhance the model's capabilities by
integrating an optical flow-based module within our Generative Adversarial
Network (GAN) based generator architecture, thereby compensating for the
constraints imposed by a smaller generator size. As a result, our model is
capable of synthesizing high-fidelity video clips at a resolution of
$256\times256$ pixels, with durations extending to more than $5$ seconds at a
frame rate of 30 fps. The efficacy and versatility of our approach are
empirically validated through qualitative and quantitative assessments across
three different datasets comprising both synthetic and real video clips.
</p>

### Title: Designing Heterogeneous LLM Agents for Financial Sentiment Analysis. (arXiv:2401.05799v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2401.05799](http://arxiv.org/abs/2401.05799)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05799] Designing Heterogeneous LLM Agents for Financial Sentiment Analysis](http://arxiv.org/abs/2401.05799) #generative`
* Summary: <p>Large language models (LLMs) have drastically changed the possible ways to
design intelligent systems, shifting the focuses from massive data acquisition
and new modeling training to human alignment and strategical elicitation of the
full potential of existing pre-trained models. This paradigm shift, however, is
not fully realized in financial sentiment analysis (FSA), due to the
discriminative nature of this task and a lack of prescriptive knowledge of how
to leverage generative models in such a context. This study investigates the
effectiveness of the new paradigm, i.e., using LLMs without fine-tuning for
FSA. Rooted in Minsky's theory of mind and emotions, a design framework with
heterogeneous LLM agents is proposed. The framework instantiates specialized
agents using prior domain knowledge of the types of FSA errors and reasons on
the aggregated agent discussions. Comprehensive evaluation on FSA datasets show
that the framework yields better accuracies, especially when the discussions
are substantial. This study contributes to the design foundations and paves new
avenues for LLMs-based FSA. Implications on business and management are also
discussed.
</p>

### Title: Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages. (arXiv:2401.05811v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2401.05811](http://arxiv.org/abs/2401.05811)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05811] Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages](http://arxiv.org/abs/2401.05811) #generative`
* Summary: <p>This article introduces contrastive alignment instructions (AlignInstruct) to
address two challenges in machine translation (MT) on large language models
(LLMs). One is the expansion of supported languages to previously unseen ones.
The second relates to the lack of data in low-resource languages. Model
fine-tuning through MT instructions (MTInstruct) is a straightforward approach
to the first challenge. However, MTInstruct is limited by weak cross-lingual
signals inherent in the second challenge. AlignInstruct emphasizes
cross-lingual supervision via a cross-lingual discriminator built using
statistical word alignments. Our results based on fine-tuning the BLOOMZ models
(1b1, 3b, and 7b1) in up to 24 unseen languages showed that: (1) LLMs can
effectively translate unseen languages using MTInstruct; (2) AlignInstruct led
to consistent improvements in translation quality across 48 translation
directions involving English; (3) Discriminator-based instructions outperformed
their generative counterparts as cross-lingual instructions; (4) AlignInstruct
improved performance in 30 zero-shot directions.
</p>

### Title: Generative Deduplication For Socia Media Data Selection. (arXiv:2401.05883v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2401.05883](http://arxiv.org/abs/2401.05883)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05883] Generative Deduplication For Socia Media Data Selection](http://arxiv.org/abs/2401.05883) #generative`
* Summary: <p>Social media data is plagued by the redundancy problem caused by its noisy
nature, leading to increased training time and model bias. To address this
issue, we propose a novel approach called generative duplication. It aims to
remove duplicate text from noisy social media data and mitigate model bias. By
doing so, it can improve social media language understanding performance and
save training time. Extensive experiments demonstrate that the proposed
generative deduplication can effectively reduce training samples while
improving performance. This evidence suggests the effectiveness of generative
deduplication and its importance in social media language understanding.
</p>

### Title: EpilepsyLLM: Domain-Specific Large Language Model Fine-tuned with Epilepsy Medical Knowledge. (arXiv:2401.05908v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2401.05908](http://arxiv.org/abs/2401.05908)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05908] EpilepsyLLM: Domain-Specific Large Language Model Fine-tuned with Epilepsy Medical Knowledge](http://arxiv.org/abs/2401.05908) #generative`
* Summary: <p>With large training datasets and massive amounts of computing sources, large
language models (LLMs) achieve remarkable performance in comprehensive and
generative ability. Based on those powerful LLMs, the model fine-tuned with
domain-specific datasets posseses more specialized knowledge and thus is more
practical like medical LLMs. However, the existing fine-tuned medical LLMs are
limited to general medical knowledge with English language. For
disease-specific problems, the model's response is inaccurate and sometimes
even completely irrelevant, especially when using a language other than
English. In this work, we focus on the particular disease of Epilepsy with
Japanese language and introduce a customized LLM termed as EpilepsyLLM. Our
model is trained from the pre-trained LLM by fine-tuning technique using
datasets from the epilepsy domain. The datasets contain knowledge of basic
information about disease, common treatment methods and drugs, and important
notes in life and work. The experimental results demonstrate that EpilepsyLLM
can provide more reliable and specialized medical knowledge responses.
</p>

### Title: Improving Large Language Models via Fine-grained Reinforcement Learning with Minimum Editing Constraint. (arXiv:2401.06081v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2401.06081](http://arxiv.org/abs/2401.06081)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.06081] Improving Large Language Models via Fine-grained Reinforcement Learning with Minimum Editing Constraint](http://arxiv.org/abs/2401.06081) #generative`
* Summary: <p>Reinforcement learning (RL) has been widely used in training large language
models~(LLMs) for preventing unexpected outputs, \eg reducing harmfulness and
errors. However, existing RL methods mostly adopt the instance-level reward,
which is unable to provide fine-grained supervision for complex reasoning
tasks, and can not focus on the few key tokens that lead to the incorrectness.
To address it, we propose a new RL method named \textbf{RLMEC} that
incorporates a generative model as the reward model, which is trained by the
erroneous solution rewriting task under the minimum editing constraint, and can
produce token-level rewards for RL training. Based on the generative reward
model, we design the token-level RL objective for training and an
imitation-based regularization for stabilizing RL process. And the both
objectives focus on the learning of the key tokens for the erroneous solution,
reducing the effect of other unimportant tokens. The experiment results on
mathematical tasks and question-answering tasks have demonstrated the
effectiveness of our approach. Our code and data are available at
\url{https://github.com/RUCAIBox/RLMEC}.
</p>

### Title: Autocompletion of Chief Complaints in the Electronic Health Records using Large Language Models. (arXiv:2401.06088v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2401.06088](http://arxiv.org/abs/2401.06088)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.06088] Autocompletion of Chief Complaints in the Electronic Health Records using Large Language Models](http://arxiv.org/abs/2401.06088) #generative`
* Summary: <p>The Chief Complaint (CC) is a crucial component of a patient's medical record
as it describes the main reason or concern for seeking medical care. It
provides critical information for healthcare providers to make informed
decisions about patient care. However, documenting CCs can be time-consuming
for healthcare providers, especially in busy emergency departments. To address
this issue, an autocompletion tool that suggests accurate and well-formatted
phrases or sentences for clinical notes can be a valuable resource for triage
nurses. In this study, we utilized text generation techniques to develop
machine learning models using CC data. In our proposed work, we train a Long
Short-Term Memory (LSTM) model and fine-tune three different variants of
Biomedical Generative Pretrained Transformers (BioGPT), namely
microsoft/biogpt, microsoft/BioGPT-Large, and microsoft/BioGPT-Large-PubMedQA.
Additionally, we tune a prompt by incorporating exemplar CC sentences,
utilizing the OpenAI API of GPT-4. We evaluate the models' performance based on
the perplexity score, modified BERTScore, and cosine similarity score. The
results show that BioGPT-Large exhibits superior performance compared to the
other models. It consistently achieves a remarkably low perplexity score of
1.65 when generating CC, whereas the baseline LSTM model achieves the best
perplexity score of 170. Further, we evaluate and assess the proposed models'
performance and the outcome of GPT-4.0. Our study demonstrates that utilizing
LLMs such as BioGPT, leads to the development of an effective autocompletion
tool for generating CC documentation in healthcare settings.
</p>

### Title: An Augmented Surprise-guided Sequential Learning Framework for Predicting the Melt Pool Geometry. (arXiv:2401.05579v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2401.05579](http://arxiv.org/abs/2401.05579)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05579] An Augmented Surprise-guided Sequential Learning Framework for Predicting the Melt Pool Geometry](http://arxiv.org/abs/2401.05579) #generative`
* Summary: <p>Metal Additive Manufacturing (MAM) has reshaped the manufacturing industry,
offering benefits like intricate design, minimal waste, rapid prototyping,
material versatility, and customized solutions. However, its full industry
adoption faces hurdles, particularly in achieving consistent product quality. A
crucial aspect for MAM's success is understanding the relationship between
process parameters and melt pool characteristics. Integrating Artificial
Intelligence (AI) into MAM is essential. Traditional machine learning (ML)
methods, while effective, depend on large datasets to capture complex
relationships, a significant challenge in MAM due to the extensive time and
resources required for dataset creation. Our study introduces a novel
surprise-guided sequential learning framework, SurpriseAF-BO, signaling a
significant shift in MAM. This framework uses an iterative, adaptive learning
process, modeling the dynamics between process parameters and melt pool
characteristics with limited data, a key benefit in MAM's cyber manufacturing
context. Compared to traditional ML models, our sequential learning method
shows enhanced predictive accuracy for melt pool dimensions. Further improving
our approach, we integrated a Conditional Tabular Generative Adversarial
Network (CTGAN) into our framework, forming the CT-SurpriseAF-BO. This produces
synthetic data resembling real experimental data, improving learning
effectiveness. This enhancement boosts predictive precision without requiring
additional physical experiments. Our study demonstrates the power of advanced
data-driven techniques in cyber manufacturing and the substantial impact of
sequential AI and ML, particularly in overcoming MAM's traditional challenges.
</p>

## anomaly
### Title: Video Anomaly Detection and Explanation via Large Language Models. (arXiv:2401.05702v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05702](http://arxiv.org/abs/2401.05702)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05702] Video Anomaly Detection and Explanation via Large Language Models](http://arxiv.org/abs/2401.05702) #anomaly`
* Summary: <p>Video Anomaly Detection (VAD) aims to localize abnormal events on the
timeline of long-range surveillance videos. Anomaly-scoring-based methods have
been prevailing for years but suffer from the high complexity of thresholding
and low explanability of detection results. In this paper, we conduct pioneer
research on equipping video-based large language models (VLLMs) in the
framework of VAD, making the VAD model free from thresholds and able to explain
the reasons for the detected anomalies. We introduce a novel network module
Long-Term Context (LTC) to mitigate the incapability of VLLMs in long-range
context modeling. We design a three-phase training method to improve the
efficiency of fine-tuning VLLMs by substantially minimizing the requirements
for VAD data and lowering the costs of annotating instruction-tuning data. Our
trained model achieves the top performance on the anomaly videos of the
UCF-Crime and TAD benchmarks, with the AUC improvements of +3.86\% and +4.96\%,
respectively. More impressively, our approach can provide textual explanations
for detected anomalies.
</p>

### Title: Root Cause Analysis on Energy Efficiency with Transfer Entropy Flow. (arXiv:2401.05664v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2401.05664](http://arxiv.org/abs/2401.05664)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05664] Root Cause Analysis on Energy Efficiency with Transfer Entropy Flow](http://arxiv.org/abs/2401.05664) #anomaly`
* Summary: <p>Energy efficiency is a big concern in industrial sectors. Finding the root
cause of anomaly state of energy efficiency can help to improve energy
efficiency of industrial systems and therefore save energy cost. In this
research, we propose to use transfer entropy (TE) for root cause analysis on
energy efficiency of industrial systems. A method, called TE flow, is proposed
in that a TE flow from physical measurements of each subsystem to the energy
efficiency indicator along timeline is considered as causal strength for
diagnosing root cause of anomaly states of energy efficiency of a system. The
copula entropy-based nonparametric TE estimator is used in the proposed method.
We conducted experiments on real data collected from a compressing air system
to verify the proposed method. Experimental results show that the TE flow
method successfully identified the root cause of the energy (in)efficiency of
the system.
</p>

### Title: Graph Spatiotemporal Process for Multivariate Time Series Anomaly Detection with Missing Values. (arXiv:2401.05800v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2401.05800](http://arxiv.org/abs/2401.05800)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05800] Graph Spatiotemporal Process for Multivariate Time Series Anomaly Detection with Missing Values](http://arxiv.org/abs/2401.05800) #anomaly`
* Summary: <p>The detection of anomalies in multivariate time series data is crucial for
various practical applications, including smart power grids, traffic flow
forecasting, and industrial process control. However, real-world time series
data is usually not well-structured, posting significant challenges to existing
approaches: (1) The existence of missing values in multivariate time series
data along variable and time dimensions hinders the effective modeling of
interwoven spatial and temporal dependencies, resulting in important patterns
being overlooked during model training; (2) Anomaly scoring with
irregularly-sampled observations is less explored, making it difficult to use
existing detectors for multivariate series without fully-observed values. In
this work, we introduce a novel framework called GST-Pro, which utilizes a
graph spatiotemporal process and anomaly scorer to tackle the aforementioned
challenges in detecting anomalies on irregularly-sampled multivariate time
series. Our approach comprises two main components. First, we propose a graph
spatiotemporal process based on neural controlled differential equations. This
process enables effective modeling of multivariate time series from both
spatial and temporal perspectives, even when the data contains missing values.
Second, we present a novel distribution-based anomaly scoring mechanism that
alleviates the reliance on complete uniform observations. By analyzing the
predictions of the graph spatiotemporal process, our approach allows anomalies
to be easily detected. Our experimental results show that the GST-Pro method
can effectively detect anomalies in time series data and outperforms
state-of-the-art methods, regardless of whether there are missing values
present in the data. Our code is available: https://github.com/huankoh/GST-Pro.
</p>

## in-context
### Title: POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource Unsupervised Neural Machine Translation. (arXiv:2401.05596v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2401.05596](http://arxiv.org/abs/2401.05596)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05596] POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource Unsupervised Neural Machine Translation](http://arxiv.org/abs/2401.05596) #in-context`
* Summary: <p>Low-resource languages (LRLs) face challenges in supervised neural machine
translation due to limited parallel data, prompting research into unsupervised
methods. Unsupervised neural machine translation (UNMT) methods, including
back-translation, transfer learning, and pivot-based translation, offer
practical solutions for LRL translation, but they are hindered by issues like
synthetic data noise, language bias, and error propagation, which can
potentially be mitigated by Large Language Models (LLMs). LLMs have advanced
NMT with in-context learning (ICL) and supervised fine-tuning methods, but
insufficient training data results in poor performance in LRLs. We argue that
LLMs can mitigate the linguistic noise with auxiliary languages to improve
translations in LRLs. In this paper, we propose Probability-driven Meta-graph
Prompter (POMP), a novel approach employing a dynamic, sampling-based graph of
multiple auxiliary languages to enhance LLMs' translation capabilities for
LRLs. POMP involves constructing a directed acyclic meta-graph for each source
language, from which we dynamically sample multiple paths to prompt LLMs to
mitigate the linguistic noise and improve translations during training. We use
the BLEURT metric to evaluate the translations and back-propagate rewards,
estimated by scores, to update the probabilities of auxiliary languages in the
paths. Our experiments show significant improvements in the translation quality
of three LRLs, demonstrating the effectiveness of our approach.
</p>

### Title: Probing Structured Semantics Understanding and Generation of Language Models via Question Answering. (arXiv:2401.05777v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2401.05777](http://arxiv.org/abs/2401.05777)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05777] Probing Structured Semantics Understanding and Generation of Language Models via Question Answering](http://arxiv.org/abs/2401.05777) #in-context`
* Summary: <p>Recent advancement in the capabilities of large language models (LLMs) has
triggered a new surge in LLMs' evaluation. Most recent evaluation works tends
to evaluate the comprehensive ability of LLMs over series of tasks. However,
the deep structure understanding of natural language is rarely explored. In
this work, we examine the ability of LLMs to deal with structured semantics on
the tasks of question answering with the help of the human-constructed formal
language. Specifically, we implement the inter-conversion of natural and formal
language through in-context learning of LLMs to verify their ability to
understand and generate the structured logical forms. Extensive experiments
with models of different sizes and in different formal languages show that
today's state-of-the-art LLMs' understanding of the logical forms can approach
human level overall, but there still are plenty of room in generating correct
logical forms, which suggest that it is more effective to use LLMs to generate
more natural language training data to reinforce a small model than directly
answering questions with LLMs. Moreover, our results also indicate that models
exhibit considerable sensitivity to different formal languages. In general, the
formal language with the lower the formalization level, i.e. the more similar
it is to natural language, is more LLMs-friendly.
</p>

### Title: Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks. (arXiv:2401.05949v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2401.05949](http://arxiv.org/abs/2401.05949)
* Code URL: [https://github.com/shuaizhao95/iclattack](https://github.com/shuaizhao95/iclattack)
* Copy Paste: `<input type="checkbox">[[2401.05949] Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks](http://arxiv.org/abs/2401.05949) #in-context`
* Summary: <p>In-context learning, a paradigm bridging the gap between pre-training and
fine-tuning, has demonstrated high efficacy in several NLP tasks, especially in
few-shot settings. Unlike traditional fine-tuning methods, in-context learning
adapts pre-trained models to unseen tasks without updating any parameters.
Despite being widely applied, in-context learning is vulnerable to malicious
attacks. In this work, we raise security concerns regarding this paradigm. Our
studies demonstrate that an attacker can manipulate the behavior of large
language models by poisoning the demonstration context, without the need for
fine-tuning the model. Specifically, we have designed a new backdoor attack
method, named ICLAttack, to target large language models based on in-context
learning. Our method encompasses two types of attacks: poisoning demonstration
examples and poisoning prompts, which can make models behave in accordance with
predefined intentions. ICLAttack does not require additional fine-tuning to
implant a backdoor, thus preserving the model's generality. Furthermore, the
poisoned examples are correctly labeled, enhancing the natural stealth of our
attack method. Extensive experimental results across several language models,
ranging in size from 1.3B to 40B parameters, demonstrate the effectiveness of
our attack method, exemplified by a high average attack success rate of 95.0%
across the three datasets on OPT models. Our findings highlight the
vulnerabilities of language models, and we hope this work will raise awareness
of the possible security threats associated with in-context learning.
</p>

### Title: Learning Cognitive Maps from Transformer Representations for Efficient Planning in Partially Observed Environments. (arXiv:2401.05946v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2401.05946](http://arxiv.org/abs/2401.05946)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05946] Learning Cognitive Maps from Transformer Representations for Efficient Planning in Partially Observed Environments](http://arxiv.org/abs/2401.05946) #in-context`
* Summary: <p>Despite their stellar performance on a wide range of tasks, including
in-context tasks only revealed during inference, vanilla transformers and
variants trained for next-token predictions (a) do not learn an explicit world
model of their environment which can be flexibly queried and (b) cannot be used
for planning or navigation. In this paper, we consider partially observed
environments (POEs), where an agent receives perceptually aliased observations
as it navigates, which makes path planning hard. We introduce a transformer
with (multiple) discrete bottleneck(s), TDB, whose latent codes learn a
compressed representation of the history of observations and actions. After
training a TDB to predict the future observation(s) given the history, we
extract interpretable cognitive maps of the environment from its active
bottleneck(s) indices. These maps are then paired with an external solver to
solve (constrained) path planning problems. First, we show that a TDB trained
on POEs (a) retains the near perfect predictive performance of a vanilla
transformer or an LSTM while (b) solving shortest path problems exponentially
faster. Second, a TDB extracts interpretable representations from text
datasets, while reaching higher in-context accuracy than vanilla sequence
models. Finally, in new POEs, a TDB (a) reaches near-perfect in-context
accuracy, (b) learns accurate in-context cognitive maps (c) solves in-context
path planning problems.
</p>

## memory
### Title: DISTWAR: Fast Differentiable Rendering on Raster-based Rendering Pipelines. (arXiv:2401.05345v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05345](http://arxiv.org/abs/2401.05345)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05345] DISTWAR: Fast Differentiable Rendering on Raster-based Rendering Pipelines](http://arxiv.org/abs/2401.05345) #memory`
* Summary: <p>Differentiable rendering is a technique used in an important emerging class
of visual computing applications that involves representing a 3D scene as a
model that is trained from 2D images using gradient descent. Recent works (e.g.
3D Gaussian Splatting) use a rasterization pipeline to enable rendering high
quality photo-realistic imagery at high speeds from these learned 3D models.
These methods have been demonstrated to be very promising, providing
state-of-art quality for many important tasks. However, training a model to
represent a scene is still a time-consuming task even when using powerful GPUs.
In this work, we observe that the gradient computation phase during training is
a significant bottleneck on GPUs due to the large number of atomic operations
that need to be processed. These atomic operations overwhelm atomic units in
the L2 partitions causing stalls. To address this challenge, we leverage the
observations that during the gradient computation: (1) for most warps, all
threads atomically update the same memory locations; and (2) warps generate
varying amounts of atomic traffic (since some threads may be inactive). We
propose DISTWAR, a software-approach to accelerate atomic operations based on
two key ideas: First, we enable warp-level reduction of threads at the SM
sub-cores using registers to leverage the locality in intra-warp atomic
updates. Second, we distribute the atomic computation between the warp-level
reduction at the SM and the L2 atomic units to increase the throughput of
atomic computation. Warps with many threads performing atomic updates to the
same memory locations are scheduled at the SM, and the rest using L2 atomic
units. We implement DISTWAR using existing warp-level primitives. We evaluate
DISTWAR on widely used raster-based differentiable rendering workloads. We
demonstrate significant speedups of 2.44x on average (up to 5.7x).
</p>

### Title: Developing a Resource-Constraint EdgeAI model for Surface Defect Detection. (arXiv:2401.05355v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05355](http://arxiv.org/abs/2401.05355)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05355] Developing a Resource-Constraint EdgeAI model for Surface Defect Detection](http://arxiv.org/abs/2401.05355) #memory`
* Summary: <p>Resource constraints have restricted several EdgeAI applications to machine
learning inference approaches, where models are trained on the cloud and
deployed to the edge device. This poses challenges such as bandwidth, latency,
and privacy associated with storing data off-site for model building. Training
on the edge device can overcome these challenges by eliminating the need to
transfer data to another device for storage and model development. On-device
training also provides robustness to data variations as models can be retrained
on newly acquired data to improve performance. We, therefore, propose a
lightweight EdgeAI architecture modified from Xception, for on-device training
in a resource-constraint edge environment. We evaluate our model on a PCB
defect detection task and compare its performance against existing lightweight
models - MobileNetV2, EfficientNetV2B0, and MobileViT-XXS. The results of our
experiment show that our model has a remarkable performance with a test
accuracy of 73.45% without pre-training. This is comparable to the test
accuracy of non-pre-trained MobileViT-XXS (75.40%) and much better than other
non-pre-trained models (MobileNetV2 - 50.05%, EfficientNetV2B0 - 54.30%). The
test accuracy of our model without pre-training is comparable to pre-trained
MobileNetV2 model - 75.45% and better than pre-trained EfficientNetV2B0 model -
58.10%. In terms of memory efficiency, our model performs better than
EfficientNetV2B0 and MobileViT-XXS. We find that the resource efficiency of
machine learning models does not solely depend on the number of parameters but
also depends on architectural considerations. Our method can be applied to
other resource-constraint applications while maintaining significant
performance.
</p>

### Title: VLP: Vision Language Planning for Autonomous Driving. (arXiv:2401.05577v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05577](http://arxiv.org/abs/2401.05577)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05577] VLP: Vision Language Planning for Autonomous Driving](http://arxiv.org/abs/2401.05577) #memory`
* Summary: <p>Autonomous driving is a complex and challenging task that aims at safe motion
planning through scene understanding and reasoning. While vision-only
autonomous driving methods have recently achieved notable performance, through
enhanced scene understanding, several key issues, including lack of reasoning,
low generalization performance and long-tail scenarios, still need to be
addressed. In this paper, we present VLP, a novel Vision-Language-Planning
framework that exploits language models to bridge the gap between linguistic
understanding and autonomous driving. VLP enhances autonomous driving systems
by strengthening both the source memory foundation and the self-driving car's
contextual understanding. VLP achieves state-of-the-art end-to-end planning
performance on the challenging NuScenes dataset by achieving 35.9\% and 60.5\%
reduction in terms of average L2 error and collision rates, respectively,
compared to the previous best method. Moreover, VLP shows improved performance
in challenging long-tail scenarios and strong generalization capabilities when
faced with new urban environments.
</p>

### Title: FourCastNeXt: Improving FourCastNet Training with Limited Compute. (arXiv:2401.05584v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05584](http://arxiv.org/abs/2401.05584)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05584] FourCastNeXt: Improving FourCastNet Training with Limited Compute](http://arxiv.org/abs/2401.05584) #memory`
* Summary: <p>Recently, the FourCastNet Neural Earth System Model (NESM) has shown
impressive results on predicting various atmospheric variables, trained on the
ERA5 reanalysis dataset. While FourCastNet enjoys quasi-linear time and memory
complexity in sequence length compared to quadratic complexity in vanilla
transformers, training FourCastNet on ERA5 from scratch still requires large
amount of compute resources, which is expensive or even inaccessible to most
researchers. In this work, we will show improved methods that can train
FourCastNet using only 1% of the compute required by the baseline, while
maintaining model performance or par or even better than the baseline.
</p>

### Title: Implications of Noise in Resistive Memory on Deep Neural Networks for Image Classification. (arXiv:2401.05820v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2401.05820](http://arxiv.org/abs/2401.05820)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05820] Implications of Noise in Resistive Memory on Deep Neural Networks for Image Classification](http://arxiv.org/abs/2401.05820) #memory`
* Summary: <p>Resistive memory is a promising alternative to SRAM, but is also an
inherently unstable device that requires substantial effort to ensure correct
read and write operations. To avoid the associated costs in terms of area, time
and energy, the present work is concerned with exploring how much noise in
memory operations can be tolerated by image classification tasks based on
neural networks. We introduce a special noisy operator that mimics the noise in
an exemplary resistive memory unit, explore the resilience of convolutional
neural networks on the CIFAR-10 classification task, and discuss a couple of
countermeasures to improve this resilience.
</p>

### Title: MGARD: A multigrid framework for high-performance, error-controlled data compression and refactoring. (arXiv:2401.05994v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05994](http://arxiv.org/abs/2401.05994)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05994] MGARD: A multigrid framework for high-performance, error-controlled data compression and refactoring](http://arxiv.org/abs/2401.05994) #memory`
* Summary: <p>We describe MGARD, a software providing MultiGrid Adaptive Reduction for
floating-point scientific data on structured and unstructured grids. With
exceptional data compression capability and precise error control, MGARD
addresses a wide range of requirements, including storage reduction,
high-performance I/O, and in-situ data analysis. It features a unified
application programming interface (API) that seamlessly operates across diverse
computing architectures. MGARD has been optimized with highly-tuned GPU kernels
and efficient memory and device management mechanisms, ensuring scalable and
rapid operations.
</p>

### Title: Transformers are Multi-State RNNs. (arXiv:2401.06104v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2401.06104](http://arxiv.org/abs/2401.06104)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.06104] Transformers are Multi-State RNNs](http://arxiv.org/abs/2401.06104) #memory`
* Summary: <p>Transformers are considered conceptually different compared to the previous
generation of state-of-the-art NLP models - recurrent neural networks (RNNs).
In this work, we demonstrate that decoder-only transformers can in fact be
conceptualized as infinite multi-state RNNs - an RNN variant with unlimited
hidden state size. We further show that pretrained transformers can be
converted into $\textit{finite}$ multi-state RNNs by fixing the size of their
hidden state. We observe that several existing transformers cache compression
techniques can be framed as such conversion policies, and introduce a novel
policy, TOVA, which is simpler compared to these policies. Our experiments with
several long range tasks indicate that TOVA outperforms all other baseline
policies, while being nearly on par with the full (infinite) model, and using
in some cases only $\frac{1}{8}$ of the original cache size. Our results
indicate that transformer decoder LLMs often behave in practice as RNNs. They
also lay out the option of mitigating one of their most painful computational
bottlenecks - the size of their cache memory. We publicly release our code at
https://github.com/schwartz-lab-NLP/TOVA.
</p>

### Title: SoK: Analysis techniques for WebAssembly. (arXiv:2401.05943v1 [cs.CR])
* Paper URL: [http://arxiv.org/abs/2401.05943](http://arxiv.org/abs/2401.05943)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05943] SoK: Analysis techniques for WebAssembly](http://arxiv.org/abs/2401.05943) #memory`
* Summary: <p>WebAssembly is a low-level bytecode language that allows high-level languages
like C, C++, and Rust to be executed in the browser at near-native performance.
In recent years, WebAssembly has gained widespread adoption is now natively
supported by all modern browsers. However, vulnerabilities in memory-unsafe
languages, like C and C++, can translate into vulnerabilities in WebAssembly
binaries. Unfortunately, most WebAssembly binaries are compiled from such
memory-unsafe languages, and these vulnerabilities have been shown to be
practical in real-world scenarios. WebAssembly smart contracts have also been
found to be vulnerable, causing significant financial loss. Additionally,
WebAssembly has been used for malicious purposes like cryptojacking. To address
these issues, several analysis techniques for WebAssembly binaries have been
proposed. In this paper, we conduct a comprehensive literature review of these
techniques and categorize them based on their analysis strategy and objectives.
Furthermore, we compare and evaluate the techniques using quantitative data,
highlighting their strengths and weaknesses. In addition, one of the main
contributions of this paper is the identification of future research directions
based on the thorough literature review conducted.
</p>

### Title: EsaCL: Efficient Continual Learning of Sparse Models. (arXiv:2401.05667v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2401.05667](http://arxiv.org/abs/2401.05667)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05667] EsaCL: Efficient Continual Learning of Sparse Models](http://arxiv.org/abs/2401.05667) #memory`
* Summary: <p>A key challenge in the continual learning setting is to efficiently learn a
sequence of tasks without forgetting how to perform previously learned tasks.
Many existing approaches to this problem work by either retraining the model on
previous tasks or by expanding the model to accommodate new tasks. However,
these approaches typically suffer from increased storage and computational
requirements, a problem that is worsened in the case of sparse models due to
need for expensive re-training after sparsification. To address this challenge,
we propose a new method for efficient continual learning of sparse models
(EsaCL) that can automatically prune redundant parameters without adversely
impacting the model's predictive power, and circumvent the need of retraining.
We conduct a theoretical analysis of loss landscapes with parameter pruning,
and design a directional pruning (SDP) strategy that is informed by the
sharpness of the loss function with respect to the model parameters. SDP
ensures model with minimal loss of predictive accuracy, accelerating the
learning of sparse models at each stage. To accelerate model update, we
introduce an intelligent data selection (IDS) strategy that can identify
critical instances for estimating loss landscape, yielding substantially
improved data efficiency. The results of our experiments show that EsaCL
achieves performance that is competitive with the state-of-the-art methods on
three continual learning benchmarks, while using substantially reduced memory
and computational resources.
</p>

## few-shot
### Title: PartSTAD: 2D-to-3D Part Segmentation Task Adaptation. (arXiv:2401.05906v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2401.05906](http://arxiv.org/abs/2401.05906)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05906] PartSTAD: 2D-to-3D Part Segmentation Task Adaptation](http://arxiv.org/abs/2401.05906) #few-shot`
* Summary: <p>We introduce PartSTAD, a method designed for the task adaptation of 2D-to-3D
segmentation lifting. Recent studies have highlighted the advantages of
utilizing 2D segmentation models to achieve high-quality 3D segmentation
through few-shot adaptation. However, previous approaches have focused on
adapting 2D segmentation models for domain shift to rendered images and
synthetic text descriptions, rather than optimizing the model specifically for
3D segmentation. Our proposed task adaptation method finetunes a 2D bounding
box prediction model with an objective function for 3D segmentation. We
introduce weights for 2D bounding boxes for adaptive merging and learn the
weights using a small additional neural network. Additionally, we incorporate
SAM, a foreground segmentation model on a bounding box, to improve the
boundaries of 2D segments and consequently those of 3D segmentation. Our
experiments on the PartNet-Mobility dataset show significant improvements with
our task adaptation approach, achieving a 7.0%p increase in mIoU and a 5.2%p
improvement in mAP_50 for semantic and instance segmentation compared to the
SotA few-shot 3D segmentation model.
</p>

### Title: Dynamic Indoor Fingerprinting Localization based on Few-Shot Meta-Learning with CSI Images. (arXiv:2401.05711v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2401.05711](http://arxiv.org/abs/2401.05711)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2401.05711] Dynamic Indoor Fingerprinting Localization based on Few-Shot Meta-Learning with CSI Images](http://arxiv.org/abs/2401.05711) #few-shot`
* Summary: <p>While fingerprinting localization is favored for its effectiveness, it is
hindered by high data acquisition costs and the inaccuracy of static
database-based estimates. Addressing these issues, this letter presents an
innovative indoor localization method using a data-efficient meta-learning
algorithm. This approach, grounded in the ``Learning to Learn'' paradigm of
meta-learning, utilizes historical localization tasks to improve adaptability
and learning efficiency in dynamic indoor environments. We introduce a
task-weighted loss to enhance knowledge transfer within this framework. Our
comprehensive experiments confirm the method's robustness and superiority over
current benchmarks, achieving a notable 23.13\% average gain in Mean Euclidean
Distance, particularly effective in scenarios with limited CSI data.
</p>

