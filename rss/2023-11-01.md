## diffusion
### Title: Battle of the Backbones: A Large-Scale Comparison of Pretrained Models across Computer Vision Tasks. (arXiv:2310.19909v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2310.19909](http://arxiv.org/abs/2310.19909)
* Code URL: [https://github.com/hsouri/battle-of-the-backbones](https://github.com/hsouri/battle-of-the-backbones)
* Copy Paste: `<input type="checkbox">[[2310.19909] Battle of the Backbones: A Large-Scale Comparison of Pretrained Models across Computer Vision Tasks](http://arxiv.org/abs/2310.19909) #diffusion`
* Summary: <p>Neural network based computer vision systems are typically built on a
backbone, a pretrained or randomly initialized feature extractor. Several years
ago, the default option was an ImageNet-trained convolutional neural network.
However, the recent past has seen the emergence of countless backbones
pretrained using various algorithms and datasets. While this abundance of
choice has led to performance increases for a range of systems, it is difficult
for practitioners to make informed decisions about which backbone to choose.
Battle of the Backbones (BoB) makes this choice easier by benchmarking a
diverse suite of pretrained models, including vision-language models, those
trained via self-supervised learning, and the Stable Diffusion backbone, across
a diverse set of computer vision tasks ranging from classification to object
detection to OOD generalization and more. Furthermore, BoB sheds light on
promising directions for the research community to advance computer vision by
illuminating strengths and weakness of existing approaches through a
comprehensive analysis conducted on more than 1500 training runs. While vision
transformers (ViTs) and self-supervised learning (SSL) are increasingly
popular, we find that convolutional neural networks pretrained in a supervised
fashion on large training sets still perform best on most tasks among the
models we consider. Moreover, in apples-to-apples comparisons on the same
architectures and similarly sized pretraining datasets, we find that SSL
backbones are highly competitive, indicating that future works should perform
SSL pretraining with advanced architectures and larger pretraining datasets. We
release the raw results of our experiments along with code that allows
researchers to put their own backbones through the gauntlet here:
https://github.com/hsouri/Battle-of-the-Backbones
</p>

### Title: 'Person' == Light-skinned, Western Man, and Sexualization of Women of Color: Stereotypes in Stable Diffusion. (arXiv:2310.19981v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2310.19981](http://arxiv.org/abs/2310.19981)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.19981] 'Person' == Light-skinned, Western Man, and Sexualization of Women of Color: Stereotypes in Stable Diffusion](http://arxiv.org/abs/2310.19981) #diffusion`
* Summary: <p>We study stereotypes embedded within one of the most popular text-to-image
generators: Stable Diffusion. We examine what stereotypes of gender and
nationality/continental identity does Stable Diffusion display in the absence
of such information i.e. what gender and nationality/continental identity is
assigned to `a person', or to `a person from Asia'. Using vision-language model
CLIP's cosine similarity to compare images generated by CLIP-based Stable
Diffusion v2.1 verified by manual examination, we chronicle results from 136
prompts (50 results/prompt) of front-facing images of persons from 6 different
continents, 27 nationalities and 3 genders. We observe how Stable Diffusion
outputs of `a person' without any additional gender/nationality information
correspond closest to images of men and least with persons of nonbinary gender,
and to persons from Europe/North America over Africa/Asia, pointing towards
Stable Diffusion having a concerning representation of personhood to be a
European/North American man. We also show continental stereotypes and resultant
harms e.g. a person from Oceania is deemed to be Australian/New Zealander over
Papua New Guinean, pointing to the erasure of Indigenous Oceanic peoples, who
form a majority over descendants of colonizers both in Papua New Guinea and in
Oceania overall. Finally, we unexpectedly observe a pattern of
oversexualization of women, specifically Latin American, Mexican, Indian and
Egyptian women relative to other nationalities, measured through an NSFW
detector. This demonstrates how Stable Diffusion perpetuates Western
fetishization of women of color through objectification in media, which if left
unchecked will amplify this stereotypical representation. Image datasets are
made publicly available.
</p>

### Title: Beyond U: Making Diffusion Models Faster & Lighter. (arXiv:2310.20092v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.20092](http://arxiv.org/abs/2310.20092)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20092] Beyond U: Making Diffusion Models Faster & Lighter](http://arxiv.org/abs/2310.20092) #diffusion`
* Summary: <p>Diffusion models are a family of generative models that yield record-breaking
performance in tasks such as image synthesis, video generation, and molecule
design. Despite their capabilities, their efficiency, especially in the reverse
denoising process, remains a challenge due to slow convergence rates and high
computational costs. In this work, we introduce an approach that leverages
continuous dynamical systems to design a novel denoising network for diffusion
models that is more parameter-efficient, exhibits faster convergence, and
demonstrates increased noise robustness. Experimenting with denoising
probabilistic diffusion models, our framework operates with approximately a
quarter of the parameters and 30% of the Floating Point Operations (FLOPs)
compared to standard U-Nets in Denoising Diffusion Probabilistic Models
(DDPMs). Furthermore, our model is up to 70% faster in inference than the
baseline models when measured in equal conditions while converging to better
quality solutions.
</p>

### Title: SemanticBoost: Elevating Motion Generation with Augmented Textual Cues. (arXiv:2310.20323v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2310.20323](http://arxiv.org/abs/2310.20323)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20323] SemanticBoost: Elevating Motion Generation with Augmented Textual Cues](http://arxiv.org/abs/2310.20323) #diffusion`
* Summary: <p>Current techniques face difficulties in generating motions from intricate
semantic descriptions, primarily due to insufficient semantic annotations in
datasets and weak contextual understanding. To address these issues, we present
SemanticBoost, a novel framework that tackles both challenges simultaneously.
Our framework comprises a Semantic Enhancement module and a Context-Attuned
Motion Denoiser (CAMD). The Semantic Enhancement module extracts supplementary
semantics from motion data, enriching the dataset's textual description and
ensuring precise alignment between text and motion data without depending on
large language models. On the other hand, the CAMD approach provides an
all-encompassing solution for generating high-quality, semantically consistent
motion sequences by effectively capturing context information and aligning the
generated motion with the given textual descriptions. Distinct from existing
methods, our approach can synthesize accurate orientational movements, combined
motions based on specific body part descriptions, and motions generated from
complex, extended sentences. Our experimental results demonstrate that
SemanticBoost, as a diffusion-based method, outperforms auto-regressive-based
techniques, achieving cutting-edge performance on the Humanml3D dataset while
maintaining realistic and smooth motion generation quality.
</p>

### Title: Learning Gradient Fields for Scalable and Generalizable Irregular Packing. (arXiv:2310.19814v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.19814](http://arxiv.org/abs/2310.19814)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.19814] Learning Gradient Fields for Scalable and Generalizable Irregular Packing](http://arxiv.org/abs/2310.19814) #diffusion`
* Summary: <p>The packing problem, also known as cutting or nesting, has diverse
applications in logistics, manufacturing, layout design, and atlas generation.
It involves arranging irregularly shaped pieces to minimize waste while
avoiding overlap. Recent advances in machine learning, particularly
reinforcement learning, have shown promise in addressing the packing problem.
In this work, we delve deeper into a novel machine learning-based approach that
formulates the packing problem as conditional generative modeling. To tackle
the challenges of irregular packing, including object validity constraints and
collision avoidance, our method employs the score-based diffusion model to
learn a series of gradient fields. These gradient fields encode the
correlations between constraint satisfaction and the spatial relationships of
polygons, learned from teacher examples. During the testing phase, packing
solutions are generated using a coarse-to-fine refinement mechanism guided by
the learned gradient fields. To enhance packing feasibility and optimality, we
introduce two key architectural designs: multi-scale feature extraction and
coarse-to-fine relation extraction. We conduct experiments on two typical
industrial packing domains, considering translations only. Empirically, our
approach demonstrates spatial utilization rates comparable to, or even
surpassing, those achieved by the teacher algorithm responsible for training
data generation. Additionally, it exhibits some level of generalization to
shape variations. We are hopeful that this method could pave the way for new
possibilities in solving the packing problem.
</p>

### Title: FuXi-Extreme: Improving extreme rainfall and wind forecasts with diffusion model. (arXiv:2310.19822v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.19822](http://arxiv.org/abs/2310.19822)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.19822] FuXi-Extreme: Improving extreme rainfall and wind forecasts with diffusion model](http://arxiv.org/abs/2310.19822) #diffusion`
* Summary: <p>Significant advancements in the development of machine learning (ML) models
for weather forecasting have produced remarkable results. State-of-the-art
ML-based weather forecast models, such as FuXi, have demonstrated superior
statistical forecast performance in comparison to the high-resolution forecasts
(HRES) of the European Centre for Medium-Range Weather Forecasts (ECMWF).
However, ML models face a common challenge: as forecast lead times increase,
they tend to generate increasingly smooth predictions, leading to an
underestimation of the intensity of extreme weather events. To address this
challenge, we developed the FuXi-Extreme model, which employs a denoising
diffusion probabilistic model (DDPM) to restore finer-scale details in the
surface forecast data generated by the FuXi model in 5-day forecasts. An
evaluation of extreme total precipitation ($\textrm{TP}$), 10-meter wind speed
($\textrm{WS10}$), and 2-meter temperature ($\textrm{T2M}$) illustrates the
superior performance of FuXi-Extreme over both FuXi and HRES. Moreover, when
evaluating tropical cyclone (TC) forecasts based on International Best Track
Archive for Climate Stewardship (IBTrACS) dataset, both FuXi and FuXi-Extreme
shows superior performance in TC track forecasts compared to HRES, but they
show inferior performance in TC intensity forecasts in comparison to HRES.
</p>

### Title: Scaling Riemannian Diffusion Models. (arXiv:2310.20030v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.20030](http://arxiv.org/abs/2310.20030)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20030] Scaling Riemannian Diffusion Models](http://arxiv.org/abs/2310.20030) #diffusion`
* Summary: <p>Riemannian diffusion models draw inspiration from standard Euclidean space
diffusion models to learn distributions on general manifolds. Unfortunately,
the additional geometric complexity renders the diffusion transition term
inexpressible in closed form, so prior methods resort to imprecise
approximations of the score matching training objective that degrade
performance and preclude applications in high dimensions. In this work, we
reexamine these approximations and propose several practical improvements. Our
key observation is that most relevant manifolds are symmetric spaces, which are
much more amenable to computation. By leveraging and combining various
ans\"{a}tze, we can quickly compute relevant quantities to high precision. On
low dimensional datasets, our correction produces a noticeable improvement,
allowing diffusion to compete with other methods. Additionally, we show that
our method enables us to scale to high dimensional tasks on nontrivial
manifolds. In particular, we model QCD densities on $SU(n)$ lattices and
contrastively learned embeddings on high dimensional hyperspheres.
</p>

## self-supervised
### Title: From Denoising Training to Test-Time Adaptation: Enhancing Domain Generalization for Medical Image Segmentation. (arXiv:2310.20271v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2310.20271](http://arxiv.org/abs/2310.20271)
* Code URL: [https://github.com/wenruxue/detta](https://github.com/wenruxue/detta)
* Copy Paste: `<input type="checkbox">[[2310.20271] From Denoising Training to Test-Time Adaptation: Enhancing Domain Generalization for Medical Image Segmentation](http://arxiv.org/abs/2310.20271) #self-supervised`
* Summary: <p>In medical image segmentation, domain generalization poses a significant
challenge due to domain shifts caused by variations in data acquisition devices
and other factors. These shifts are particularly pronounced in the most common
scenario, which involves only single-source domain data due to privacy
concerns. To address this, we draw inspiration from the self-supervised
learning paradigm that effectively discourages overfitting to the source
domain. We propose the Denoising Y-Net (DeY-Net), a novel approach
incorporating an auxiliary denoising decoder into the basic U-Net architecture.
The auxiliary decoder aims to perform denoising training, augmenting the
domain-invariant representation that facilitates domain generalization.
Furthermore, this paradigm provides the potential to utilize unlabeled data.
Building upon denoising training, we propose Denoising Test Time Adaptation
(DeTTA) that further: (i) adapts the model to the target domain in a
sample-wise manner, and (ii) adapts to the noise-corrupted input. Extensive
experiments conducted on widely-adopted liver segmentation benchmarks
demonstrate significant domain generalization improvements over our baseline
and state-of-the-art results compared to other methods. Code is available at
https://github.com/WenRuxue/DeTTA.
</p>

### Title: Self-supervised Pre-training for Precipitation Post-processor. (arXiv:2310.20187v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.20187](http://arxiv.org/abs/2310.20187)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20187] Self-supervised Pre-training for Precipitation Post-processor](http://arxiv.org/abs/2310.20187) #self-supervised`
* Summary: <p>Securing sufficient forecast lead time for local precipitation is essential
for preventing hazardous weather events. Nonetheless, global warming-induced
climate change is adding to the challenge of accurately predicting severe
precipitation events, such as heavy rainfall. In this work, we propose a deep
learning-based precipitation post-processor approach to numerical weather
prediction (NWP) models. The precipitation post-processor consists of (i)
self-supervised pre-training, where parameters of encoder are pre-trained on
the reconstruction of masked variables of the atmospheric physics domain, and
(ii) transfer learning on precipitation segmentation tasks (target domain) from
the pre-trained encoder. We also introduce a heuristic labeling approach for
effectively training class-imbalanced datasets. Our experiment results in
precipitation correction for regional NWP show that the proposed method
outperforms other approaches.
</p>

## foundation model
### Title: Res-Tuning: A Flexible and Efficient Tuning Paradigm via Unbinding Tuner from Backbone. (arXiv:2310.19859v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2310.19859](http://arxiv.org/abs/2310.19859)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.19859] Res-Tuning: A Flexible and Efficient Tuning Paradigm via Unbinding Tuner from Backbone](http://arxiv.org/abs/2310.19859) #foundation model`
* Summary: <p>Parameter-efficient tuning has become a trend in transferring large-scale
foundation models to downstream applications. Existing methods typically embed
some light-weight tuners into the backbone, where both the design and the
learning of the tuners are highly dependent on the base model. This work offers
a new tuning paradigm, dubbed Res-Tuning, which intentionally unbinds tuners
from the backbone. With both theoretical and empirical evidence, we show that
popular tuning approaches have their equivalent counterparts under our
unbinding formulation, and hence can be integrated into our framework
effortlessly. Thanks to the structural disentanglement, we manage to free the
design of tuners from the network architecture, facilitating flexible
combination of various tuning strategies. We further propose a memory-efficient
variant of Res-Tuning, where the bypass i.e., formed by a sequence of tuners)
is effectively detached from the main branch, such that the gradients are
back-propagated only to the tuners but not to the backbone. Such a detachment
also allows one-time backbone forward for multi-task inference. Extensive
experiments on both discriminative and generative tasks demonstrate the
superiority of our method over existing alternatives from the perspectives of
efficacy and efficiency. Project page:
$\href{https://res-tuning.github.io/}{\textit{https://res-tuning.github.io/}}$.
</p>

### Title: Deep Learning for Spatiotemporal Big Data: A Vision on Opportunities and Challenges. (arXiv:2310.19957v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.19957](http://arxiv.org/abs/2310.19957)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.19957] Deep Learning for Spatiotemporal Big Data: A Vision on Opportunities and Challenges](http://arxiv.org/abs/2310.19957) #foundation model`
* Summary: <p>With advancements in GPS, remote sensing, and computational simulation, an
enormous volume of spatiotemporal data is being collected at an increasing
speed from various application domains, spanning Earth sciences, agriculture,
smart cities, and public safety. Such emerging geospatial and spatiotemporal
big data, coupled with recent advances in deep learning technologies, foster
new opportunities to solve problems that have not been possible before. For
instance, remote sensing researchers can potentially train a foundation model
using Earth imagery big data for numerous land cover and land use modeling
tasks. Coastal modelers can train AI surrogates to speed up numerical
simulations. However, the distinctive characteristics of spatiotemporal big
data pose new challenges for deep learning technologies. This vision paper
introduces various types of spatiotemporal big data, discusses new research
opportunities in the realm of deep learning applied to spatiotemporal big data,
lists the unique challenges, and identifies several future research needs.
</p>

### Title: AutoMixer for Improved Multivariate Time-Series Forecasting on BizITOps Data. (arXiv:2310.20280v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.20280](http://arxiv.org/abs/2310.20280)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20280] AutoMixer for Improved Multivariate Time-Series Forecasting on BizITOps Data](http://arxiv.org/abs/2310.20280) #foundation model`
* Summary: <p>The efficiency of business processes relies on business key performance
indicators (Biz-KPIs), that can be negatively impacted by IT failures. BizITOps
data fuses both Biz-KPIs and IT event channels together as multivariate time
series data. Forecasting Biz-KPIs in advance can enhance efficiency and revenue
through proactive corrective measures. However, BizITOps data generally exhibit
both useful and noisy inter-channel interactions between Biz-KPIs and IT events
that need to be effectively decoupled. This leads to suboptimal forecasting
performance when existing multivariate forecasting models are employed. To
address this, we introduce AutoMixer, a time-series Foundation Model (FM)
approach, grounded on the novel technique of channel-compressed pretrain and
finetune workflows. AutoMixer leverages an AutoEncoder for channel-compressed
pretraining and integrates it with the advanced TSMixer model for multivariate
time series forecasting. This fusion greatly enhances the potency of TSMixer
for accurate forecasts and also generalizes well across several downstream
tasks. Through detailed experiments and dashboard analytics, we show
AutoMixer's capability to consistently improve the Biz-KPI's forecasting
accuracy (by 11-15%) which directly translates to actionable business insights.
</p>

## generative
### Title: Addressing Weak Decision Boundaries in Image Classification by Leveraging Web Search and Generative Models. (arXiv:2310.19986v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.19986](http://arxiv.org/abs/2310.19986)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.19986] Addressing Weak Decision Boundaries in Image Classification by Leveraging Web Search and Generative Models](http://arxiv.org/abs/2310.19986) #generative`
* Summary: <p>Machine learning (ML) technologies are known to be riddled with ethical and
operational problems, however, we are witnessing an increasing thrust by
businesses to deploy them in sensitive applications. One major issue among many
is that ML models do not perform equally well for underrepresented groups. This
puts vulnerable populations in an even disadvantaged and unfavorable position.
We propose an approach that leverages the power of web search and generative
models to alleviate some of the shortcomings of discriminative models. We
demonstrate our method on an image classification problem using ImageNet's
People Subtree subset, and show that it is effective in enhancing robustness
and mitigating bias in certain classes that represent vulnerable populations
(e.g., female doctor of color). Our new method is able to (1) identify weak
decision boundaries for such classes; (2) construct search queries for Google
as well as text for generating images through DALL-E 2 and Stable Diffusion;
and (3) show how these newly captured training samples could alleviate
population bias issue. While still improving the model's overall performance
considerably, we achieve a significant reduction (77.30\%) in the model's
gender accuracy disparity. In addition to these improvements, we observed a
notable enhancement in the classifier's decision boundary, as it is
characterized by fewer weakspots and an increased separation between classes.
Although we showcase our method on vulnerable populations in this study, the
proposed technique is extendable to a wide range of problems and domains.
</p>

### Title: Visible to Thermal image Translation for improving visual task in low light conditions. (arXiv:2310.20190v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2310.20190](http://arxiv.org/abs/2310.20190)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20190] Visible to Thermal image Translation for improving visual task in low light conditions](http://arxiv.org/abs/2310.20190) #generative`
* Summary: <p>Several visual tasks, such as pedestrian detection and image-to-image
translation, are challenging to accomplish in low light using RGB images. Heat
variation of objects in thermal images can be used to overcome this. In this
work, an end-to-end framework, which consists of a generative network and a
detector network, is proposed to translate RGB image into Thermal ones and
compare generated thermal images with real data. We have collected images from
two different locations using the Parrot Anafi Thermal drone. After that, we
created a two-stream network, preprocessed, augmented, the image data, and
trained the generator and discriminator models from scratch. The findings
demonstrate that it is feasible to translate RGB training data to thermal data
using GAN. As a result, thermal data can now be produced more quickly and
affordably, which is useful for security and surveillance applications.
</p>

### Title: Muscle volume quantification: guiding transformers with anatomical priors. (arXiv:2310.20355v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2310.20355](http://arxiv.org/abs/2310.20355)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20355] Muscle volume quantification: guiding transformers with anatomical priors](http://arxiv.org/abs/2310.20355) #generative`
* Summary: <p>Muscle volume is a useful quantitative biomarker in sports, but also for the
follow-up of degenerative musculo-skelletal diseases. In addition to volume,
other shape biomarkers can be extracted by segmenting the muscles of interest
from medical images. Manual segmentation is still today the gold standard for
such measurements despite being very time-consuming. We propose a method for
automatic segmentation of 18 muscles of the lower limb on 3D Magnetic Resonance
Images to assist such morphometric analysis. By their nature, the tissue of
different muscles is undistinguishable when observed in MR Images. Thus, muscle
segmentation algorithms cannot rely on appearance but only on contour cues.
However, such contours are hard to detect and their thickness varies across
subjects. To cope with the above challenges, we propose a segmentation approach
based on a hybrid architecture, combining convolutional and visual transformer
blocks. We investigate for the first time the behaviour of such hybrid
architectures in the context of muscle segmentation for shape analysis.
Considering the consistent anatomical muscle configuration, we rely on
transformer blocks to capture the longrange relations between the muscles. To
further exploit the anatomical priors, a second contribution of this work
consists in adding a regularisation loss based on an adjacency matrix of
plausible muscle neighbourhoods estimated from the training data. Our
experimental results on a unique database of elite athletes show it is possible
to train complex hybrid models from a relatively small database of large
volumes, while the anatomical prior regularisation favours better predictions.
</p>

### Title: Generative retrieval-augmented ontologic graph and multi-agent strategies for interpretive large language model-based materials design. (arXiv:2310.19998v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2310.19998](http://arxiv.org/abs/2310.19998)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.19998] Generative retrieval-augmented ontologic graph and multi-agent strategies for interpretive large language model-based materials design](http://arxiv.org/abs/2310.19998) #generative`
* Summary: <p>Transformer neural networks show promising capabilities, in particular for
uses in materials analysis, design and manufacturing, including their capacity
to work effectively with both human language, symbols, code, and numerical
data. Here we explore the use of large language models (LLMs) as a tool that
can support engineering analysis of materials, applied to retrieving key
information about subject areas, developing research hypotheses, discovery of
mechanistic relationships across disparate areas of knowledge, and writing and
executing simulation codes for active knowledge generation based on physical
ground truths. When used as sets of AI agents with specific features,
capabilities, and instructions, LLMs can provide powerful problem solution
strategies for applications in analysis and design problems. Our experiments
focus on using a fine-tuned model, MechGPT, developed based on training data in
the mechanics of materials domain. We first affirm how finetuning endows LLMs
with reasonable understanding of domain knowledge. However, when queried
outside the context of learned matter, LLMs can have difficulty to recall
correct information. We show how this can be addressed using
retrieval-augmented Ontological Knowledge Graph strategies that discern how the
model understands what concepts are important and how they are related.
Illustrated for a use case of relating distinct areas of knowledge - here,
music and proteins - such strategies can also provide an interpretable graph
structure with rich information at the node, edge and subgraph level. We
discuss nonlinear sampling strategies and agent-based modeling applied to
complex question answering, code generation and execution in the context of
automated force field development from actively learned Density Functional
Theory (DFT) modeling, and data analysis.
</p>

### Title: Automatic Evaluation of Generative Models with Instruction Tuning. (arXiv:2310.20072v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2310.20072](http://arxiv.org/abs/2310.20072)
* Code URL: [https://github.com/shuhaibm/heap](https://github.com/shuhaibm/heap)
* Copy Paste: `<input type="checkbox">[[2310.20072] Automatic Evaluation of Generative Models with Instruction Tuning](http://arxiv.org/abs/2310.20072) #generative`
* Summary: <p>Automatic evaluation of natural language generation has long been an elusive
goal in NLP.A recent paradigm fine-tunes pre-trained language models to emulate
human judgements for a particular task and evaluation criterion. Inspired by
the generalization ability of instruction-tuned models, we propose a learned
metric based on instruction tuning. To test our approach, we collected HEAP, a
dataset of human judgements across various NLG tasks and evaluation criteria.
Our findings demonstrate that instruction tuning language models on HEAP yields
good performance on many evaluation tasks, though some criteria are less
trivial to learn than others. Further, jointly training on multiple tasks can
yield additional performance improvements, which can be beneficial for future
tasks with little to no human annotated data.
</p>

### Title: Generating Continuations in Multilingual Idiomatic Contexts. (arXiv:2310.20195v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2310.20195](http://arxiv.org/abs/2310.20195)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20195] Generating Continuations in Multilingual Idiomatic Contexts](http://arxiv.org/abs/2310.20195) #generative`
* Summary: <p>The ability to process idiomatic or literal multiword expressions is a
crucial aspect of understanding and generating any language. The task of
generating contextually relevant continuations for narratives containing
idiomatic (or literal) expressions can allow us to test the ability of
generative language models (LMs) in understanding nuanced language containing
non-compositional figurative text. We conduct a series of experiments using
datasets in two distinct languages (English and Portuguese) under three
different training settings (zero-shot, few-shot, and fine-tuned). Our results
suggest that the models are only slightly better at generating continuations
for literal contexts than idiomatic contexts, with exceedingly small margins.
Furthermore, the models studied in this work perform equally well across both
languages, indicating the robustness of generative models in performing this
task.
</p>

### Title: Stochastic Thermodynamics of Learning Generative Parametric Probabilistic Models. (arXiv:2310.19802v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.19802](http://arxiv.org/abs/2310.19802)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.19802] Stochastic Thermodynamics of Learning Generative Parametric Probabilistic Models](http://arxiv.org/abs/2310.19802) #generative`
* Summary: <p>We have formulated generative machine learning problems as the time evolution
of Parametric Probabilistic Models (PPMs), inherently rendering a thermodynamic
process. Then, we have studied the thermodynamic exchange between the model's
parameters, denoted as $\Theta$, and the model's generated samples, denoted as
$X$. We demonstrate that the training dataset and the action of the Stochastic
Gradient Descent (SGD) optimizer serve as a work source that governs the time
evolution of these two subsystems. Our findings reveal that the model learns
through the dissipation of heat during the generation of samples $X$, leading
to an increase in the entropy of the model's parameters, $\Theta$. Thus, the
parameter subsystem acts as a heat reservoir, effectively storing the learned
information. Furthermore, the role of the model's parameters as a heat
reservoir provides valuable thermodynamic insights into the generalization
power of over-parameterized models. This approach offers an unambiguous
framework for computing information-theoretic quantities within deterministic
neural networks by establishing connections with thermodynamic variables. To
illustrate the utility of this framework, we introduce two
information-theoretic metrics: Memorized-information (M-info) and
Learned-information (L-info), which trace the dynamic flow of information
during the learning process of PPMs.
</p>

### Title: Model-Based Reparameterization Policy Gradient Methods: Theory and Practical Algorithms. (arXiv:2310.19927v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.19927](http://arxiv.org/abs/2310.19927)
* Code URL: [https://github.com/agentification/rp_pgm](https://github.com/agentification/rp_pgm)
* Copy Paste: `<input type="checkbox">[[2310.19927] Model-Based Reparameterization Policy Gradient Methods: Theory and Practical Algorithms](http://arxiv.org/abs/2310.19927) #generative`
* Summary: <p>ReParameterization (RP) Policy Gradient Methods (PGMs) have been widely
adopted for continuous control tasks in robotics and computer graphics.
However, recent studies have revealed that, when applied to long-term
reinforcement learning problems, model-based RP PGMs may experience chaotic and
non-smooth optimization landscapes with exploding gradient variance, which
leads to slow convergence. This is in contrast to the conventional belief that
reparameterization methods have low gradient estimation variance in problems
such as training deep generative models. To comprehend this phenomenon, we
conduct a theoretical examination of model-based RP PGMs and search for
solutions to the optimization difficulties. Specifically, we analyze the
convergence of the model-based RP PGMs and pinpoint the smoothness of function
approximators as a major factor that affects the quality of gradient
estimation. Based on our analysis, we propose a spectral normalization method
to mitigate the exploding variance issue caused by long model unrolls. Our
experimental results demonstrate that proper normalization significantly
reduces the gradient variance of model-based RP PGMs. As a result, the
performance of the proposed method is comparable or superior to other gradient
estimators, such as the Likelihood Ratio (LR) gradient estimator. Our code is
available at https://github.com/agentification/RP_PGM.
</p>

### Title: The Acquisition of Physical Knowledge in Generative Neural Networks. (arXiv:2310.19943v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.19943](http://arxiv.org/abs/2310.19943)
* Code URL: [https://github.com/cross32768/PlaNet_PyTorch](https://github.com/cross32768/PlaNet_PyTorch)
* Copy Paste: `<input type="checkbox">[[2310.19943] The Acquisition of Physical Knowledge in Generative Neural Networks](http://arxiv.org/abs/2310.19943) #generative`
* Summary: <p>As children grow older, they develop an intuitive understanding of the
physical processes around them. Their physical understanding develops in
stages, moving along developmental trajectories which have been mapped out
extensively in previous empirical research. Here, we investigate how the
learning trajectories of deep generative neural networks compare to children's
developmental trajectories using physical understanding as a testbed. We
outline an approach that allows us to examine two distinct hypotheses of human
development - stochastic optimization and complexity increase. We find that
while our models are able to accurately predict a number of physical processes,
their learning trajectories under both hypotheses do not follow the
developmental trajectories of children.
</p>

### Title: GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with Learned Models. (arXiv:2310.20025v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.20025](http://arxiv.org/abs/2310.20025)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20025] GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with Learned Models](http://arxiv.org/abs/2310.20025) #generative`
* Summary: <p>Offline goal-conditioned RL (GCRL) offers a feasible paradigm to learn
general-purpose policies from diverse and multi-task offline datasets. Despite
notable recent progress, the predominant offline GCRL methods have been
restricted to model-free approaches, constraining their capacity to tackle
limited data budgets and unseen goal generalization. In this work, we propose a
novel two-stage model-based framework, Goal-conditioned Offline Planning
(GOPlan), including (1) pretraining a prior policy capable of capturing
multi-modal action distribution within the multi-goal dataset; (2) employing
the reanalysis method with planning to generate imagined trajectories for
funetuning policies. Specifically, the prior policy is based on an
advantage-weighted Conditioned Generative Adversarial Networks that exhibits
distinct mode separation to overcome the pitfalls of out-of-distribution (OOD)
actions. For further policy optimization, the reanalysis method generates
high-quality imaginary data by planning with learned models for both
intra-trajectory and inter-trajectory goals. Through experimental evaluations,
we demonstrate that GOPlan achieves state-of-the-art performance on various
offline multi-goal manipulation tasks. Moreover, our results highlight the
superior ability of GOPlan to handle small data budgets and generalize to OOD
goals.
</p>

### Title: Advancing Bayesian Optimization via Learning Correlated Latent Space. (arXiv:2310.20258v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.20258](http://arxiv.org/abs/2310.20258)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20258] Advancing Bayesian Optimization via Learning Correlated Latent Space](http://arxiv.org/abs/2310.20258) #generative`
* Summary: <p>Bayesian optimization is a powerful method for optimizing black-box functions
with limited function evaluations. Recent works have shown that optimization in
a latent space through deep generative models such as variational autoencoders
leads to effective and efficient Bayesian optimization for structured or
discrete data. However, as the optimization does not take place in the input
space, it leads to an inherent gap that results in potentially suboptimal
solutions. To alleviate the discrepancy, we propose Correlated latent space
Bayesian Optimization (CoBO), which focuses on learning correlated latent
spaces characterized by a strong correlation between the distances in the
latent space and the distances within the objective function. Specifically, our
method introduces Lipschitz regularization, loss weighting, and trust region
recoordination to minimize the inherent gap around the promising areas. We
demonstrate the effectiveness of our approach on several optimization tasks in
discrete data, such as molecule design and arithmetic expression fitting, and
achieve high performance within a small budget.
</p>

## anomaly
### Title: A Low-cost Strategic Monitoring Approach for Scalable and Interpretable Error Detection in Deep Neural Networks. (arXiv:2310.20349v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2310.20349](http://arxiv.org/abs/2310.20349)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20349] A Low-cost Strategic Monitoring Approach for Scalable and Interpretable Error Detection in Deep Neural Networks](http://arxiv.org/abs/2310.20349) #anomaly`
* Summary: <p>We present a highly compact run-time monitoring approach for deep computer
vision networks that extracts selected knowledge from only a few (down to
merely two) hidden layers, yet can efficiently detect silent data corruption
originating from both hardware memory and input faults. Building on the insight
that critical faults typically manifest as peak or bulk shifts in the
activation distribution of the affected network layers, we use strategically
placed quantile markers to make accurate estimates about the anomaly of the
current inference as a whole. Importantly, the detector component itself is
kept algorithmically transparent to render the categorization of regular and
abnormal behavior interpretable to a human. Our technique achieves up to ~96%
precision and ~98% recall of detection. Compared to state-of-the-art anomaly
detection techniques, this approach requires minimal compute overhead (as
little as 0.3% with respect to non-supervised inference time) and contributes
to the explainability of the model.
</p>

## in-context
### Title: Which Examples to Annotate for In-Context Learning? Towards Effective and Efficient Selection. (arXiv:2310.20046v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2310.20046](http://arxiv.org/abs/2310.20046)
* Code URL: [https://github.com/amazon-science/adaptive-in-context-learning](https://github.com/amazon-science/adaptive-in-context-learning)
* Copy Paste: `<input type="checkbox">[[2310.20046] Which Examples to Annotate for In-Context Learning? Towards Effective and Efficient Selection](http://arxiv.org/abs/2310.20046) #in-context`
* Summary: <p>Large Language Models (LLMs) can adapt to new tasks via in-context learning
(ICL). ICL is efficient as it does not require any parameter updates to the
trained LLM, but only few annotated examples as input for the LLM. In this
work, we investigate an active learning approach for ICL, where there is a
limited budget for annotating examples. We propose a model-adaptive
optimization-free algorithm, termed AdaICL, which identifies examples that the
model is uncertain about, and performs semantic diversity-based example
selection. Diversity-based sampling improves overall effectiveness, while
uncertainty sampling improves budget efficiency and helps the LLM learn new
information. Moreover, AdaICL poses its sampling strategy as a Maximum Coverage
problem, that dynamically adapts based on the model's feedback and can be
approximately solved via greedy algorithms. Extensive experiments on nine
datasets and seven LLMs show that AdaICL improves performance by 4.4% accuracy
points over SOTA (7.7% relative improvement), is up to 3x more budget-efficient
than performing annotations uniformly at random, while it outperforms SOTA with
2x fewer ICL examples.
</p>

### Title: Interactive Multi-fidelity Learning for Cost-effective Adaptation of Language Model with Sparse Human Supervision. (arXiv:2310.20153v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2310.20153](http://arxiv.org/abs/2310.20153)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20153] Interactive Multi-fidelity Learning for Cost-effective Adaptation of Language Model with Sparse Human Supervision](http://arxiv.org/abs/2310.20153) #in-context`
* Summary: <p>Large language models (LLMs) have demonstrated remarkable capabilities in
various tasks. However, their suitability for domain-specific tasks, is limited
due to their immense scale at deployment, susceptibility to misinformation, and
more importantly, high data annotation costs. We propose a novel Interactive
Multi-Fidelity Learning (IMFL) framework for the cost-effective development of
small domain-specific LMs under limited annotation budgets. Our approach
formulates the domain-specific fine-tuning process as a multi-fidelity learning
problem, focusing on identifying the optimal acquisition strategy that balances
between low-fidelity automatic LLM annotations and high-fidelity human
annotations to maximize model performance. We further propose an
exploration-exploitation query strategy that enhances annotation diversity and
informativeness, incorporating two innovative designs: 1) prompt retrieval that
selects in-context examples from human-annotated samples to improve LLM
annotation, and 2) variable batch size that controls the order for choosing
each fidelity to facilitate knowledge distillation, ultimately enhancing
annotation quality. Extensive experiments on financial and medical tasks
demonstrate that IMFL achieves superior performance compared with single
fidelity annotations. Given a limited budget of human annotation, IMFL
significantly outperforms the human annotation baselines in all four tasks and
achieves very close performance as human annotations on two of the tasks. These
promising results suggest that the high human annotation costs in
domain-specific tasks can be significantly reduced by employing IMFL, which
utilizes fewer human annotations, supplemented with cheaper and faster LLM
(e.g., GPT-3.5) annotations to achieve comparable performance.
</p>

## memory
### Title: NetDistiller: Empowering Tiny Deep Learning via In-Situ Distillation. (arXiv:2310.19820v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.19820](http://arxiv.org/abs/2310.19820)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.19820] NetDistiller: Empowering Tiny Deep Learning via In-Situ Distillation](http://arxiv.org/abs/2310.19820) #memory`
* Summary: <p>Boosting the task accuracy of tiny neural networks (TNNs) has become a
fundamental challenge for enabling the deployments of TNNs on edge devices
which are constrained by strict limitations in terms of memory, computation,
bandwidth, and power supply. To this end, we propose a framework called
NetDistiller to boost the achievable accuracy of TNNs by treating them as
sub-networks of a weight-sharing teacher constructed by expanding the number of
channels of the TNN. Specifically, the target TNN model is jointly trained with
the weight-sharing teacher model via (1) gradient surgery to tackle the
gradient conflicts between them and (2) uncertainty-aware distillation to
mitigate the overfitting of the teacher model. Extensive experiments across
diverse tasks validate NetDistiller's effectiveness in boosting TNNs'
achievable accuracy over state-of-the-art methods. Our code is available at
https://github.com/GATECH-EIC/NetDistiller.
</p>

### Title: Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents. (arXiv:2310.19923v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2310.19923](http://arxiv.org/abs/2310.19923)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.19923] Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents](http://arxiv.org/abs/2310.19923) #memory`
* Summary: <p>Text embedding models have emerged as powerful tools for transforming
sentences into fixed-sized feature vectors that encapsulate semantic
information. While these models are essential for tasks like information
retrieval, semantic clustering, and text re-ranking, most existing open-source
models, especially those built on architectures like BERT, struggle to
represent lengthy documents and often resort to truncation. One common approach
to mitigate this challenge involves splitting documents into smaller paragraphs
for embedding. However, this strategy results in a much larger set of vectors,
consequently leading to increased memory consumption and computationally
intensive vector searches with elevated latency.
</p>
<p>To address these challenges, we introduce Jina Embeddings 2, an open-source
text embedding model capable of accommodating up to 8192 tokens. This model is
designed to transcend the conventional 512-token limit and adeptly process long
documents. Jina Embeddings 2 not only achieves state-of-the-art performance on
a range of embedding-related tasks in the MTEB benchmark but also matches the
performance of OpenAI's proprietary ada-002 model. Additionally, our
experiments indicate that an extended context can enhance performance in tasks
such as NarrativeQA.
</p>

### Title: Partial Tensorized Transformers for Natural Language Processing. (arXiv:2310.20077v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2310.20077](http://arxiv.org/abs/2310.20077)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20077] Partial Tensorized Transformers for Natural Language Processing](http://arxiv.org/abs/2310.20077) #memory`
* Summary: <p>The transformer architecture has revolutionized Natural Language Processing
(NLP) and other machine-learning tasks, due to its unprecedented accuracy.
However, their extensive memory and parameter requirements often hinder their
practical applications. In this work, we study the effect of tensor-train
decomposition to improve the accuracy and compress transformer vision-language
neural networks, namely BERT and ViT. We focus both on embedding-layer
compression and partial tensorization of neural networks (PTNN) through an
algorithmic approach. Our novel PTNN approach significantly improves the
accuracy of existing models by up to 5%, all without the need for post-training
adjustments, breaking new ground in the field of tensor decomposition.
</p>

### Title: Automatic Generators for a Family of Matrix Multiplication Routines with Apache TVM. (arXiv:2310.20347v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2310.20347](http://arxiv.org/abs/2310.20347)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20347] Automatic Generators for a Family of Matrix Multiplication Routines with Apache TVM](http://arxiv.org/abs/2310.20347) #memory`
* Summary: <p>We explore the utilization of the Apache TVM open source framework to
automatically generate a family of algorithms that follow the approach taken by
popular linear algebra libraries, such as GotoBLAS2, BLIS and OpenBLAS, in
order to obtain high-performance blocked formulations of the general matrix
multiplication (GEMM). % In addition, we fully automatize the generation
process, by also leveraging the Apache TVM framework to derive a complete
variety of the processor-specific micro-kernels for GEMM. This is in contrast
with the convention in high performance libraries, which hand-encode a single
micro-kernel per architecture using Assembly code. % In global, the combination
of our TVM-generated blocked algorithms and micro-kernels for GEMM 1)~improves
portability, maintainability and, globally, streamlines the software life
cycle; 2)~provides high flexibility to easily tailor and optimize the solution
to different data types, processor architectures, and matrix operand shapes,
yielding performance on a par (or even superior for specific matrix shapes)
with that of hand-tuned libraries; and 3)~features a small memory footprint.
</p>

### Title: Training binary neural networks without floating point precision. (arXiv:2310.19815v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.19815](http://arxiv.org/abs/2310.19815)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.19815] Training binary neural networks without floating point precision](http://arxiv.org/abs/2310.19815) #memory`
* Summary: <p>The main goal of this work is to improve the efficiency of training binary
neural networks, which are low latency and low energy networks. The main
contribution of this work is the proposal of two solutions comprised of
topology changes and strategy training that allow the network to achieve near
the state-of-the-art performance and efficient training. The time required for
training and the memory required in the process are two factors that contribute
to efficient training.
</p>

### Title: PolyThrottle: Energy-efficient Neural Network Inference on Edge Devices. (arXiv:2310.19991v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.19991](http://arxiv.org/abs/2310.19991)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.19991] PolyThrottle: Energy-efficient Neural Network Inference on Edge Devices](http://arxiv.org/abs/2310.19991) #memory`
* Summary: <p>As neural networks (NN) are deployed across diverse sectors, their energy
demand correspondingly grows. While several prior works have focused on
reducing energy consumption during training, the continuous operation of
ML-powered systems leads to significant energy use during inference. This paper
investigates how the configuration of on-device hardware-elements such as GPU,
memory, and CPU frequency, often neglected in prior studies, affects energy
consumption for NN inference with regular fine-tuning. We propose PolyThrottle,
a solution that optimizes configurations across individual hardware components
using Constrained Bayesian Optimization in an energy-conserving manner. Our
empirical evaluation uncovers novel facets of the energy-performance
equilibrium showing that we can save up to 36 percent of energy for popular
models. We also validate that PolyThrottle can quickly converge towards
near-optimal settings while satisfying application constraints.
</p>

### Title: Accelerating Generalized Linear Models by Trading off Computation for Uncertainty. (arXiv:2310.20285v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.20285](http://arxiv.org/abs/2310.20285)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20285] Accelerating Generalized Linear Models by Trading off Computation for Uncertainty](http://arxiv.org/abs/2310.20285) #memory`
* Summary: <p>Bayesian Generalized Linear Models (GLMs) define a flexible probabilistic
framework to model categorical, ordinal and continuous data, and are widely
used in practice. However, exact inference in GLMs is prohibitively expensive
for large datasets, thus requiring approximations in practice. The resulting
approximation error adversely impacts the reliability of the model and is not
accounted for in the uncertainty of the prediction. In this work, we introduce
a family of iterative methods that explicitly model this error. They are
uniquely suited to parallel modern computing hardware, efficiently recycle
computations, and compress information to reduce both the time and memory
requirements for GLMs. As we demonstrate on a realistically large
classification problem, our method significantly accelerates training by
explicitly trading off reduced computation for increased uncertainty.
</p>

## few-shot
### Title: Towards Few-Annotation Learning for Object Detection: Are Transformer-based Models More Efficient ?. (arXiv:2310.19936v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2310.19936](http://arxiv.org/abs/2310.19936)
* Code URL: [https://github.com/cea-list/mt-detr](https://github.com/cea-list/mt-detr)
* Copy Paste: `<input type="checkbox">[[2310.19936] Towards Few-Annotation Learning for Object Detection: Are Transformer-based Models More Efficient ?](http://arxiv.org/abs/2310.19936) #few-shot`
* Summary: <p>For specialized and dense downstream tasks such as object detection, labeling
data requires expertise and can be very expensive, making few-shot and
semi-supervised models much more attractive alternatives. While in the few-shot
setup we observe that transformer-based object detectors perform better than
convolution-based two-stage models for a similar amount of parameters, they are
not as effective when used with recent approaches in the semi-supervised
setting. In this paper, we propose a semi-supervised method tailored for the
current state-of-the-art object detector Deformable DETR in the few-annotation
learning setup using a student-teacher architecture, which avoids relying on a
sensitive post-processing of the pseudo-labels generated by the teacher model.
We evaluate our method on the semi-supervised object detection benchmarks COCO
and Pascal VOC, and it outperforms previous methods, especially when
annotations are scarce. We believe that our contributions open new
possibilities to adapt similar object detection methods in this setup as well.
</p>

### Title: Adaptive Anchor Label Propagation for Transductive Few-Shot Learning. (arXiv:2310.19996v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2310.19996](http://arxiv.org/abs/2310.19996)
* Code URL: [https://github.com/michalislazarou/a2lp](https://github.com/michalislazarou/a2lp)
* Copy Paste: `<input type="checkbox">[[2310.19996] Adaptive Anchor Label Propagation for Transductive Few-Shot Learning](http://arxiv.org/abs/2310.19996) #few-shot`
* Summary: <p>Few-shot learning addresses the issue of classifying images using limited
labeled data. Exploiting unlabeled data through the use of transductive
inference methods such as label propagation has been shown to improve the
performance of few-shot learning significantly. Label propagation infers
pseudo-labels for unlabeled data by utilizing a constructed graph that exploits
the underlying manifold structure of the data. However, a limitation of the
existing label propagation approaches is that the positions of all data points
are fixed and might be sub-optimal so that the algorithm is not as effective as
possible. In this work, we propose a novel algorithm that adapts the feature
embeddings of the labeled data by minimizing a differentiable loss function
optimizing their positions in the manifold in the process. Our novel algorithm,
Adaptive Anchor Label Propagation}, outperforms the standard label propagation
algorithm by as much as 7% and 2% in the 1-shot and 5-shot settings
respectively. We provide experimental results highlighting the merits of our
algorithm on four widely used few-shot benchmark datasets, namely miniImageNet,
tieredImageNet, CUB and CIFAR-FS and two commonly used backbones, ResNet12 and
WideResNet-28-10. The source code can be found at
https://github.com/MichalisLazarou/A2LP.
</p>

### Title: Constructing Sample-to-Class Graph for Few-Shot Class-Incremental Learning. (arXiv:2310.20268v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2310.20268](http://arxiv.org/abs/2310.20268)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20268] Constructing Sample-to-Class Graph for Few-Shot Class-Incremental Learning](http://arxiv.org/abs/2310.20268) #few-shot`
* Summary: <p>Few-shot class-incremental learning (FSCIL) aims to build machine learning
model that can continually learn new concepts from a few data samples, without
forgetting knowledge of old classes.
</p>
<p>The challenges of FSCIL lies in the limited data of new classes, which not
only lead to significant overfitting issues but also exacerbates the notorious
catastrophic forgetting problems. As proved in early studies, building sample
relationships is beneficial for learning from few-shot samples. In this paper,
we promote the idea to the incremental scenario, and propose a Sample-to-Class
(S2C) graph learning method for FSCIL.
</p>
<p>Specifically, we propose a Sample-level Graph Network (SGN) that focuses on
analyzing sample relationships within a single session. This network helps
aggregate similar samples, ultimately leading to the extraction of more refined
class-level features.
</p>
<p>Then, we present a Class-level Graph Network (CGN) that establishes
connections across class-level features of both new and old classes. This
network plays a crucial role in linking the knowledge between different
sessions and helps improve overall learning in the FSCIL scenario. Moreover, we
design a multi-stage strategy for training S2C model, which mitigates the
training challenges posed by limited data in the incremental process.
</p>
<p>The multi-stage training strategy is designed to build S2C graph from base to
few-shot stages, and improve the capacity via an extra pseudo-incremental
stage. Experiments on three popular benchmark datasets show that our method
clearly outperforms the baselines and sets new state-of-the-art results in
FSCIL.
</p>

### Title: Keyword-optimized Template Insertion for Clinical Information Extraction via Prompt-based Learning. (arXiv:2310.20089v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2310.20089](http://arxiv.org/abs/2310.20089)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20089] Keyword-optimized Template Insertion for Clinical Information Extraction via Prompt-based Learning](http://arxiv.org/abs/2310.20089) #few-shot`
* Summary: <p>Clinical note classification is a common clinical NLP task. However,
annotated data-sets are scarse. Prompt-based learning has recently emerged as
an effective method to adapt pre-trained models for text classification using
only few training examples. A critical component of prompt design is the
definition of the template (i.e. prompt text). The effect of template position,
however, has been insufficiently investigated. This seems particularly
important in the clinical setting, where task-relevant information is usually
sparse in clinical notes. In this study we develop a keyword-optimized template
insertion method (KOTI) and show how optimizing position can improve
performance on several clinical tasks in a zero-shot and few-shot training
setting.
</p>

### Title: Improving Prompt Tuning with Learned Prompting Layers. (arXiv:2310.20127v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2310.20127](http://arxiv.org/abs/2310.20127)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20127] Improving Prompt Tuning with Learned Prompting Layers](http://arxiv.org/abs/2310.20127) #few-shot`
* Summary: <p>Prompt tuning prepends a soft prompt to the input embeddings or hidden states
and only optimizes the prompt to adapt pretrained models (PTMs) to downstream
tasks. The previous work manually selects prompt layers which are far from
optimal and failed to exploit the potential of prompt tuning. In this work, we
propose a novel framework, \underline{S}elective \underline{P}rompt
\underline{T}uning (SPT), that learns to select the proper prompt layers by
inserting a prompt controlled by a learnable probabilistic gate at each
intermediate layer. We further propose a novel bi-level optimization framework,
SPT-DARTS, that can better optimize the learnable gates and improve the final
prompt tuning performances of the learned prompt layer settings. We conduct
extensive experiments with ten benchmark datasets under the full-data and
few-shot scenarios. The results demonstrate that our SPT framework can perform
better than the previous state-of-the-art PETuning baselines with comparable or
fewer tunable parameters.
</p>

### Title: Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations. (arXiv:2310.20246v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2310.20246](http://arxiv.org/abs/2310.20246)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20246] Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations](http://arxiv.org/abs/2310.20246) #few-shot`
* Summary: <p>Existing research predominantly focuses on developing powerful language
learning models (LLMs) for mathematical reasoning within monolingual languages,
with few explorations in preserving efficacy in a multilingual context. To
bridge this gap, this paper pioneers exploring and training powerful
Multilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we
construct the first multilingual math reasoning instruction dataset,
MGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue
of training data scarcity in xMR tasks. Based on the collected dataset, we
propose different training strategies to build powerful xMR LLMs, named
MathOctopus, notably outperform conventional open-source LLMs and exhibit
superiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B
reaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond
remarkable results, we unearth several pivotal observations and insights from
extensive experiments: (1) When extending the rejection sampling strategy to
the multilingual context, it proves effective for model performances, albeit
limited. (2) Employing parallel corpora for math Supervised Fine-Tuning (SFT)
across multiple languages not only significantly enhances model performance
multilingually but also elevates their monolingual performance. This indicates
that crafting multilingual corpora can be regarded as a vital strategy for
enhancing model performance in a specific language, especially in mathematical
reasoning tasks. For instance, MathOctopus-7B improves its counterparts that
trained on English from 42.2% to 50.8% on GSM8K testset.
</p>

### Title: ExPT: Synthetic Pretraining for Few-Shot Experimental Design. (arXiv:2310.19961v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.19961](http://arxiv.org/abs/2310.19961)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.19961] ExPT: Synthetic Pretraining for Few-Shot Experimental Design](http://arxiv.org/abs/2310.19961) #few-shot`
* Summary: <p>Experimental design is a fundamental problem in many science and engineering
fields. In this problem, sample efficiency is crucial due to the time, money,
and safety costs of real-world design evaluations. Existing approaches either
rely on active data collection or access to large, labeled datasets of past
experiments, making them impractical in many real-world scenarios. In this
work, we address the more challenging yet realistic setting of few-shot
experimental design, where only a few labeled data points of input designs and
their corresponding values are available. We approach this problem as a
conditional generation task, where a model conditions on a few labeled examples
and the desired output to generate an optimal input design. To this end, we
introduce Experiment Pretrained Transformers (ExPT), a foundation model for
few-shot experimental design that employs a novel combination of synthetic
pretraining with in-context learning. In ExPT, we only assume knowledge of a
finite collection of unlabelled data points from the input domain and pretrain
a transformer neural network to optimize diverse synthetic functions defined
over this domain. Unsupervised pretraining allows ExPT to adapt to any design
task at test time in an in-context fashion by conditioning on a few labeled
data points from the target task and generating the candidate optima. We
evaluate ExPT on few-shot experimental design in challenging domains and
demonstrate its superior generality and performance compared to existing
methods. The source code is available at https://github.com/tung-nd/ExPT.git.
</p>

### Title: STDA-Meta: A Meta-Learning Framework for Few-Shot Traffic Prediction. (arXiv:2310.20223v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2310.20223](http://arxiv.org/abs/2310.20223)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2310.20223] STDA-Meta: A Meta-Learning Framework for Few-Shot Traffic Prediction](http://arxiv.org/abs/2310.20223) #few-shot`
* Summary: <p>As the development of cities, traffic congestion becomes an increasingly
pressing issue, and traffic prediction is a classic method to relieve that
issue. Traffic prediction is one specific application of spatio-temporal
prediction learning, like taxi scheduling, weather prediction, and ship
trajectory prediction. Against these problems, classical spatio-temporal
prediction learning methods including deep learning, require large amounts of
training data. In reality, some newly developed cities with insufficient
sensors would not hold that assumption, and the data scarcity makes predictive
performance worse. In such situation, the learning method on insufficient data
is known as few-shot learning (FSL), and the FSL of traffic prediction remains
challenges. On the one hand, graph structures' irregularity and dynamic nature
of graphs cannot hold the performance of spatio-temporal learning method. On
the other hand, conventional domain adaptation methods cannot work well on
insufficient training data, when transferring knowledge from different domains
to the intended target domain.To address these challenges, we propose a novel
spatio-temporal domain adaptation (STDA) method that learns transferable
spatio-temporal meta-knowledge from data-sufficient cities in an adversarial
manner. This learned meta-knowledge can improve the prediction performance of
data-scarce cities. Specifically, we train the STDA model using a
Model-Agnostic Meta-Learning (MAML) based episode learning process, which is a
model-agnostic meta-learning framework that enables the model to solve new
learning tasks using only a small number of training samples. We conduct
numerous experiments on four traffic prediction datasets, and our results show
that the prediction performance of our model has improved by 7\% compared to
baseline models on the two metrics of MAE and RMSE.
</p>

