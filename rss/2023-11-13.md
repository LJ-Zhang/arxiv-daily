## diffusion
### Title: Diffusion Shape Prior for Wrinkle-Accurate Cloth Registration. (arXiv:2311.05828v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2311.05828](http://arxiv.org/abs/2311.05828)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.05828] Diffusion Shape Prior for Wrinkle-Accurate Cloth Registration](http://arxiv.org/abs/2311.05828) #diffusion`
* Summary: <p>Registering clothes from 4D scans with vertex-accurate correspondence is
challenging, yet important for dynamic appearance modeling and physics
parameter estimation from real-world data. However, previous methods either
rely on texture information, which is not always reliable, or achieve only
coarse-level alignment. In this work, we present a novel approach to enabling
accurate surface registration of texture-less clothes with large deformation.
Our key idea is to effectively leverage a shape prior learned from pre-captured
clothing using diffusion models. We also propose a multi-stage guidance scheme
based on learned functional maps, which stabilizes registration for large-scale
deformation even when they vary significantly from training data. Using
high-fidelity real captured clothes, our experiments show that the proposed
approach based on diffusion models generalizes better than surface registration
with VAE or PCA-based priors, outperforming both optimization-based and
learning-based non-rigid registration methods for both interpolation and
extrapolation tests.
</p>

### Title: Instant3D: Fast Text-to-3D with Sparse-View Generation and Large Reconstruction Model. (arXiv:2311.06214v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2311.06214](http://arxiv.org/abs/2311.06214)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.06214] Instant3D: Fast Text-to-3D with Sparse-View Generation and Large Reconstruction Model](http://arxiv.org/abs/2311.06214) #diffusion`
* Summary: <p>Text-to-3D with diffusion models have achieved remarkable progress in recent
years. However, existing methods either rely on score distillation-based
optimization which suffer from slow inference, low diversity and Janus
problems, or are feed-forward methods that generate low quality results due to
the scarcity of 3D training data. In this paper, we propose Instant3D, a novel
method that generates high-quality and diverse 3D assets from text prompts in a
feed-forward manner. We adopt a two-stage paradigm, which first generates a
sparse set of four structured and consistent views from text in one shot with a
fine-tuned 2D text-to-image diffusion model, and then directly regresses the
NeRF from the generated images with a novel transformer-based sparse-view
reconstructor. Through extensive experiments, we demonstrate that our method
can generate high-quality, diverse and Janus-free 3D assets within 20 seconds,
which is two order of magnitude faster than previous optimization-based methods
that can take 1 to 10 hours. Our project webpage: https://jiahao.ai/instant3d/.
</p>

### Title: Diffusion Models for Earth Observation Use-cases: from cloud removal to urban change detection. (arXiv:2311.06222v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2311.06222](http://arxiv.org/abs/2311.06222)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.06222] Diffusion Models for Earth Observation Use-cases: from cloud removal to urban change detection](http://arxiv.org/abs/2311.06222) #diffusion`
* Summary: <p>The advancements in the state of the art of generative Artificial
Intelligence (AI) brought by diffusion models can be highly beneficial in novel
contexts involving Earth observation data. After introducing this new family of
generative models, this work proposes and analyses three use cases which
demonstrate the potential of diffusion-based approaches for satellite image
data. Namely, we tackle cloud removal and inpainting, dataset generation for
change-detection tasks, and urban replanning.
</p>

### Title: Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization. (arXiv:2311.06243v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2311.06243](http://arxiv.org/abs/2311.06243)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.06243] Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization](http://arxiv.org/abs/2311.06243) #diffusion`
* Summary: <p>Large foundation models are becoming ubiquitous, but training them from
scratch is prohibitively expensive. Thus, efficiently adapting these powerful
models to downstream tasks is increasingly important. In this paper, we study a
principled finetuning paradigm -- Orthogonal Finetuning (OFT) -- for downstream
task adaptation. Despite demonstrating good generalizability, OFT still uses a
fairly large number of trainable parameters due to the high dimensionality of
orthogonal matrices. To address this, we start by examining OFT from an
information transmission perspective, and then identify a few key desiderata
that enable better parameter-efficiency. Inspired by how the Cooley-Tukey fast
Fourier transform algorithm enables efficient information transmission, we
propose an efficient orthogonal parameterization using butterfly structures. We
apply this parameterization to OFT, creating a novel parameter-efficient
finetuning method, called Orthogonal Butterfly (BOFT). By subsuming OFT as a
special case, BOFT introduces a generalized orthogonal finetuning framework.
Finally, we conduct an extensive empirical study of adapting large vision
transformers, large language models, and text-to-image diffusion models to
various downstream tasks in vision and language.
</p>

## self-supervised
### Title: OmniVec: Learning robust representations with cross modal sharing. (arXiv:2311.05709v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2311.05709](http://arxiv.org/abs/2311.05709)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.05709] OmniVec: Learning robust representations with cross modal sharing](http://arxiv.org/abs/2311.05709) #self-supervised`
* Summary: <p>Majority of research in learning based methods has been towards designing and
training networks for specific tasks. However, many of the learning based
tasks, across modalities, share commonalities and could be potentially tackled
in a joint framework. We present an approach in such direction, to learn
multiple tasks, in multiple modalities, with a unified architecture. The
proposed network is composed of task specific encoders, a common trunk in the
middle, followed by task specific prediction heads. We first pre-train it by
self-supervised masked training, followed by sequential training for the
different tasks. We train the network on all major modalities, e.g.\ visual,
audio, text and 3D, and report results on $22$ diverse and challenging public
benchmarks. We demonstrate empirically that, using a joint network to train
across modalities leads to meaningful information sharing and this allows us to
achieve state-of-the-art results on most of the benchmarks. We also show
generalization of the trained network on cross-modal tasks as well as unseen
datasets and tasks.
</p>

### Title: MonoProb: Self-Supervised Monocular Depth Estimation with Interpretable Uncertainty. (arXiv:2311.06137v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2311.06137](http://arxiv.org/abs/2311.06137)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.06137] MonoProb: Self-Supervised Monocular Depth Estimation with Interpretable Uncertainty](http://arxiv.org/abs/2311.06137) #self-supervised`
* Summary: <p>Self-supervised monocular depth estimation methods aim to be used in critical
applications such as autonomous vehicles for environment analysis. To
circumvent the potential imperfections of these approaches, a quantification of
the prediction confidence is crucial to guide decision-making systems that rely
on depth estimation. In this paper, we propose MonoProb, a new unsupervised
monocular depth estimation method that returns an interpretable uncertainty,
which means that the uncertainty reflects the expected error of the network in
its depth predictions. We rethink the stereo or the structure-from-motion
paradigms used to train unsupervised monocular depth models as a probabilistic
problem. Within a single forward pass inference, this model provides a depth
prediction and a measure of its confidence, without increasing the inference
time. We then improve the performance on depth and uncertainty with a novel
self-distillation loss for which a student is supervised by a pseudo ground
truth that is a probability distribution on depth output by a teacher. To
quantify the performance of our models we design new metrics that, unlike
traditional ones, measure the absolute performance of uncertainty predictions.
Our experiments highlight enhancements achieved by our method on standard depth
and uncertainty metrics as well as on our tailored metrics.
https://github.com/CEA-LIST/MonoProb
</p>

## foundation model
### Title: Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks. (arXiv:2311.06242v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2311.06242](http://arxiv.org/abs/2311.06242)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.06242] Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks](http://arxiv.org/abs/2311.06242) #foundation model`
* Summary: <p>We introduce Florence-2, a novel vision foundation model with a unified,
prompt-based representation for a variety of computer vision and
vision-language tasks. While existing large vision models excel in transfer
learning, they struggle to perform a diversity of tasks with simple
instructions, a capability that implies handling the complexity of various
spatial hierarchy and semantic granularity. Florence-2 was designed to take
text-prompt as task instructions and generate desirable results in text forms,
whether it be captioning, object detection, grounding or segmentation. This
multi-task learning setup demands large-scale, high-quality annotated data. To
this end, we co-developed FLD-5B that consists of 5.4 billion comprehensive
visual annotations on 126 million images, using an iterative strategy of
automated image annotation and model refinement. We adopted a
sequence-to-sequence structure to train Florence-2 to perform versatile and
comprehensive vision tasks. Extensive evaluations on numerous tasks
demonstrated Florence-2 to be a strong vision foundation model contender with
unprecedented zero-shot and fine-tuning capabilities.
</p>

## generative
### Title: Enhancing Rock Image Segmentation in Digital Rock Physics: A Fusion of Generative AI and State-of-the-Art Neural Networks. (arXiv:2311.06079v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2311.06079](http://arxiv.org/abs/2311.06079)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.06079] Enhancing Rock Image Segmentation in Digital Rock Physics: A Fusion of Generative AI and State-of-the-Art Neural Networks](http://arxiv.org/abs/2311.06079) #generative`
* Summary: <p>In digital rock physics, analysing microstructures from CT and SEM scans is
crucial for estimating properties like porosity and pore connectivity.
Traditional segmentation methods like thresholding and CNNs often fall short in
accurately detailing rock microstructures and are prone to noise. U-Net
improved segmentation accuracy but required many expert-annotated samples, a
laborious and error-prone process due to complex pore shapes. Our study
employed an advanced generative AI model, the diffusion model, to overcome
these limitations. This model generated a vast dataset of CT/SEM and binary
segmentation pairs from a small initial dataset. We assessed the efficacy of
three neural networks: U-Net, Attention-U-net, and TransUNet, for segmenting
these enhanced images. The diffusion model proved to be an effective data
augmentation technique, improving the generalization and robustness of deep
learning models. TransU-Net, incorporating Transformer structures, demonstrated
superior segmentation accuracy and IoU metrics, outperforming both U-Net and
Attention-U-net. Our research advances rock image segmentation by combining the
diffusion model with cutting-edge neural networks, reducing dependency on
extensive expert data and boosting segmentation accuracy and robustness.
TransU-Net sets a new standard in digital rock physics, paving the way for
future geoscience and engineering breakthroughs.
</p>

### Title: FinGPT: Large Generative Models for a Small Language. (arXiv:2311.05640v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2311.05640](http://arxiv.org/abs/2311.05640)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.05640] FinGPT: Large Generative Models for a Small Language](http://arxiv.org/abs/2311.05640) #generative`
* Summary: <p>Large language models (LLMs) excel in many tasks in NLP and beyond, but most
open models have very limited coverage of smaller languages and LLM work tends
to focus on languages where nearly unlimited data is available for pretraining.
In this work, we study the challenges of creating LLMs for Finnish, a language
spoken by less than 0.1% of the world population. We compile an extensive
dataset of Finnish combining web crawls, news, social media and eBooks. We
pursue two approaches to pretrain models: 1) we train seven monolingual models
from scratch (186M to 13B parameters) dubbed FinGPT, 2) we continue the
pretraining of the multilingual BLOOM model on a mix of its original training
data and Finnish, resulting in a 176 billion parameter model we call BLUUMI.
For model evaluation, we introduce FIN-bench, a version of BIG-bench with
Finnish tasks. We also assess other model qualities such as toxicity and bias.
Our models and tools are openly available at https://turkunlp.org/gpt3-finnish.
</p>

### Title: Syntax-semantics interface: an algebraic model. (arXiv:2311.06189v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2311.06189](http://arxiv.org/abs/2311.06189)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.06189] Syntax-semantics interface: an algebraic model](http://arxiv.org/abs/2311.06189) #generative`
* Summary: <p>We extend our formulation of Merge and Minimalism in terms of Hopf algebras
to an algebraic model of a syntactic-semantic interface. We show that methods
adopted in the formulation of renormalization (extraction of meaningful
physical values) in theoretical physics are relevant to describe the extraction
of meaning from syntactic expressions. We show how this formulation relates to
computational models of semantics and we answer some recent controversies about
implications for generative linguistics of the current functioning of large
language models.
</p>

### Title: BanglaBait: Semi-Supervised Adversarial Approach for Clickbait Detection on Bangla Clickbait Dataset. (arXiv:2311.06204v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2311.06204](http://arxiv.org/abs/2311.06204)
* Code URL: [https://github.com/mdmotaharmahtab/banglabait](https://github.com/mdmotaharmahtab/banglabait)
* Copy Paste: `<input type="checkbox">[[2311.06204] BanglaBait: Semi-Supervised Adversarial Approach for Clickbait Detection on Bangla Clickbait Dataset](http://arxiv.org/abs/2311.06204) #generative`
* Summary: <p>Intentionally luring readers to click on a particular content by exploiting
their curiosity defines a title as clickbait. Although several studies focused
on detecting clickbait titles in English articles, low resource language like
Bangla has not been given adequate attention. To tackle clickbait titles in
Bangla, we have constructed the first Bangla clickbait detection dataset
containing 15,056 labeled news articles and 65,406 unlabelled news articles
extracted from clickbait dense news sites. Each article has been labeled by
three expert linguists and includes an article's title, body, and other
metadata. By incorporating labeled and unlabelled data, we finetune a
pretrained Bangla transformer model in an adversarial fashion using Semi
Supervised Generative Adversarial Networks (SS GANs). The proposed model acts
as a good baseline for this dataset, outperforming traditional neural network
models (LSTM, GRU, CNN) and linguistic feature based models. We expect that
this dataset and the detailed analysis and comparison of these clickbait
detection models will provide a fundamental basis for future research into
detecting clickbait titles in Bengali articles. We have released the
corresponding code and dataset.
</p>

### Title: Generative Explanations for Graph Neural Network: Methods and Evaluations. (arXiv:2311.05764v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2311.05764](http://arxiv.org/abs/2311.05764)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.05764] Generative Explanations for Graph Neural Network: Methods and Evaluations](http://arxiv.org/abs/2311.05764) #generative`
* Summary: <p>Graph Neural Networks (GNNs) achieve state-of-the-art performance in various
graph-related tasks. However, the black-box nature often limits their
interpretability and trustworthiness. Numerous explainability methods have been
proposed to uncover the decision-making logic of GNNs, by generating underlying
explanatory substructures. In this paper, we conduct a comprehensive review of
the existing explanation methods for GNNs from the perspective of graph
generation. Specifically, we propose a unified optimization objective for
generative explanation methods, comprising two sub-objectives: Attribution and
Information constraints. We further demonstrate their specific manifestations
in various generative model architectures and different explanation scenarios.
With the unified objective of the explanation problem, we reveal the shared
characteristics and distinctions among current methods, laying the foundation
for future methodological advancements. Empirical results demonstrate the
advantages and limitations of different explainability approaches in terms of
explanation performance, efficiency, and generalizability.
</p>

### Title: Scale-MIA: A Scalable Model Inversion Attack against Secure Federated Learning via Latent Space Reconstruction. (arXiv:2311.05808v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2311.05808](http://arxiv.org/abs/2311.05808)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.05808] Scale-MIA: A Scalable Model Inversion Attack against Secure Federated Learning via Latent Space Reconstruction](http://arxiv.org/abs/2311.05808) #generative`
* Summary: <p>Federated learning is known for its capability to safeguard participants'
data privacy. However, recently emerged model inversion attacks (MIAs) have
shown that a malicious parameter server can reconstruct individual users' local
data samples through model updates. The state-of-the-art attacks either rely on
computation-intensive search-based optimization processes to recover each input
batch, making scaling difficult, or they involve the malicious parameter server
adding extra modules before the global model architecture, rendering the
attacks too conspicuous and easily detectable.
</p>
<p>To overcome these limitations, we propose Scale-MIA, a novel MIA capable of
efficiently and accurately recovering training samples of clients from the
aggregated updates, even when the system is under the protection of a robust
secure aggregation protocol. Unlike existing approaches treating models as
black boxes, Scale-MIA recognizes the importance of the intricate architecture
and inner workings of machine learning models. It identifies the latent space
as the critical layer for breaching privacy and decomposes the complex recovery
task into an innovative two-step process to reduce computation complexity. The
first step involves reconstructing the latent space representations (LSRs) from
the aggregated model updates using a closed-form inversion mechanism,
leveraging specially crafted adversarial linear layers. In the second step, the
whole input batches are recovered from the LSRs by feeding them into a
fine-tuned generative decoder.
</p>
<p>We implemented Scale-MIA on multiple commonly used machine learning models
and conducted comprehensive experiments across various settings. The results
demonstrate that Scale-MIA achieves excellent recovery performance on different
datasets, exhibiting high reconstruction rates, accuracy, and attack efficiency
on a larger scale compared to state-of-the-art MIAs.
</p>

### Title: Testing Dependency of Unlabeled Databases. (arXiv:2311.05874v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2311.05874](http://arxiv.org/abs/2311.05874)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.05874] Testing Dependency of Unlabeled Databases](http://arxiv.org/abs/2311.05874) #generative`
* Summary: <p>In this paper, we investigate the problem of deciding whether two random
databases $\mathsf{X}\in\mathcal{X}^{n\times d}$ and
$\mathsf{Y}\in\mathcal{Y}^{n\times d}$ are statistically dependent or not. This
is formulated as a hypothesis testing problem, where under the null hypothesis,
these two databases are statistically independent, while under the alternative,
there exists an unknown row permutation $\sigma$, such that $\mathsf{X}$ and
$\mathsf{Y}^\sigma$, a permuted version of $\mathsf{Y}$, are statistically
dependent with some known joint distribution, but have the same marginal
distributions as the null. We characterize the thresholds at which optimal
testing is information-theoretically impossible and possible, as a function of
$n$, $d$, and some spectral properties of the generative distributions of the
datasets. For example, we prove that if a certain function of the eigenvalues
of the likelihood function and $d$, is below a certain threshold, as
$d\to\infty$, then weak detection (performing slightly better than random
guessing) is statistically impossible, no matter what the value of $n$ is. This
mimics the performance of an efficient test that thresholds a centered version
of the log-likelihood function of the observed matrices. We also analyze the
case where $d$ is fixed, for which we derive strong (vanishing error) and weak
detection lower and upper bounds.
</p>

## anomaly
### Title: Interpretable Graph Anomaly Detection using Gradient Attention Maps. (arXiv:2311.06153v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2311.06153](http://arxiv.org/abs/2311.06153)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.06153] Interpretable Graph Anomaly Detection using Gradient Attention Maps](http://arxiv.org/abs/2311.06153) #anomaly`
* Summary: <p>Detecting unusual patterns in graph data is a crucial task in data mining.
However, existing methods often face challenges in consistently achieving
satisfactory performance and lack interpretability, which hinders our
understanding of anomaly detection decisions. In this paper, we propose a novel
approach to graph anomaly detection that leverages the power of
interpretability to enhance performance. Specifically, our method extracts an
attention map derived from gradients of graph neural networks, which serves as
a basis for scoring anomalies. In addition, we conduct theoretical analysis
using synthetic data to validate our method and gain insights into its
decision-making process. To demonstrate the effectiveness of our method, we
extensively evaluate our approach against state-of-the-art graph anomaly
detection techniques. The results consistently demonstrate the superior
performance of our method compared to the baselines.
</p>

## in-context
### Title: Deep Natural Language Feature Learning for Interpretable Prediction. (arXiv:2311.05754v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2311.05754](http://arxiv.org/abs/2311.05754)
* Code URL: [https://github.com/furrutiav/nllf-emnlp-2023](https://github.com/furrutiav/nllf-emnlp-2023)
* Copy Paste: `<input type="checkbox">[[2311.05754] Deep Natural Language Feature Learning for Interpretable Prediction](http://arxiv.org/abs/2311.05754) #in-context`
* Summary: <p>We propose a general method to break down a main complex task into a set of
intermediary easier sub-tasks, which are formulated in natural language as
binary questions related to the final target task. Our method allows for
representing each example by a vector consisting of the answers to these
questions. We call this representation Natural Language Learned Features
(NLLF). NLLF is generated by a small transformer language model (e.g., BERT)
that has been trained in a Natural Language Inference (NLI) fashion, using weak
labels automatically obtained from a Large Language Model (LLM). We show that
the LLM normally struggles for the main task using in-context learning, but can
handle these easiest subtasks and produce useful weak labels to train a BERT.
The NLI-like training of the BERT allows for tackling zero-shot inference with
any binary question, and not necessarily the ones seen during the training. We
show that this NLLF vector not only helps to reach better performances by
enhancing any classifier, but that it can be used as input of an
easy-to-interpret machine learning model like a decision tree. This decision
tree is interpretable but also reaches high performances, surpassing those of a
pre-trained transformer in some cases.We have successfully applied this method
to two completely different tasks: detecting incoherence in students' answers
to open-ended mathematics exam questions, and screening abstracts for a
systematic literature review of scientific papers on climate change and
agroecology.
</p>

## memory
### Title: FMViT: A multiple-frequency mixing Vision Transformer. (arXiv:2311.05707v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2311.05707](http://arxiv.org/abs/2311.05707)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.05707] FMViT: A multiple-frequency mixing Vision Transformer](http://arxiv.org/abs/2311.05707) #memory`
* Summary: <p>The transformer model has gained widespread adoption in computer vision tasks
in recent times. However, due to the quadratic time and memory complexity of
self-attention, which is proportional to the number of input tokens, most
existing Vision Transformers (ViTs) encounter challenges in achieving efficient
performance in practical industrial deployment scenarios, such as TensorRT and
CoreML, where traditional CNNs excel. Although some recent attempts have been
made to design CNN-Transformer hybrid architectures to tackle this problem,
their overall performance has not met expectations. To tackle these challenges,
we propose an efficient hybrid ViT architecture named FMViT. This approach
enhances the model's expressive power by blending high-frequency features and
low-frequency features with varying frequencies, enabling it to capture both
local and global information effectively. Additionally, we introduce
deploy-friendly mechanisms such as Convolutional Multigroup Reparameterization
(gMLP), Lightweight Multi-head Self-Attention (RLMHSA), and Convolutional
Fusion Block (CFB) to further improve the model's performance and reduce
computational overhead. Our experiments demonstrate that FMViT surpasses
existing CNNs, ViTs, and CNNTransformer hybrid architectures in terms of
latency/accuracy trade-offs for various vision tasks. On the TensorRT platform,
FMViT outperforms Resnet101 by 2.5% (83.3% vs. 80.8%) in top-1 accuracy on the
ImageNet dataset while maintaining similar inference latency. Moreover, FMViT
achieves comparable performance with EfficientNet-B5, but with a 43%
improvement in inference speed. On CoreML, FMViT outperforms MobileOne by 2.6%
in top-1 accuracy on the ImageNet dataset, with inference latency comparable to
MobileOne (78.5% vs. 75.9%). Our code can be found at
https://github.com/tany0699/FMViT.
</p>

### Title: DONUT-hole: DONUT Sparsification by Harnessing Knowledge and Optimizing Learning Efficiency. (arXiv:2311.05778v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2311.05778](http://arxiv.org/abs/2311.05778)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.05778] DONUT-hole: DONUT Sparsification by Harnessing Knowledge and Optimizing Learning Efficiency](http://arxiv.org/abs/2311.05778) #memory`
* Summary: <p>This paper introduces DONUT-hole, a sparse OCR-free visual document
understanding (VDU) model that addresses the limitations of its predecessor
model, dubbed DONUT. The DONUT model, leveraging a transformer architecture,
overcoming the challenges of separate optical character recognition (OCR) and
visual semantic understanding (VSU) components. However, its deployment in
production environments and edge devices is hindered by high memory and
computational demands, particularly in large-scale request services. To
overcome these challenges, we propose an optimization strategy based on
knowledge distillation and model pruning. Our paradigm to produce DONUT-hole,
reduces the model denisty by 54\% while preserving performance. We also achieve
a global representational similarity index between DONUT and DONUT-hole based
on centered kernel alignment (CKA) metric of 0.79. Moreover, we evaluate the
effectiveness of DONUT-hole in the document image key information extraction
(KIE) task, highlighting its potential for developing more efficient VDU
systems for logistic companies.
</p>

### Title: Quantized Distillation: Optimizing Driver Activity Recognition Models for Resource-Constrained Environments. (arXiv:2311.05970v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2311.05970](http://arxiv.org/abs/2311.05970)
* Code URL: [https://github.com/calvintanama/qd-driver-activity-reco](https://github.com/calvintanama/qd-driver-activity-reco)
* Copy Paste: `<input type="checkbox">[[2311.05970] Quantized Distillation: Optimizing Driver Activity Recognition Models for Resource-Constrained Environments](http://arxiv.org/abs/2311.05970) #memory`
* Summary: <p>Deep learning-based models are at the forefront of most driver observation
benchmarks due to their remarkable accuracies but are also associated with high
computational costs. This is challenging, as resources are often limited in
real-world driving scenarios. This paper introduces a lightweight framework for
resource-efficient driver activity recognition. The framework enhances 3D
MobileNet, a neural architecture optimized for speed in video classification,
by incorporating knowledge distillation and model quantization to balance model
accuracy and computational efficiency. Knowledge distillation helps maintain
accuracy while reducing the model size by leveraging soft labels from a larger
teacher model (I3D), instead of relying solely on original ground truth data.
Model quantization significantly lowers memory and computation demands by using
lower precision integers for model weights and activations. Extensive testing
on a public dataset for in-vehicle monitoring during autonomous driving
demonstrates that this new framework achieves a threefold reduction in model
size and a 1.4-fold improvement in inference time, compared to an already
optimized architecture. The code for this study is available at
https://github.com/calvintanama/qd-driver-activity-reco.
</p>

### Title: Robust Adversarial Attacks Detection for Deep Learning based Relative Pose Estimation for Space Rendezvous. (arXiv:2311.05992v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2311.05992](http://arxiv.org/abs/2311.05992)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.05992] Robust Adversarial Attacks Detection for Deep Learning based Relative Pose Estimation for Space Rendezvous](http://arxiv.org/abs/2311.05992) #memory`
* Summary: <p>Research on developing deep learning techniques for autonomous spacecraft
relative navigation challenges is continuously growing in recent years.
Adopting those techniques offers enhanced performance. However, such approaches
also introduce heightened apprehensions regarding the trustability and security
of such deep learning methods through their susceptibility to adversarial
attacks. In this work, we propose a novel approach for adversarial attack
detection for deep neural network-based relative pose estimation schemes based
on the explainability concept. We develop for an orbital rendezvous scenario an
innovative relative pose estimation technique adopting our proposed
Convolutional Neural Network (CNN), which takes an image from the chaser's
onboard camera and outputs accurately the target's relative position and
rotation. We perturb seamlessly the input images using adversarial attacks that
are generated by the Fast Gradient Sign Method (FGSM). The adversarial attack
detector is then built based on a Long Short Term Memory (LSTM) network which
takes the explainability measure namely SHapley Value from the CNN-based pose
estimator and flags the detection of adversarial attacks when acting.
Simulation results show that the proposed adversarial attack detector achieves
a detection accuracy of 99.21%. Both the deep relative pose estimator and
adversarial attack detector are then tested on real data captured from our
laboratory-designed setup. The experimental results from our
laboratory-designed setup demonstrate that the proposed adversarial attack
detector achieves an average detection accuracy of 96.29%.
</p>

### Title: Learning Contrastive Self-Distillation for Ultra-Fine-Grained Visual Categorization Targeting Limited Samples. (arXiv:2311.06056v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2311.06056](http://arxiv.org/abs/2311.06056)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.06056] Learning Contrastive Self-Distillation for Ultra-Fine-Grained Visual Categorization Targeting Limited Samples](http://arxiv.org/abs/2311.06056) #memory`
* Summary: <p>In the field of intelligent multimedia analysis, ultra-fine-grained visual
categorization (Ultra-FGVC) plays a vital role in distinguishing intricate
subcategories within broader categories. However, this task is inherently
challenging due to the complex granularity of category subdivisions and the
limited availability of data for each category. To address these challenges,
this work proposes CSDNet, a pioneering framework that effectively explores
contrastive learning and self-distillation to learn discriminative
representations specifically designed for Ultra-FGVC tasks. CSDNet comprises
three main modules: Subcategory-Specific Discrepancy Parsing (SSDP), Dynamic
Discrepancy Learning (DDL), and Subcategory-Specific Discrepancy Transfer
(SSDT), which collectively enhance the generalization of deep models across
instance, feature, and logit prediction levels. To increase the diversity of
training samples, the SSDP module introduces augmented samples from different
viewpoints to spotlight subcategory-specific discrepancies. Simultaneously, the
proposed DDL module stores historical intermediate features by a dynamic memory
queue, which optimizes the feature learning space through iterative contrastive
learning. Furthermore, the SSDT module is developed by a novel
self-distillation paradigm at the logit prediction level of raw and augmented
samples, which effectively distills more subcategory-specific discrepancies
knowledge from the inherent structure of limited training data without
requiring additional annotations. Experimental results demonstrate that CSDNet
outperforms current state-of-the-art Ultra-FGVC methods, emphasizing its
powerful efficacy and adaptability in addressing Ultra-FGVC tasks.
</p>

### Title: Robust Constant-Time Cryptography. (arXiv:2311.05831v1 [cs.CR])
* Paper URL: [http://arxiv.org/abs/2311.05831](http://arxiv.org/abs/2311.05831)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.05831] Robust Constant-Time Cryptography](http://arxiv.org/abs/2311.05831) #memory`
* Summary: <p>The constant-time property is considered the security standard for
cryptographic code. Code following the constant-time discipline is free from
secret-dependent branches and memory accesses, and thus avoids leaking secrets
through cache and timing side-channels. The constant-time property makes a
number of implicit assumptions that are fundamentally at odds with the reality
of cryptographic code. Constant-time is not robust. The first issue with
constant-time is that it is a whole-program property: It relies on the entirety
of the code base being constant-time. But, cryptographic developers do not
generally write whole programs; rather, they provide libraries and specific
algorithms for other application developers to use. As such, developers of
security libraries must maintain their security guarantees even when their code
is operating within (potentially untrusted) application contexts. Constant-time
requires memory safety. The whole-program nature of constant-time also leads to
a second issue: constant-time requires memory safety of all the running code.
Any memory safety bugs, whether in the library or the application, will wend
their way back to side-channel leaks of secrets if not direct disclosure. And
although cryptographic libraries should (and are) written to be memory-safe, it
is unfortunately unrealistic to expect the same from every application that
uses each library. We formalize robust constant-time and build a RobustIsoCrypt
compiler that transforms the library code and protects the secrets even when
they are linked with untrusted code. Our evaluation with SUPERCOP benchmarking
framework shows that the performance overhead is less than five percent on
average.
</p>

### Title: FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores. (arXiv:2311.05908v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2311.05908](http://arxiv.org/abs/2311.05908)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.05908] FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores](http://arxiv.org/abs/2311.05908) #memory`
* Summary: <p>Convolution models with long filters have demonstrated state-of-the-art
reasoning abilities in many long-sequence tasks but lag behind the most
optimized Transformers in wall-clock time. A major bottleneck is the Fast
Fourier Transform (FFT)--which allows long convolutions to run in $O(N logN)$
time in sequence length $N$ but has poor hardware utilization. In this paper,
we study how to optimize the FFT convolution. We find two key bottlenecks: the
FFT does not effectively use specialized matrix multiply units, and it incurs
expensive I/O between layers of the memory hierarchy. In response, we propose
FlashFFTConv. FlashFFTConv uses a matrix decomposition that computes the FFT
using matrix multiply units and enables kernel fusion for long sequences,
reducing I/O. We also present two sparse convolution algorithms--1) partial
convolutions and 2) frequency-sparse convolutions--which can be implemented
simply by skipping blocks in the matrix decomposition, enabling further
opportunities for memory and compute savings. FlashFFTConv speeds up exact FFT
convolutions by up to 7.93$\times$ over PyTorch and achieves up to 4.4$\times$
speedup end-to-end. Given the same compute budget, FlashFFTConv allows
Hyena-GPT-s to achieve 2.3 points better perplexity on the PILE and
M2-BERT-base to achieve 3.3 points higher GLUE score--matching models with
twice the parameter count. FlashFFTConv also achieves 96.1% accuracy on
Path-512, a high-resolution vision task where no model had previously achieved
better than 50%. Furthermore, partial convolutions enable longer-sequence
models--yielding the first DNA model that can process the longest human genes
(2.3M base pairs)--and frequency-sparse convolutions speed up pretrained models
while maintaining or improving model quality.
</p>

## few-shot
### Title: Semantic-aware Video Representation for Few-shot Action Recognition. (arXiv:2311.06218v1 [cs.CV])
* Paper URL: [http://arxiv.org/abs/2311.06218](http://arxiv.org/abs/2311.06218)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.06218] Semantic-aware Video Representation for Few-shot Action Recognition](http://arxiv.org/abs/2311.06218) #few-shot`
* Summary: <p>Recent work on action recognition leverages 3D features and textual
information to achieve state-of-the-art performance. However, most of the
current few-shot action recognition methods still rely on 2D frame-level
representations, often require additional components to model temporal
relations, and employ complex distance functions to achieve accurate alignment
of these representations. In addition, existing methods struggle to effectively
integrate textual semantics, some resorting to concatenation or addition of
textual and visual features, and some using text merely as an additional
supervision without truly achieving feature fusion and information transfer
from different modalities. In this work, we propose a simple yet effective
Semantic-Aware Few-Shot Action Recognition (SAFSAR) model to address these
issues. We show that directly leveraging a 3D feature extractor combined with
an effective feature-fusion scheme, and a simple cosine similarity for
classification can yield better performance without the need of extra
components for temporal modeling or complex distance functions. We introduce an
innovative scheme to encode the textual semantics into the video representation
which adaptively fuses features from text and video, and encourages the visual
encoder to extract more semantically consistent features. In this scheme,
SAFSAR achieves alignment and fusion in a compact way. Experiments on five
challenging few-shot action recognition benchmarks under various settings
demonstrate that the proposed SAFSAR model significantly improves the
state-of-the-art performance.
</p>

### Title: Chatbots Are Not Reliable Text Annotators. (arXiv:2311.05769v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2311.05769](http://arxiv.org/abs/2311.05769)
* Code URL: [https://github.com/centre-for-humanities-computing/llm-tweet-classification](https://github.com/centre-for-humanities-computing/llm-tweet-classification)
* Copy Paste: `<input type="checkbox">[[2311.05769] Chatbots Are Not Reliable Text Annotators](http://arxiv.org/abs/2311.05769) #few-shot`
* Summary: <p>Recent research highlights the significant potential of ChatGPT for text
annotation in social science research. However, ChatGPT is a closed-source
product which has major drawbacks with regards to transparency,
reproducibility, cost, and data protection. Recent advances in open-source (OS)
large language models (LLMs) offer alternatives which remedy these challenges.
This means that it is important to evaluate the performance of OS LLMs relative
to ChatGPT and standard approaches to supervised machine learning
classification. We conduct a systematic comparative evaluation of the
performance of a range of OS LLM models alongside ChatGPT, using both zero- and
few-shot learning as well as generic and custom prompts, with results compared
to more traditional supervised classification models. Using a new dataset of
Tweets from US news media, and focusing on simple binary text annotation tasks
for standard social science concepts, we find significant variation in the
performance of ChatGPT and OS models across the tasks, and that supervised
classifiers consistently outperform both. Given the unreliable performance of
ChatGPT and the significant challenges it poses to Open Science we advise
against using ChatGPT for substantive text annotation tasks in social science
research.
</p>

### Title: Chain of Thought with Explicit Evidence Reasoning for Few-shot Relation Extraction. (arXiv:2311.05922v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2311.05922](http://arxiv.org/abs/2311.05922)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.05922] Chain of Thought with Explicit Evidence Reasoning for Few-shot Relation Extraction](http://arxiv.org/abs/2311.05922) #few-shot`
* Summary: <p>Few-shot relation extraction involves identifying the type of relationship
between two specific entities within a text, using a limited number of
annotated samples. A variety of solutions to this problem have emerged by
applying meta-learning and neural graph techniques which typically necessitate
a training process for adaptation. Recently, the strategy of in-context
learning has been demonstrating notable results without the need of training.
Few studies have already utilized in-context learning for zero-shot information
extraction. Unfortunately, the evidence for inference is either not considered
or implicitly modeled during the construction of chain-of-thought prompts. In
this paper, we propose a novel approach for few-shot relation extraction using
large language models, named CoT-ER, chain-of-thought with explicit evidence
reasoning. In particular, CoT-ER first induces large language models to
generate evidences using task-specific and concept-level knowledge. Then these
evidences are explicitly incorporated into chain-of-thought prompting for
relation extraction. Experimental results demonstrate that our CoT-ER approach
(with 0% training data) achieves competitive performance compared to the
fully-supervised (with 100% training data) state-of-the-art approach on the
FewRel1.0 and FewRel2.0 datasets.
</p>

### Title: Large Language Models are Zero Shot Hypothesis Proposers. (arXiv:2311.05965v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2311.05965](http://arxiv.org/abs/2311.05965)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.05965] Large Language Models are Zero Shot Hypothesis Proposers](http://arxiv.org/abs/2311.05965) #few-shot`
* Summary: <p>Significant scientific discoveries have driven the progress of human
civilisation. The explosion of scientific literature and data has created
information barriers across disciplines that have slowed the pace of scientific
discovery. Large Language Models (LLMs) hold a wealth of global and
interdisciplinary knowledge that promises to break down these information
barriers and foster a new wave of scientific discovery. However, the potential
of LLMs for scientific discovery has not been formally explored. In this paper,
we start from investigating whether LLMs can propose scientific hypotheses. To
this end, we construct a dataset consist of background knowledge and hypothesis
pairs from biomedical literature. The dataset is divided into training, seen,
and unseen test sets based on the publication date to control visibility. We
subsequently evaluate the hypothesis generation capabilities of various
top-tier instructed models in zero-shot, few-shot, and fine-tuning settings,
including both closed and open-source LLMs. Additionally, we introduce an
LLM-based multi-agent cooperative framework with different role designs and
external tools to enhance the capabilities related to generating hypotheses. We
also design four metrics through a comprehensive review to evaluate the
generated hypotheses for both ChatGPT-based and human evaluations. Through
experiments and analyses, we arrive at the following findings: 1) LLMs
surprisingly generate untrained yet validated hypotheses from testing
literature. 2) Increasing uncertainty facilitates candidate generation,
potentially enhancing zero-shot hypothesis generation capabilities. These
findings strongly support the potential of LLMs as catalysts for new scientific
discoveries and guide further exploration.
</p>

### Title: Making LLMs Worth Every Penny: Resource-Limited Text Classification in Banking. (arXiv:2311.06102v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2311.06102](http://arxiv.org/abs/2311.06102)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.06102] Making LLMs Worth Every Penny: Resource-Limited Text Classification in Banking](http://arxiv.org/abs/2311.06102) #few-shot`
* Summary: <p>Standard Full-Data classifiers in NLP demand thousands of labeled examples,
which is impractical in data-limited domains. Few-shot methods offer an
alternative, utilizing contrastive learning techniques that can be effective
with as little as 20 examples per class. Similarly, Large Language Models
(LLMs) like GPT-4 can perform effectively with just 1-5 examples per class.
However, the performance-cost trade-offs of these methods remain underexplored,
a critical concern for budget-limited organizations. Our work addresses this
gap by studying the aforementioned approaches over the Banking77 financial
intent detection dataset, including the evaluation of cutting-edge LLMs by
OpenAI, Cohere, and Anthropic in a comprehensive set of few-shot scenarios. We
complete the picture with two additional methods: first, a cost-effective
querying method for LLMs based on retrieval-augmented generation (RAG), able to
reduce operational costs multiple times compared to classic few-shot
approaches, and second, a data augmentation method using GPT-4, able to improve
performance in data-limited scenarios. Finally, to inspire future research, we
provide a human expert's curated subset of Banking77, along with extensive
error analysis.
</p>

### Title: Language Models can be Logical Solvers. (arXiv:2311.06158v1 [cs.CL])
* Paper URL: [http://arxiv.org/abs/2311.06158](http://arxiv.org/abs/2311.06158)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.06158] Language Models can be Logical Solvers](http://arxiv.org/abs/2311.06158) #few-shot`
* Summary: <p>Logical reasoning is a fundamental aspect of human intelligence and a key
component of tasks like problem-solving and decision-making. Recent
advancements have enabled Large Language Models (LLMs) to potentially exhibit
reasoning capabilities, but complex logical reasoning remains a challenge. The
state-of-the-art, solver-augmented language models, use LLMs to parse natural
language logical questions into symbolic representations first and then adopt
external logical solvers to take in the symbolic representations and output the
answers. Despite their impressive performance, any parsing errors will
inevitably result in the failure of the execution of the external logical
solver and no answer to the logical questions. In this paper, we introduce
LoGiPT, a novel language model that directly emulates the reasoning processes
of logical solvers and bypasses the parsing errors by learning to strict
adherence to solver syntax and grammar. LoGiPT is fine-tuned on a newly
constructed instruction-tuning dataset derived from revealing and refining the
invisible reasoning process of deductive solvers. Experimental results on two
public deductive reasoning datasets demonstrate that LoGiPT outperforms
state-of-the-art solver-augmented LMs and few-shot prompting methods on
competitive LLMs like ChatGPT or GPT-4.
</p>

### Title: Enhancing Instance-Level Image Classification with Set-Level Labels. (arXiv:2311.05659v1 [cs.LG])
* Paper URL: [http://arxiv.org/abs/2311.05659](http://arxiv.org/abs/2311.05659)
* Code URL: null
* Copy Paste: `<input type="checkbox">[[2311.05659] Enhancing Instance-Level Image Classification with Set-Level Labels](http://arxiv.org/abs/2311.05659) #few-shot`
* Summary: <p>Instance-level image classification tasks have traditionally relied on
single-instance labels to train models, e.g., few-shot learning and transfer
learning. However, set-level coarse-grained labels that capture relationships
among instances can provide richer information in real-world scenarios. In this
paper, we present a novel approach to enhance instance-level image
classification by leveraging set-level labels. We provide a theoretical
analysis of the proposed method, including recognition conditions for fast
excess risk rate, shedding light on the theoretical foundations of our
approach. We conducted experiments on two distinct categories of datasets:
natural image datasets and histopathology image datasets. Our experimental
results demonstrate the effectiveness of our approach, showcasing improved
classification performance compared to traditional single-instance label-based
methods. Notably, our algorithm achieves 13% improvement in classification
accuracy compared to the strongest baseline on the histopathology image
classification benchmarks. Importantly, our experimental findings align with
the theoretical analysis, reinforcing the robustness and reliability of our
proposed method. This work bridges the gap between instance-level and set-level
image classification, offering a promising avenue for advancing the
capabilities of image classification models with set-level coarse-grained
labels.
</p>

