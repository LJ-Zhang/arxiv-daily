### Title: Localizing narrow Fe K$Î±$ emission within bright AGN
* Paper ID: 2204.09469v2
* Paper URL: [http://arxiv.org/abs/2204.09469v2](http://arxiv.org/abs/2204.09469v2)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The 6.4 keV Fe Ka emission line is a ubiquitous feature in X-ray spectra of
AGN, and its properties track the interaction between the variable primary
X-ray continuum and the surrounding structure from which it arises. We clarify
the nature and origin of the narrow Fe Ka emission using X-ray spectral,
timing, and imaging constraints, plus possible correlations to AGN and host
galaxy properties, for 38 bright nearby AGN ($z<0.5$) from the BAT AGN
Spectroscopic Survey. Modeling Chandra and XMM-Newton spectra, we computed line
full-width half-maxima (FWHMs) and constructed Fe Ka line and 2-10 keV
continuum light curves. The FWHM provides one estimate of the Fe Ka emitting
region size, RFeKa, assuming virial motion. A second estimate comes from
comparing the degree of correlation between the variability of the continuum
and line-only light curves, compared to simulated light curves. Finally, we
extracted Chandra radial profiles to place upper limits on RFeKa. We found that
for 90% (21/24) of AGN with FWHM measurements, RFeKa is smaller than the
fiducial dust sublimation radius, Rsub. Despite a wide range of variability
properties, the constraints on the Fe Ka photon reprocessor size independently
confirm that RFeKa is smaller than Rsub in 83% of AGN. Finally, the imaging
analysis yields loose upper limits for all but two sources; notably, the
Circinus Galaxy and NGC 1068 show significant but subdominant extended Fe Ka
emission out to $\sim$100 and $\sim$800 pc, respectively. Based on independent
constraints, we conclude that the majority of the narrow Fe Ka emission in
typical AGN predominantly arises from regions smaller than and presumably
inside Rsub, and thus it is associated either with the outer broad line region
or outer accretion disk. However, the large diversity of continuum and narrow
Fe Ka variability properties are not easily accommodated by a universal
scenario.

### Title: MANIQA: Multi-dimension Attention Network for No-Reference Image Quality Assessment
* Paper ID: 2204.08958v2
* Paper URL: [http://arxiv.org/abs/2204.08958v2](http://arxiv.org/abs/2204.08958v2)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/iigroup/maniqa](https://github.com/iigroup/maniqa)
* Summary: No-Reference Image Quality Assessment (NR-IQA) aims to assess the perceptual
quality of images in accordance with human subjective perception.
Unfortunately, existing NR-IQA methods are far from meeting the needs of
predicting accurate quality scores on GAN-based distortion images. To this end,
we propose Multi-dimension Attention Network for no-reference Image Quality
Assessment (MANIQA) to improve the performance on GAN-based distortion. We
firstly extract features via ViT, then to strengthen global and local
interactions, we propose the Transposed Attention Block (TAB) and the Scale
Swin Transformer Block (SSTB). These two modules apply attention mechanisms
across the channel and spatial dimension, respectively. In this
multi-dimensional manner, the modules cooperatively increase the interaction
among different regions of images globally and locally. Finally, a dual branch
structure for patch-weighted quality prediction is applied to predict the final
score depending on the weight of each patch's score. Experimental results
demonstrate that MANIQA outperforms state-of-the-art methods on four standard
datasets (LIVE, TID2013, CSIQ, and KADID-10K) by a large margin. Besides, our
method ranked first place in the final testing phase of the NTIRE 2022
Perceptual Image Quality Assessment Challenge Track 2: No-Reference. Codes and
models are available at https://github.com/IIGROUP/MANIQA.

### Title: Coulomb-Nuclear Interference: Theory and Practice for pp-Scattering at 13 TeV
* Paper ID: 2204.08815v2
* Paper URL: [http://arxiv.org/abs/2204.08815v2](http://arxiv.org/abs/2204.08815v2)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: We provide a detailed reconsideration of the theoretical basis for the
treatment of Coulomb-nuclear interference (CNI) and a corresponding thorough
analysis of the procedure of extraction of the basic parameters $\rho^{~pp},
\sigma_{tot}^{~pp}$ and $B^{~pp}$ from the TOTEM data at $\sqrt{s} = 13$ TeV. A
more substantiated account of CNI, as well as an in-depth statistical analysis
of the TOTEM data at low transferred momenta, give results that differ from
those published by the TOTEM collaboration.

### Title: Measurement of inclusive and leading subjet fragmentation in pp and Pb-Pb collisions at $\sqrt{s_{\rm NN}}$ = 5.02 TeV
* Paper ID: 2204.10270v1
* Paper URL: [http://arxiv.org/abs/2204.10270v1](http://arxiv.org/abs/2204.10270v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: This article presents new measurements of the fragmentation properties of
jets in both proton-proton (pp) and heavy-ion collisions with the ALICE
experiment at the Large Hadron Collider (LHC). We report distributions of the
fraction $z_r$ of transverse momentum carried by subjets of radius $r$ within
jets of radius $R$. Charged-particle jets are reconstructed at midrapidity
using the anti-$k_{\rm{T}}$ algorithm with jet radius $R=0.4$, and subjets are
reconstructed by reclustering the jet constituents using the anti-$k_{\rm{T}}$
algorithm with radii $r=0.1$ and $r=0.2$. In proton-proton collisions, we
measure both the inclusive and leading subjet distributions. We compare these
measurements to perturbative calculations at next-to-leading logarithmic
accuracy, which suggest a large impact of threshold resummation and
hadronization effects on the $z_r$ distribution. In heavy-ion collisions, we
measure the leading subjet distributions, which allow access to a region of
harder jet fragmentation than has been probed by previous measurements of jet
quenching via hadron fragmentation distributions. The $z_r$ distributions
enable extraction of the parton-to-subjet fragmentation function and allow for
tests of the universality of jet fragmentation functions in the quark-gluon
plasma (QGP). We find indications that there is a turnover in the ratio between
the distributions in Pb-Pb and pp collisions as $z_r \rightarrow 1$, exposing
qualitatively new possibilities to disentangle competing jet quenching
mechanisms. By comparing our results to theoretical calculations based on an
independent extraction of the parton-to-jet fragmentation function, we find
consistency with the universality of jet fragmentation and no indication of
factorization breaking in the QGP.

### Title: Elliptic flow of charged particles at midrapidity relative to the spectator plane in Pb-Pb and Xe-Xe collisions
* Paper ID: 2204.10240v1
* Paper URL: [http://arxiv.org/abs/2204.10240v1](http://arxiv.org/abs/2204.10240v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Measurements of the elliptic flow coefficient relative to the collision plane
defined by the spectator neutrons $v_2${$\Psi_{\rm SP}$} in collisions of Pb
ions at center-of-mass energy per nucleon-nucleon pair $\sqrt{s_{\rm NN}}$=2.76
TeV and Xe ions at $\sqrt{s_{\rm NN}}$=5.44 TeV are reported. The results are
presented for charged particles produced at midrapidity as a function of
centrality and transverse momentum. The ratio between $v_2${$\Psi_{\rm SP}$}
and the elliptic flow coefficient relative to the participant plane $v_2${4},
estimated using four-particle correlations, deviates by up to 20% from unity
depending on centrality. This observation differs strongly from the magnitude
of the corresponding eccentricity ratios predicted by the TRENTo and the
elliptic power models of initial state fluctuations that are tuned to describe
the participant plane anisotropies. The differences can be interpreted as a
decorrelation of the neutron spectator plane and the reaction plane because of
fragmentation of the remnants from the colliding nuclei, which points to an
incompleteness of current models of initial state fluctuations. A significant
transverse momentum dependence of the ratio $v_2${$\Psi_{\rm SP}$}/$v_2${4} is
observed in all but the most central collisions, which may help to understand
whether momentum anisotropies at low and intermediate transverse momentum have
a common origin in initial state fluctuations. The ratios of $v_2${$\Psi_{\rm
SP}$} and $v_2${4} to the corresponding initial state eccentricities for Xe-Xe
and Pb-Pb collisions at similar initial entropy density show a difference of
$(7.0 \pm 0.9)$% with an additional variation of +1.8% when including RHIC data
in the TRENTo parameter extraction. These observations provide new experimental
constraints for viscous effects in the hydrodynamic modeling of the expanding
quark-gluon plasma.

### Title: HEATGait: Hop-Extracted Adjacency Technique in Graph Convolution based Gait Recognition
* Paper ID: 2204.10238v1
* Paper URL: [http://arxiv.org/abs/2204.10238v1](http://arxiv.org/abs/2204.10238v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Biometric authentication using gait has become a promising field due to its
unobtrusive nature. Recent approaches in model-based gait recognition
techniques utilize spatio-temporal graphs for the elegant extraction of gait
features. However, existing methods often rely on multi-scale operators for
extracting long-range relationships among joints resulting in biased weighting.
In this paper, we present HEATGait, a gait recognition system that improves the
existing multi-scale graph convolution by efficient hop-extraction technique to
alleviate the issue. Combined with preprocessing and augmentation techniques,
we propose a powerful feature extractor that utilizes ResGCN to achieve
state-of-the-art performance in model-based gait recognition on the CASIA-B
gait dataset.

### Title: Cross-Lingual Query-Based Summarization of Crisis-Related Social Media: An Abstractive Approach Using Transformers
* Paper ID: 2204.10230v1
* Paper URL: [http://arxiv.org/abs/2204.10230v1](http://arxiv.org/abs/2204.10230v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/vitiugin/cliqs-cm](https://github.com/vitiugin/cliqs-cm)
* Summary: Relevant and timely information collected from social media during crises can
be an invaluable resource for emergency management. However, extracting this
information remains a challenging task, particularly when dealing with social
media postings in multiple languages. This work proposes a cross-lingual method
for retrieving and summarizing crisis-relevant information from social media
postings. We describe a uniform way of expressing various information needs
through structured queries and a way of creating summaries answering those
information needs. The method is based on multilingual transformers embeddings.
Queries are written in one of the languages supported by the embeddings, and
the extracted sentences can be in any of the other languages supported.
Abstractive summaries are created by transformers. The evaluation, done by
crowdsourcing evaluators and emergency management experts, and carried out on
collections extracted from Twitter during five large-scale disasters spanning
ten languages, shows the flexibility of our approach. The generated summaries
are regarded as more focused, structured, and coherent than existing
state-of-the-art methods, and experts compare them favorably against summaries
created by existing, state-of-the-art methods.

### Title: The NIST CTS Speaker Recognition Challenge
* Paper ID: 2204.10228v1
* Paper URL: [http://arxiv.org/abs/2204.10228v1](http://arxiv.org/abs/2204.10228v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The US National Institute of Standards and Technology (NIST) has been
conducting a second iteration of the CTS challenge since August 2020. The
current iteration of the CTS Challenge is a leaderboard-style speaker
recognition evaluation using telephony data extracted from the unexposed
portions of the Call My Net 2 (CMN2) and Multi-Language Speech (MLS) corpora
collected by the LDC. The CTS Challenge is currently organized in a similar
manner to the SRE19 CTS Challenge, offering only an open training condition
using two evaluation subsets, namely Progress and Test. Unlike in the SRE19
Challenge, no training or development set was initially released, and NIST has
publicly released the leaderboards on both subsets for the CTS Challenge. Which
subset (i.e., Progress or Test) a trial belongs to is unknown to challenge
participants, and each system submission needs to contain outputs for all of
the trials. The CTS Challenge has also served, and will continue to do so, as a
prerequisite for entrance to the regular SREs (such as SRE21). Since August
2020, a total of 53 organizations (forming 33 teams) from academia and industry
have participated in the CTS Challenge and submitted more than 4400 valid
system outputs. This paper presents an overview of the evaluation and several
analyses of system performance for some primary conditions in the CTS
Challenge. The CTS Challenge results thus far indicate remarkable improvements
in performance due to 1) speaker embeddings extracted using large-scale and
complex neural network architectures such as ResNets along with angular margin
losses for speaker embedding extraction, 2) extensive data augmentation, 3) the
use of large amounts of in-house proprietary data from a large number of
labeled speakers, 4) long-duration fine-tuning.

### Title: The Proton Spin Structure Function $g_2$ and Generalized Polarizabilities in the Strong QCD Regime
* Paper ID: 2204.10224v1
* Paper URL: [http://arxiv.org/abs/2204.10224v1](http://arxiv.org/abs/2204.10224v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The strong interaction is not well understood at low energy, or for
interactions with low momentum transfer $Q^2$, but one of the clearest insights
we have comes from Chiral Perturbation Theory ($\chi$PT). This effective
treatment gives testable predictions for the nucleonic generalized
polarizabilities -- fundamental quantities describing the nucleon's response to
an external field. We have measured the proton's generalized spin
polarizabilities in the region where $\chi$PT is expected to be valid. Our
results include the first ever data for the transverse-longitudinal spin
polarizability $\delta_{LT}$, and also extend the coverage of the
polarizability $\overline{d_2}$ to very low $Q^2$ for the first time. These
results were extracted from moments of the structure function $g_2$, a quantity
which characterizes the internal spin structure of the proton. Our experiment
ran at Jefferson Lab using a polarized electron beam and a polarized solid
ammonia (NH$_3$) target. The $\delta_{LT}$ polarizability has remained a
challenging quantity for $\chi$PT to reproduce, despite its reduced sensitivity
to higher resonance contributions; recent competing calculations still disagree
with each other and also diverge from the measured neutron data at very low
$Q^2$. Our proton results provide discriminating power between existing
calculations, and will help provide a better understanding of this strong QCD
regime.

### Title: Learning spatiotemporal features from incomplete data for traffic flow prediction using hybrid deep neural networks
* Paper ID: 2204.10222v1
* Paper URL: [http://arxiv.org/abs/2204.10222v1](http://arxiv.org/abs/2204.10222v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Urban traffic flow prediction using data-driven models can play an important
role in route planning and preventing congestion on highways. These methods
utilize data collected from traffic recording stations at different timestamps
to predict the future status of traffic. Hence, data collection, transmission,
storage, and extraction techniques can have a significant impact on the
performance of the traffic flow model. On the other hand, a comprehensive
database can provide the opportunity for using complex, yet reliable predictive
models such as deep learning methods. However, most of these methods have
difficulties in handling missing values and outliers. This study focuses on
hybrid deep neural networks to predict traffic flow in the California Freeway
Performance Measurement System (PeMS) with missing values. The proposed
networks are based on a combination of recurrent neural networks (RNNs) to
consider the temporal dependencies in the data recorded in each station and
convolutional neural networks (CNNs) to take the spatial correlations in the
adjacent stations into account. Various architecture configurations with series
and parallel connections are considered based on RNNs and CNNs, and several
prevalent data imputation techniques are used to examine the robustness of the
hybrid networks to missing values. A comprehensive analysis performed on two
different datasets from PeMS indicates that the proposed series-parallel hybrid
network with the mean imputation technique achieves the lowest error in
predicting the traffic flow and is robust to missing values up until 21%
missing ratio in both complete and incomplete training data scenarios when
applied to an incomplete test data.

### Title: Message Flow Analysis with Complex Causal Links for Distributed ROS 2 Systems
* Paper ID: 2204.10208v1
* Paper URL: [http://arxiv.org/abs/2204.10208v1](http://arxiv.org/abs/2204.10208v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Distributed robotic systems rely heavily on publish-subscribe frameworks,
such as ROS, to efficiently implement modular computation graphs. The ROS 2
executor, a high-level task scheduler which handles messages internally, is a
performance bottleneck. In previous work, we presented ros2_tracing, a
framework with instrumentation and tools for real-time tracing of ROS 2. We now
extend on that instrumentation and leverage the tracing tools to propose an
analysis and visualization of the flow of messages across distributed ROS 2
systems. Our proposed method detects one-to-many and many-to-many causal links
between input and output messages, including indirect causal links through
simple user-level annotations. We validate our method on both synthetic and
real robotic systems, and demonstrate its low runtime overhead. Moreover, the
underlying intermediate execution representation database can be further
leveraged to extract additional metrics and high-level results. This can
provide valuable timing and scheduling information to further study and improve
the ROS 2 executor as well as optimize any ROS 2 system. The source code is
available at: https://github.com/christophebedard/ros2-message-flow-analysis.

### Title: Measurement of the vertical atmospheric density profile from the X-ray Earth occultation of the Crab Nebula with Insight-HXMT
* Paper ID: 2204.09674v1
* Paper URL: [http://arxiv.org/abs/2204.09674v1](http://arxiv.org/abs/2204.09674v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: In this paper, the X-ray Earth occultation (XEO) of the Crab Nebula is
investigated by using the Hard X-ray Modulation Telescope (Insight-HXMT). The
pointing observation data on the 30th September, 2018 recorded by the Low
Energy X-ray telescope (LE) of Insight-HXMT are selected and analyzed. The
extinction lightcurves and spectra during the X-ray Earth occultation process
are extracted. A forward model for the XEO lightcurve is established and the
theoretical observational signal for lightcurve is predicted. The atmospheric
density model is built with a scale factor to the commonly used MSIS density
profile within a certain altitude range. A Bayesian data analysis method is
developed for the XEO lightcurve modeling and the atmospheric density
retrieval. The posterior probability distribution of the model parameters is
derived through the Markov Chain Monte Carlo (MCMC) algorithm with the
NRLMSISE-00 model and the NRLMSIS 2.0 model as basis functions and the best-fit
density profiles are retrieved respectively. It is found that in the altitude
range of 105--200 km, the retrieved density profile is 88.8% of the density of
NRLMSISE-00 and 109.7% of the density of NRLMSIS 2.0 by fitting the lightcurve
in the energy range of 1.0--2.5 keV based on XEOS method. In the altitude range
of 95--125 km, the retrieved density profile is 81.0% of the density of
NRLMSISE-00 and 92.3% of the density of NRLMSIS 2.0 by fitting the lightcurve
in the energy range of 2.5--6.0 keV based on XEOS method. In the altitude range
of 85--110 km, the retrieved density profile is 87.7% of the density of
NRLMSISE-00 and 101.4% of the density of NRLMSIS 2.0 by fitting the lightcurve
in the energy range of 6.0--10.0 keV based on XEOS method. This study
demonstrates that the XEOS from the X-ray astronomical satellite Insight-HXMT
can provide an approach for the study of the upper atmosphere.

### Title: ALICE luminosity determination for Pb$-$Pb collisions at $\sqrt{s_{\mathrm{NN}}} = 5.02$ TeV
* Paper ID: 2204.10148v1
* Paper URL: [http://arxiv.org/abs/2204.10148v1](http://arxiv.org/abs/2204.10148v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Luminosity determination within the ALICE experiment is based on the
measurement, in van der Meer scans, of the cross sections for visible processes
involving one or more detectors (visible cross sections). In 2015 and 2018, the
Large Hadron Collider provided Pb$-$Pb collisions at a centre-of-mass energy
per nucleon pair of $\sqrt{s_{\rm NN}} = 5.02$ TeV. Two visible cross sections,
associated with particle detection in the Zero Degree Calorimeter (ZDC) and in
the V0 detector, were measured in a van der Meer scan. This article describes
the experimental set-up and the analysis procedure, and presents the
measurement results. The analysis involves a comprehensive study of
beam-related effects and an improved fitting procedure, compared to previous
ALICE studies, for the extraction of the visible cross section. The resulting
uncertainty of the ZDC-based (V0-based) luminosity measurement for the full
sample is 2.3% (2.2%). The inelastic cross section for hadronic interactions in
Pb$-$Pb collisions at $\sqrt{s_{\rm NN}} = 5.02$ TeV, obtained by efficiency
correction of the V0-based visible cross section, was measured to be $7.67 \pm
0.24$ b.

### Title: Learnable Model Augmentation Self-Supervised Learning for Sequential Recommendation
* Paper ID: 2204.10128v1
* Paper URL: [http://arxiv.org/abs/2204.10128v1](http://arxiv.org/abs/2204.10128v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Sequential Recommendation aims to predict the next item based on user
behaviour. Recently, Self-Supervised Learning (SSL) has been proposed to
improve recommendation performance. However, most of existing SSL methods use a
uniform data augmentation scheme, which loses the sequence correlation of an
original sequence. To this end, in this paper, we propose a Learnable Model
Augmentation self-supervised learning for sequential Recommendation (LMA4Rec).
Specifically, LMA4Rec first takes model augmentation as a supplementary method
for data augmentation to generate views. Then, LMA4Rec uses learnable Bernoulli
dropout to implement model augmentation learnable operations. Next,
self-supervised learning is used between the contrastive views to extract
self-supervised signals from an original sequence. Finally, experiments on
three public datasets show that the LMA4Rec method effectively improves
sequential recommendation performance compared with baseline methods.

### Title: Working memory inspired hierarchical video decomposition with transformative representations
* Paper ID: 2204.10105v1
* Paper URL: [http://arxiv.org/abs/2204.10105v1](http://arxiv.org/abs/2204.10105v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Video decomposition is very important to extract moving foreground objects
from complex backgrounds in computer vision, machine learning, and medical
imaging, e.g., extracting moving contrast-filled vessels from the complex and
noisy backgrounds of X-ray coronary angiography (XCA). However, the challenges
caused by dynamic backgrounds, overlapping heterogeneous environments and
complex noises still exist in video decomposition. To solve these problems,
this study is the first to introduce a flexible visual working memory model in
video decomposition tasks to provide interpretable and high-performance
hierarchical deep architecture, integrating the transformative representations
between sensory and control layers from the perspective of visual and cognitive
neuroscience. Specifically, robust PCA unrolling networks acting as a
structure-regularized sensor layer decompose XCA into sparse/low-rank
structured representations to separate moving contrast-filled vessels from
noisy and complex backgrounds. Then, patch recurrent convolutional LSTM
networks with a backprojection module embody unstructured random
representations of the control layer in working memory, recurrently projecting
spatiotemporally decomposed nonlocal patches into orthogonal subspaces for
heterogeneous vessel retrieval and interference suppression. This video
decomposition deep architecture effectively restores the heterogeneous profiles
of intensity and the geometries of moving objects against the complex
background interferences. Experiments show that the proposed method
significantly outperforms state-of-the-art methods in accurate moving
contrast-filled vessel extraction with excellent flexibility and computational
efficiency.

### Title: R2-Trans:Fine-Grained Visual Categorization with Redundancy Reduction
* Paper ID: 2204.10095v1
* Paper URL: [http://arxiv.org/abs/2204.10095v1](http://arxiv.org/abs/2204.10095v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Fine-grained visual categorization (FGVC) aims to discriminate similar
subcategories, whose main challenge is the large intraclass diversities and
subtle inter-class differences. Existing FGVC methods usually select
discriminant regions found by a trained model, which is prone to neglect other
potential discriminant information. On the other hand, the massive interactions
between the sequence of image patches in ViT make the resulting class-token
contain lots of redundant information, which may also impacts FGVC performance.
In this paper, we present a novel approach for FGVC, which can simultaneously
make use of partial yet sufficient discriminative information in environmental
cues and also compress the redundant information in class-token with respect to
the target. Specifically, our model calculates the ratio of high-weight regions
in a batch, adaptively adjusts the masking threshold and achieves moderate
extraction of background information in the input space. Moreover, we also use
the Information Bottleneck~(IB) approach to guide our network to learn a
minimum sufficient representations in the feature space. Experimental results
on three widely-used benchmark datasets verify that our approach can achieve
outperforming performance than other state-of-the-art approaches and baseline
models.

### Title: OTExtSum: Extractive Text Summarisation with Optimal Transport
* Paper ID: 2204.10086v1
* Paper URL: [http://arxiv.org/abs/2204.10086v1](http://arxiv.org/abs/2204.10086v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/peggypytang/otextsum](https://github.com/peggypytang/otextsum)
* Summary: Extractive text summarisation aims to select salient sentences from a
document to form a short yet informative summary. While learning-based methods
have achieved promising results, they have several limitations, such as
dependence on expensive training and lack of interpretability. Therefore, in
this paper, we propose a novel non-learning-based method by for the first time
formulating text summarisation as an Optimal Transport (OT) problem, namely
Optimal Transport Extractive Summariser (OTExtSum). Optimal sentence extraction
is conceptualised as obtaining an optimal summary that minimises the
transportation cost to a given document regarding their semantic distributions.
Such a cost is defined by the Wasserstein distance and used to measure the
summary's semantic coverage of the original document. Comprehensive experiments
on four challenging and widely used datasets - MultiNews, PubMed, BillSum, and
CNN/DM demonstrate that our proposed method outperforms the state-of-the-art
non-learning-based methods and several recent learning-based methods in terms
of the ROUGE metric.

### Title: Absolute Wrong Makes Better: Boosting Weakly Supervised Object Detection via Negative Deterministic Information
* Paper ID: 2204.10068v1
* Paper URL: [http://arxiv.org/abs/2204.10068v1](http://arxiv.org/abs/2204.10068v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Weakly supervised object detection (WSOD) is a challenging task, in which
image-level labels (e.g., categories of the instances in the whole image) are
used to train an object detector. Many existing methods follow the standard
multiple instance learning (MIL) paradigm and have achieved promising
performance. However, the lack of deterministic information leads to part
domination and missing instances. To address these issues, this paper focuses
on identifying and fully exploiting the deterministic information in WSOD. We
discover that negative instances (i.e. absolutely wrong instances), ignored in
most of the previous studies, normally contain valuable deterministic
information. Based on this observation, we here propose a negative
deterministic information (NDI) based method for improving WSOD, namely
NDI-WSOD. Specifically, our method consists of two stages: NDI collecting and
exploiting. In the collecting stage, we design several processes to identify
and distill the NDI from negative instances online. In the exploiting stage, we
utilize the extracted NDI to construct a novel negative contrastive learning
mechanism and a negative guided instance selection strategy for dealing with
the issues of part domination and missing instances, respectively. Experimental
results on several public benchmarks including VOC 2007, VOC 2012 and MS COCO
show that our method achieves satisfactory performance.

### Title: Mass spectra of $Î_{cc}$, $Î_{bc}$, $Î©_{cc}$, and $Î©_{bc}$ baryons in Regge Phenomenology
* Paper ID: 2204.10045v1
* Paper URL: [http://arxiv.org/abs/2204.10045v1](http://arxiv.org/abs/2204.10045v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: In this article, we study the mass spectra of baryons containing two heavy
quarks; charm-charm ($cc$) and bottom-charm ($bc$) with a light quark ($u,d,s$)
within the framework of Regge phenomenology. With the assumption of linear
Regge trajectories we have derived the relations between slope ratios,
intercepts, and baryon masses. Using these relations, the ground state masses
of $\Xi_{cc}$, $\Xi_{bc}$, $\Omega_{cc}$, and $\Omega_{bc}$ baryons are
obtained. The values of Regge slopes and Regge intercepts are extracted for
these baryons to estimate the excited state masses in both the ($J,M^{2}$) and
($n,M^{2}$) planes. Our obtained results are compared with the experimental
observations where available and other theoretical predictions, which could be
a valuable addition to the interpretations of experimentally unknown heavy
baryon spectra.

### Title: Measuring the anomalous quartic gauge couplings in the $W^+W^-\to W^+W^-$ process at muon collider using artificial neural networks
* Paper ID: 2204.10034v1
* Paper URL: [http://arxiv.org/abs/2204.10034v1](http://arxiv.org/abs/2204.10034v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The muon collider provides a unique opportunity to study the vector boson
scattering processes and dimension-8 operators contributing to anomalous
quartic gauge couplings. Because of the cleaner final state, it is easier to
decode subprocess and certain operator couplings at a muon collider. We attempt
to identify the anomalous $WWWW$ coupling in $WW\to WW$ scattering in this
paper. The vector boson scattering process corresponding to the anomalous
$WWWW$ coupling is $\mu^+\mu^-\to \nu\nu\bar{\nu}\bar{\nu}\ell^+\ell^-$, with
four (anti-)neutrinos in the final state, which pose difficulties for
phenomenological studies. In this paper, the machine learning method is used to
tackle this problem. We find that, the artificial neural network can be used to
extract the $W^+W^-\to W^+W^-$ contribution, and is useful to reconstruct the
center of mass energy of the subprocess which is important in the study of the
Standard Model effective field theory. The sensitivities and the expected
constraints on the dimension-8 operators at the muon collider with
$\sqrt{s}=30$ TeV are presented. The artificial neural networks exhibit great
potential in the phenomenological study of processes with multiple neutrinos in
the final state.

### Title: Ferrous Metal Matrix Composites Status Scope and Challenges
* Paper ID: 2204.09999v1
* Paper URL: [http://arxiv.org/abs/2204.09999v1](http://arxiv.org/abs/2204.09999v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The present paper is an effort to culminate the status, scopes and challenges
in the development of ferrous metal matrix composites (FMMCs). The FMMCs are
old but less in use than the non-ferrous metal matrix composites (NFMMCs), as
far as literature and actual applications are concerned. Therefore, this
stimulates the exploration of the reasons behind the scarcity of literature and
field applications of the FMMCs, which must be investigated scientifically. The
powder metallurgy route is the most used process for fabricating iron and steel
based FMMCs by reinforcing particulates. At the same time, the in-situ method
has been used for the fabrication and cast iron-based FMMCs. The main
characteristics being considered during the designing and fabrication of FMMCs
are wear resistance and improved specific mechanical properties. To fabricate
cheaper and eco-friendly FMMCs, traditionally used costly reinforcements such
as SiC, WC, TiC, SiO2, TiO2, TiB2 are required to be replaced by inexpensive
industrial wastes like red-mud, fly-ashes and grinding swarf. The data
extracted from the web of science exhibited that the FMMCs have been researched
less than the NFMMCs. The increasing number of research papers on FMMCs
indicates a bright future. FMMCs are going to be a favourite topic among
researchers and manufacturers. Higher strengths, wear resistance, dimensional
stability at elevated temperatures, and, most importantly, the lower cost will
put forward the FMMCs as a stiff competitor of NFMMCs. In developing and mass
production of FMMCs for field applications, challenges like oxidation and
higher weight still require special research efforts.

### Title: DGECN: A Depth-Guided Edge Convolutional Network for End-to-End 6D Pose Estimation
* Paper ID: 2204.09983v1
* Paper URL: [http://arxiv.org/abs/2204.09983v1](http://arxiv.org/abs/2204.09983v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Monocular 6D pose estimation is a fundamental task in computer vision.
Existing works often adopt a two-stage pipeline by establishing correspondences
and utilizing a RANSAC algorithm to calculate 6 degrees-of-freedom (6DoF) pose.
Recent works try to integrate differentiable RANSAC algorithms to achieve an
end-to-end 6D pose estimation. However, most of them hardly consider the
geometric features in 3D space, and ignore the topology cues when performing
differentiable RANSAC algorithms. To this end, we proposed a Depth-Guided Edge
Convolutional Network (DGECN) for 6D pose estimation task. We have made efforts
from the following three aspects: 1) We take advantages ofestimated depth
information to guide both the correspondences-extraction process and the
cascaded differentiable RANSAC algorithm with geometric information. 2)We
leverage the uncertainty ofthe estimated depth map to improve accuracy and
robustness ofthe output 6D pose. 3) We propose a differentiable
Perspective-n-Point(PnP) algorithm via edge convolution to explore the topology
relations between 2D-3D correspondences. Experiments demonstrate that our
proposed network outperforms current works on both effectiveness and
efficiency.

### Title: Using consumer feedback from location-based services in PoI recommender systems for people with autism
* Paper ID: 2204.09969v1
* Paper URL: [http://arxiv.org/abs/2204.09969v1](http://arxiv.org/abs/2204.09969v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: When suggesting Points of Interest (PoIs) to people with autism spectrum
disorders, we must take into account that they have idiosyncratic sensory
aversions to noise, brightness and other features that influence the way they
perceive places. Therefore, recommender systems must deal with these aspects.
However, the retrieval of sensory data about PoIs is a real challenge because
most geographical information servers fail to provide this data. Moreover,
ad-hoc crowdsourcing campaigns do not guarantee to cover large geographical
areas and lack sustainability. Thus, we investigate the extraction of sensory
data about places from the consumer feedback collected by location-based
services, on which people spontaneously post reviews from all over the world.
Specifically, we propose a model for the extraction of sensory data from the
reviews about PoIs, and its integration in recommender systems to predict item
ratings by considering both user preferences and compatibility information. We
tested our approach with autistic and neurotypical people by integrating it
into diverse recommendation algorithms. For the test, we used a dataset built
in a crowdsourcing campaign and another one extracted from TripAdvisor reviews.
The results show that the algorithms obtain the highest accuracy and ranking
capability when using TripAdvisor data. Moreover, by jointly using these two
datasets, the algorithms further improve their performance. These results
encourage the use of consumer feedback as a reliable source of information
about places in the development of inclusive recommender systems.

### Title: Transformer-Guided Convolutional Neural Network for Cross-View Geolocalization
* Paper ID: 2204.09967v1
* Paper URL: [http://arxiv.org/abs/2204.09967v1](http://arxiv.org/abs/2204.09967v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Ground-to-aerial geolocalization refers to localizing a ground-level query
image by matching it to a reference database of geo-tagged aerial imagery. This
is very challenging due to the huge perspective differences in visual
appearances and geometric configurations between these two views. In this work,
we propose a novel Transformer-guided convolutional neural network (TransGCNN)
architecture, which couples CNN-based local features with Transformer-based
global representations for enhanced representation learning. Specifically, our
TransGCNN consists of a CNN backbone extracting feature map from an input image
and a Transformer head modeling global context from the CNN map. In particular,
our Transformer head acts as a spatial-aware importance generator to select
salient CNN features as the final feature representation. Such a coupling
procedure allows us to leverage a lightweight Transformer network to greatly
enhance the discriminative capability of the embedded features. Furthermore, we
design a dual-branch Transformer head network to combine image features from
multi-scale windows in order to improve details of the global feature
representation. Extensive experiments on popular benchmark datasets demonstrate
that our model achieves top-1 accuracy of 94.12\% and 84.92\% on CVUSA and
CVACT_val, respectively, which outperforms the second-performing baseline with
less than 50% parameters and almost 2x higher frame rate, therefore achieving a
preferable accuracy-efficiency tradeoff.

### Title: Referring Expression Comprehension via Cross-Level Multi-Modal Fusion
* Paper ID: 2204.09957v1
* Paper URL: [http://arxiv.org/abs/2204.09957v1](http://arxiv.org/abs/2204.09957v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: As an important and challenging problem in vision-language tasks, referring
expression comprehension (REC) aims to localize the target object specified by
a given referring expression. Recently, most of the state-of-the-art REC
methods mainly focus on multi-modal fusion while overlooking the inherent
hierarchical information contained in visual and language encoders. Considering
that REC requires visual and textual hierarchical information for accurate
target localization, and encoders inherently extract features in a hierarchical
fashion, we propose to effectively utilize the rich hierarchical information
contained in different layers of visual and language encoders. To this end, we
design a Cross-level Multi-modal Fusion (CMF) framework, which gradually
integrates visual and textual features of multi-layer through intra- and
inter-modal. Experimental results on RefCOCO, RefCOCO+, RefCOCOg, and
ReferItGame datasets demonstrate the proposed framework achieves significant
performance improvements over state-of-the-art methods.

### Title: Recovering Patient Journeys: A Corpus of Biomedical Entities and Relations on Twitter (BEAR)
* Paper ID: 2204.09952v1
* Paper URL: [http://arxiv.org/abs/2204.09952v1](http://arxiv.org/abs/2204.09952v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Text mining and information extraction for the medical domain has focused on
scientific text generated by researchers. However, their direct access to
individual patient experiences or patient-doctor interactions can be limited.
Information provided on social media, e.g., by patients and their relatives,
complements the knowledge in scientific text. It reflects the patient's journey
and their subjective perspective on the process of developing symptoms, being
diagnosed and offered a treatment, being cured or learning to live with a
medical condition. The value of this type of data is therefore twofold:
Firstly, it offers direct access to people's perspectives. Secondly, it might
cover information that is not available elsewhere, including self-treatment or
self-diagnoses. Named entity recognition and relation extraction are methods to
structure information that is available in unstructured text. However, existing
medical social media corpora focused on a comparably small set of entities and
relations and particular domains, rather than putting the patient into the
center of analyses. With this paper we contribute a corpus with a rich set of
annotation layers following the motivation to uncover and model patients'
journeys and experiences in more detail. We label 14 entity classes (incl.
environmental factors, diagnostics, biochemical processes, patients'
quality-of-life descriptions, pathogens, medical conditions, and treatments)
and 20 relation classes (e.g., prevents, influences, interactions, causes) most
of which have not been considered before for social media data. The publicly
available dataset consists of 2,100 tweets with approx. 6,000 entity and 3,000
relation annotations. In a corpus analysis we find that over 80 % of documents
contain relevant entities. Over 50 % of tweets express relations which we
consider essential for uncovering patients' narratives about their journeys.

### Title: Hybrid Cloud-Edge Collaborative Data Anomaly Detection in Industrial Sensor Networks
* Paper ID: 2204.09942v1
* Paper URL: [http://arxiv.org/abs/2204.09942v1](http://arxiv.org/abs/2204.09942v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Industrial control systems (ICSs) are facing increasing cyber-physical
attacks that can cause catastrophes in the physical system. Efficient anomaly
detection models in the industrial sensor networks are essential for enhancing
ICS reliability and security, due to the sensor data is related to the
operational state of the ICS. Considering the limited availability of computing
resources, this paper proposes a hybrid anomaly detection approach in
cloud-edge collaboration industrial sensor networks. The hybrid approach
consists of sensor data detection models deployed at the edges and a sensor
data analysis model deployed in the cloud. The sensor data detection model
based on Gaussian and Bayesian algorithms can detect the anomalous sensor data
in real-time and upload them to the cloud for further analysis, filtering the
normal sensor data and reducing traffic load. The sensor data analysis model
based on Graph convolutional network, Residual algorithm and Long short-term
memory network (GCRL) can effectively extract the spatial and temporal features
and then identify the attack precisely. The proposed hybrid anomaly detection
approach is evaluated using a benchmark dataset and baseline anomaly detection
models. The experimental results show that the proposed approach can achieve an
overall 11.19% increase in Recall and an impressive 14.29% improvement in
F1-score, compared with the existing models.

### Title: Multi-task recommendation system for scientific papers with high-way networks
* Paper ID: 2204.09930v1
* Paper URL: [http://arxiv.org/abs/2204.09930v1](http://arxiv.org/abs/2204.09930v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Finding and selecting the most relevant scientific papers from a large number
of papers written in a research community is one of the key challenges for
researchers these days. As we know, much information around research interest
for scholars and academicians belongs to papers they read. Analysis and
extracting contextual features from these papers could help us to suggest the
most related paper to them. In this paper, we present a multi-task
recommendation system (RS) that predicts a paper recommendation and generates
its meta-data such as keywords. The system is implemented as a three-stage deep
neural network encoder that tries to maps longer sequences of text to an
embedding vector and learns simultaneously to predict the recommendation rate
for a particular user and the paper's keywords. The motivation behind this
approach is that the paper's topics expressed as keywords are a useful
predictor of preferences of researchers. To achieve this goal, we use a system
combination of RNNs, Highway and Convolutional Neural Networks to train
end-to-end a context-aware collaborative matrix. Our application uses Highway
networks to train the system very deep, combine the benefits of RNN and CNN to
find the most important factor and make latent representation. Highway Networks
allow us to enhance the traditional RNN and CNN pipeline by learning more
sophisticated semantic structural representations. Using this method we can
also overcome the cold start problem and learn latent features over large
sequences of text.

### Title: Normalization procedure for obtaining the local density of states from high-bias scanning tunneling spectroscopy
* Paper ID: 2204.09929v1
* Paper URL: [http://arxiv.org/abs/2204.09929v1](http://arxiv.org/abs/2204.09929v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Differential conductance spectroscopy performed in the high bias regime -- in
which the applied voltage exceeds the sample work function -- is a poor measure
of the local density of states due to the effects of the changing tunnel
barrier. Additionally, the large applied voltage oftentimes makes
constant-height measurement experimentally impractical, lending
constant-current spectroscopy an advantageous edge; but the differential
conductance in that case is even further removed from the local density of
states due to the changing tip height. Here, we present a normalization scheme
for extracting the local density of states from high bias scanning tunneling
spectroscopy, obtained in either constant-current or constant-height mode. We
extend this model to account for the effects of the in-plane momentum of the
probed states to the overall current. We demonstrate the validity of the
proposed scheme by applying it to laterally confined field-emission resonances,
which appear as peak-shaped spectroscopic features with a well-defined in-plane
momentum.

### Title: CPGNet: Cascade Point-Grid Fusion Network for Real-Time LiDAR Semantic Segmentation
* Paper ID: 2204.09914v1
* Paper URL: [http://arxiv.org/abs/2204.09914v1](http://arxiv.org/abs/2204.09914v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: LiDAR semantic segmentation essential for advanced autonomous driving is
required to be accurate, fast, and easy-deployed on mobile platforms. Previous
point-based or sparse voxel-based methods are far away from real-time
applications since time-consuming neighbor searching or sparse 3D convolution
are employed. Recent 2D projection-based methods, including range view and
multi-view fusion, can run in real time, but suffer from lower accuracy due to
information loss during the 2D projection. Besides, to improve the performance,
previous methods usually adopt test time augmentation (TTA), which further
slows down the inference process. To achieve a better speed-accuracy trade-off,
we propose Cascade Point-Grid Fusion Network (CPGNet), which ensures both
effectiveness and efficiency mainly by the following two techniques: 1) the
novel Point-Grid (PG) fusion block extracts semantic features mainly on the 2D
projected grid for efficiency, while summarizes both 2D and 3D features on 3D
point for minimal information loss; 2) the proposed transformation consistency
loss narrows the gap between the single-time model inference and TTA. The
experiments on the SemanticKITTI and nuScenes benchmarks demonstrate that the
CPGNet without ensemble models or TTA is comparable with the state-of-the-art
RPVNet, while it runs 4.7 times faster.

### Title: MAP-SNN: Mapping Spike Activities with Multiplicity, Adaptability, and Plasticity into Bio-Plausible Spiking Neural Networks
* Paper ID: 2204.09893v1
* Paper URL: [http://arxiv.org/abs/2204.09893v1](http://arxiv.org/abs/2204.09893v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Spiking Neural Network (SNN) is considered more biologically realistic and
power-efficient as it imitates the fundamental mechanism of the human brain.
Recently, backpropagation (BP) based SNN learning algorithms that utilize deep
learning frameworks have achieved good performance. However,
bio-interpretability is partially neglected in those BP-based algorithms.
Toward bio-plausible BP-based SNNs, we consider three properties in modeling
spike activities: Multiplicity, Adaptability, and Plasticity (MAP). In terms of
multiplicity, we propose a Multiple-Spike Pattern (MSP) with multiple spike
transmission to strengthen model robustness in discrete time-iteration. To
realize adaptability, we adopt Spike Frequency Adaption (SFA) under MSP to
decrease spike activities for improved efficiency. For plasticity, we propose a
trainable convolutional synapse that models spike response current to enhance
the diversity of spiking neurons for temporal feature extraction. The proposed
SNN model achieves competitive performances on neuromorphic datasets: N-MNIST
and SHD. Furthermore, experimental results demonstrate that the proposed three
aspects are significant to iterative robustness, spike efficiency, and temporal
feature extraction capability of spike activities. In summary, this work
proposes a feasible scheme for bio-inspired spike activities with MAP, offering
a new neuromorphic perspective to embed biological characteristics into spiking
neural networks.

### Title: Layer-wise Fast Adaptation for End-to-End Multi-Accent Speech Recognition
* Paper ID: 2204.09883v1
* Paper URL: [http://arxiv.org/abs/2204.09883v1](http://arxiv.org/abs/2204.09883v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Accent variability has posed a huge challenge to automatic speech
recognition~(ASR) modeling. Although one-hot accent vector based adaptation
systems are commonly used, they require prior knowledge about the target accent
and cannot handle unseen accents. Furthermore, simply concatenating accent
embeddings does not make good use of accent knowledge, which has limited
improvements. In this work, we aim to tackle these problems with a novel
layer-wise adaptation structure injected into the E2E ASR model encoder. The
adapter layer encodes an arbitrary accent in the accent space and assists the
ASR model in recognizing accented speech. Given an utterance, the adaptation
structure extracts the corresponding accent information and transforms the
input acoustic feature into an accent-related feature through the linear
combination of all accent bases. We further explore the injection position of
the adaptation layer, the number of accent bases, and different types of accent
bases to achieve better accent adaptation. Experimental results show that the
proposed adaptation structure brings 12\% and 10\% relative word error
rate~(WER) reduction on the AESRC2020 accent dataset and the Librispeech
dataset, respectively, compared to the baseline.

### Title: Exploring a Fine-Grained Multiscale Method for Cross-Modal Remote Sensing Image Retrieval
* Paper ID: 2204.09868v1
* Paper URL: [http://arxiv.org/abs/2204.09868v1](http://arxiv.org/abs/2204.09868v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/xiaoyuan1996/AMFMN](https://github.com/xiaoyuan1996/AMFMN)
* Summary: Remote sensing (RS) cross-modal text-image retrieval has attracted extensive
attention for its advantages of flexible input and efficient query. However,
traditional methods ignore the characteristics of multi-scale and redundant
targets in RS image, leading to the degradation of retrieval accuracy. To cope
with the problem of multi-scale scarcity and target redundancy in RS multimodal
retrieval task, we come up with a novel asymmetric multimodal feature matching
network (AMFMN). Our model adapts to multi-scale feature inputs, favors
multi-source retrieval methods, and can dynamically filter redundant features.
AMFMN employs the multi-scale visual self-attention (MVSA) module to extract
the salient features of RS image and utilizes visual features to guide the text
representation. Furthermore, to alleviate the positive samples ambiguity caused
by the strong intraclass similarity in RS image, we propose a triplet loss
function with dynamic variable margin based on prior similarity of sample
pairs. Finally, unlike the traditional RS image-text dataset with coarse text
and higher intraclass similarity, we construct a fine-grained and more
challenging Remote sensing Image-Text Match dataset (RSITMD), which supports RS
image retrieval through keywords and sentence separately and jointly.
Experiments on four RS text-image datasets demonstrate that the proposed model
can achieve state-of-the-art performance in cross-modal RS text-image retrieval
task.

### Title: Remote Sensing Cross-Modal Text-Image Retrieval Based on Global and Local Information
* Paper ID: 2204.09860v1
* Paper URL: [http://arxiv.org/abs/2204.09860v1](http://arxiv.org/abs/2204.09860v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/xiaoyuan1996/galr](https://github.com/xiaoyuan1996/galr)
* Summary: Cross-modal remote sensing text-image retrieval (RSCTIR) has recently become
an urgent research hotspot due to its ability of enabling fast and flexible
information extraction on remote sensing (RS) images. However, current RSCTIR
methods mainly focus on global features of RS images, which leads to the
neglect of local features that reflect target relationships and saliency. In
this article, we first propose a novel RSCTIR framework based on global and
local information (GaLR), and design a multi-level information dynamic fusion
(MIDF) module to efficaciously integrate features of different levels. MIDF
leverages local information to correct global information, utilizes global
information to supplement local information, and uses the dynamic addition of
the two to generate prominent visual representation. To alleviate the pressure
of the redundant targets on the graph convolution network (GCN) and to improve
the model s attention on salient instances during modeling local features, the
de-noised representation matrix and the enhanced adjacency matrix (DREA) are
devised to assist GCN in producing superior local representations. DREA not
only filters out redundant features with high similarity, but also obtains more
powerful local features by enhancing the features of prominent objects.
Finally, to make full use of the information in the similarity matrix during
inference, we come up with a plug-and-play multivariate rerank (MR) algorithm.
The algorithm utilizes the k nearest neighbors of the retrieval results to
perform a reverse search, and improves the performance by combining multiple
components of bidirectional retrieval. Extensive experiments on public datasets
strongly demonstrate the state-of-the-art performance of GaLR methods on the
RSCTIR task. The code of GaLR method, MR algorithm, and corresponding files
have been made available at https://github.com/xiaoyuan1996/GaLR .

### Title: Self-Supervised Learning to Guide Scientifically Relevant Categorization of Martian Terrain Images
* Paper ID: 2204.09854v1
* Paper URL: [http://arxiv.org/abs/2204.09854v1](http://arxiv.org/abs/2204.09854v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/tejaspanambur/mastcam](https://github.com/tejaspanambur/mastcam)
* Summary: Automatic terrain recognition in Mars rover images is an important problem
not just for navigation, but for scientists interested in studying rock types,
and by extension, conditions of the ancient Martian paleoclimate and
habitability. Existing approaches to label Martian terrain either involve the
use of non-expert annotators producing taxonomies of limited granularity (e.g.
soil, sand, bedrock, float rock, etc.), or rely on generic class discovery
approaches that tend to produce perceptual classes such as rover parts and
landscape, which are irrelevant to geologic analysis. Expert-labeled datasets
containing granular geological/geomorphological terrain categories are rare or
inaccessible to public, and sometimes require the extraction of relevant
categorical information from complex annotations. In order to facilitate the
creation of a dataset with detailed terrain categories, we present a
self-supervised method that can cluster sedimentary textures in images captured
from the Mast camera onboard the Curiosity rover (Mars Science Laboratory). We
then present a qualitative analysis of these clusters and describe their
geologic significance via the creation of a set of granular terrain categories.
The precision and geologic validation of these automatically discovered
clusters suggest that our methods are promising for the rapid classification of
important geologic features and will therefore facilitate our long-term goal of
producing a large, granular, and publicly available dataset for Mars terrain
recognition.

### Title: A Masked Image Reconstruction Network for Document-level Relation Extraction
* Paper ID: 2204.09851v1
* Paper URL: [http://arxiv.org/abs/2204.09851v1](http://arxiv.org/abs/2204.09851v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Document-level relation extraction aims to extract relations among entities
within a document. Compared with its sentence-level counterpart, Document-level
relation extraction requires inference over multiple sentences to extract
complex relational triples. Previous research normally complete reasoning
through information propagation on the mention-level or entity-level
document-graphs, regardless of the correlations between the relationships. In
this paper, we propose a novel Document-level Relation Extraction model based
on a Masked Image Reconstruction network (DRE-MIR), which models inference as a
masked image reconstruction problem to capture the correlations between
relationships. Specifically, we first leverage an encoder module to get the
features of entities and construct the entity-pair matrix based on the
features. After that, we look on the entity-pair matrix as an image and then
randomly mask it and restore it through an inference module to capture the
correlations between the relationships. We evaluate our model on three public
document-level relation extraction datasets, i.e. DocRED, CDR, and GDA.
Experimental results demonstrate that our model achieves state-of-the-art
performance on these three datasets and has excellent robustness against the
noises during the inference process.

### Title: Multiscale Analysis for Improving Texture Classification
* Paper ID: 2204.09841v1
* Paper URL: [http://arxiv.org/abs/2204.09841v1](http://arxiv.org/abs/2204.09841v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Information from an image occurs over multiple and distinct spatial scales.
Image pyramid multiresolution representations are a useful data structure for
image analysis and manipulation over a spectrum of spatial scales. This paper
employs the Gaussian-Laplacian pyramid to treat different spatial frequency
bands of a texture separately. First, we generate three images corresponding to
three levels of the Gaussian-Laplacian pyramid for an input image to capture
intrinsic details. Then we aggregate features extracted from gray and color
texture images using bio-inspired texture descriptors, information-theoretic
measures, gray-level co-occurrence matrix features, and Haralick statistical
features into a single feature vector. Such an aggregation aims at producing
features that characterize textures to their maximum extent, unlike employing
each descriptor separately, which may lose some relevant textural information
and reduce the classification performance. The experimental results on texture
and histopathologic image datasets have shown the advantages of the proposed
method compared to state-of-the-art approaches. Such findings emphasize the
importance of multiscale image analysis and corroborate that the descriptors
mentioned above are complementary.

### Title: Localizing narrow Fe K$Î±$ emission within bright AGN
* Paper ID: 2204.09469v2
* Paper URL: [http://arxiv.org/abs/2204.09469v2](http://arxiv.org/abs/2204.09469v2)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The 6.4 keV Fe Ka emission line is a ubiquitous feature in X-ray spectra of
AGN, and its properties track the interaction between the variable primary
X-ray continuum and the surrounding structure from which it arises. We clarify
the nature and origin of the narrow Fe Ka emission using X-ray spectral,
timing, and imaging constraints, plus possible correlations to AGN and host
galaxy properties, for 38 bright nearby AGN ($z<0.5$) from the BAT AGN
Spectroscopic Survey. Modeling Chandra and XMM-Newton spectra, we computed line
full-width half-maxima (FWHMs) and constructed Fe Ka line and 2-10 keV
continuum light curves. The FWHM provides one estimate of the Fe Ka emitting
region size, RFeKa, assuming virial motion. A second estimate comes from
comparing the degree of correlation between the variability of the continuum
and line-only light curves, compared to simulated light curves. Finally, we
extracted Chandra radial profiles to place upper limits on RFeKa. We found that
for 90% (21/24) of AGN with FWHM measurements, RFeKa is smaller than the
fiducial dust sublimation radius, Rsub. Despite a wide range of variability
properties, the constraints on the Fe Ka photon reprocessor size independently
confirm that RFeKa is smaller than Rsub in 83% of AGN. Finally, the imaging
analysis yields loose upper limits for all but two sources; notably, the
Circinus Galaxy and NGC 1068 show significant but subdominant extended Fe Ka
emission out to $\sim$100 and $\sim$800 pc, respectively. Based on independent
constraints, we conclude that the majority of the narrow Fe Ka emission in
typical AGN predominantly arises from regions smaller than and presumably
inside Rsub, and thus it is associated either with the outer broad line region
or outer accretion disk. However, the large diversity of continuum and narrow
Fe Ka variability properties are not easily accommodated by a universal
scenario.

### Title: Measurement of inclusive and leading subjet fragmentation in pp and Pb-Pb collisions at $\sqrt{s_{\rm NN}}$ = 5.02 TeV
* Paper ID: 2204.10270v1
* Paper URL: [http://arxiv.org/abs/2204.10270v1](http://arxiv.org/abs/2204.10270v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: This article presents new measurements of the fragmentation properties of
jets in both proton-proton (pp) and heavy-ion collisions with the ALICE
experiment at the Large Hadron Collider (LHC). We report distributions of the
fraction $z_r$ of transverse momentum carried by subjets of radius $r$ within
jets of radius $R$. Charged-particle jets are reconstructed at midrapidity
using the anti-$k_{\rm{T}}$ algorithm with jet radius $R=0.4$, and subjets are
reconstructed by reclustering the jet constituents using the anti-$k_{\rm{T}}$
algorithm with radii $r=0.1$ and $r=0.2$. In proton-proton collisions, we
measure both the inclusive and leading subjet distributions. We compare these
measurements to perturbative calculations at next-to-leading logarithmic
accuracy, which suggest a large impact of threshold resummation and
hadronization effects on the $z_r$ distribution. In heavy-ion collisions, we
measure the leading subjet distributions, which allow access to a region of
harder jet fragmentation than has been probed by previous measurements of jet
quenching via hadron fragmentation distributions. The $z_r$ distributions
enable extraction of the parton-to-subjet fragmentation function and allow for
tests of the universality of jet fragmentation functions in the quark-gluon
plasma (QGP). We find indications that there is a turnover in the ratio between
the distributions in Pb-Pb and pp collisions as $z_r \rightarrow 1$, exposing
qualitatively new possibilities to disentangle competing jet quenching
mechanisms. By comparing our results to theoretical calculations based on an
independent extraction of the parton-to-jet fragmentation function, we find
consistency with the universality of jet fragmentation and no indication of
factorization breaking in the QGP.

### Title: Elliptic flow of charged particles at midrapidity relative to the spectator plane in Pb-Pb and Xe-Xe collisions
* Paper ID: 2204.10240v1
* Paper URL: [http://arxiv.org/abs/2204.10240v1](http://arxiv.org/abs/2204.10240v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Measurements of the elliptic flow coefficient relative to the collision plane
defined by the spectator neutrons $v_2${$\Psi_{\rm SP}$} in collisions of Pb
ions at center-of-mass energy per nucleon-nucleon pair $\sqrt{s_{\rm NN}}$=2.76
TeV and Xe ions at $\sqrt{s_{\rm NN}}$=5.44 TeV are reported. The results are
presented for charged particles produced at midrapidity as a function of
centrality and transverse momentum. The ratio between $v_2${$\Psi_{\rm SP}$}
and the elliptic flow coefficient relative to the participant plane $v_2${4},
estimated using four-particle correlations, deviates by up to 20% from unity
depending on centrality. This observation differs strongly from the magnitude
of the corresponding eccentricity ratios predicted by the TRENTo and the
elliptic power models of initial state fluctuations that are tuned to describe
the participant plane anisotropies. The differences can be interpreted as a
decorrelation of the neutron spectator plane and the reaction plane because of
fragmentation of the remnants from the colliding nuclei, which points to an
incompleteness of current models of initial state fluctuations. A significant
transverse momentum dependence of the ratio $v_2${$\Psi_{\rm SP}$}/$v_2${4} is
observed in all but the most central collisions, which may help to understand
whether momentum anisotropies at low and intermediate transverse momentum have
a common origin in initial state fluctuations. The ratios of $v_2${$\Psi_{\rm
SP}$} and $v_2${4} to the corresponding initial state eccentricities for Xe-Xe
and Pb-Pb collisions at similar initial entropy density show a difference of
$(7.0 \pm 0.9)$% with an additional variation of +1.8% when including RHIC data
in the TRENTo parameter extraction. These observations provide new experimental
constraints for viscous effects in the hydrodynamic modeling of the expanding
quark-gluon plasma.

### Title: HEATGait: Hop-Extracted Adjacency Technique in Graph Convolution based Gait Recognition
* Paper ID: 2204.10238v1
* Paper URL: [http://arxiv.org/abs/2204.10238v1](http://arxiv.org/abs/2204.10238v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Biometric authentication using gait has become a promising field due to its
unobtrusive nature. Recent approaches in model-based gait recognition
techniques utilize spatio-temporal graphs for the elegant extraction of gait
features. However, existing methods often rely on multi-scale operators for
extracting long-range relationships among joints resulting in biased weighting.
In this paper, we present HEATGait, a gait recognition system that improves the
existing multi-scale graph convolution by efficient hop-extraction technique to
alleviate the issue. Combined with preprocessing and augmentation techniques,
we propose a powerful feature extractor that utilizes ResGCN to achieve
state-of-the-art performance in model-based gait recognition on the CASIA-B
gait dataset.

### Title: Cross-Lingual Query-Based Summarization of Crisis-Related Social Media: An Abstractive Approach Using Transformers
* Paper ID: 2204.10230v1
* Paper URL: [http://arxiv.org/abs/2204.10230v1](http://arxiv.org/abs/2204.10230v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/vitiugin/cliqs-cm](https://github.com/vitiugin/cliqs-cm)
* Summary: Relevant and timely information collected from social media during crises can
be an invaluable resource for emergency management. However, extracting this
information remains a challenging task, particularly when dealing with social
media postings in multiple languages. This work proposes a cross-lingual method
for retrieving and summarizing crisis-relevant information from social media
postings. We describe a uniform way of expressing various information needs
through structured queries and a way of creating summaries answering those
information needs. The method is based on multilingual transformers embeddings.
Queries are written in one of the languages supported by the embeddings, and
the extracted sentences can be in any of the other languages supported.
Abstractive summaries are created by transformers. The evaluation, done by
crowdsourcing evaluators and emergency management experts, and carried out on
collections extracted from Twitter during five large-scale disasters spanning
ten languages, shows the flexibility of our approach. The generated summaries
are regarded as more focused, structured, and coherent than existing
state-of-the-art methods, and experts compare them favorably against summaries
created by existing, state-of-the-art methods.

### Title: The NIST CTS Speaker Recognition Challenge
* Paper ID: 2204.10228v1
* Paper URL: [http://arxiv.org/abs/2204.10228v1](http://arxiv.org/abs/2204.10228v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The US National Institute of Standards and Technology (NIST) has been
conducting a second iteration of the CTS challenge since August 2020. The
current iteration of the CTS Challenge is a leaderboard-style speaker
recognition evaluation using telephony data extracted from the unexposed
portions of the Call My Net 2 (CMN2) and Multi-Language Speech (MLS) corpora
collected by the LDC. The CTS Challenge is currently organized in a similar
manner to the SRE19 CTS Challenge, offering only an open training condition
using two evaluation subsets, namely Progress and Test. Unlike in the SRE19
Challenge, no training or development set was initially released, and NIST has
publicly released the leaderboards on both subsets for the CTS Challenge. Which
subset (i.e., Progress or Test) a trial belongs to is unknown to challenge
participants, and each system submission needs to contain outputs for all of
the trials. The CTS Challenge has also served, and will continue to do so, as a
prerequisite for entrance to the regular SREs (such as SRE21). Since August
2020, a total of 53 organizations (forming 33 teams) from academia and industry
have participated in the CTS Challenge and submitted more than 4400 valid
system outputs. This paper presents an overview of the evaluation and several
analyses of system performance for some primary conditions in the CTS
Challenge. The CTS Challenge results thus far indicate remarkable improvements
in performance due to 1) speaker embeddings extracted using large-scale and
complex neural network architectures such as ResNets along with angular margin
losses for speaker embedding extraction, 2) extensive data augmentation, 3) the
use of large amounts of in-house proprietary data from a large number of
labeled speakers, 4) long-duration fine-tuning.

### Title: The Proton Spin Structure Function $g_2$ and Generalized Polarizabilities in the Strong QCD Regime
* Paper ID: 2204.10224v1
* Paper URL: [http://arxiv.org/abs/2204.10224v1](http://arxiv.org/abs/2204.10224v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The strong interaction is not well understood at low energy, or for
interactions with low momentum transfer $Q^2$, but one of the clearest insights
we have comes from Chiral Perturbation Theory ($\chi$PT). This effective
treatment gives testable predictions for the nucleonic generalized
polarizabilities -- fundamental quantities describing the nucleon's response to
an external field. We have measured the proton's generalized spin
polarizabilities in the region where $\chi$PT is expected to be valid. Our
results include the first ever data for the transverse-longitudinal spin
polarizability $\delta_{LT}$, and also extend the coverage of the
polarizability $\overline{d_2}$ to very low $Q^2$ for the first time. These
results were extracted from moments of the structure function $g_2$, a quantity
which characterizes the internal spin structure of the proton. Our experiment
ran at Jefferson Lab using a polarized electron beam and a polarized solid
ammonia (NH$_3$) target. The $\delta_{LT}$ polarizability has remained a
challenging quantity for $\chi$PT to reproduce, despite its reduced sensitivity
to higher resonance contributions; recent competing calculations still disagree
with each other and also diverge from the measured neutron data at very low
$Q^2$. Our proton results provide discriminating power between existing
calculations, and will help provide a better understanding of this strong QCD
regime.

### Title: Learning spatiotemporal features from incomplete data for traffic flow prediction using hybrid deep neural networks
* Paper ID: 2204.10222v1
* Paper URL: [http://arxiv.org/abs/2204.10222v1](http://arxiv.org/abs/2204.10222v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Urban traffic flow prediction using data-driven models can play an important
role in route planning and preventing congestion on highways. These methods
utilize data collected from traffic recording stations at different timestamps
to predict the future status of traffic. Hence, data collection, transmission,
storage, and extraction techniques can have a significant impact on the
performance of the traffic flow model. On the other hand, a comprehensive
database can provide the opportunity for using complex, yet reliable predictive
models such as deep learning methods. However, most of these methods have
difficulties in handling missing values and outliers. This study focuses on
hybrid deep neural networks to predict traffic flow in the California Freeway
Performance Measurement System (PeMS) with missing values. The proposed
networks are based on a combination of recurrent neural networks (RNNs) to
consider the temporal dependencies in the data recorded in each station and
convolutional neural networks (CNNs) to take the spatial correlations in the
adjacent stations into account. Various architecture configurations with series
and parallel connections are considered based on RNNs and CNNs, and several
prevalent data imputation techniques are used to examine the robustness of the
hybrid networks to missing values. A comprehensive analysis performed on two
different datasets from PeMS indicates that the proposed series-parallel hybrid
network with the mean imputation technique achieves the lowest error in
predicting the traffic flow and is robust to missing values up until 21%
missing ratio in both complete and incomplete training data scenarios when
applied to an incomplete test data.

### Title: Message Flow Analysis with Complex Causal Links for Distributed ROS 2 Systems
* Paper ID: 2204.10208v1
* Paper URL: [http://arxiv.org/abs/2204.10208v1](http://arxiv.org/abs/2204.10208v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Distributed robotic systems rely heavily on publish-subscribe frameworks,
such as ROS, to efficiently implement modular computation graphs. The ROS 2
executor, a high-level task scheduler which handles messages internally, is a
performance bottleneck. In previous work, we presented ros2_tracing, a
framework with instrumentation and tools for real-time tracing of ROS 2. We now
extend on that instrumentation and leverage the tracing tools to propose an
analysis and visualization of the flow of messages across distributed ROS 2
systems. Our proposed method detects one-to-many and many-to-many causal links
between input and output messages, including indirect causal links through
simple user-level annotations. We validate our method on both synthetic and
real robotic systems, and demonstrate its low runtime overhead. Moreover, the
underlying intermediate execution representation database can be further
leveraged to extract additional metrics and high-level results. This can
provide valuable timing and scheduling information to further study and improve
the ROS 2 executor as well as optimize any ROS 2 system. The source code is
available at: https://github.com/christophebedard/ros2-message-flow-analysis.

### Title: Measurement of the vertical atmospheric density profile from the X-ray Earth occultation of the Crab Nebula with Insight-HXMT
* Paper ID: 2204.09674v1
* Paper URL: [http://arxiv.org/abs/2204.09674v1](http://arxiv.org/abs/2204.09674v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: In this paper, the X-ray Earth occultation (XEO) of the Crab Nebula is
investigated by using the Hard X-ray Modulation Telescope (Insight-HXMT). The
pointing observation data on the 30th September, 2018 recorded by the Low
Energy X-ray telescope (LE) of Insight-HXMT are selected and analyzed. The
extinction lightcurves and spectra during the X-ray Earth occultation process
are extracted. A forward model for the XEO lightcurve is established and the
theoretical observational signal for lightcurve is predicted. The atmospheric
density model is built with a scale factor to the commonly used MSIS density
profile within a certain altitude range. A Bayesian data analysis method is
developed for the XEO lightcurve modeling and the atmospheric density
retrieval. The posterior probability distribution of the model parameters is
derived through the Markov Chain Monte Carlo (MCMC) algorithm with the
NRLMSISE-00 model and the NRLMSIS 2.0 model as basis functions and the best-fit
density profiles are retrieved respectively. It is found that in the altitude
range of 105--200 km, the retrieved density profile is 88.8% of the density of
NRLMSISE-00 and 109.7% of the density of NRLMSIS 2.0 by fitting the lightcurve
in the energy range of 1.0--2.5 keV based on XEOS method. In the altitude range
of 95--125 km, the retrieved density profile is 81.0% of the density of
NRLMSISE-00 and 92.3% of the density of NRLMSIS 2.0 by fitting the lightcurve
in the energy range of 2.5--6.0 keV based on XEOS method. In the altitude range
of 85--110 km, the retrieved density profile is 87.7% of the density of
NRLMSISE-00 and 101.4% of the density of NRLMSIS 2.0 by fitting the lightcurve
in the energy range of 6.0--10.0 keV based on XEOS method. This study
demonstrates that the XEOS from the X-ray astronomical satellite Insight-HXMT
can provide an approach for the study of the upper atmosphere.

### Title: ALICE luminosity determination for Pb$-$Pb collisions at $\sqrt{s_{\mathrm{NN}}} = 5.02$ TeV
* Paper ID: 2204.10148v1
* Paper URL: [http://arxiv.org/abs/2204.10148v1](http://arxiv.org/abs/2204.10148v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Luminosity determination within the ALICE experiment is based on the
measurement, in van der Meer scans, of the cross sections for visible processes
involving one or more detectors (visible cross sections). In 2015 and 2018, the
Large Hadron Collider provided Pb$-$Pb collisions at a centre-of-mass energy
per nucleon pair of $\sqrt{s_{\rm NN}} = 5.02$ TeV. Two visible cross sections,
associated with particle detection in the Zero Degree Calorimeter (ZDC) and in
the V0 detector, were measured in a van der Meer scan. This article describes
the experimental set-up and the analysis procedure, and presents the
measurement results. The analysis involves a comprehensive study of
beam-related effects and an improved fitting procedure, compared to previous
ALICE studies, for the extraction of the visible cross section. The resulting
uncertainty of the ZDC-based (V0-based) luminosity measurement for the full
sample is 2.3% (2.2%). The inelastic cross section for hadronic interactions in
Pb$-$Pb collisions at $\sqrt{s_{\rm NN}} = 5.02$ TeV, obtained by efficiency
correction of the V0-based visible cross section, was measured to be $7.67 \pm
0.24$ b.

### Title: Learnable Model Augmentation Self-Supervised Learning for Sequential Recommendation
* Paper ID: 2204.10128v1
* Paper URL: [http://arxiv.org/abs/2204.10128v1](http://arxiv.org/abs/2204.10128v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Sequential Recommendation aims to predict the next item based on user
behaviour. Recently, Self-Supervised Learning (SSL) has been proposed to
improve recommendation performance. However, most of existing SSL methods use a
uniform data augmentation scheme, which loses the sequence correlation of an
original sequence. To this end, in this paper, we propose a Learnable Model
Augmentation self-supervised learning for sequential Recommendation (LMA4Rec).
Specifically, LMA4Rec first takes model augmentation as a supplementary method
for data augmentation to generate views. Then, LMA4Rec uses learnable Bernoulli
dropout to implement model augmentation learnable operations. Next,
self-supervised learning is used between the contrastive views to extract
self-supervised signals from an original sequence. Finally, experiments on
three public datasets show that the LMA4Rec method effectively improves
sequential recommendation performance compared with baseline methods.

### Title: Working memory inspired hierarchical video decomposition with transformative representations
* Paper ID: 2204.10105v1
* Paper URL: [http://arxiv.org/abs/2204.10105v1](http://arxiv.org/abs/2204.10105v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Video decomposition is very important to extract moving foreground objects
from complex backgrounds in computer vision, machine learning, and medical
imaging, e.g., extracting moving contrast-filled vessels from the complex and
noisy backgrounds of X-ray coronary angiography (XCA). However, the challenges
caused by dynamic backgrounds, overlapping heterogeneous environments and
complex noises still exist in video decomposition. To solve these problems,
this study is the first to introduce a flexible visual working memory model in
video decomposition tasks to provide interpretable and high-performance
hierarchical deep architecture, integrating the transformative representations
between sensory and control layers from the perspective of visual and cognitive
neuroscience. Specifically, robust PCA unrolling networks acting as a
structure-regularized sensor layer decompose XCA into sparse/low-rank
structured representations to separate moving contrast-filled vessels from
noisy and complex backgrounds. Then, patch recurrent convolutional LSTM
networks with a backprojection module embody unstructured random
representations of the control layer in working memory, recurrently projecting
spatiotemporally decomposed nonlocal patches into orthogonal subspaces for
heterogeneous vessel retrieval and interference suppression. This video
decomposition deep architecture effectively restores the heterogeneous profiles
of intensity and the geometries of moving objects against the complex
background interferences. Experiments show that the proposed method
significantly outperforms state-of-the-art methods in accurate moving
contrast-filled vessel extraction with excellent flexibility and computational
efficiency.

### Title: R2-Trans:Fine-Grained Visual Categorization with Redundancy Reduction
* Paper ID: 2204.10095v1
* Paper URL: [http://arxiv.org/abs/2204.10095v1](http://arxiv.org/abs/2204.10095v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Fine-grained visual categorization (FGVC) aims to discriminate similar
subcategories, whose main challenge is the large intraclass diversities and
subtle inter-class differences. Existing FGVC methods usually select
discriminant regions found by a trained model, which is prone to neglect other
potential discriminant information. On the other hand, the massive interactions
between the sequence of image patches in ViT make the resulting class-token
contain lots of redundant information, which may also impacts FGVC performance.
In this paper, we present a novel approach for FGVC, which can simultaneously
make use of partial yet sufficient discriminative information in environmental
cues and also compress the redundant information in class-token with respect to
the target. Specifically, our model calculates the ratio of high-weight regions
in a batch, adaptively adjusts the masking threshold and achieves moderate
extraction of background information in the input space. Moreover, we also use
the Information Bottleneck~(IB) approach to guide our network to learn a
minimum sufficient representations in the feature space. Experimental results
on three widely-used benchmark datasets verify that our approach can achieve
outperforming performance than other state-of-the-art approaches and baseline
models.

### Title: OTExtSum: Extractive Text Summarisation with Optimal Transport
* Paper ID: 2204.10086v1
* Paper URL: [http://arxiv.org/abs/2204.10086v1](http://arxiv.org/abs/2204.10086v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/peggypytang/otextsum](https://github.com/peggypytang/otextsum)
* Summary: Extractive text summarisation aims to select salient sentences from a
document to form a short yet informative summary. While learning-based methods
have achieved promising results, they have several limitations, such as
dependence on expensive training and lack of interpretability. Therefore, in
this paper, we propose a novel non-learning-based method by for the first time
formulating text summarisation as an Optimal Transport (OT) problem, namely
Optimal Transport Extractive Summariser (OTExtSum). Optimal sentence extraction
is conceptualised as obtaining an optimal summary that minimises the
transportation cost to a given document regarding their semantic distributions.
Such a cost is defined by the Wasserstein distance and used to measure the
summary's semantic coverage of the original document. Comprehensive experiments
on four challenging and widely used datasets - MultiNews, PubMed, BillSum, and
CNN/DM demonstrate that our proposed method outperforms the state-of-the-art
non-learning-based methods and several recent learning-based methods in terms
of the ROUGE metric.

### Title: Absolute Wrong Makes Better: Boosting Weakly Supervised Object Detection via Negative Deterministic Information
* Paper ID: 2204.10068v1
* Paper URL: [http://arxiv.org/abs/2204.10068v1](http://arxiv.org/abs/2204.10068v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Weakly supervised object detection (WSOD) is a challenging task, in which
image-level labels (e.g., categories of the instances in the whole image) are
used to train an object detector. Many existing methods follow the standard
multiple instance learning (MIL) paradigm and have achieved promising
performance. However, the lack of deterministic information leads to part
domination and missing instances. To address these issues, this paper focuses
on identifying and fully exploiting the deterministic information in WSOD. We
discover that negative instances (i.e. absolutely wrong instances), ignored in
most of the previous studies, normally contain valuable deterministic
information. Based on this observation, we here propose a negative
deterministic information (NDI) based method for improving WSOD, namely
NDI-WSOD. Specifically, our method consists of two stages: NDI collecting and
exploiting. In the collecting stage, we design several processes to identify
and distill the NDI from negative instances online. In the exploiting stage, we
utilize the extracted NDI to construct a novel negative contrastive learning
mechanism and a negative guided instance selection strategy for dealing with
the issues of part domination and missing instances, respectively. Experimental
results on several public benchmarks including VOC 2007, VOC 2012 and MS COCO
show that our method achieves satisfactory performance.

### Title: Mass spectra of $Î_{cc}$, $Î_{bc}$, $Î©_{cc}$, and $Î©_{bc}$ baryons in Regge Phenomenology
* Paper ID: 2204.10045v1
* Paper URL: [http://arxiv.org/abs/2204.10045v1](http://arxiv.org/abs/2204.10045v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: In this article, we study the mass spectra of baryons containing two heavy
quarks; charm-charm ($cc$) and bottom-charm ($bc$) with a light quark ($u,d,s$)
within the framework of Regge phenomenology. With the assumption of linear
Regge trajectories we have derived the relations between slope ratios,
intercepts, and baryon masses. Using these relations, the ground state masses
of $\Xi_{cc}$, $\Xi_{bc}$, $\Omega_{cc}$, and $\Omega_{bc}$ baryons are
obtained. The values of Regge slopes and Regge intercepts are extracted for
these baryons to estimate the excited state masses in both the ($J,M^{2}$) and
($n,M^{2}$) planes. Our obtained results are compared with the experimental
observations where available and other theoretical predictions, which could be
a valuable addition to the interpretations of experimentally unknown heavy
baryon spectra.

### Title: Measuring the anomalous quartic gauge couplings in the $W^+W^-\to W^+W^-$ process at muon collider using artificial neural networks
* Paper ID: 2204.10034v1
* Paper URL: [http://arxiv.org/abs/2204.10034v1](http://arxiv.org/abs/2204.10034v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The muon collider provides a unique opportunity to study the vector boson
scattering processes and dimension-8 operators contributing to anomalous
quartic gauge couplings. Because of the cleaner final state, it is easier to
decode subprocess and certain operator couplings at a muon collider. We attempt
to identify the anomalous $WWWW$ coupling in $WW\to WW$ scattering in this
paper. The vector boson scattering process corresponding to the anomalous
$WWWW$ coupling is $\mu^+\mu^-\to \nu\nu\bar{\nu}\bar{\nu}\ell^+\ell^-$, with
four (anti-)neutrinos in the final state, which pose difficulties for
phenomenological studies. In this paper, the machine learning method is used to
tackle this problem. We find that, the artificial neural network can be used to
extract the $W^+W^-\to W^+W^-$ contribution, and is useful to reconstruct the
center of mass energy of the subprocess which is important in the study of the
Standard Model effective field theory. The sensitivities and the expected
constraints on the dimension-8 operators at the muon collider with
$\sqrt{s}=30$ TeV are presented. The artificial neural networks exhibit great
potential in the phenomenological study of processes with multiple neutrinos in
the final state.

### Title: Ferrous Metal Matrix Composites Status Scope and Challenges
* Paper ID: 2204.09999v1
* Paper URL: [http://arxiv.org/abs/2204.09999v1](http://arxiv.org/abs/2204.09999v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The present paper is an effort to culminate the status, scopes and challenges
in the development of ferrous metal matrix composites (FMMCs). The FMMCs are
old but less in use than the non-ferrous metal matrix composites (NFMMCs), as
far as literature and actual applications are concerned. Therefore, this
stimulates the exploration of the reasons behind the scarcity of literature and
field applications of the FMMCs, which must be investigated scientifically. The
powder metallurgy route is the most used process for fabricating iron and steel
based FMMCs by reinforcing particulates. At the same time, the in-situ method
has been used for the fabrication and cast iron-based FMMCs. The main
characteristics being considered during the designing and fabrication of FMMCs
are wear resistance and improved specific mechanical properties. To fabricate
cheaper and eco-friendly FMMCs, traditionally used costly reinforcements such
as SiC, WC, TiC, SiO2, TiO2, TiB2 are required to be replaced by inexpensive
industrial wastes like red-mud, fly-ashes and grinding swarf. The data
extracted from the web of science exhibited that the FMMCs have been researched
less than the NFMMCs. The increasing number of research papers on FMMCs
indicates a bright future. FMMCs are going to be a favourite topic among
researchers and manufacturers. Higher strengths, wear resistance, dimensional
stability at elevated temperatures, and, most importantly, the lower cost will
put forward the FMMCs as a stiff competitor of NFMMCs. In developing and mass
production of FMMCs for field applications, challenges like oxidation and
higher weight still require special research efforts.

### Title: DGECN: A Depth-Guided Edge Convolutional Network for End-to-End 6D Pose Estimation
* Paper ID: 2204.09983v1
* Paper URL: [http://arxiv.org/abs/2204.09983v1](http://arxiv.org/abs/2204.09983v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Monocular 6D pose estimation is a fundamental task in computer vision.
Existing works often adopt a two-stage pipeline by establishing correspondences
and utilizing a RANSAC algorithm to calculate 6 degrees-of-freedom (6DoF) pose.
Recent works try to integrate differentiable RANSAC algorithms to achieve an
end-to-end 6D pose estimation. However, most of them hardly consider the
geometric features in 3D space, and ignore the topology cues when performing
differentiable RANSAC algorithms. To this end, we proposed a Depth-Guided Edge
Convolutional Network (DGECN) for 6D pose estimation task. We have made efforts
from the following three aspects: 1) We take advantages ofestimated depth
information to guide both the correspondences-extraction process and the
cascaded differentiable RANSAC algorithm with geometric information. 2)We
leverage the uncertainty ofthe estimated depth map to improve accuracy and
robustness ofthe output 6D pose. 3) We propose a differentiable
Perspective-n-Point(PnP) algorithm via edge convolution to explore the topology
relations between 2D-3D correspondences. Experiments demonstrate that our
proposed network outperforms current works on both effectiveness and
efficiency.

### Title: Using consumer feedback from location-based services in PoI recommender systems for people with autism
* Paper ID: 2204.09969v1
* Paper URL: [http://arxiv.org/abs/2204.09969v1](http://arxiv.org/abs/2204.09969v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: When suggesting Points of Interest (PoIs) to people with autism spectrum
disorders, we must take into account that they have idiosyncratic sensory
aversions to noise, brightness and other features that influence the way they
perceive places. Therefore, recommender systems must deal with these aspects.
However, the retrieval of sensory data about PoIs is a real challenge because
most geographical information servers fail to provide this data. Moreover,
ad-hoc crowdsourcing campaigns do not guarantee to cover large geographical
areas and lack sustainability. Thus, we investigate the extraction of sensory
data about places from the consumer feedback collected by location-based
services, on which people spontaneously post reviews from all over the world.
Specifically, we propose a model for the extraction of sensory data from the
reviews about PoIs, and its integration in recommender systems to predict item
ratings by considering both user preferences and compatibility information. We
tested our approach with autistic and neurotypical people by integrating it
into diverse recommendation algorithms. For the test, we used a dataset built
in a crowdsourcing campaign and another one extracted from TripAdvisor reviews.
The results show that the algorithms obtain the highest accuracy and ranking
capability when using TripAdvisor data. Moreover, by jointly using these two
datasets, the algorithms further improve their performance. These results
encourage the use of consumer feedback as a reliable source of information
about places in the development of inclusive recommender systems.

### Title: Transformer-Guided Convolutional Neural Network for Cross-View Geolocalization
* Paper ID: 2204.09967v1
* Paper URL: [http://arxiv.org/abs/2204.09967v1](http://arxiv.org/abs/2204.09967v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Ground-to-aerial geolocalization refers to localizing a ground-level query
image by matching it to a reference database of geo-tagged aerial imagery. This
is very challenging due to the huge perspective differences in visual
appearances and geometric configurations between these two views. In this work,
we propose a novel Transformer-guided convolutional neural network (TransGCNN)
architecture, which couples CNN-based local features with Transformer-based
global representations for enhanced representation learning. Specifically, our
TransGCNN consists of a CNN backbone extracting feature map from an input image
and a Transformer head modeling global context from the CNN map. In particular,
our Transformer head acts as a spatial-aware importance generator to select
salient CNN features as the final feature representation. Such a coupling
procedure allows us to leverage a lightweight Transformer network to greatly
enhance the discriminative capability of the embedded features. Furthermore, we
design a dual-branch Transformer head network to combine image features from
multi-scale windows in order to improve details of the global feature
representation. Extensive experiments on popular benchmark datasets demonstrate
that our model achieves top-1 accuracy of 94.12\% and 84.92\% on CVUSA and
CVACT_val, respectively, which outperforms the second-performing baseline with
less than 50% parameters and almost 2x higher frame rate, therefore achieving a
preferable accuracy-efficiency tradeoff.

### Title: Referring Expression Comprehension via Cross-Level Multi-Modal Fusion
* Paper ID: 2204.09957v1
* Paper URL: [http://arxiv.org/abs/2204.09957v1](http://arxiv.org/abs/2204.09957v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: As an important and challenging problem in vision-language tasks, referring
expression comprehension (REC) aims to localize the target object specified by
a given referring expression. Recently, most of the state-of-the-art REC
methods mainly focus on multi-modal fusion while overlooking the inherent
hierarchical information contained in visual and language encoders. Considering
that REC requires visual and textual hierarchical information for accurate
target localization, and encoders inherently extract features in a hierarchical
fashion, we propose to effectively utilize the rich hierarchical information
contained in different layers of visual and language encoders. To this end, we
design a Cross-level Multi-modal Fusion (CMF) framework, which gradually
integrates visual and textual features of multi-layer through intra- and
inter-modal. Experimental results on RefCOCO, RefCOCO+, RefCOCOg, and
ReferItGame datasets demonstrate the proposed framework achieves significant
performance improvements over state-of-the-art methods.

### Title: Recovering Patient Journeys: A Corpus of Biomedical Entities and Relations on Twitter (BEAR)
* Paper ID: 2204.09952v1
* Paper URL: [http://arxiv.org/abs/2204.09952v1](http://arxiv.org/abs/2204.09952v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Text mining and information extraction for the medical domain has focused on
scientific text generated by researchers. However, their direct access to
individual patient experiences or patient-doctor interactions can be limited.
Information provided on social media, e.g., by patients and their relatives,
complements the knowledge in scientific text. It reflects the patient's journey
and their subjective perspective on the process of developing symptoms, being
diagnosed and offered a treatment, being cured or learning to live with a
medical condition. The value of this type of data is therefore twofold:
Firstly, it offers direct access to people's perspectives. Secondly, it might
cover information that is not available elsewhere, including self-treatment or
self-diagnoses. Named entity recognition and relation extraction are methods to
structure information that is available in unstructured text. However, existing
medical social media corpora focused on a comparably small set of entities and
relations and particular domains, rather than putting the patient into the
center of analyses. With this paper we contribute a corpus with a rich set of
annotation layers following the motivation to uncover and model patients'
journeys and experiences in more detail. We label 14 entity classes (incl.
environmental factors, diagnostics, biochemical processes, patients'
quality-of-life descriptions, pathogens, medical conditions, and treatments)
and 20 relation classes (e.g., prevents, influences, interactions, causes) most
of which have not been considered before for social media data. The publicly
available dataset consists of 2,100 tweets with approx. 6,000 entity and 3,000
relation annotations. In a corpus analysis we find that over 80 % of documents
contain relevant entities. Over 50 % of tweets express relations which we
consider essential for uncovering patients' narratives about their journeys.

### Title: Hybrid Cloud-Edge Collaborative Data Anomaly Detection in Industrial Sensor Networks
* Paper ID: 2204.09942v1
* Paper URL: [http://arxiv.org/abs/2204.09942v1](http://arxiv.org/abs/2204.09942v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Industrial control systems (ICSs) are facing increasing cyber-physical
attacks that can cause catastrophes in the physical system. Efficient anomaly
detection models in the industrial sensor networks are essential for enhancing
ICS reliability and security, due to the sensor data is related to the
operational state of the ICS. Considering the limited availability of computing
resources, this paper proposes a hybrid anomaly detection approach in
cloud-edge collaboration industrial sensor networks. The hybrid approach
consists of sensor data detection models deployed at the edges and a sensor
data analysis model deployed in the cloud. The sensor data detection model
based on Gaussian and Bayesian algorithms can detect the anomalous sensor data
in real-time and upload them to the cloud for further analysis, filtering the
normal sensor data and reducing traffic load. The sensor data analysis model
based on Graph convolutional network, Residual algorithm and Long short-term
memory network (GCRL) can effectively extract the spatial and temporal features
and then identify the attack precisely. The proposed hybrid anomaly detection
approach is evaluated using a benchmark dataset and baseline anomaly detection
models. The experimental results show that the proposed approach can achieve an
overall 11.19% increase in Recall and an impressive 14.29% improvement in
F1-score, compared with the existing models.

### Title: Multi-task recommendation system for scientific papers with high-way networks
* Paper ID: 2204.09930v1
* Paper URL: [http://arxiv.org/abs/2204.09930v1](http://arxiv.org/abs/2204.09930v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Finding and selecting the most relevant scientific papers from a large number
of papers written in a research community is one of the key challenges for
researchers these days. As we know, much information around research interest
for scholars and academicians belongs to papers they read. Analysis and
extracting contextual features from these papers could help us to suggest the
most related paper to them. In this paper, we present a multi-task
recommendation system (RS) that predicts a paper recommendation and generates
its meta-data such as keywords. The system is implemented as a three-stage deep
neural network encoder that tries to maps longer sequences of text to an
embedding vector and learns simultaneously to predict the recommendation rate
for a particular user and the paper's keywords. The motivation behind this
approach is that the paper's topics expressed as keywords are a useful
predictor of preferences of researchers. To achieve this goal, we use a system
combination of RNNs, Highway and Convolutional Neural Networks to train
end-to-end a context-aware collaborative matrix. Our application uses Highway
networks to train the system very deep, combine the benefits of RNN and CNN to
find the most important factor and make latent representation. Highway Networks
allow us to enhance the traditional RNN and CNN pipeline by learning more
sophisticated semantic structural representations. Using this method we can
also overcome the cold start problem and learn latent features over large
sequences of text.

### Title: Normalization procedure for obtaining the local density of states from high-bias scanning tunneling spectroscopy
* Paper ID: 2204.09929v1
* Paper URL: [http://arxiv.org/abs/2204.09929v1](http://arxiv.org/abs/2204.09929v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Differential conductance spectroscopy performed in the high bias regime -- in
which the applied voltage exceeds the sample work function -- is a poor measure
of the local density of states due to the effects of the changing tunnel
barrier. Additionally, the large applied voltage oftentimes makes
constant-height measurement experimentally impractical, lending
constant-current spectroscopy an advantageous edge; but the differential
conductance in that case is even further removed from the local density of
states due to the changing tip height. Here, we present a normalization scheme
for extracting the local density of states from high bias scanning tunneling
spectroscopy, obtained in either constant-current or constant-height mode. We
extend this model to account for the effects of the in-plane momentum of the
probed states to the overall current. We demonstrate the validity of the
proposed scheme by applying it to laterally confined field-emission resonances,
which appear as peak-shaped spectroscopic features with a well-defined in-plane
momentum.

### Title: CPGNet: Cascade Point-Grid Fusion Network for Real-Time LiDAR Semantic Segmentation
* Paper ID: 2204.09914v1
* Paper URL: [http://arxiv.org/abs/2204.09914v1](http://arxiv.org/abs/2204.09914v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: LiDAR semantic segmentation essential for advanced autonomous driving is
required to be accurate, fast, and easy-deployed on mobile platforms. Previous
point-based or sparse voxel-based methods are far away from real-time
applications since time-consuming neighbor searching or sparse 3D convolution
are employed. Recent 2D projection-based methods, including range view and
multi-view fusion, can run in real time, but suffer from lower accuracy due to
information loss during the 2D projection. Besides, to improve the performance,
previous methods usually adopt test time augmentation (TTA), which further
slows down the inference process. To achieve a better speed-accuracy trade-off,
we propose Cascade Point-Grid Fusion Network (CPGNet), which ensures both
effectiveness and efficiency mainly by the following two techniques: 1) the
novel Point-Grid (PG) fusion block extracts semantic features mainly on the 2D
projected grid for efficiency, while summarizes both 2D and 3D features on 3D
point for minimal information loss; 2) the proposed transformation consistency
loss narrows the gap between the single-time model inference and TTA. The
experiments on the SemanticKITTI and nuScenes benchmarks demonstrate that the
CPGNet without ensemble models or TTA is comparable with the state-of-the-art
RPVNet, while it runs 4.7 times faster.

### Title: MAP-SNN: Mapping Spike Activities with Multiplicity, Adaptability, and Plasticity into Bio-Plausible Spiking Neural Networks
* Paper ID: 2204.09893v1
* Paper URL: [http://arxiv.org/abs/2204.09893v1](http://arxiv.org/abs/2204.09893v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Spiking Neural Network (SNN) is considered more biologically realistic and
power-efficient as it imitates the fundamental mechanism of the human brain.
Recently, backpropagation (BP) based SNN learning algorithms that utilize deep
learning frameworks have achieved good performance. However,
bio-interpretability is partially neglected in those BP-based algorithms.
Toward bio-plausible BP-based SNNs, we consider three properties in modeling
spike activities: Multiplicity, Adaptability, and Plasticity (MAP). In terms of
multiplicity, we propose a Multiple-Spike Pattern (MSP) with multiple spike
transmission to strengthen model robustness in discrete time-iteration. To
realize adaptability, we adopt Spike Frequency Adaption (SFA) under MSP to
decrease spike activities for improved efficiency. For plasticity, we propose a
trainable convolutional synapse that models spike response current to enhance
the diversity of spiking neurons for temporal feature extraction. The proposed
SNN model achieves competitive performances on neuromorphic datasets: N-MNIST
and SHD. Furthermore, experimental results demonstrate that the proposed three
aspects are significant to iterative robustness, spike efficiency, and temporal
feature extraction capability of spike activities. In summary, this work
proposes a feasible scheme for bio-inspired spike activities with MAP, offering
a new neuromorphic perspective to embed biological characteristics into spiking
neural networks.

### Title: Layer-wise Fast Adaptation for End-to-End Multi-Accent Speech Recognition
* Paper ID: 2204.09883v1
* Paper URL: [http://arxiv.org/abs/2204.09883v1](http://arxiv.org/abs/2204.09883v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Accent variability has posed a huge challenge to automatic speech
recognition~(ASR) modeling. Although one-hot accent vector based adaptation
systems are commonly used, they require prior knowledge about the target accent
and cannot handle unseen accents. Furthermore, simply concatenating accent
embeddings does not make good use of accent knowledge, which has limited
improvements. In this work, we aim to tackle these problems with a novel
layer-wise adaptation structure injected into the E2E ASR model encoder. The
adapter layer encodes an arbitrary accent in the accent space and assists the
ASR model in recognizing accented speech. Given an utterance, the adaptation
structure extracts the corresponding accent information and transforms the
input acoustic feature into an accent-related feature through the linear
combination of all accent bases. We further explore the injection position of
the adaptation layer, the number of accent bases, and different types of accent
bases to achieve better accent adaptation. Experimental results show that the
proposed adaptation structure brings 12\% and 10\% relative word error
rate~(WER) reduction on the AESRC2020 accent dataset and the Librispeech
dataset, respectively, compared to the baseline.

### Title: Exploring a Fine-Grained Multiscale Method for Cross-Modal Remote Sensing Image Retrieval
* Paper ID: 2204.09868v1
* Paper URL: [http://arxiv.org/abs/2204.09868v1](http://arxiv.org/abs/2204.09868v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/xiaoyuan1996/AMFMN](https://github.com/xiaoyuan1996/AMFMN)
* Summary: Remote sensing (RS) cross-modal text-image retrieval has attracted extensive
attention for its advantages of flexible input and efficient query. However,
traditional methods ignore the characteristics of multi-scale and redundant
targets in RS image, leading to the degradation of retrieval accuracy. To cope
with the problem of multi-scale scarcity and target redundancy in RS multimodal
retrieval task, we come up with a novel asymmetric multimodal feature matching
network (AMFMN). Our model adapts to multi-scale feature inputs, favors
multi-source retrieval methods, and can dynamically filter redundant features.
AMFMN employs the multi-scale visual self-attention (MVSA) module to extract
the salient features of RS image and utilizes visual features to guide the text
representation. Furthermore, to alleviate the positive samples ambiguity caused
by the strong intraclass similarity in RS image, we propose a triplet loss
function with dynamic variable margin based on prior similarity of sample
pairs. Finally, unlike the traditional RS image-text dataset with coarse text
and higher intraclass similarity, we construct a fine-grained and more
challenging Remote sensing Image-Text Match dataset (RSITMD), which supports RS
image retrieval through keywords and sentence separately and jointly.
Experiments on four RS text-image datasets demonstrate that the proposed model
can achieve state-of-the-art performance in cross-modal RS text-image retrieval
task.

### Title: Remote Sensing Cross-Modal Text-Image Retrieval Based on Global and Local Information
* Paper ID: 2204.09860v1
* Paper URL: [http://arxiv.org/abs/2204.09860v1](http://arxiv.org/abs/2204.09860v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/xiaoyuan1996/galr](https://github.com/xiaoyuan1996/galr)
* Summary: Cross-modal remote sensing text-image retrieval (RSCTIR) has recently become
an urgent research hotspot due to its ability of enabling fast and flexible
information extraction on remote sensing (RS) images. However, current RSCTIR
methods mainly focus on global features of RS images, which leads to the
neglect of local features that reflect target relationships and saliency. In
this article, we first propose a novel RSCTIR framework based on global and
local information (GaLR), and design a multi-level information dynamic fusion
(MIDF) module to efficaciously integrate features of different levels. MIDF
leverages local information to correct global information, utilizes global
information to supplement local information, and uses the dynamic addition of
the two to generate prominent visual representation. To alleviate the pressure
of the redundant targets on the graph convolution network (GCN) and to improve
the model s attention on salient instances during modeling local features, the
de-noised representation matrix and the enhanced adjacency matrix (DREA) are
devised to assist GCN in producing superior local representations. DREA not
only filters out redundant features with high similarity, but also obtains more
powerful local features by enhancing the features of prominent objects.
Finally, to make full use of the information in the similarity matrix during
inference, we come up with a plug-and-play multivariate rerank (MR) algorithm.
The algorithm utilizes the k nearest neighbors of the retrieval results to
perform a reverse search, and improves the performance by combining multiple
components of bidirectional retrieval. Extensive experiments on public datasets
strongly demonstrate the state-of-the-art performance of GaLR methods on the
RSCTIR task. The code of GaLR method, MR algorithm, and corresponding files
have been made available at https://github.com/xiaoyuan1996/GaLR .

### Title: Self-Supervised Learning to Guide Scientifically Relevant Categorization of Martian Terrain Images
* Paper ID: 2204.09854v1
* Paper URL: [http://arxiv.org/abs/2204.09854v1](http://arxiv.org/abs/2204.09854v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/tejaspanambur/mastcam](https://github.com/tejaspanambur/mastcam)
* Summary: Automatic terrain recognition in Mars rover images is an important problem
not just for navigation, but for scientists interested in studying rock types,
and by extension, conditions of the ancient Martian paleoclimate and
habitability. Existing approaches to label Martian terrain either involve the
use of non-expert annotators producing taxonomies of limited granularity (e.g.
soil, sand, bedrock, float rock, etc.), or rely on generic class discovery
approaches that tend to produce perceptual classes such as rover parts and
landscape, which are irrelevant to geologic analysis. Expert-labeled datasets
containing granular geological/geomorphological terrain categories are rare or
inaccessible to public, and sometimes require the extraction of relevant
categorical information from complex annotations. In order to facilitate the
creation of a dataset with detailed terrain categories, we present a
self-supervised method that can cluster sedimentary textures in images captured
from the Mast camera onboard the Curiosity rover (Mars Science Laboratory). We
then present a qualitative analysis of these clusters and describe their
geologic significance via the creation of a set of granular terrain categories.
The precision and geologic validation of these automatically discovered
clusters suggest that our methods are promising for the rapid classification of
important geologic features and will therefore facilitate our long-term goal of
producing a large, granular, and publicly available dataset for Mars terrain
recognition.

### Title: A Masked Image Reconstruction Network for Document-level Relation Extraction
* Paper ID: 2204.09851v1
* Paper URL: [http://arxiv.org/abs/2204.09851v1](http://arxiv.org/abs/2204.09851v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Document-level relation extraction aims to extract relations among entities
within a document. Compared with its sentence-level counterpart, Document-level
relation extraction requires inference over multiple sentences to extract
complex relational triples. Previous research normally complete reasoning
through information propagation on the mention-level or entity-level
document-graphs, regardless of the correlations between the relationships. In
this paper, we propose a novel Document-level Relation Extraction model based
on a Masked Image Reconstruction network (DRE-MIR), which models inference as a
masked image reconstruction problem to capture the correlations between
relationships. Specifically, we first leverage an encoder module to get the
features of entities and construct the entity-pair matrix based on the
features. After that, we look on the entity-pair matrix as an image and then
randomly mask it and restore it through an inference module to capture the
correlations between the relationships. We evaluate our model on three public
document-level relation extraction datasets, i.e. DocRED, CDR, and GDA.
Experimental results demonstrate that our model achieves state-of-the-art
performance on these three datasets and has excellent robustness against the
noises during the inference process.

### Title: Multiscale Analysis for Improving Texture Classification
* Paper ID: 2204.09841v1
* Paper URL: [http://arxiv.org/abs/2204.09841v1](http://arxiv.org/abs/2204.09841v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Information from an image occurs over multiple and distinct spatial scales.
Image pyramid multiresolution representations are a useful data structure for
image analysis and manipulation over a spectrum of spatial scales. This paper
employs the Gaussian-Laplacian pyramid to treat different spatial frequency
bands of a texture separately. First, we generate three images corresponding to
three levels of the Gaussian-Laplacian pyramid for an input image to capture
intrinsic details. Then we aggregate features extracted from gray and color
texture images using bio-inspired texture descriptors, information-theoretic
measures, gray-level co-occurrence matrix features, and Haralick statistical
features into a single feature vector. Such an aggregation aims at producing
features that characterize textures to their maximum extent, unlike employing
each descriptor separately, which may lose some relevant textural information
and reduce the classification performance. The experimental results on texture
and histopathologic image datasets have shown the advantages of the proposed
method compared to state-of-the-art approaches. Such findings emphasize the
importance of multiscale image analysis and corroborate that the descriptors
mentioned above are complementary.

### Title: Localizing narrow Fe K$Î±$ emission within bright AGN
* Paper ID: 2204.09469v2
* Paper URL: [http://arxiv.org/abs/2204.09469v2](http://arxiv.org/abs/2204.09469v2)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The 6.4 keV Fe Ka emission line is a ubiquitous feature in X-ray spectra of
AGN, and its properties track the interaction between the variable primary
X-ray continuum and the surrounding structure from which it arises. We clarify
the nature and origin of the narrow Fe Ka emission using X-ray spectral,
timing, and imaging constraints, plus possible correlations to AGN and host
galaxy properties, for 38 bright nearby AGN ($z<0.5$) from the BAT AGN
Spectroscopic Survey. Modeling Chandra and XMM-Newton spectra, we computed line
full-width half-maxima (FWHMs) and constructed Fe Ka line and 2-10 keV
continuum light curves. The FWHM provides one estimate of the Fe Ka emitting
region size, RFeKa, assuming virial motion. A second estimate comes from
comparing the degree of correlation between the variability of the continuum
and line-only light curves, compared to simulated light curves. Finally, we
extracted Chandra radial profiles to place upper limits on RFeKa. We found that
for 90% (21/24) of AGN with FWHM measurements, RFeKa is smaller than the
fiducial dust sublimation radius, Rsub. Despite a wide range of variability
properties, the constraints on the Fe Ka photon reprocessor size independently
confirm that RFeKa is smaller than Rsub in 83% of AGN. Finally, the imaging
analysis yields loose upper limits for all but two sources; notably, the
Circinus Galaxy and NGC 1068 show significant but subdominant extended Fe Ka
emission out to $\sim$100 and $\sim$800 pc, respectively. Based on independent
constraints, we conclude that the majority of the narrow Fe Ka emission in
typical AGN predominantly arises from regions smaller than and presumably
inside Rsub, and thus it is associated either with the outer broad line region
or outer accretion disk. However, the large diversity of continuum and narrow
Fe Ka variability properties are not easily accommodated by a universal
scenario.

### Title: A simple denoising approach to exploit multi-fidelity data for machine learning materials properties
* Paper ID: 2204.10430v1
* Paper URL: [http://arxiv.org/abs/2204.10430v1](http://arxiv.org/abs/2204.10430v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Machine-learning models have recently encountered enormous success for
predicting the properties of materials. These are often trained based on data
that present various levels of accuracy, with typically much less high- than
low-fidelity data. In order to extract as much information as possible from all
available data, we here introduce an approach which aims to improve the quality
of the data through denoising. We investigate the possibilities that it offers
in the case of the prediction of the band gap relying on both limited
experimental data and density-functional theory relying different
exchange-correlation functionals (with an increasing amount of data as the
accuracy of the functional decreases). We explore different ways to combine the
data into training sequences and analyze the effect of the chosen denoiser.
Finally, we analyze the effect of applying the denoising procedure several
times until convergence. Our approach provides an improvement over existing
methods to exploit multi-fidelity data.

### Title: Lightweight Hybrid CNN-ELM Model for Multi-building and Multi-floor Classification
* Paper ID: 2204.10418v1
* Paper URL: [http://arxiv.org/abs/2204.10418v1](http://arxiv.org/abs/2204.10418v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Machine learning models have become an essential tool in current indoor
positioning solutions, given their high capabilities to extract meaningful
information from the environment. Convolutional neural networks (CNNs) are one
of the most used neural networks (NNs) due to that they are capable of learning
complex patterns from the input data. Another model used in indoor positioning
solutions is the Extreme Learning Machine (ELM), which provides an acceptable
generalization performance as well as a fast speed of learning. In this paper,
we offer a lightweight combination of CNN and ELM, which provides a quick and
accurate classification of building and floor, suitable for power and
resource-constrained devices. As a result, the proposed model is 58\% faster
than the benchmark, with a slight improvement in the classification accuracy
(by less than 1\%

### Title: A Study of Flares in the Ultra-Cool Regime from SPECULOOS-South
* Paper ID: 2204.10417v1
* Paper URL: [http://arxiv.org/abs/2204.10417v1](http://arxiv.org/abs/2204.10417v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: We present a study of photometric flares on 154 low-mass ($\leq 0.2
\textrm{M}_{\odot}$) objects observed by the SPECULOOS-South Observatory from
1st June 2018 to 23rd March 2020. In this sample we identify 85 flaring
objects, ranging in spectral type from M4 to L0. We detect 234 flares in this
sample, with energies between $10^{29.2}$ and $10^{32.7}$ erg, using both
automated and manual methods. With this work, we present the largest
photometric sample of flares on late-M and ultra-cool dwarfs to date. By
extending previous M dwarf flare studies into the ultra-cool regime, we find
M5-M7 stars are more likely to flare than both earlier, and later, M dwarfs. By
performing artificial flare injection-recovery tests we demonstrate that we can
detect a significant proportion of flares down to an amplitude of 1 per cent,
and we are most sensitive to flares on the coolest stars. Our results reveal an
absence of high-energy flares on the reddest dwarfs. To probe the relations
between rotation and activity for fully convective stars, we extract rotation
periods for fast rotators and lower-bound period estimates of slow rotators.
These rotation periods span from 2.2 hours to 65 days, and we find that the
proportion of flaring stars increases for the very fastest rotators. Finally,
we discuss the impact of our flare sample on planets orbiting ultra-cool stars.
As stars become cooler, they flare less frequently; therefore, it is unlikely
that planets around the very reddest dwarfs would enter the `abiogenesis' zone
or drive visible-light photosynthesis through flares alone.

### Title: Parallel Vertex Cover Algorithms on GPUs
* Paper ID: 2204.10402v1
* Paper URL: [http://arxiv.org/abs/2204.10402v1](http://arxiv.org/abs/2204.10402v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Finding small vertex covers in a graph has applications in numerous domains.
Two common formulations of the problem include: Minimum Vertex Cover, which
finds the smallest vertex cover in a graph, and Parameterized Vertex Cover,
which finds a vertex cover whose size is less than or equal to some parameter
$k$. Algorithms for both formulations traverse a search tree, which grows
exponentially with the size of the graph or the value of $k$.
  Parallelizing the traversal of the vertex cover search tree on GPUs is
challenging for multiple reasons. First, the search tree is a narrow binary
tree which makes it difficult to extract enough sub-trees to process in
parallel to fully utilize the GPU's resources. Second, the search tree is
highly imbalanced which makes load balancing across a massive number of
parallel GPU workers challenging. Third, keeping around all the intermediate
state needed to traverse many sub-trees in parallel puts high pressure on the
GPU's memory resources and may act as a limiting factor to parallelism.
  To address these challenges, we propose an approach to traverse the vertex
cover search tree in parallel using GPUs while handling dynamic load balancing.
Each thread block traverses a different sub-tree using a local stack, however,
we also use a global worklist to balance load. Blocks contribute branches of
their sub-trees to the global worklist on an as-needed basis, while blocks that
finish their sub-trees get new ones from the global worklist. We use degree
arrays to represent intermediate graphs so that the representation is compact
in memory to avoid limiting parallelism, but self-contained which is necessary
for load balancing. Our evaluation shows that compared to prior work, our
hybrid approach of using local stacks and a global worklist substantially
improves performance and reduces load imbalance, especially on difficult
instances of the problem.

### Title: STD: A Seasonal-Trend-Dispersion Decomposition of Time Series
* Paper ID: 2204.10398v1
* Paper URL: [http://arxiv.org/abs/2204.10398v1](http://arxiv.org/abs/2204.10398v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/gmdudek/std](https://github.com/gmdudek/std)
* Summary: The decomposition of a time series is an essential task that helps to
understand its very nature. It facilitates the analysis and forecasting of
complex time series expressing various hidden components such as the trend,
seasonal components, cyclic components and irregular fluctuations. Therefore,
it is crucial in many fields for forecasting and decision processes. In recent
years, many methods of time series decomposition have been developed, which
extract and reveal different time series properties. Unfortunately, they
neglect a very important property, i.e. time series variance. To deal with
heteroscedasticity in time series, the method proposed in this work -- a
seasonal-trend-dispersion decomposition (STD) -- extracts the trend, seasonal
component and component related to the dispersion of the time series. We define
STD decomposition in two ways: with and without an irregular component. We show
how STD can be used for time series analysis and forecasting.

### Title: Facilitating automated conversion of scientific knowledge into scientific simulation models with the Machine Assisted Generation, Calibration, and Comparison (MAGCC) Framework
* Paper ID: 2204.10382v1
* Paper URL: [http://arxiv.org/abs/2204.10382v1](http://arxiv.org/abs/2204.10382v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The Machine Assisted Generation, Comparison, and Calibration (MAGCC)
framework provides machine assistance and automation of recurrent crucial steps
and processes in the development, implementation, testing, and use of
scientific simulation models. MAGCC bridges systems for knowledge extraction
via natural language processing or extracted from existing mathematical models
and provides a comprehensive workflow encompassing the composition of
scientific models and artificial intelligence (AI) assisted code generation.
MAGCC accomplishes this through: 1) the development of a comprehensively
expressive formal knowledge representation knowledgebase, the Structured
Scientific Knowledge Representation (SSKR) that encompasses all the types of
information needed to make any simulation model, 2) the use of an artificially
intelligent logic reasoning system, the Computational Modeling Assistant (CMA),
that takes information from the SSKR and generates, in a traceable fashion,
model specifications across a range of simulation modeling methods, and 3) the
use of the CMA to generate executable code for a simulation model from those
model specifications. The MAGCC framework can be customized any scientific
domain, and future work will integrate newly developed code-generating AI
systems.

### Title: Text-mined dataset of gold nanoparticle synthesis procedures, morphologies, and size entities
* Paper ID: 2204.10379v1
* Paper URL: [http://arxiv.org/abs/2204.10379v1](http://arxiv.org/abs/2204.10379v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Gold nanoparticles are highly desired for a range of technological
applications due to their tunable properties, which are dictated by the size
and shape of the constituent particles. Many heuristic methods for controlling
the morphological characteristics of gold nanoparticles are well known.
However, the underlying mechanisms controlling their size and shape remain
poorly understood, partly due to the immense range of possible combinations of
synthesis parameters. Data-driven methods can offer insight to help guide
understanding of these underlying mechanisms, so long as sufficient synthesis
data are available. To facilitate data mining in this direction, we have
constructed and made publicly available a dataset of codified gold nanoparticle
synthesis protocols and outcomes extracted directly from the nanoparticle
materials science literature using natural language processing and text-mining
techniques. This dataset contains 5,154 data records, each representing a
single gold nanoparticle synthesis article, filtered from a database of
4,973,165 publications. Each record contains codified synthesis protocols and
extracted morphological information from a total of 7,608 experimental and
12,519 characterization paragraphs.

### Title: Thermodynamic speed limits for mechanical work
* Paper ID: 2204.10368v1
* Paper URL: [http://arxiv.org/abs/2204.10368v1](http://arxiv.org/abs/2204.10368v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Thermodynamic speed limits are a set of classical uncertainty relations that,
so far, place global bounds on the stochastic dissipation of energy as heat and
the irreversible production of entropy. Here, instead of constraints on these
thermodynamic costs, we derive upper and lower bounds on a thermodynamic
benefit -- the minimum time for an amount of mechanical work to be done on or
by a system. These bounds are expressed entirely in terms of measurable
quantities and can be extracted from experiments. In the short time limit, we
define an intrinsic timescale for work, recover the intrinsic timescales in
differential speed limits from integral speed limits, and turn the first law of
stochastic thermodynamics into a first law of speeds. As physical examples, we
consider the work done by a flashing Brownian ratchet and the work done on a
particle in a potential well subject to external driving.

### Title: Flops of any length, Gopakumar-Vafa invariants, and 5d Higgs Branches
* Paper ID: 2204.10366v1
* Paper URL: [http://arxiv.org/abs/2204.10366v1](http://arxiv.org/abs/2204.10366v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The conifold is a basic example of a noncompact Calabi-Yau threefold that
admits a simple flop, and in M-theory, gives rise to a 5d hypermultiplet at low
energies, realized by an M2-brane wrapped on the vanishing sphere. We develop a
novel gauge-theoretic method to construct new classes of examples that
generalize the simple flop to so-called length l=1,...,6. The method allows us
to naturally read off the Gopakumar-Vafa invariants. Although they share
similar properties to the beloved conifold, these threefolds are expected to
admit M2-bound states of higher degree. We demonstrate this through our
computations of the GV invariants. Furthermore we fully characterize the
associated Higgs branches by computing their dimensions and flavor groups. With
our techniques we extract more refined data such as the charges of the hypers
under the flavor group.

### Title: Decorate the Examples: A Simple Method of Prompt Design for Biomedical Relation Extraction
* Paper ID: 2204.10360v1
* Paper URL: [http://arxiv.org/abs/2204.10360v1](http://arxiv.org/abs/2204.10360v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Relation extraction is a core problem for natural language processing in the
biomedical domain. Recent research on relation extraction showed that
prompt-based learning improves the performance on both fine-tuning on full
training set and few-shot training. However, less effort has been made on
domain-specific tasks where good prompt design can be even harder. In this
paper, we investigate prompting for biomedical relation extraction, with
experiments on the ChemProt dataset. We present a simple yet effective method
to systematically generate comprehensive prompts that reformulate the relation
extraction task as a cloze-test task under a simple prompt formulation. In
particular, we experiment with different ranking scores for prompt selection.
With BioMed-RoBERTa-base, our results show that prompting-based fine-tuning
obtains gains by 14.21 F1 over its regular fine-tuning baseline, and 1.14 F1
over SciFive-Large, the current state-of-the-art on ChemProt. Besides, we find
prompt-based learning requires fewer training examples to make reasonable
predictions. The results demonstrate the potential of our methods in such a
domain-specific relation extraction task.

### Title: Constraining Energy-dependent emissivity profiles of AGN inflows
* Paper ID: 2204.10346v1
* Paper URL: [http://arxiv.org/abs/2204.10346v1](http://arxiv.org/abs/2204.10346v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The emissivity of the accretion flow is a key parameter affecting the shape
of both the energy and variability power spectrum of AGN. We explore the
energy-dependence of the power spectrum for five AGN, across the XMM-Newton
bandpass, and across the 0.01-1 mHz frequency range, finding a ubiquitous
flattening of the power spectrum towards higher energies. We develop a
framework to explore this behaviour and thereby extract the energy dependence
of the emissivity assuming a simple disc-like geometry for the inflow. We find
that the emissivity ranges from R^-2 at energies around the soft excess and
increases to R^-4 or steeper above ~4-6 keV. We describe the changing
emissivity index with a linear function in energy, finding the best-fitting
slopes to vary between AGN. We attempt to correlate the slope of the linear
function against key AGN parameters but, as yet, the sample size is too small
to confirm hints of a correlation with Eddington ratio.

### Title: On the Superiority of the $|V_{cb}|-Î³$ Plots over the Unitarity Triangle Plots in the 2020s
* Paper ID: 2204.10337v1
* Paper URL: [http://arxiv.org/abs/2204.10337v1](http://arxiv.org/abs/2204.10337v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The UT plots played already for three decades an important role in the tests
of the SM and the determination of the CKM parameters. As of 2022, among the
four CKM parameters, $V_{us}$ and $\beta$ are already measured with respectable
precision, while this is not the case of $|V_{cb}|$ and $\gamma$. In the case
of $|V_{cb}|$ the main obstacle are the significant tensions between its
inclusive and exclusive determinations from tree-level decays. The present
uncertainty in $\gamma$ of $4^\circ$ from tree-level decays will be reduced to
$1^\circ$ by the LHCb and Belle II collaborations in the coming years.
Unfortunately in the UT plots $|V_{cb}|$ is not seen and the experimental
improvements in the determination of $\gamma$ from tree-level decays at the
level of a few degrees are difficult to appreciate. In view of these
deficiencies of the UT plots with respect to $|V_{cb}|$ and $\gamma$ and the
central role these two CKM parameters will play in this decade, the recently
proposed plots of $|V_{cb}|$ versus $\gamma$ extracted from various processes
appear to be superior to the UT plots in the flavour phenomenology. We
illustrate this idea with $\Delta M_s$, $\Delta M_d$, $\epsilon_K$ and with
rare decays $B_s\to\mu^+\mu^-$, $B_d\to\mu^+\mu^-$, $K^+\to \pi^+\nu\bar\nu$
and $K_L\to\pi^0\nu\bar\nu$. The power of $\epsilon_K$,
$K^+\to\pi^+\nu\bar\nu)$ and $K_{L}\to\pi^0\nu\bar\nu)$ in the determination of
$|V_{cb}|$, due to their strong dependence on $|V_{cb}|$, is transparently
exhibited in this manner. Combined with future reduced errors on $\gamma$ and
$|V_{cb}|$ from tree-level decays such plots can better exhibit possible
inconsistenices between various determinations of these two parameters, caused
by new physics, than it is possible with the UT plots. This can already be
illustrated on the example of the $2.7\sigma$ anomaly in $B_s\to\mu^+\mu^-$.

### Title: Parallel QND measurement tomography of multi-qubit quantum devices
* Paper ID: 2204.10336v1
* Paper URL: [http://arxiv.org/abs/2204.10336v1](http://arxiv.org/abs/2204.10336v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: An efficient characterization of QND measurements is an important ingredient
towards certifying and improving the performance and scalability of quantum
processors. In this work, we introduce a protocol for the parallelized QND
measurement tomography (QND-MT) of a multiqubit quantum processor that
addresses single- and two-qubit measurements. We demonstrate the excellent
scaling of this protocol experimentally, fully characterizing a 7-qubit IBM-Q
quantum processor for direct measurements and measurement-and-reset schemes.
Our protocol reconstructs the Choi matrices of the single- and two-qubit
measurement processes, extracts relevant quantifiers -- fidelity, QND-ness,
destructiveness -- and identifies sources of errors that limit the performance
of the device for repeated QND measurements. We also introduce quantification
schemes that reveal the influence of cross-talk on the measurement outcomes.

### Title: Measurement of inclusive and leading subjet fragmentation in pp and Pb-Pb collisions at $\sqrt{s_{\rm NN}}$ = 5.02 TeV
* Paper ID: 2204.10270v1
* Paper URL: [http://arxiv.org/abs/2204.10270v1](http://arxiv.org/abs/2204.10270v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: This article presents new measurements of the fragmentation properties of
jets in both proton-proton (pp) and heavy-ion collisions with the ALICE
experiment at the Large Hadron Collider (LHC). We report distributions of the
fraction $z_r$ of transverse momentum carried by subjets of radius $r$ within
jets of radius $R$. Charged-particle jets are reconstructed at midrapidity
using the anti-$k_{\rm{T}}$ algorithm with jet radius $R=0.4$, and subjets are
reconstructed by reclustering the jet constituents using the anti-$k_{\rm{T}}$
algorithm with radii $r=0.1$ and $r=0.2$. In proton-proton collisions, we
measure both the inclusive and leading subjet distributions. We compare these
measurements to perturbative calculations at next-to-leading logarithmic
accuracy, which suggest a large impact of threshold resummation and
hadronization effects on the $z_r$ distribution. In heavy-ion collisions, we
measure the leading subjet distributions, which allow access to a region of
harder jet fragmentation than has been probed by previous measurements of jet
quenching via hadron fragmentation distributions. The $z_r$ distributions
enable extraction of the parton-to-subjet fragmentation function and allow for
tests of the universality of jet fragmentation functions in the quark-gluon
plasma (QGP). We find indications that there is a turnover in the ratio between
the distributions in Pb-Pb and pp collisions as $z_r \rightarrow 1$, exposing
qualitatively new possibilities to disentangle competing jet quenching
mechanisms. By comparing our results to theoretical calculations based on an
independent extraction of the parton-to-jet fragmentation function, we find
consistency with the universality of jet fragmentation and no indication of
factorization breaking in the QGP.

### Title: Elliptic flow of charged particles at midrapidity relative to the spectator plane in Pb-Pb and Xe-Xe collisions
* Paper ID: 2204.10240v1
* Paper URL: [http://arxiv.org/abs/2204.10240v1](http://arxiv.org/abs/2204.10240v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Measurements of the elliptic flow coefficient relative to the collision plane
defined by the spectator neutrons $v_2${$\Psi_{\rm SP}$} in collisions of Pb
ions at center-of-mass energy per nucleon-nucleon pair $\sqrt{s_{\rm NN}}$=2.76
TeV and Xe ions at $\sqrt{s_{\rm NN}}$=5.44 TeV are reported. The results are
presented for charged particles produced at midrapidity as a function of
centrality and transverse momentum. The ratio between $v_2${$\Psi_{\rm SP}$}
and the elliptic flow coefficient relative to the participant plane $v_2${4},
estimated using four-particle correlations, deviates by up to 20% from unity
depending on centrality. This observation differs strongly from the magnitude
of the corresponding eccentricity ratios predicted by the TRENTo and the
elliptic power models of initial state fluctuations that are tuned to describe
the participant plane anisotropies. The differences can be interpreted as a
decorrelation of the neutron spectator plane and the reaction plane because of
fragmentation of the remnants from the colliding nuclei, which points to an
incompleteness of current models of initial state fluctuations. A significant
transverse momentum dependence of the ratio $v_2${$\Psi_{\rm SP}$}/$v_2${4} is
observed in all but the most central collisions, which may help to understand
whether momentum anisotropies at low and intermediate transverse momentum have
a common origin in initial state fluctuations. The ratios of $v_2${$\Psi_{\rm
SP}$} and $v_2${4} to the corresponding initial state eccentricities for Xe-Xe
and Pb-Pb collisions at similar initial entropy density show a difference of
$(7.0 \pm 0.9)$% with an additional variation of +1.8% when including RHIC data
in the TRENTo parameter extraction. These observations provide new experimental
constraints for viscous effects in the hydrodynamic modeling of the expanding
quark-gluon plasma.

### Title: HEATGait: Hop-Extracted Adjacency Technique in Graph Convolution based Gait Recognition
* Paper ID: 2204.10238v1
* Paper URL: [http://arxiv.org/abs/2204.10238v1](http://arxiv.org/abs/2204.10238v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Biometric authentication using gait has become a promising field due to its
unobtrusive nature. Recent approaches in model-based gait recognition
techniques utilize spatio-temporal graphs for the elegant extraction of gait
features. However, existing methods often rely on multi-scale operators for
extracting long-range relationships among joints resulting in biased weighting.
In this paper, we present HEATGait, a gait recognition system that improves the
existing multi-scale graph convolution by efficient hop-extraction technique to
alleviate the issue. Combined with preprocessing and augmentation techniques,
we propose a powerful feature extractor that utilizes ResGCN to achieve
state-of-the-art performance in model-based gait recognition on the CASIA-B
gait dataset.

### Title: Cross-Lingual Query-Based Summarization of Crisis-Related Social Media: An Abstractive Approach Using Transformers
* Paper ID: 2204.10230v1
* Paper URL: [http://arxiv.org/abs/2204.10230v1](http://arxiv.org/abs/2204.10230v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/vitiugin/cliqs-cm](https://github.com/vitiugin/cliqs-cm)
* Summary: Relevant and timely information collected from social media during crises can
be an invaluable resource for emergency management. However, extracting this
information remains a challenging task, particularly when dealing with social
media postings in multiple languages. This work proposes a cross-lingual method
for retrieving and summarizing crisis-relevant information from social media
postings. We describe a uniform way of expressing various information needs
through structured queries and a way of creating summaries answering those
information needs. The method is based on multilingual transformers embeddings.
Queries are written in one of the languages supported by the embeddings, and
the extracted sentences can be in any of the other languages supported.
Abstractive summaries are created by transformers. The evaluation, done by
crowdsourcing evaluators and emergency management experts, and carried out on
collections extracted from Twitter during five large-scale disasters spanning
ten languages, shows the flexibility of our approach. The generated summaries
are regarded as more focused, structured, and coherent than existing
state-of-the-art methods, and experts compare them favorably against summaries
created by existing, state-of-the-art methods.

### Title: The NIST CTS Speaker Recognition Challenge
* Paper ID: 2204.10228v1
* Paper URL: [http://arxiv.org/abs/2204.10228v1](http://arxiv.org/abs/2204.10228v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The US National Institute of Standards and Technology (NIST) has been
conducting a second iteration of the CTS challenge since August 2020. The
current iteration of the CTS Challenge is a leaderboard-style speaker
recognition evaluation using telephony data extracted from the unexposed
portions of the Call My Net 2 (CMN2) and Multi-Language Speech (MLS) corpora
collected by the LDC. The CTS Challenge is currently organized in a similar
manner to the SRE19 CTS Challenge, offering only an open training condition
using two evaluation subsets, namely Progress and Test. Unlike in the SRE19
Challenge, no training or development set was initially released, and NIST has
publicly released the leaderboards on both subsets for the CTS Challenge. Which
subset (i.e., Progress or Test) a trial belongs to is unknown to challenge
participants, and each system submission needs to contain outputs for all of
the trials. The CTS Challenge has also served, and will continue to do so, as a
prerequisite for entrance to the regular SREs (such as SRE21). Since August
2020, a total of 53 organizations (forming 33 teams) from academia and industry
have participated in the CTS Challenge and submitted more than 4400 valid
system outputs. This paper presents an overview of the evaluation and several
analyses of system performance for some primary conditions in the CTS
Challenge. The CTS Challenge results thus far indicate remarkable improvements
in performance due to 1) speaker embeddings extracted using large-scale and
complex neural network architectures such as ResNets along with angular margin
losses for speaker embedding extraction, 2) extensive data augmentation, 3) the
use of large amounts of in-house proprietary data from a large number of
labeled speakers, 4) long-duration fine-tuning.

### Title: The Proton Spin Structure Function $g_2$ and Generalized Polarizabilities in the Strong QCD Regime
* Paper ID: 2204.10224v1
* Paper URL: [http://arxiv.org/abs/2204.10224v1](http://arxiv.org/abs/2204.10224v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The strong interaction is not well understood at low energy, or for
interactions with low momentum transfer $Q^2$, but one of the clearest insights
we have comes from Chiral Perturbation Theory ($\chi$PT). This effective
treatment gives testable predictions for the nucleonic generalized
polarizabilities -- fundamental quantities describing the nucleon's response to
an external field. We have measured the proton's generalized spin
polarizabilities in the region where $\chi$PT is expected to be valid. Our
results include the first ever data for the transverse-longitudinal spin
polarizability $\delta_{LT}$, and also extend the coverage of the
polarizability $\overline{d_2}$ to very low $Q^2$ for the first time. These
results were extracted from moments of the structure function $g_2$, a quantity
which characterizes the internal spin structure of the proton. Our experiment
ran at Jefferson Lab using a polarized electron beam and a polarized solid
ammonia (NH$_3$) target. The $\delta_{LT}$ polarizability has remained a
challenging quantity for $\chi$PT to reproduce, despite its reduced sensitivity
to higher resonance contributions; recent competing calculations still disagree
with each other and also diverge from the measured neutron data at very low
$Q^2$. Our proton results provide discriminating power between existing
calculations, and will help provide a better understanding of this strong QCD
regime.

### Title: Learning spatiotemporal features from incomplete data for traffic flow prediction using hybrid deep neural networks
* Paper ID: 2204.10222v1
* Paper URL: [http://arxiv.org/abs/2204.10222v1](http://arxiv.org/abs/2204.10222v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Urban traffic flow prediction using data-driven models can play an important
role in route planning and preventing congestion on highways. These methods
utilize data collected from traffic recording stations at different timestamps
to predict the future status of traffic. Hence, data collection, transmission,
storage, and extraction techniques can have a significant impact on the
performance of the traffic flow model. On the other hand, a comprehensive
database can provide the opportunity for using complex, yet reliable predictive
models such as deep learning methods. However, most of these methods have
difficulties in handling missing values and outliers. This study focuses on
hybrid deep neural networks to predict traffic flow in the California Freeway
Performance Measurement System (PeMS) with missing values. The proposed
networks are based on a combination of recurrent neural networks (RNNs) to
consider the temporal dependencies in the data recorded in each station and
convolutional neural networks (CNNs) to take the spatial correlations in the
adjacent stations into account. Various architecture configurations with series
and parallel connections are considered based on RNNs and CNNs, and several
prevalent data imputation techniques are used to examine the robustness of the
hybrid networks to missing values. A comprehensive analysis performed on two
different datasets from PeMS indicates that the proposed series-parallel hybrid
network with the mean imputation technique achieves the lowest error in
predicting the traffic flow and is robust to missing values up until 21%
missing ratio in both complete and incomplete training data scenarios when
applied to an incomplete test data.

### Title: Measurement of the vertical atmospheric density profile from the X-ray Earth occultation of the Crab Nebula with Insight-HXMT
* Paper ID: 2204.09674v1
* Paper URL: [http://arxiv.org/abs/2204.09674v1](http://arxiv.org/abs/2204.09674v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: In this paper, the X-ray Earth occultation (XEO) of the Crab Nebula is
investigated by using the Hard X-ray Modulation Telescope (Insight-HXMT). The
pointing observation data on the 30th September, 2018 recorded by the Low
Energy X-ray telescope (LE) of Insight-HXMT are selected and analyzed. The
extinction lightcurves and spectra during the X-ray Earth occultation process
are extracted. A forward model for the XEO lightcurve is established and the
theoretical observational signal for lightcurve is predicted. The atmospheric
density model is built with a scale factor to the commonly used MSIS density
profile within a certain altitude range. A Bayesian data analysis method is
developed for the XEO lightcurve modeling and the atmospheric density
retrieval. The posterior probability distribution of the model parameters is
derived through the Markov Chain Monte Carlo (MCMC) algorithm with the
NRLMSISE-00 model and the NRLMSIS 2.0 model as basis functions and the best-fit
density profiles are retrieved respectively. It is found that in the altitude
range of 105--200 km, the retrieved density profile is 88.8% of the density of
NRLMSISE-00 and 109.7% of the density of NRLMSIS 2.0 by fitting the lightcurve
in the energy range of 1.0--2.5 keV based on XEOS method. In the altitude range
of 95--125 km, the retrieved density profile is 81.0% of the density of
NRLMSISE-00 and 92.3% of the density of NRLMSIS 2.0 by fitting the lightcurve
in the energy range of 2.5--6.0 keV based on XEOS method. In the altitude range
of 85--110 km, the retrieved density profile is 87.7% of the density of
NRLMSISE-00 and 101.4% of the density of NRLMSIS 2.0 by fitting the lightcurve
in the energy range of 6.0--10.0 keV based on XEOS method. This study
demonstrates that the XEOS from the X-ray astronomical satellite Insight-HXMT
can provide an approach for the study of the upper atmosphere.

### Title: ALICE luminosity determination for Pb$-$Pb collisions at $\sqrt{s_{\mathrm{NN}}} = 5.02$ TeV
* Paper ID: 2204.10148v1
* Paper URL: [http://arxiv.org/abs/2204.10148v1](http://arxiv.org/abs/2204.10148v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Luminosity determination within the ALICE experiment is based on the
measurement, in van der Meer scans, of the cross sections for visible processes
involving one or more detectors (visible cross sections). In 2015 and 2018, the
Large Hadron Collider provided Pb$-$Pb collisions at a centre-of-mass energy
per nucleon pair of $\sqrt{s_{\rm NN}} = 5.02$ TeV. Two visible cross sections,
associated with particle detection in the Zero Degree Calorimeter (ZDC) and in
the V0 detector, were measured in a van der Meer scan. This article describes
the experimental set-up and the analysis procedure, and presents the
measurement results. The analysis involves a comprehensive study of
beam-related effects and an improved fitting procedure, compared to previous
ALICE studies, for the extraction of the visible cross section. The resulting
uncertainty of the ZDC-based (V0-based) luminosity measurement for the full
sample is 2.3% (2.2%). The inelastic cross section for hadronic interactions in
Pb$-$Pb collisions at $\sqrt{s_{\rm NN}} = 5.02$ TeV, obtained by efficiency
correction of the V0-based visible cross section, was measured to be $7.67 \pm
0.24$ b.

### Title: Learnable Model Augmentation Self-Supervised Learning for Sequential Recommendation
* Paper ID: 2204.10128v1
* Paper URL: [http://arxiv.org/abs/2204.10128v1](http://arxiv.org/abs/2204.10128v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Sequential Recommendation aims to predict the next item based on user
behaviour. Recently, Self-Supervised Learning (SSL) has been proposed to
improve recommendation performance. However, most of existing SSL methods use a
uniform data augmentation scheme, which loses the sequence correlation of an
original sequence. To this end, in this paper, we propose a Learnable Model
Augmentation self-supervised learning for sequential Recommendation (LMA4Rec).
Specifically, LMA4Rec first takes model augmentation as a supplementary method
for data augmentation to generate views. Then, LMA4Rec uses learnable Bernoulli
dropout to implement model augmentation learnable operations. Next,
self-supervised learning is used between the contrastive views to extract
self-supervised signals from an original sequence. Finally, experiments on
three public datasets show that the LMA4Rec method effectively improves
sequential recommendation performance compared with baseline methods.

### Title: A systematic review of guidelines for the use of race, ethnicity, and ancestry reveals widespread consensus but also points of ongoing disagreement
* Paper ID: 2204.10672v1
* Paper URL: [http://arxiv.org/abs/2204.10672v1](http://arxiv.org/abs/2204.10672v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The use of population descriptors like race, ethnicity, and ancestry in
science, medicine and public health has a long, complicated, and at times dark
history, particularly for genetics, given the field's perceived importance for
understanding between-group differences. The historical and potential harms
that come with irresponsible use of these categories suggests a clear need for
definitive guidance about when and how they can be used appropriately. However,
while many prior authors have provided such guidance, no established consensus
exists, and the extant literature has not been examined for implied consensus
and sources of disagreement. Here we present the results of a systematic review
of published normative recommendations regarding the use of population
categories, particularly in genetics research. Following PRISMA guidelines, we
extracted recommendations from n=121 articles matching inclusion criteria.
Articles were published consistently throughout the time period examined and in
a broad range of journals, demonstrating an ongoing and interdisciplinary
perceived need for guidance. Examined recommendations fall under one of eight
themes identified during analysis. Seven are characterized by broad agreement
across articles; one, Appropriate definitions of population categories and
contexts for use, revealed substantial fundamental disagreement among articles.
While many articles focus on the inappropriate use of race, none fundamentally
problematize ancestry. This work can be a resource to researchers looking for
normative guidance on the use of population descriptors, and can orient authors
of future guidelines to this complex field, contributing to the development of
more effective future guidelines for genetics research.

### Title: R2-Trans:Fine-Grained Visual Categorization with Redundancy Reduction
* Paper ID: 2204.10095v1
* Paper URL: [http://arxiv.org/abs/2204.10095v1](http://arxiv.org/abs/2204.10095v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Fine-grained visual categorization (FGVC) aims to discriminate similar
subcategories, whose main challenge is the large intraclass diversities and
subtle inter-class differences. Existing FGVC methods usually select
discriminant regions found by a trained model, which is prone to neglect other
potential discriminant information. On the other hand, the massive interactions
between the sequence of image patches in ViT make the resulting class-token
contain lots of redundant information, which may also impacts FGVC performance.
In this paper, we present a novel approach for FGVC, which can simultaneously
make use of partial yet sufficient discriminative information in environmental
cues and also compress the redundant information in class-token with respect to
the target. Specifically, our model calculates the ratio of high-weight regions
in a batch, adaptively adjusts the masking threshold and achieves moderate
extraction of background information in the input space. Moreover, we also use
the Information Bottleneck~(IB) approach to guide our network to learn a
minimum sufficient representations in the feature space. Experimental results
on three widely-used benchmark datasets verify that our approach can achieve
outperforming performance than other state-of-the-art approaches and baseline
models.

### Title: OTExtSum: Extractive Text Summarisation with Optimal Transport
* Paper ID: 2204.10086v1
* Paper URL: [http://arxiv.org/abs/2204.10086v1](http://arxiv.org/abs/2204.10086v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/peggypytang/otextsum](https://github.com/peggypytang/otextsum)
* Summary: Extractive text summarisation aims to select salient sentences from a
document to form a short yet informative summary. While learning-based methods
have achieved promising results, they have several limitations, such as
dependence on expensive training and lack of interpretability. Therefore, in
this paper, we propose a novel non-learning-based method by for the first time
formulating text summarisation as an Optimal Transport (OT) problem, namely
Optimal Transport Extractive Summariser (OTExtSum). Optimal sentence extraction
is conceptualised as obtaining an optimal summary that minimises the
transportation cost to a given document regarding their semantic distributions.
Such a cost is defined by the Wasserstein distance and used to measure the
summary's semantic coverage of the original document. Comprehensive experiments
on four challenging and widely used datasets - MultiNews, PubMed, BillSum, and
CNN/DM demonstrate that our proposed method outperforms the state-of-the-art
non-learning-based methods and several recent learning-based methods in terms
of the ROUGE metric.

### Title: Absolute Wrong Makes Better: Boosting Weakly Supervised Object Detection via Negative Deterministic Information
* Paper ID: 2204.10068v1
* Paper URL: [http://arxiv.org/abs/2204.10068v1](http://arxiv.org/abs/2204.10068v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Weakly supervised object detection (WSOD) is a challenging task, in which
image-level labels (e.g., categories of the instances in the whole image) are
used to train an object detector. Many existing methods follow the standard
multiple instance learning (MIL) paradigm and have achieved promising
performance. However, the lack of deterministic information leads to part
domination and missing instances. To address these issues, this paper focuses
on identifying and fully exploiting the deterministic information in WSOD. We
discover that negative instances (i.e. absolutely wrong instances), ignored in
most of the previous studies, normally contain valuable deterministic
information. Based on this observation, we here propose a negative
deterministic information (NDI) based method for improving WSOD, namely
NDI-WSOD. Specifically, our method consists of two stages: NDI collecting and
exploiting. In the collecting stage, we design several processes to identify
and distill the NDI from negative instances online. In the exploiting stage, we
utilize the extracted NDI to construct a novel negative contrastive learning
mechanism and a negative guided instance selection strategy for dealing with
the issues of part domination and missing instances, respectively. Experimental
results on several public benchmarks including VOC 2007, VOC 2012 and MS COCO
show that our method achieves satisfactory performance.

### Title: Mass spectra of $Î_{cc}$, $Î_{bc}$, $Î©_{cc}$, and $Î©_{bc}$ baryons in Regge Phenomenology
* Paper ID: 2204.10045v1
* Paper URL: [http://arxiv.org/abs/2204.10045v1](http://arxiv.org/abs/2204.10045v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: In this article, we study the mass spectra of baryons containing two heavy
quarks; charm-charm ($cc$) and bottom-charm ($bc$) with a light quark ($u,d,s$)
within the framework of Regge phenomenology. With the assumption of linear
Regge trajectories we have derived the relations between slope ratios,
intercepts, and baryon masses. Using these relations, the ground state masses
of $\Xi_{cc}$, $\Xi_{bc}$, $\Omega_{cc}$, and $\Omega_{bc}$ baryons are
obtained. The values of Regge slopes and Regge intercepts are extracted for
these baryons to estimate the excited state masses in both the ($J,M^{2}$) and
($n,M^{2}$) planes. Our obtained results are compared with the experimental
observations where available and other theoretical predictions, which could be
a valuable addition to the interpretations of experimentally unknown heavy
baryon spectra.

### Title: Measuring the anomalous quartic gauge couplings in the $W^+W^-\to W^+W^-$ process at muon collider using artificial neural networks
* Paper ID: 2204.10034v1
* Paper URL: [http://arxiv.org/abs/2204.10034v1](http://arxiv.org/abs/2204.10034v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The muon collider provides a unique opportunity to study the vector boson
scattering processes and dimension-8 operators contributing to anomalous
quartic gauge couplings. Because of the cleaner final state, it is easier to
decode subprocess and certain operator couplings at a muon collider. We attempt
to identify the anomalous $WWWW$ coupling in $WW\to WW$ scattering in this
paper. The vector boson scattering process corresponding to the anomalous
$WWWW$ coupling is $\mu^+\mu^-\to \nu\nu\bar{\nu}\bar{\nu}\ell^+\ell^-$, with
four (anti-)neutrinos in the final state, which pose difficulties for
phenomenological studies. In this paper, the machine learning method is used to
tackle this problem. We find that, the artificial neural network can be used to
extract the $W^+W^-\to W^+W^-$ contribution, and is useful to reconstruct the
center of mass energy of the subprocess which is important in the study of the
Standard Model effective field theory. The sensitivities and the expected
constraints on the dimension-8 operators at the muon collider with
$\sqrt{s}=30$ TeV are presented. The artificial neural networks exhibit great
potential in the phenomenological study of processes with multiple neutrinos in
the final state.

### Title: Ferrous Metal Matrix Composites Status Scope and Challenges
* Paper ID: 2204.09999v1
* Paper URL: [http://arxiv.org/abs/2204.09999v1](http://arxiv.org/abs/2204.09999v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The present paper is an effort to culminate the status, scopes and challenges
in the development of ferrous metal matrix composites (FMMCs). The FMMCs are
old but less in use than the non-ferrous metal matrix composites (NFMMCs), as
far as literature and actual applications are concerned. Therefore, this
stimulates the exploration of the reasons behind the scarcity of literature and
field applications of the FMMCs, which must be investigated scientifically. The
powder metallurgy route is the most used process for fabricating iron and steel
based FMMCs by reinforcing particulates. At the same time, the in-situ method
has been used for the fabrication and cast iron-based FMMCs. The main
characteristics being considered during the designing and fabrication of FMMCs
are wear resistance and improved specific mechanical properties. To fabricate
cheaper and eco-friendly FMMCs, traditionally used costly reinforcements such
as SiC, WC, TiC, SiO2, TiO2, TiB2 are required to be replaced by inexpensive
industrial wastes like red-mud, fly-ashes and grinding swarf. The data
extracted from the web of science exhibited that the FMMCs have been researched
less than the NFMMCs. The increasing number of research papers on FMMCs
indicates a bright future. FMMCs are going to be a favourite topic among
researchers and manufacturers. Higher strengths, wear resistance, dimensional
stability at elevated temperatures, and, most importantly, the lower cost will
put forward the FMMCs as a stiff competitor of NFMMCs. In developing and mass
production of FMMCs for field applications, challenges like oxidation and
higher weight still require special research efforts.

### Title: DGECN: A Depth-Guided Edge Convolutional Network for End-to-End 6D Pose Estimation
* Paper ID: 2204.09983v1
* Paper URL: [http://arxiv.org/abs/2204.09983v1](http://arxiv.org/abs/2204.09983v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Monocular 6D pose estimation is a fundamental task in computer vision.
Existing works often adopt a two-stage pipeline by establishing correspondences
and utilizing a RANSAC algorithm to calculate 6 degrees-of-freedom (6DoF) pose.
Recent works try to integrate differentiable RANSAC algorithms to achieve an
end-to-end 6D pose estimation. However, most of them hardly consider the
geometric features in 3D space, and ignore the topology cues when performing
differentiable RANSAC algorithms. To this end, we proposed a Depth-Guided Edge
Convolutional Network (DGECN) for 6D pose estimation task. We have made efforts
from the following three aspects: 1) We take advantages ofestimated depth
information to guide both the correspondences-extraction process and the
cascaded differentiable RANSAC algorithm with geometric information. 2)We
leverage the uncertainty ofthe estimated depth map to improve accuracy and
robustness ofthe output 6D pose. 3) We propose a differentiable
Perspective-n-Point(PnP) algorithm via edge convolution to explore the topology
relations between 2D-3D correspondences. Experiments demonstrate that our
proposed network outperforms current works on both effectiveness and
efficiency.

### Title: Using consumer feedback from location-based services in PoI recommender systems for people with autism
* Paper ID: 2204.09969v1
* Paper URL: [http://arxiv.org/abs/2204.09969v1](http://arxiv.org/abs/2204.09969v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: When suggesting Points of Interest (PoIs) to people with autism spectrum
disorders, we must take into account that they have idiosyncratic sensory
aversions to noise, brightness and other features that influence the way they
perceive places. Therefore, recommender systems must deal with these aspects.
However, the retrieval of sensory data about PoIs is a real challenge because
most geographical information servers fail to provide this data. Moreover,
ad-hoc crowdsourcing campaigns do not guarantee to cover large geographical
areas and lack sustainability. Thus, we investigate the extraction of sensory
data about places from the consumer feedback collected by location-based
services, on which people spontaneously post reviews from all over the world.
Specifically, we propose a model for the extraction of sensory data from the
reviews about PoIs, and its integration in recommender systems to predict item
ratings by considering both user preferences and compatibility information. We
tested our approach with autistic and neurotypical people by integrating it
into diverse recommendation algorithms. For the test, we used a dataset built
in a crowdsourcing campaign and another one extracted from TripAdvisor reviews.
The results show that the algorithms obtain the highest accuracy and ranking
capability when using TripAdvisor data. Moreover, by jointly using these two
datasets, the algorithms further improve their performance. These results
encourage the use of consumer feedback as a reliable source of information
about places in the development of inclusive recommender systems.

### Title: Transformer-Guided Convolutional Neural Network for Cross-View Geolocalization
* Paper ID: 2204.09967v1
* Paper URL: [http://arxiv.org/abs/2204.09967v1](http://arxiv.org/abs/2204.09967v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Ground-to-aerial geolocalization refers to localizing a ground-level query
image by matching it to a reference database of geo-tagged aerial imagery. This
is very challenging due to the huge perspective differences in visual
appearances and geometric configurations between these two views. In this work,
we propose a novel Transformer-guided convolutional neural network (TransGCNN)
architecture, which couples CNN-based local features with Transformer-based
global representations for enhanced representation learning. Specifically, our
TransGCNN consists of a CNN backbone extracting feature map from an input image
and a Transformer head modeling global context from the CNN map. In particular,
our Transformer head acts as a spatial-aware importance generator to select
salient CNN features as the final feature representation. Such a coupling
procedure allows us to leverage a lightweight Transformer network to greatly
enhance the discriminative capability of the embedded features. Furthermore, we
design a dual-branch Transformer head network to combine image features from
multi-scale windows in order to improve details of the global feature
representation. Extensive experiments on popular benchmark datasets demonstrate
that our model achieves top-1 accuracy of 94.12\% and 84.92\% on CVUSA and
CVACT_val, respectively, which outperforms the second-performing baseline with
less than 50% parameters and almost 2x higher frame rate, therefore achieving a
preferable accuracy-efficiency tradeoff.

### Title: Referring Expression Comprehension via Cross-Level Multi-Modal Fusion
* Paper ID: 2204.09957v1
* Paper URL: [http://arxiv.org/abs/2204.09957v1](http://arxiv.org/abs/2204.09957v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: As an important and challenging problem in vision-language tasks, referring
expression comprehension (REC) aims to localize the target object specified by
a given referring expression. Recently, most of the state-of-the-art REC
methods mainly focus on multi-modal fusion while overlooking the inherent
hierarchical information contained in visual and language encoders. Considering
that REC requires visual and textual hierarchical information for accurate
target localization, and encoders inherently extract features in a hierarchical
fashion, we propose to effectively utilize the rich hierarchical information
contained in different layers of visual and language encoders. To this end, we
design a Cross-level Multi-modal Fusion (CMF) framework, which gradually
integrates visual and textual features of multi-layer through intra- and
inter-modal. Experimental results on RefCOCO, RefCOCO+, RefCOCOg, and
ReferItGame datasets demonstrate the proposed framework achieves significant
performance improvements over state-of-the-art methods.

### Title: Recovering Patient Journeys: A Corpus of Biomedical Entities and Relations on Twitter (BEAR)
* Paper ID: 2204.09952v1
* Paper URL: [http://arxiv.org/abs/2204.09952v1](http://arxiv.org/abs/2204.09952v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Text mining and information extraction for the medical domain has focused on
scientific text generated by researchers. However, their direct access to
individual patient experiences or patient-doctor interactions can be limited.
Information provided on social media, e.g., by patients and their relatives,
complements the knowledge in scientific text. It reflects the patient's journey
and their subjective perspective on the process of developing symptoms, being
diagnosed and offered a treatment, being cured or learning to live with a
medical condition. The value of this type of data is therefore twofold:
Firstly, it offers direct access to people's perspectives. Secondly, it might
cover information that is not available elsewhere, including self-treatment or
self-diagnoses. Named entity recognition and relation extraction are methods to
structure information that is available in unstructured text. However, existing
medical social media corpora focused on a comparably small set of entities and
relations and particular domains, rather than putting the patient into the
center of analyses. With this paper we contribute a corpus with a rich set of
annotation layers following the motivation to uncover and model patients'
journeys and experiences in more detail. We label 14 entity classes (incl.
environmental factors, diagnostics, biochemical processes, patients'
quality-of-life descriptions, pathogens, medical conditions, and treatments)
and 20 relation classes (e.g., prevents, influences, interactions, causes) most
of which have not been considered before for social media data. The publicly
available dataset consists of 2,100 tweets with approx. 6,000 entity and 3,000
relation annotations. In a corpus analysis we find that over 80 % of documents
contain relevant entities. Over 50 % of tweets express relations which we
consider essential for uncovering patients' narratives about their journeys.

### Title: Hybrid Cloud-Edge Collaborative Data Anomaly Detection in Industrial Sensor Networks
* Paper ID: 2204.09942v1
* Paper URL: [http://arxiv.org/abs/2204.09942v1](http://arxiv.org/abs/2204.09942v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Industrial control systems (ICSs) are facing increasing cyber-physical
attacks that can cause catastrophes in the physical system. Efficient anomaly
detection models in the industrial sensor networks are essential for enhancing
ICS reliability and security, due to the sensor data is related to the
operational state of the ICS. Considering the limited availability of computing
resources, this paper proposes a hybrid anomaly detection approach in
cloud-edge collaboration industrial sensor networks. The hybrid approach
consists of sensor data detection models deployed at the edges and a sensor
data analysis model deployed in the cloud. The sensor data detection model
based on Gaussian and Bayesian algorithms can detect the anomalous sensor data
in real-time and upload them to the cloud for further analysis, filtering the
normal sensor data and reducing traffic load. The sensor data analysis model
based on Graph convolutional network, Residual algorithm and Long short-term
memory network (GCRL) can effectively extract the spatial and temporal features
and then identify the attack precisely. The proposed hybrid anomaly detection
approach is evaluated using a benchmark dataset and baseline anomaly detection
models. The experimental results show that the proposed approach can achieve an
overall 11.19% increase in Recall and an impressive 14.29% improvement in
F1-score, compared with the existing models.

### Title: Multi-task recommendation system for scientific papers with high-way networks
* Paper ID: 2204.09930v1
* Paper URL: [http://arxiv.org/abs/2204.09930v1](http://arxiv.org/abs/2204.09930v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Finding and selecting the most relevant scientific papers from a large number
of papers written in a research community is one of the key challenges for
researchers these days. As we know, much information around research interest
for scholars and academicians belongs to papers they read. Analysis and
extracting contextual features from these papers could help us to suggest the
most related paper to them. In this paper, we present a multi-task
recommendation system (RS) that predicts a paper recommendation and generates
its meta-data such as keywords. The system is implemented as a three-stage deep
neural network encoder that tries to maps longer sequences of text to an
embedding vector and learns simultaneously to predict the recommendation rate
for a particular user and the paper's keywords. The motivation behind this
approach is that the paper's topics expressed as keywords are a useful
predictor of preferences of researchers. To achieve this goal, we use a system
combination of RNNs, Highway and Convolutional Neural Networks to train
end-to-end a context-aware collaborative matrix. Our application uses Highway
networks to train the system very deep, combine the benefits of RNN and CNN to
find the most important factor and make latent representation. Highway Networks
allow us to enhance the traditional RNN and CNN pipeline by learning more
sophisticated semantic structural representations. Using this method we can
also overcome the cold start problem and learn latent features over large
sequences of text.

### Title: CPGNet: Cascade Point-Grid Fusion Network for Real-Time LiDAR Semantic Segmentation
* Paper ID: 2204.09914v1
* Paper URL: [http://arxiv.org/abs/2204.09914v1](http://arxiv.org/abs/2204.09914v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: LiDAR semantic segmentation essential for advanced autonomous driving is
required to be accurate, fast, and easy-deployed on mobile platforms. Previous
point-based or sparse voxel-based methods are far away from real-time
applications since time-consuming neighbor searching or sparse 3D convolution
are employed. Recent 2D projection-based methods, including range view and
multi-view fusion, can run in real time, but suffer from lower accuracy due to
information loss during the 2D projection. Besides, to improve the performance,
previous methods usually adopt test time augmentation (TTA), which further
slows down the inference process. To achieve a better speed-accuracy trade-off,
we propose Cascade Point-Grid Fusion Network (CPGNet), which ensures both
effectiveness and efficiency mainly by the following two techniques: 1) the
novel Point-Grid (PG) fusion block extracts semantic features mainly on the 2D
projected grid for efficiency, while summarizes both 2D and 3D features on 3D
point for minimal information loss; 2) the proposed transformation consistency
loss narrows the gap between the single-time model inference and TTA. The
experiments on the SemanticKITTI and nuScenes benchmarks demonstrate that the
CPGNet without ensemble models or TTA is comparable with the state-of-the-art
RPVNet, while it runs 4.7 times faster.

### Title: MAP-SNN: Mapping Spike Activities with Multiplicity, Adaptability, and Plasticity into Bio-Plausible Spiking Neural Networks
* Paper ID: 2204.09893v1
* Paper URL: [http://arxiv.org/abs/2204.09893v1](http://arxiv.org/abs/2204.09893v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Spiking Neural Network (SNN) is considered more biologically realistic and
power-efficient as it imitates the fundamental mechanism of the human brain.
Recently, backpropagation (BP) based SNN learning algorithms that utilize deep
learning frameworks have achieved good performance. However,
bio-interpretability is partially neglected in those BP-based algorithms.
Toward bio-plausible BP-based SNNs, we consider three properties in modeling
spike activities: Multiplicity, Adaptability, and Plasticity (MAP). In terms of
multiplicity, we propose a Multiple-Spike Pattern (MSP) with multiple spike
transmission to strengthen model robustness in discrete time-iteration. To
realize adaptability, we adopt Spike Frequency Adaption (SFA) under MSP to
decrease spike activities for improved efficiency. For plasticity, we propose a
trainable convolutional synapse that models spike response current to enhance
the diversity of spiking neurons for temporal feature extraction. The proposed
SNN model achieves competitive performances on neuromorphic datasets: N-MNIST
and SHD. Furthermore, experimental results demonstrate that the proposed three
aspects are significant to iterative robustness, spike efficiency, and temporal
feature extraction capability of spike activities. In summary, this work
proposes a feasible scheme for bio-inspired spike activities with MAP, offering
a new neuromorphic perspective to embed biological characteristics into spiking
neural networks.

### Title: Layer-wise Fast Adaptation for End-to-End Multi-Accent Speech Recognition
* Paper ID: 2204.09883v1
* Paper URL: [http://arxiv.org/abs/2204.09883v1](http://arxiv.org/abs/2204.09883v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Accent variability has posed a huge challenge to automatic speech
recognition~(ASR) modeling. Although one-hot accent vector based adaptation
systems are commonly used, they require prior knowledge about the target accent
and cannot handle unseen accents. Furthermore, simply concatenating accent
embeddings does not make good use of accent knowledge, which has limited
improvements. In this work, we aim to tackle these problems with a novel
layer-wise adaptation structure injected into the E2E ASR model encoder. The
adapter layer encodes an arbitrary accent in the accent space and assists the
ASR model in recognizing accented speech. Given an utterance, the adaptation
structure extracts the corresponding accent information and transforms the
input acoustic feature into an accent-related feature through the linear
combination of all accent bases. We further explore the injection position of
the adaptation layer, the number of accent bases, and different types of accent
bases to achieve better accent adaptation. Experimental results show that the
proposed adaptation structure brings 12\% and 10\% relative word error
rate~(WER) reduction on the AESRC2020 accent dataset and the Librispeech
dataset, respectively, compared to the baseline.

### Title: Exploring a Fine-Grained Multiscale Method for Cross-Modal Remote Sensing Image Retrieval
* Paper ID: 2204.09868v1
* Paper URL: [http://arxiv.org/abs/2204.09868v1](http://arxiv.org/abs/2204.09868v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/xiaoyuan1996/AMFMN](https://github.com/xiaoyuan1996/AMFMN)
* Summary: Remote sensing (RS) cross-modal text-image retrieval has attracted extensive
attention for its advantages of flexible input and efficient query. However,
traditional methods ignore the characteristics of multi-scale and redundant
targets in RS image, leading to the degradation of retrieval accuracy. To cope
with the problem of multi-scale scarcity and target redundancy in RS multimodal
retrieval task, we come up with a novel asymmetric multimodal feature matching
network (AMFMN). Our model adapts to multi-scale feature inputs, favors
multi-source retrieval methods, and can dynamically filter redundant features.
AMFMN employs the multi-scale visual self-attention (MVSA) module to extract
the salient features of RS image and utilizes visual features to guide the text
representation. Furthermore, to alleviate the positive samples ambiguity caused
by the strong intraclass similarity in RS image, we propose a triplet loss
function with dynamic variable margin based on prior similarity of sample
pairs. Finally, unlike the traditional RS image-text dataset with coarse text
and higher intraclass similarity, we construct a fine-grained and more
challenging Remote sensing Image-Text Match dataset (RSITMD), which supports RS
image retrieval through keywords and sentence separately and jointly.
Experiments on four RS text-image datasets demonstrate that the proposed model
can achieve state-of-the-art performance in cross-modal RS text-image retrieval
task.

### Title: Remote Sensing Cross-Modal Text-Image Retrieval Based on Global and Local Information
* Paper ID: 2204.09860v1
* Paper URL: [http://arxiv.org/abs/2204.09860v1](http://arxiv.org/abs/2204.09860v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/xiaoyuan1996/galr](https://github.com/xiaoyuan1996/galr)
* Summary: Cross-modal remote sensing text-image retrieval (RSCTIR) has recently become
an urgent research hotspot due to its ability of enabling fast and flexible
information extraction on remote sensing (RS) images. However, current RSCTIR
methods mainly focus on global features of RS images, which leads to the
neglect of local features that reflect target relationships and saliency. In
this article, we first propose a novel RSCTIR framework based on global and
local information (GaLR), and design a multi-level information dynamic fusion
(MIDF) module to efficaciously integrate features of different levels. MIDF
leverages local information to correct global information, utilizes global
information to supplement local information, and uses the dynamic addition of
the two to generate prominent visual representation. To alleviate the pressure
of the redundant targets on the graph convolution network (GCN) and to improve
the model s attention on salient instances during modeling local features, the
de-noised representation matrix and the enhanced adjacency matrix (DREA) are
devised to assist GCN in producing superior local representations. DREA not
only filters out redundant features with high similarity, but also obtains more
powerful local features by enhancing the features of prominent objects.
Finally, to make full use of the information in the similarity matrix during
inference, we come up with a plug-and-play multivariate rerank (MR) algorithm.
The algorithm utilizes the k nearest neighbors of the retrieval results to
perform a reverse search, and improves the performance by combining multiple
components of bidirectional retrieval. Extensive experiments on public datasets
strongly demonstrate the state-of-the-art performance of GaLR methods on the
RSCTIR task. The code of GaLR method, MR algorithm, and corresponding files
have been made available at https://github.com/xiaoyuan1996/GaLR .

### Title: Self-Supervised Learning to Guide Scientifically Relevant Categorization of Martian Terrain Images
* Paper ID: 2204.09854v1
* Paper URL: [http://arxiv.org/abs/2204.09854v1](http://arxiv.org/abs/2204.09854v1)
* Updated Date: 2022-04-21
* Code URL: [https://github.com/tejaspanambur/mastcam](https://github.com/tejaspanambur/mastcam)
* Summary: Automatic terrain recognition in Mars rover images is an important problem
not just for navigation, but for scientists interested in studying rock types,
and by extension, conditions of the ancient Martian paleoclimate and
habitability. Existing approaches to label Martian terrain either involve the
use of non-expert annotators producing taxonomies of limited granularity (e.g.
soil, sand, bedrock, float rock, etc.), or rely on generic class discovery
approaches that tend to produce perceptual classes such as rover parts and
landscape, which are irrelevant to geologic analysis. Expert-labeled datasets
containing granular geological/geomorphological terrain categories are rare or
inaccessible to public, and sometimes require the extraction of relevant
categorical information from complex annotations. In order to facilitate the
creation of a dataset with detailed terrain categories, we present a
self-supervised method that can cluster sedimentary textures in images captured
from the Mast camera onboard the Curiosity rover (Mars Science Laboratory). We
then present a qualitative analysis of these clusters and describe their
geologic significance via the creation of a set of granular terrain categories.
The precision and geologic validation of these automatically discovered
clusters suggest that our methods are promising for the rapid classification of
important geologic features and will therefore facilitate our long-term goal of
producing a large, granular, and publicly available dataset for Mars terrain
recognition.

### Title: A Masked Image Reconstruction Network for Document-level Relation Extraction
* Paper ID: 2204.09851v1
* Paper URL: [http://arxiv.org/abs/2204.09851v1](http://arxiv.org/abs/2204.09851v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Document-level relation extraction aims to extract relations among entities
within a document. Compared with its sentence-level counterpart, Document-level
relation extraction requires inference over multiple sentences to extract
complex relational triples. Previous research normally complete reasoning
through information propagation on the mention-level or entity-level
document-graphs, regardless of the correlations between the relationships. In
this paper, we propose a novel Document-level Relation Extraction model based
on a Masked Image Reconstruction network (DRE-MIR), which models inference as a
masked image reconstruction problem to capture the correlations between
relationships. Specifically, we first leverage an encoder module to get the
features of entities and construct the entity-pair matrix based on the
features. After that, we look on the entity-pair matrix as an image and then
randomly mask it and restore it through an inference module to capture the
correlations between the relationships. We evaluate our model on three public
document-level relation extraction datasets, i.e. DocRED, CDR, and GDA.
Experimental results demonstrate that our model achieves state-of-the-art
performance on these three datasets and has excellent robustness against the
noises during the inference process.

### Title: Mining Root Cause Knowledge from Cloud Service Incident Investigations for AIOps
* Paper ID: 2204.11598v1
* Paper URL: [http://arxiv.org/abs/2204.11598v1](http://arxiv.org/abs/2204.11598v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Root Cause Analysis (RCA) of any service-disrupting incident is one of the
most critical as well as complex tasks in IT processes, especially for cloud
industry leaders like Salesforce. Typically RCA investigation leverages
data-sources like application error logs or service call traces. However a rich
goldmine of root cause information is also hidden in the natural language
documentation of the past incidents investigations by domain experts. This is
generally termed as Problem Review Board (PRB) Data which constitute a core
component of IT Incident Management. However, owing to the raw unstructured
nature of PRBs, such root cause knowledge is not directly reusable by manual or
automated pipelines for RCA of new incidents. This motivates us to leverage
this widely-available data-source to build an Incident Causation Analysis (ICA)
engine, using SoTA neural NLP techniques to extract targeted information and
construct a structured Causal Knowledge Graph from PRB documents. ICA forms the
backbone of a simple-yet-effective Retrieval based RCA for new incidents,
through an Information Retrieval system to search and rank past incidents and
detect likely root causes from them, given the incident symptom. In this work,
we present ICA and the downstream Incident Search and Retrieval based RCA
pipeline, built at Salesforce, over 2K documented cloud service incident
investigations collected over a few years. We also establish the effectiveness
of ICA and the downstream tasks through various quantitative benchmarks,
qualitative analysis as well as domain expert's validation and real incident
case studies after deployment.

### Title: Multiscale Analysis for Improving Texture Classification
* Paper ID: 2204.09841v1
* Paper URL: [http://arxiv.org/abs/2204.09841v1](http://arxiv.org/abs/2204.09841v1)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: Information from an image occurs over multiple and distinct spatial scales.
Image pyramid multiresolution representations are a useful data structure for
image analysis and manipulation over a spectrum of spatial scales. This paper
employs the Gaussian-Laplacian pyramid to treat different spatial frequency
bands of a texture separately. First, we generate three images corresponding to
three levels of the Gaussian-Laplacian pyramid for an input image to capture
intrinsic details. Then we aggregate features extracted from gray and color
texture images using bio-inspired texture descriptors, information-theoretic
measures, gray-level co-occurrence matrix features, and Haralick statistical
features into a single feature vector. Such an aggregation aims at producing
features that characterize textures to their maximum extent, unlike employing
each descriptor separately, which may lose some relevant textural information
and reduce the classification performance. The experimental results on texture
and histopathologic image datasets have shown the advantages of the proposed
method compared to state-of-the-art approaches. Such findings emphasize the
importance of multiscale image analysis and corroborate that the descriptors
mentioned above are complementary.

### Title: Localizing narrow Fe K$Î±$ emission within bright AGN
* Paper ID: 2204.09469v2
* Paper URL: [http://arxiv.org/abs/2204.09469v2](http://arxiv.org/abs/2204.09469v2)
* Updated Date: 2022-04-21
* Code URL: null
* Summary: The 6.4 keV Fe Ka emission line is a ubiquitous feature in X-ray spectra of
AGN, and its properties track the interaction between the variable primary
X-ray continuum and the surrounding structure from which it arises. We clarify
the nature and origin of the narrow Fe Ka emission using X-ray spectral,
timing, and imaging constraints, plus possible correlations to AGN and host
galaxy properties, for 38 bright nearby AGN ($z<0.5$) from the BAT AGN
Spectroscopic Survey. Modeling Chandra and XMM-Newton spectra, we computed line
full-width half-maxima (FWHMs) and constructed Fe Ka line and 2-10 keV
continuum light curves. The FWHM provides one estimate of the Fe Ka emitting
region size, RFeKa, assuming virial motion. A second estimate comes from
comparing the degree of correlation between the variability of the continuum
and line-only light curves, compared to simulated light curves. Finally, we
extracted Chandra radial profiles to place upper limits on RFeKa. We found that
for 90% (21/24) of AGN with FWHM measurements, RFeKa is smaller than the
fiducial dust sublimation radius, Rsub. Despite a wide range of variability
properties, the constraints on the Fe Ka photon reprocessor size independently
confirm that RFeKa is smaller than Rsub in 83% of AGN. Finally, the imaging
analysis yields loose upper limits for all but two sources; notably, the
Circinus Galaxy and NGC 1068 show significant but subdominant extended Fe Ka
emission out to $\sim$100 and $\sim$800 pc, respectively. Based on independent
constraints, we conclude that the majority of the narrow Fe Ka emission in
typical AGN predominantly arises from regions smaller than and presumably
inside Rsub, and thus it is associated either with the outer broad line region
or outer accretion disk. However, the large diversity of continuum and narrow
Fe Ka variability properties are not easily accommodated by a universal
scenario.

