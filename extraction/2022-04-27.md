### Title: An Adversarial Attack Analysis on Malicious Advertisement URL Detection Framework
* Paper ID: 2204.13172v1
* Paper URL: [http://arxiv.org/abs/2204.13172v1](http://arxiv.org/abs/2204.13172v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Malicious advertisement URLs pose a security risk since they are the source
of cyber-attacks, and the need to address this issue is growing in both
industry and academia. Generally, the attacker delivers an attack vector to the
user by means of an email, an advertisement link or any other means of
communication and directs them to a malicious website to steal sensitive
information and to defraud them. Existing malicious URL detection techniques
are limited and to handle unseen features as well as generalize to test data.
In this study, we extract a novel set of lexical and web-scrapped features and
employ machine learning technique to set up system for fraudulent advertisement
URLs detection. The combination set of six different kinds of features
precisely overcome the obfuscation in fraudulent URL classification. Based on
different statistical properties, we use twelve different formatted datasets
for detection, prediction and classification task. We extend our prediction
analysis for mismatched and unlabelled datasets. For this framework, we analyze
the performance of four machine learning techniques: Random Forest, Gradient
Boost, XGBoost and AdaBoost in the detection part. With our proposed method, we
can achieve a false negative rate as low as 0.0037 while maintaining high
accuracy of 99.63%. Moreover, we devise a novel unsupervised technique for data
clustering using K- Means algorithm for the visual analysis. This paper
analyses the vulnerability of decision tree-based models using the limited
knowledge attack scenario. We considered the exploratory attack and implemented
Zeroth Order Optimization adversarial attack on the detection models.

### Title: Diffraction of an Off-axis Vector-Beam by a Tilted Aperture
* Paper ID: 2204.13081v1
* Paper URL: [http://arxiv.org/abs/2204.13081v1](http://arxiv.org/abs/2204.13081v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Manifestations of orbital angular momentum induced effects in the diffraction
of a radially polarized vector beam by an off-axis tilted aperture are studied
both experimentally and theoretically. Experiments were carried out to extract
the degree of circular polarization, which was shown to be proportional to the
on-axis component of the spin angular momentum density. We report a clear
separation of the regions of dominance of the right and left circular
polarizations associated with positive and negative topological charges
respectively, which is reminiscent of the standard vortex-induced transverse
shift, albeit in the diffraction scenario. The experimental results are
supported by model simulations and the agreement is quite satisfactory. The
results are useful to appreciate the orbit-orbit related effects due to
unavoidable misalignment problems (especially for vortex beams).

### Title: Refined nuclear magnetic dipole moment of rhenium: $^{185}$Re and $^{187}$Re
* Paper ID: 2204.13015v1
* Paper URL: [http://arxiv.org/abs/2204.13015v1](http://arxiv.org/abs/2204.13015v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: The refined values of the magnetic dipole moments of $^{185}$Re and
$^{187}$Re nuclei are obtained. For this, we perform a combined relativistic
coupled cluster and density functional theory calculation of the shielding
constant for the ReO$_4^-$ anion. In this calculation, we explicitly include
the effect of the finite nuclear magnetization distribution in the
single-particle nuclear model using the Woods-Saxon potential for the valence
nucleon. By combining the obtained value of the shielding constant
$\sigma=4142(389)$ ppm with the available experimental nuclear magnetic
resonance data we obtain the values: $\mu(^{185}{\rm Re})=3.1564(3)(12) \mu_N,
\mu(^{187}{\rm Re})=3.1887(3)(12) \mu_N$, where the first uncertainty is the
experimental one and second is due to theory. The refined values of magnetic
moments are in disagreement with the tabulated values, $\mu(^{185}{\rm
Re})=3.1871(3) \mu_N, \mu(^{187}{\rm Re})=3.2197(3) \mu_N$, which were obtained
using the shielding constant value calculated for the atomic cation Re$^{7+}$
rather than the molecular anion. The updated values of the nuclear magnetic
moments resolve the disagreement between theoretical predictions of the
hyperfine structure of H-like rhenium ions which were based on the tabulated
magnetic moment values and available experimental measurements. Using these
experimental data we also extract the value of the parameter of nuclear
magnetization distribution introduced in [J. Chem. Phys. \textbf{153}, 114114
(2020)], which is required to predict hyperfine structure constants of rhenium
compounds.

### Title: How much gallium do we need for a p-type Cu(In,Ga)Se2?
* Paper ID: 2204.12973v1
* Paper URL: [http://arxiv.org/abs/2204.12973v1](http://arxiv.org/abs/2204.12973v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Doping in the chalcopyrite Cu(In,Ga)Se2 is determined by intrinsic point
defects. In the ternary CuInSe2, both N-type and P-type conductivity can be
obtained depending on the growth conditions and stoichiometry: N-type is
obtained when grown Cu-poor, Se-poor and alkali-free. CuGaSe2, on the other
hand, is found to be always a P-type semiconductor that seems to resist all
kinds of N-type doping no matter whether it comes from native defects or
extrinsic impurities. In this contribution, we study the N-to-P transition in
Cu-poor Cu(In,Ga)Se2 single crystals in dependence of the gallium content. Our
results show that Cu(In,Ga)Se2 can still be grown as an N-type semiconductor
until the gallium content reaches the critical concentration of 15-19%, where
the N-to-P transition occurs. Furthermore, trends in the Seebeck coefficient
and activation energies extracted from temperature-dependent conductivity
measurements, demonstrate that the carrier concentration drops by around two
orders of magnitude near the transition concentration. Our proposed model
explains the N-to-P transition based on the differences in formation energies
of donor and acceptor defects caused by the addition of gallium.

### Title: Accelerating Materials-Space Exploration by Mapping Materials Properties via Artificial Intelligence: The Case of the Lattice Thermal Conductivity
* Paper ID: 2204.12968v1
* Paper URL: [http://arxiv.org/abs/2204.12968v1](http://arxiv.org/abs/2204.12968v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Accurate artificial-intelligence models are key to accelerate the discovery
of new functional materials with optimal properties for various applications.
Examples include superconductivity, catalysis, and thermoelectricity.
Advancements in this field are often hindered by the scarcity and quality of
available data and the significant effort required to acquire new data. For
such applications, reliable surrogate models that help guide materials space
exploration using easily accessible materials properties are urgently needed.
Here, we present a general, data-driven framework that provides quantitative
predictions as well as qualitative rules for steering data creation for all
datasets via a combination of symbolic regression and sensitivity analysis. We
demonstrate the power of the framework by generating an accurate analytic model
for the lattice thermal conductivity using only 75 experimentally measured
values. By extracting the most influential material properties from this model,
we are then able to hierarchically screen 732 materials and find 80
ultra-insulating materials.

### Title: Towards assessing agricultural land suitability with causal machine learning
* Paper ID: 2204.12956v1
* Paper URL: [http://arxiv.org/abs/2204.12956v1](http://arxiv.org/abs/2204.12956v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Understanding the suitability of agricultural land for applying specific
management practices is of great importance for sustainable and resilient
agriculture against climate change. Recent developments in the field of causal
machine learning enable the estimation of intervention impacts on an outcome of
interest, for samples described by a set of observed characteristics. We
introduce an extensible data-driven framework that leverages earth observations
and frames agricultural land suitability as a geospatial impact assessment
problem, where the estimated effects of agricultural practices on
agroecosystems serve as a land suitability score and guide decision making. We
formulate this as a causal machine learning task and discuss how this approach
can be used for agricultural planning in a changing climate. Specifically, we
extract the agricultural management practices of "crop rotation" and "landscape
crop diversity" from crop type maps, account for climate and land use data, and
use double machine learning to estimate their heterogeneous effect on Net
Primary Productivity (NPP), within the Flanders region of Belgium from 2010 to
2020. We find that the effect of crop rotation was insignificant, while
landscape crop diversity had a small negative effect on NPP. Finally, we
observe considerable effect heterogeneity in space for both practices and
analyze it.

### Title: Search for Higgs boson decays to a Z boson and a photon in proton-proton collisions at $\sqrt{s}$ = 13 TeV
* Paper ID: 2204.12945v1
* Paper URL: [http://arxiv.org/abs/2204.12945v1](http://arxiv.org/abs/2204.12945v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Results are presented from a search for the Higgs boson decay
H$\to$Z$\gamma$, where Z$\to\ell^+\ell^-$ with $\ell$ = e or $\mu$. The search
is performed using a sample of proton-proton (pp) collision data at a
center-of-mass energy of 13 TeV, recorded by the CMS experiment at the LHC,
corresponding to an integrated luminosity of 138 fb$^{-1}$. Events are assigned
to mutually exclusive categories, which exploit differences in both event
topology and kinematics of distinct Higgs production mechanisms to enhance
signal sensitivity. The signal strength $\mu$, defined as the product of the
cross section and the branching fraction
[$\sigma($pp$\to$H$)\mathcal{B}($H$\to$Z$\gamma)$] relative to the standard
model prediction, is extracted from a simultaneous fit to the
$\ell^+\ell^-\gamma$ invariant mass distributions in all categories and is
found to be $\mu$=2.4$\pm$0.9 for a Higgs boson mass of 125.38 GeV. The
statistical significance of the observed excess of events is 2.7 standard
deviations. This measurement corresponds to
$\sigma($pp$\to$H$)\mathcal{B}($H$\to$Z$\gamma)$ = 0.21$\pm$0.08 pb. The
observed (expected) upper limit at 95% confidence level on $\mu$ is 4.1 (1.8).
The ratio of branching fractions
$\mathcal{B}($H$\to$Z$\gamma)/\mathcal{B}($H$\to\gamma\gamma)$ is measured to
be 1.5$^{+0.7}_{-0.6}$, which agrees with the standard model prediction of 0.69
$\pm$ 0.04 at the 1.5 standard deviation level.

### Title: Towards A COLREGs Compliant Autonomous Surface Vessel in a Constrained Channel
* Paper ID: 2204.12906v1
* Paper URL: [http://arxiv.org/abs/2204.12906v1](http://arxiv.org/abs/2204.12906v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: In this paper, we look at the role of autonomous navigation in the maritime
domain. Specifically, we examine how an Autonomous Surface Vessel(ASV) can
achieve obstacle avoidance based on the Convention on the International
Regulations for Preventing Collisions at Sea (1972), or COLREGs, in real-world
environments. Our ASV is equipped with a broadband marine radar, an Inertial
Navigation System (INS), and uses official Electronic Navigational Charts
(ENC). These sensors are used to provide situational awareness and, in series
of well-defined steps, we can exclude land objects from the radar data, extract
tracks associated with moving vessels within range of the radar, and then use a
Kalman Filter to track and predict the motion of other moving vessels in the
vicinity. A Constant Velocity model for the Kalman Filter allows us to solve
the data association to build a consistent model between successive radar
scans. We account for multiple COLREGs situations based on the predicted
relative motion. Finally, an efficient path planning algorithm is presented to
find a path and publish waypoints to perform real-time COLREGs compliant
autonomous navigation within highly constrained environments. We demonstrate
the results of our framework with operational results collected over the course
of a 3.4 nautical mile mission on the Charles River in Boston in which the ASV
encountered and successfully navigated multiple scenarios and encounters with
other moving vessels at close quarters.

### Title: Global Trajectory Helps Person Retrieval in a Camera Network
* Paper ID: 2204.12900v1
* Paper URL: [http://arxiv.org/abs/2204.12900v1](http://arxiv.org/abs/2204.12900v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: We are concerned about retrieving a query person from the videos taken by a
non-overlapping camera network. Existing methods often rely on pure visual
matching or consider temporal constraint, but ignore the spatial information of
the camera network. To address this problem, we propose a framework of person
retrieval based on cross-camera trajectory generation which integrates both
temporal and spatial information. To obtain the pedestrian trajectories, we
propose a new cross-camera spatio-temporal model that integrates the walking
habits of pedestrians and the path layout between cameras, forming a joint
probability distribution. Such a spatio-temporal model among a camera network
can be specified using sparsely sampled pedestrian data. Based on the
spatio-temporal model, the cross-camera trajectories of a specific pedestrian
can be extracted by the conditional random field model, and further optimized
by the restricted nonnegative matrix factorization. Finally, a trajectory
re-ranking technology is proposed to improve the person retrieval results. To
verify the effectiveness of our approach, we build the first dataset of
cross-camera pedestrian trajectories over an actual monitoring scenario, namely
the Person Trajectory Dataset. Extensive experiments have verified the
effectiveness and robustness of the proposed method.

### Title: Improving constraints on gluon spin-momentum correlations in transversely polarized protons via midrapidity open-heavy-flavor electrons in $p^{\uparrow}+p$ collisions at $\sqrt{s}=200$ GeV
* Paper ID: 2204.12899v1
* Paper URL: [http://arxiv.org/abs/2204.12899v1](http://arxiv.org/abs/2204.12899v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Polarized proton-proton collisions provide leading-order access to gluons,
presenting an opportunity to constrain gluon spin-momentum correlations within
transversely polarized protons and enhance our understanding of the
three-dimensional structure of the proton. Midrapidity open-heavy-flavor
production at $\sqrt{s}=200$ GeV is dominated by gluon-gluon fusion, providing
heightened sensitivity to gluon dynamics relative to other production channels.
Transverse single-spin asymmetries of electrons and positrons from heavy-flavor
hadron decays are measured at midrapidity using the PHENIX detector at the
Relativistic Heavy Ion Collider. These charge-separated measurements are
sensitive to gluon correlators that can in principle be related to gluon
orbital angular momentum via model calculations. Explicit constraints on gluon
correlators are extracted for two separate models, one of which had not been
constrained previously.

### Title: 20 years of ordinal patterns: Perspectives and challenges
* Paper ID: 2204.12883v1
* Paper URL: [http://arxiv.org/abs/2204.12883v1](http://arxiv.org/abs/2204.12883v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: In 2002, in a seminal article, Christoph Bandt and Bernd Pompe proposed a new
methodology for the analysis of complex time series, now known as Ordinal
Analysis. The ordinal methodology is based on the computation of symbols (known
as ordinal patterns) which are defined in terms of the temporal ordering of
data points in a time series, and whose probabilities are known as ordinal
probabilities. With the ordinal probabilities, the Shannon entropy can be
calculated, which is the permutation entropy. Since it was proposed, the
ordinal method has found applications in fields as diverse as biomedicine and
climatology. However, some properties of ordinal probabilities are still not
fully understood, and how to combine the ordinal approach of feature extraction
with machine learning techniques for model identification, time series
classification or forecasting remains a challenge. The objective of this
perspective article is to present some recent advances and to discuss some open
problems.

### Title: The Revisiting Problem in Simultaneous Localization and Mapping: A Survey on Visual Loop Closure Detection
* Paper ID: 2204.12831v1
* Paper URL: [http://arxiv.org/abs/2204.12831v1](http://arxiv.org/abs/2204.12831v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Where am I? This is one of the most critical questions that any intelligent
system should answer to decide whether it navigates to a previously visited
area. This problem has long been acknowledged for its challenging nature in
simultaneous localization and mapping (SLAM), wherein the robot needs to
correctly associate the incoming sensory data to the database allowing
consistent map generation. The significant advances in computer vision achieved
over the last 20 years, the increased computational power, and the growing
demand for long-term exploration contributed to efficiently performing such a
complex task with inexpensive perception sensors. In this article, visual loop
closure detection, which formulates a solution based solely on appearance input
data, is surveyed. We start by briefly introducing place recognition and SLAM
concepts in robotics. Then, we describe a loop closure detection system's
structure, covering an extensive collection of topics, including the feature
extraction, the environment representation, the decision-making step, and the
evaluation process. We conclude by discussing open and new research challenges,
particularly concerning the robustness in dynamic environments, the
computational complexity, and scalability in long-term operations. The article
aims to serve as a tutorial and a position paper for newcomers to visual loop
closure detection.

### Title: SkillSpan: Hard and Soft Skill Extraction from English Job Postings
* Paper ID: 2204.12811v1
* Paper URL: [http://arxiv.org/abs/2204.12811v1](http://arxiv.org/abs/2204.12811v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Skill Extraction (SE) is an important and widely-studied task useful to gain
insights into labor market dynamics. However, there is a lacuna of datasets and
annotation guidelines; available datasets are few and contain crowd-sourced
labels on the span-level or labels from a predefined skill inventory. To
address this gap, we introduce SKILLSPAN, a novel SE dataset consisting of
14.5K sentences and over 12.5K annotated spans. We release its respective
guidelines created over three different sources annotated for hard and soft
skills by domain experts. We introduce a BERT baseline (Devlin et al., 2019).
To improve upon this baseline, we experiment with language models that are
optimized for long spans (Joshi et al., 2020; Beltagy et al., 2020), continuous
pre-training on the job posting domain (Han and Eisenstein, 2019; Gururangan et
al., 2020), and multi-task learning (Caruana, 1997). Our results show that the
domain-adapted models significantly outperform their non-adapted counterparts,
and single-task outperforms multi-task learning.

### Title: Worst-Case Dynamic Power Distribution Network Noise Prediction Using Convolutional Neural Network
* Paper ID: 2204.13109v1
* Paper URL: [http://arxiv.org/abs/2204.13109v1](http://arxiv.org/abs/2204.13109v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Worst-case dynamic PDN noise analysis is an essential step in PDN sign-off to
ensure the performance and reliability of chips. However, with the growing PDN
size and increasing scenarios to be validated, it becomes very time- and
resource-consuming to conduct full-stack PDN simulation to check the worst-case
noise for different test vectors. Recently, various works have proposed machine
learning based methods for supply noise prediction, many of which still suffer
from large training overhead, inefficiency, or non-scalability. Thus, this
paper proposed an efficient and scalable framework for the worst-case dynamic
PDN noise prediction. The framework first reduces the spatial and temporal
redundancy in the PDN and input current vector, and then employs efficient
feature extraction as well as a novel convolutional neural network architecture
to predict the worst-case dynamic PDN noise. Experimental results show that the
proposed framework consistently outperforms the commercial tool and the
state-of-the-art machine learning method with only 0.63-1.02% mean relative
error and 25-69$\times$ speedup.

### Title: Optical microscope based universal parameter for identifying layer number in two-dimensional materials
* Paper ID: 2204.12745v1
* Paper URL: [http://arxiv.org/abs/2204.12745v1](http://arxiv.org/abs/2204.12745v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Optical contrast is the most common preliminary method to identify layer
number of two-dimensional (2D) materials, but is seldom used as a confirmatory
technique. We explain the reason for variation of optical contrast between
imaging systems. We introduce a universal method to quantify the layer number
using the RGB (red-green-blue) and RAW optical images. For RGB images, the
slope of 2D flake (MoS2, WSe2, graphene) intensity vs. substrate intensity is
extracted from optical images with varying lamp power. The intensity slope
identifies layer number and is system independent. For RAW images, intensity
slopes and intensity ratios are completely system and intensity independent.
Intensity slope (for RGB) and intensity ratio (for RAW) are thus universal
parameters for identifying layer number. A Fresnel-reflectance-based optical
model provides an excellent match with experiments. Further, we have created a
MATLAB-based graphical user interface that can identify layer number rapidly.
This technique is expected to accelerate the preparation of heterostructures,
and fulfil a prolonged need for universal optical contrast method.

### Title: Analysis of the data from photoelectric gas polarimeters
* Paper ID: 2204.12739v1
* Paper URL: [http://arxiv.org/abs/2204.12739v1](http://arxiv.org/abs/2204.12739v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: We review the tools and procedures for the analysis of the data collected by
X-ray photoelectric gas polarimeters, like the ones on-board the Imaging X-ray
Polarimetry Explorer (IXPE). Although many of such tools are in principle
common with polarimeters working at other energy bands, the peculiar
characteristics and performance of these devices require a specific approach.
We will start from the analysis of the raw data read-out from this kind of
instruments, that is, the image of the track of the photoelectron. We will
briefly present how such images are processed with highly-specialized
algorithms to extract all the information collected by the instrument. These
include energy, time of arrival and, possibly, absorption point of the photon,
in addition to the initial direction of emission of the photoelectron. The last
is the quantity relevant for polarimetry, and we will present different methods
to obtain the polarization degree and angle from it. A simple method, used
extensively especially during the development phase of X-ray photoelectric gas
polarimeters, is based on the construction and fitting of the azimuthal
distribution of the photoelectrons. We will discuss that there are several
reasons to prefer an analysis based on Stokes parameters, especially when one
wants to analyze measurements of real, i.e., not laboratory, sources. These are
quantities commonly used at all wavelengths because they are additive, and then
operations like background subtraction or the application of calibration are
trivial to apply. We will summarize how Stokes parameters can be used to adapt
current spectroscopy software based on forward folding fitting to perform
spectro-polarimetry. Moreover, we will derive how to properly associate the
statistical uncertainty on a polarimetry measurement and the relation with
another statistical indicator, which is in the minimum detectable polarization.

### Title: A Multi-Head Convolutional Neural Network With Multi-path Attention improves Image Denoising
* Paper ID: 2204.12736v1
* Paper URL: [http://arxiv.org/abs/2204.12736v1](http://arxiv.org/abs/2204.12736v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Recently, convolutional neural networks (CNNs) and attention mechanisms have
been widely used in image denoising and achieved satisfactory performance.
However, the previous works mostly use a single head to receive the noisy
image, limiting the richness of extracted features. Therefore, a novel CNN with
multiple heads (MH) named MHCNN is proposed in this paper, whose heads will
receive the input images rotated by different rotation angles. MH makes MHCNN
simultaneously utilize features of rotated images to remove noise. We also
present a novel multi-path attention mechanism (MPA) to integrate these
features effectively. Unlike previous attention mechanisms that handle
pixel-level, channel-level, and patch-level features, MPA focuses on features
at the image level. Experiments show MHCNN surpasses other state-of-the-art CNN
models on additive white Gaussian noise (AWGN) denoising and real-world image
denoising. Its peak signal-to-noise ratio (PSNR) results are higher than other
networks, such as DnCNN, BRDNet, RIDNet, PAN-Net, and CSANN. It is also
demonstrated that the proposed MH with MPA mechanism can be used as a pluggable
component.

### Title: CREER: A Large-Scale Corpus for Relation Extraction and Entity Recognition
* Paper ID: 2204.12710v1
* Paper URL: [http://arxiv.org/abs/2204.12710v1](http://arxiv.org/abs/2204.12710v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: We describe the design and use of the CREER dataset, a large corpus annotated
with rich English grammar and semantic attributes. The CREER dataset uses the
Stanford CoreNLP Annotator to capture rich language structures from Wikipedia
plain text. This dataset follows widely used linguistic and semantic
annotations so that it can be used for not only most natural language
processing tasks but also scaling the dataset. This large supervised dataset
can serve as the basis for improving the performance of NLP tasks in the
future.

### Title: Heterogeneous Ensemble Knowledge Transfer for Training Large Models in Federated Learning
* Paper ID: 2204.12703v1
* Paper URL: [http://arxiv.org/abs/2204.12703v1](http://arxiv.org/abs/2204.12703v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Federated learning (FL) enables edge-devices to collaboratively learn a model
without disclosing their private data to a central aggregating server. Most
existing FL algorithms require models of identical architecture to be deployed
across the clients and server, making it infeasible to train large models due
to clients' limited system resources. In this work, we propose a novel ensemble
knowledge transfer method named Fed-ET in which small models (different in
architecture) are trained on clients, and used to train a larger model at the
server. Unlike in conventional ensemble learning, in FL the ensemble can be
trained on clients' highly heterogeneous data. Cognizant of this property,
Fed-ET uses a weighted consensus distillation scheme with diversity
regularization that efficiently extracts reliable consensus from the ensemble
while improving generalization by exploiting the diversity within the ensemble.
We show the generalization bound for the ensemble of weighted models trained on
heterogeneous datasets that supports the intuition of Fed-ET. Our experiments
on image and language tasks show that Fed-ET significantly outperforms other
state-of-the-art FL algorithms with fewer communicated parameters, and is also
robust against high data-heterogeneity.

### Title: Grasping the Arrow of Time from the Singularity: Decoding Micromotion in Low-dimensional Latent Spaces from StyleGAN
* Paper ID: 2204.12696v1
* Paper URL: [http://arxiv.org/abs/2204.12696v1](http://arxiv.org/abs/2204.12696v1)
* Updated Date: 2022-04-27
* Code URL: [https://github.com/wuqiuche/micromotion-stylegan](https://github.com/wuqiuche/micromotion-stylegan)
* Summary: The disentanglement of StyleGAN latent space has paved the way for realistic
and controllable image editing, but does StyleGAN know anything about temporal
motion, as it was only trained on static images? To study the motion features
in the latent space of StyleGAN, in this paper, we hypothesize and demonstrate
that a series of meaningful, natural, and versatile small, local movements
(referred to as "micromotion", such as expression, head movement, and aging
effect) can be represented in low-rank spaces extracted from the latent space
of a conventionally pre-trained StyleGAN-v2 model for face generation, with the
guidance of proper "anchors" in the form of either short text or video clips.
Starting from one target face image, with the editing direction decoded from
the low-rank space, its micromotion features can be represented as simple as an
affine transformation over its latent feature. Perhaps more surprisingly, such
micromotion subspace, even learned from just single target face, can be
painlessly transferred to other unseen face images, even those from vastly
different domains (such as oil painting, cartoon, and sculpture faces). It
demonstrates that the local feature geometry corresponding to one type of
micromotion is aligned across different face subjects, and hence that
StyleGAN-v2 is indeed "secretly" aware of the subject-disentangled feature
variations caused by that micromotion. We present various successful examples
of applying our low-dimensional micromotion subspace technique to directly and
effortlessly manipulate faces, showing high robustness, low computational
overhead, and impressive domain transferability. Our codes are available at
https://github.com/wuqiuche/micromotion-StyleGAN.

### Title: Distant finetuning with discourse relations for stance classification
* Paper ID: 2204.12693v1
* Paper URL: [http://arxiv.org/abs/2204.12693v1](http://arxiv.org/abs/2204.12693v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Approaches for the stance classification task, an important task for
understanding argumentation in debates and detecting fake news, have been
relying on models which deal with individual debate topics. In this paper, in
order to train a system independent from topics, we propose a new method to
extract data with silver labels from raw text to finetune a model for stance
classification. The extraction relies on specific discourse relation
information, which is shown as a reliable and accurate source for providing
stance information. We also propose a 3-stage training framework where the
noisy level in the data used for finetuning decreases over different stages
going from the most noisy to the least noisy. Detailed experiments show that
the automatically annotated dataset as well as the 3-stage training help
improve model performance in stance classification. Our approach ranks 1st
among 26 competing teams in the stance classification track of the NLPCC 2021
shared task Argumentative Text Understanding for AI Debater, which confirms the
effectiveness of our approach.

### Title: McMillan map and nonlinear Twiss parameters
* Paper ID: 2204.12691v1
* Paper URL: [http://arxiv.org/abs/2204.12691v1](http://arxiv.org/abs/2204.12691v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: In this article we consider two dynamical systems: the McMillan sextupole and
octupole integrable mappings originally introduced by Edwin McMillan; the
second one is also known as canonical McMillan map. Both of them are simplest
symmetric McMillan maps with only one intrinsic parameter, the trace of the
Jacobian at the fixed point. While these dynamical systems have numerous of
applications and are used in many areas of math and physics, some of their
dynamical properties have not been described yet. We fulfill the gap and
provide complete description of all stable trajectories including
parametrization of invariant curves, Pioncar\'e rotation numbers and canonical
action-angle variables.
  In the second part we relate these maps with general chaotic map in
McMillan-Turaev form. We show that McMillan sextupole and octupole mappings are
first order approximations of dynamics around the fixed point, in a similar way
as linear map and quadratic invariant (Courant-Snyder invariant in accelerator
physics) is the zeroth order approximation (known as linearization). Finally we
suggest the new formalism of nonlinear Twiss parameters which incorporate
dependence of rotation number as a function of amplitude, in contrast to e.g.
betatron phase advance used in accelerator physics which is independent of
amplitude. Specifically in application to accelerator physics this new
formalism is capable of predicting dynamical aperture around 1-st, 2-nd, 3-rd
and 4-th order resonances for flat beams, which is critical for beam
injection/extraction.

### Title: Document-Level Relation Extraction with Sentences Importance Estimation and Focusing
* Paper ID: 2204.12679v1
* Paper URL: [http://arxiv.org/abs/2204.12679v1](http://arxiv.org/abs/2204.12679v1)
* Updated Date: 2022-04-27
* Code URL: [https://github.com/xwjim/sief](https://github.com/xwjim/sief)
* Summary: Document-level relation extraction (DocRE) aims to determine the relation
between two entities from a document of multiple sentences. Recent studies
typically represent the entire document by sequence- or graph-based models to
predict the relations of all entity pairs. However, we find that such a model
is not robust and exhibits bizarre behaviors: it predicts correctly when an
entire test document is fed as input, but errs when non-evidence sentences are
removed. To this end, we propose a Sentence Importance Estimation and Focusing
(SIEF) framework for DocRE, where we design a sentence importance score and a
sentence focusing loss, encouraging DocRE models to focus on evidence
sentences. Experimental results on two domains show that our SIEF not only
improves overall performance, but also makes DocRE models more robust.
Moreover, SIEF is a general framework, shown to be effective when combined with
a variety of base DocRE models.

### Title: Span-level Bidirectional Cross-attention Framework for Aspect Sentiment Triplet Extraction
* Paper ID: 2204.12674v1
* Paper URL: [http://arxiv.org/abs/2204.12674v1](http://arxiv.org/abs/2204.12674v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Aspect Sentiment Triplet Extraction (ASTE) is a new fine-grained sentiment
analysis task that aims to extract triplets of aspect terms, sentiments, and
opinion terms from review sentences. Recently, span-level models achieve
gratifying results on ASTE task by taking advantage of whole span predictions.
However, all the spans generated by these methods inevitably share at least one
token with some others, and these method suffer from the similarity of these
spans due to their similar distributions. Moreover, since either the aspect
term or opinion term can trigger a sentiment triplet, it is challenging to make
use of the information more comprehensively and adequately. To address these
concerns, we propose a span-level bidirectional cross-attention framework.
Specifically, we design a similar span separation loss to detach the spans with
shared tokens and a bidirectional cross-attention structure that consists of
aspect and opinion decoders to decode the span-level representations in both
aspect-to-opinion and opinion-to-aspect directions. With differentiated span
representations and bidirectional decoding structure, our model can extract
sentiment triplets more precisely and efficiently. Experimental results show
that our framework significantly outperforms state-of-the-art methods,
achieving better performance in predicting triplets with multi-token entities
and extracting triplets in sentences with multi-triplets.

### Title: SCGC : Self-Supervised Contrastive Graph Clustering
* Paper ID: 2204.12656v1
* Paper URL: [http://arxiv.org/abs/2204.12656v1](http://arxiv.org/abs/2204.12656v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Graph clustering discovers groups or communities within networks. Deep
learning methods such as autoencoders (AE) extract effective clustering and
downstream representations but cannot incorporate rich structural information.
While Graph Neural Networks (GNN) have shown great success in encoding graph
structure, typical GNNs based on convolution or attention variants suffer from
over-smoothing, noise, heterophily, are computationally expensive and typically
require the complete graph being present. Instead, we propose Self-Supervised
Contrastive Graph Clustering (SCGC), which imposes graph-structure via
contrastive loss signals to learn discriminative node representations and
iteratively refined soft cluster labels. We also propose SCGC*, with a more
effective, novel, Influence Augmented Contrastive (IAC) loss to fuse richer
structural information, and half the original model parameters. SCGC(*) is
faster with simple linear units, completely eliminate convolutions and
attention of traditional GNNs, yet efficiently incorporates structure. It is
impervious to layer depth and robust to over-smoothing, incorrect edges and
heterophily. It is scalable by batching, a limitation in many prior GNN models,
and trivially parallelizable. We obtain significant improvements over
state-of-the-art on a wide range of benchmark graph datasets, including images,
sensor data, text, and citation networks efficiently. Specifically, 20% on ARI
and 18% on NMI for DBLP; overall 55% reduction in training time and overall,
81% reduction on inference time. Our code is available at :
https://github.com/gayanku/SCGC

### Title: Generating Self-Serendipity Preference in Recommender Systems for Addressing Cold Start Problems
* Paper ID: 2204.12651v1
* Paper URL: [http://arxiv.org/abs/2204.12651v1](http://arxiv.org/abs/2204.12651v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Classical accuracy-oriented Recommender Systems (RSs) typically face the
cold-start problem and the filter-bubble problem when users suffer the
familiar, repeated, and even predictable recommendations, making them boring
and unsatisfied. To address the above issues, serendipity-oriented RSs are
proposed to recommend appealing and valuable items significantly deviating from
users' historical interactions and thus satisfying them by introducing
unexplored but relevant candidate items to them. In this paper, we devise a
novel serendipity-oriented recommender system (\textbf{G}enerative
\textbf{S}elf-\textbf{S}erendipity \textbf{R}ecommender \textbf{S}ystem,
\textbf{GS$^2$-RS}) that generates users' self-serendipity preferences to
enhance the recommendation performance. Specifically, this model extracts
users' interest and satisfaction preferences, generates virtual but convincible
neighbors' preferences from themselves, and achieves their self-serendipity
preference. Then these preferences are injected into the rating matrix as
additional information for RS models. Note that GS$^2$-RS can not only tackle
the cold-start problem but also provides diverse but relevant recommendations
to relieve the filter-bubble problem. Extensive experiments on benchmark
datasets illustrate that the proposed GS$^2$-RS model can significantly
outperform the state-of-the-art baseline approaches in serendipity measures
with a stable accuracy performance.

### Title: Contrastive learning-based computational histopathology predict differential expression of cancer driver genes
* Paper ID: 2204.11994v2
* Paper URL: [http://arxiv.org/abs/2204.11994v2](http://arxiv.org/abs/2204.11994v2)
* Updated Date: 2022-04-27
* Code URL: [https://github.com/hoarjour/histcode](https://github.com/hoarjour/histcode)
* Summary: Digital pathological analysis is run as the main examination used for cancer
diagnosis. Recently, deep learning-driven feature extraction from pathology
images is able to detect genetic variations and tumor environment, but few
studies focus on differential gene expression in tumor cells. In this paper, we
propose a self-supervised contrastive learning framework, HistCode, to infer
differential gene expressions from whole slide images (WSIs). We leveraged
contrastive learning on large-scale unannotated WSIs to derive slide-level
histopathological feature in latent space, and then transfer it to tumor
diagnosis and prediction of differentially expressed cancer driver genes. Our
extensive experiments showed that our method outperformed other
state-of-the-art models in tumor diagnosis tasks, and also effectively
predicted differential gene expressions. Interestingly, we found the higher
fold-changed genes can be more precisely predicted. To intuitively illustrate
the ability to extract informative features from pathological images, we
spatially visualized the WSIs colored by the attentive scores of image tiles.
We found that the tumor and necrosis areas were highly consistent with the
annotations of experienced pathologists. Moreover, the spatial heatmap
generated by lymphocyte-specific gene expression patterns was also consistent
with the manually labeled WSI.

### Title: Performer: A Novel PPG to ECG Reconstruction Transformer For a Digital Biomarker of Cardiovascular Disease Detection
* Paper ID: 2204.11795v2
* Paper URL: [http://arxiv.org/abs/2204.11795v2](http://arxiv.org/abs/2204.11795v2)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Cardiovascular diseases (CVDs) have become the top one cause of death;
three-quarters of these deaths occur in lower-income communities.
Electrocardiography (ECG), an electrical measurement capturing the cardiac
activities, is a gold-standard to diagnose CVDs. However, ECG is infeasible for
continuous cardiac monitoring due to its requirement for user participation.
Meanwhile, photoplethysmography (PPG) is easy to collect, but the limited
accuracy constrains its clinical usage. In this research, a novel
Transformer-based architecture, Performer, is invented to reconstruct ECG from
PPG and to create a novel digital biomarker, PPG along with its reconstructed
ECG, as multiple modalities for CVD detection. This architecture, for the first
time, performs Transformer sequence to sequence translation on biomedical
waveforms, while also utilizing the advantages of the easily accessible PPG and
the well-studied base of ECG. Shifted Patch-based Attention (SPA) is created to
maximize the signal features by fetching the various sequence lengths as
hierarchical stages into the training while also capturing cross-patch
connections through the shifted patch mechanism. This architecture generates a
state-of-the-art performance of 0.29 RMSE for reconstructing ECG from PPG,
achieving an average of 95.9% diagnosis for CVDs on the MIMIC III dataset and
75.9% for diabetes on the PPG-BP dataset. Performer, along with its novel
digital biomarker, offers a low-cost and non-invasive solution for continuous
cardiac monitoring, only requiring the easily extractable PPG data to
reconstruct the not-as-accessible ECG data. As a prove of concept, an earring
wearable, named PEARL (prototype), is designed to scale up the point-of-care
(POC) healthcare system.

