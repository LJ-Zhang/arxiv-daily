### Title: Is the Contralateral Delay Activity (CDA) a robust neural correlate for Visual Working Memory (VWM) tasks? A reproducibility study
* Paper ID: 2204.08578v1
* Paper URL: [http://arxiv.org/abs/2204.08578v1](http://arxiv.org/abs/2204.08578v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Visual working memory (VWM) allows us to actively store, update and
manipulate visual information surrounding us. While the underlying neural
mechanisms of VWM remain unclear, contralateral delay activity (CDA), a
sustained negativity over the hemisphere contralateral to the positions of
visual items to be remembered, is often used to study VWM. To investigate if
the CDA is a robust neural correlate for VWM tasks, we reproduced eight
CDA-related studies with a publicly accessible EEG dataset. We used the raw EEG
data from these eight studies and analyzed all of them with the same basic
pipeline to extract CDA. We were able to reproduce the results from all the
studies and show that with a basic automated EEG pipeline we can extract a
clear CDA signal. We share insights from the trends observed across the studies
and raise some questions about the CDA decay and the CDA during the recall
phase, which surprisingly, none of the eight studies did address. Finally, we
also provide reproducibility recommendations based on our experience and
challenges in reproducing these studies.

### Title: Quantum Computation of Hydrogen Bond Dynamics and Vibrational Spectra
* Paper ID: 2204.08571v1
* Paper URL: [http://arxiv.org/abs/2204.08571v1](http://arxiv.org/abs/2204.08571v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Calculating the observable properties of chemical systems is often
classically intractable, and is widely viewed as a promising application of
quantum information processing. This is because a full description of chemical
behavior relies upon the complex interplay of quantum-mechanical electrons and
nuclei, demanding an exponential scaling of computational resources with system
size. While considerable progress has been made in mapping electronic-structure
calculations to quantum hardware, these approaches are unsuitable for
describing the quantum dynamics of nuclei, proton- and hydrogen-transfer
processes, or the vibrational spectra of molecules. Here, we use the QSCOUT
ion-trap quantum computer to determine the quantum dynamics and vibrational
properties of a shared proton within a short-strong hydrogen-bonded system. For
a range of initial states, we experimentally drive the ion-trap system to
emulate the quantum trajectory of the shared proton wavepacket as it evolves
along the potential surface generated by the nuclear frameworks and electronic
structure. We then extract the characteristic vibrational frequencies for the
shared proton motion to spectroscopic accuracy and determine all energy
eigenvalues of the system Hamiltonian to > 99.9% fidelity. Our approach offers
a new paradigm for studying the quantum chemical dynamics and vibrational
spectra of molecules, and when combined with quantum algorithms for electronic
structure, opens the possibility to describe the complete behavior of molecules
using exclusively quantum computation techniques.

### Title: Learning Similarity Preserving Binary Codes for Recommender Systems
* Paper ID: 2204.08569v1
* Paper URL: [http://arxiv.org/abs/2204.08569v1](http://arxiv.org/abs/2204.08569v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Hashing-based Recommender Systems (RSs) are widely studied to provide
scalable services. The existing methods for the systems combine three modules
to achieve efficiency: feature extraction, interaction modeling, and
binarization. In this paper, we study an unexplored module combination for the
hashing-based recommender systems, namely Compact Cross-Similarity Recommender
(CCSR). Inspired by cross-modal retrieval, CCSR utilizes Maximum a Posteriori
similarity instead of matrix factorization and rating reconstruction to model
interactions between users and items. We conducted experiments on MovieLens1M,
Amazon product review, Ichiba purchase dataset and confirmed CCSR outperformed
the existing matrix factorization-based methods. On the Movielens1M dataset,
the absolute performance improvements are up to 15.69% in NDCG and 4.29% in
Recall. In addition, we extensively studied three binarization modules: $sign$,
scaled tanh, and sign-scaled tanh. The result demonstrated that although
differentiable scaled tanh is popular in recent discrete feature learning
literature, a huge performance drop occurs when outputs of scaled $tanh$ are
forced to be binary.

### Title: Automated Audio Captioning using Audio Event Clues
* Paper ID: 2204.08567v1
* Paper URL: [http://arxiv.org/abs/2204.08567v1](http://arxiv.org/abs/2204.08567v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Audio captioning is an important research area that aims to generate
meaningful descriptions for audio clips. Most of the existing research extracts
acoustic features of audio clips as input to encoder-decoder and transformer
architectures to produce the captions in a sequence-to-sequence manner. Due to
data insufficiency and the architecture's inadequate learning capacity,
additional information is needed to generate natural language sentences, as
well as acoustic features. To address these problems, an encoder-decoder
architecture is proposed that learns from both acoustic features and extracted
audio event labels as inputs. The proposed model is based on pre-trained
acoustic features and audio event detection. Various experiments used different
acoustic features, word embedding models, audio event label extraction methods,
and implementation configurations to show which combinations have better
performance on the audio captioning task. Results of the extensive experiments
on multiple datasets show that using audio event labels with the acoustic
features improves the recognition performance and the proposed method either
outperforms or achieves competitive results with the state-of-the-art models.

### Title: Star formation in disk galaxies and its relation with spiral structure in numerical simulations
* Paper ID: 2204.08560v1
* Paper URL: [http://arxiv.org/abs/2204.08560v1](http://arxiv.org/abs/2204.08560v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: The spiral structure of a spiral galaxy can be seen through different
observational tracers such as the dust in the interstellar medium, the free
electrons in ionized regions, the molecular gas, or the atomic hydrogen in
H{\alpha} regions. In this work, we use an N-body simulation with
Magnetohydrodynamics (MHD) to investigate the spiral pattern and the star
formation activity in the gas component of a disk galaxy. Some of the questions
that we tackle include: how are galaxies observed through the different
properties of the gas? Does the spiral structure of the galaxy change when we
trace it with the different properties of the gas? Do the spiral arms in the
simulation change its shape and width depending on what property we are
"looking" through? Can we somehow model the shape of the arms to measure their
width consistently? Does this model apply to all the properties? To answer
these questions, we developed a method for the identification and extraction of
the spiral structure in a disk galaxy. Using the results of this procedure, we
further investigate the features of the spiral pattern through the different
properties of the gas, with special attention to the star formation activity
and how it behaves along and across the spiral structure.

### Title: Correlation between Unconscious Mouse Actions and Human Cognitive Workload
* Paper ID: 2204.08559v1
* Paper URL: [http://arxiv.org/abs/2204.08559v1](http://arxiv.org/abs/2204.08559v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Unconscious behaviors are one of the indicators of the human perception
process from a psychological perspective. As a result of perception responses,
hand gestures show behavioral responses from given stimuli. Mouse usages in
Human-Computer Interaction (HCI) show hand gestures that individuals perceive
information processing. This paper presents an investigation of the correlation
between unconscious mouse actions and human cognitive workload. We extracted
mouse behaviors from a Robot Operating System (ROS) file-based dataset that
user responses are reproducible. We analyzed redundant mouse movements to
complete a dual $n$-back game by solely pressing the left and right buttons.
Starting from a hypothesis that unconscious mouse behaviors predict different
levels of cognitive loads, we statistically analyzed mouse movements. We also
validated mouse behaviors with other modalities in the dataset, including
self-questionnaire and eye blinking results. As a result, we found that mouse
behaviors that occur unconsciously and human cognitive workload correlate.

### Title: Learning to Retrieve Relevant Experiences for Motion Planning
* Paper ID: 2204.08550v1
* Paper URL: [http://arxiv.org/abs/2204.08550v1](http://arxiv.org/abs/2204.08550v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Recent work has demonstrated that motion planners' performance can be
significantly improved by retrieving past experiences from a database.
Typically, the experience database is queried for past similar problems using a
similarity function defined over the motion planning problems. However, to
date, most works rely on simple hand-crafted similarity functions and fail to
generalize outside their corresponding training dataset. To address this
limitation, we propose (FIRE), a framework that extracts local representations
of planning problems and learns a similarity function over them. To generate
the training data we introduce a novel self-supervised method that identifies
similar and dissimilar pairs of local primitives from past solution paths. With
these pairs, a Siamese network is trained with the contrastive loss and the
similarity function is realized in the network's latent space. We evaluate FIRE
on an 8-DOF manipulator in five categories of motion planning problems with
sensed environments. Our experiments show that FIRE retrieves relevant
experiences which can informatively guide sampling-based planners even in
problems outside its training distribution, outperforming other baselines.

### Title: Influence of the presence of multiple resonances on material parameter determination using broadband ferromagnetic resonance spectroscopy
* Paper ID: 2204.08500v1
* Paper URL: [http://arxiv.org/abs/2204.08500v1](http://arxiv.org/abs/2204.08500v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: The influence of the presence of multiple resonances in ferromagnetic
resonance spectra on extracted material parameters is investigated using
numerical simulations. Our results show that the systematic error of assuming
an incorrect number of resonances for a material can lead to the extraction of
material parameters that significantly deviate from any of the true material
parameters. When noise is present in experimental ferromagnetic resonance
spectra increasing the frequency range of the broadband characterization can
significantly reduce the error-margins when the data is analyzed assuming the
correct number of resonances present in the material. For the cases
investigated in this study it was found that analyzing the data using a single
resonance results in extracted gyromagnetic ratios and effective magnetization
parameters that are consistent with the weighted average of the true material
parameters. We further provide a cautionary example regarding the extraction of
the inhomogeneous linewidth broadening and damping parameters of materials that
contain an unknown number of resonances.

### Title: Exploring Dimensionality Reduction Techniques in Multilingual Transformers
* Paper ID: 2204.08415v1
* Paper URL: [http://arxiv.org/abs/2204.08415v1](http://arxiv.org/abs/2204.08415v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Both in scientific literature and in industry,, Semantic and context-aware
Natural Language Processing-based solutions have been gaining importance in
recent years. The possibilities and performance shown by these models when
dealing with complex Language Understanding tasks is unquestionable, from
conversational agents to the fight against disinformation in social networks.
In addition, considerable attention is also being paid to developing
multilingual models to tackle the language bottleneck. The growing need to
provide more complex models implementing all these features has been
accompanied by an increase in their size, without being conservative in the
number of dimensions required. This paper aims to give a comprehensive account
of the impact of a wide variety of dimensional reduction techniques on the
performance of different state-of-the-art multilingual Siamese Transformers,
including unsupervised dimensional reduction techniques such as linear and
nonlinear feature extraction, feature selection, and manifold techniques. In
order to evaluate the effects of these techniques, we considered the
multilingual extended version of Semantic Textual Similarity Benchmark (mSTSb)
and two different baseline approaches, one using the pre-trained version of
several models and another using their fine-tuned STS version. The results
evidence that it is possible to achieve an average reduction in the number of
dimensions of $91.58\% \pm 2.59\%$ and $54.65\% \pm 32.20\%$, respectively.
This work has also considered the consequences of dimensionality reduction for
visualization purposes. The results of this study will significantly contribute
to the understanding of how different tuning approaches affect performance on
semantic-aware tasks and how dimensional reduction techniques deal with the
high-dimensional embeddings computed for the STS task and their potential for
highly demanding NLP tasks

### Title: Robust, Nonparametric, Efficient Decomposition of Spectral Peaks under Distortion and Interference
* Paper ID: 2204.08411v1
* Paper URL: [http://arxiv.org/abs/2204.08411v1](http://arxiv.org/abs/2204.08411v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: We propose a decomposition method for the spectral peaks in an observed
frequency spectrum, which is efficiently acquired by utilizing the Fast Fourier
Transform. In contrast to the traditional methods of waveform fitting on the
spectrum, we optimize the problem from a more robust perspective. We model the
peaks in spectrum as pseudo-symmetric functions, where the only constraint is a
nonincreasing behavior around a central frequency when the distance increases.
Our approach is more robust against arbitrary distortion, interference and
noise on the spectrum that may be caused by an observation system. The time
complexity of our method is linear, i.e., $O(N)$ per extracted spectral peak.
Moreover, the decomposed spectral peaks show a pseudo-orthogonal behavior,
where they conform to a power preserving equality.

### Title: Multiple-environment Self-adaptive Network for Aerial-view Geo-localization
* Paper ID: 2204.08381v1
* Paper URL: [http://arxiv.org/abs/2204.08381v1](http://arxiv.org/abs/2204.08381v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Aerial-view geo-localization tends to determine an unknown position through
matching the drone-view image with the geo-tagged satellite-view image. This
task is mostly regarded as an image retrieval problem. The key underpinning
this task is to design a series of deep neural networks to learn discriminative
image descriptors. However, existing methods meet large performance drops under
realistic weather, such as rain and fog, since they do not take the domain
shift between the training data and multiple test environments into
consideration. To minor this domain gap, we propose a Multiple-environment
Self-adaptive Network (MuSe-Net) to dynamically adjust the domain shift caused
by environmental changing. In particular, MuSe-Net employs a two-branch neural
network containing one multiple-environment style extraction network and one
self-adaptive feature extraction network. As the name implies, the
multiple-environment style extraction network is to extract the
environment-related style information, while the self-adaptive feature
extraction network utilizes an adaptive modulation module to dynamically
minimize the environment-related style gap. Extensive experiments on two
widely-used benchmarks, i.e., University-1652 and CVUSA, demonstrate that the
proposed MuSe-Net achieves a competitive result for geo-localization in
multiple environments. Furthermore, we observe that the proposed method also
shows great potential to the unseen extreme weather, such as mixing the fog,
rain and snow.

### Title: The role of the bile salt surfactant sodium deoxycholate in aqueous two-phase separation of single-wall carbon nanotubes revealed by systematic parameter variations
* Paper ID: 2204.08379v1
* Paper URL: [http://arxiv.org/abs/2204.08379v1](http://arxiv.org/abs/2204.08379v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Aqueous two-phase (ATP) extraction has been demonstrated as a fast, scalable,
and effective separation technique to sort single-wall carbon nanotubes
(SWCNTs) according to their diameter and chiral structure. The exact mechanism
behind the chirality-dependent migration of SWCNTs between the two phases is
however not completely understood, and depends on many parameters (e.g., choice
of surfactants and their concentration, pH, temperature, ...), making it
difficult to optimize the multivariable parameter space. In this work, we
present a systematic study of the choice and concentration of specific
surfactants on the ATP sorting, by performing a series of single-step ATP
separations in which each time only one parameter is systematically varied,
while monitoring the structure-specific migration of every SWCNT chirality
between both phases with detailed wavelength-dependent spectroscopy. These
systematic studies reveal that the diameter-dependent stacking of a discrete
number of sodium deoxycholate molecules fitting around the SWCNT circumference
determines the separation order in the form of a periodically modulated pattern
as a function of SWCNT diameter. Addition of cosurfactants can be used to
compete with the bile salt surfactant to enhance the separation yields, but
does not affect the sorting order. The results are afterwards directly applied
to predict the parameters required to separate specific chiral structures in
just two ATP steps.

### Title: Observing Supernova Neutrino Light Curves with Super-Kamiokande. III. Extraction of Mass and Radius of Neutron Stars from Synthetic Data
* Paper ID: 2204.08363v1
* Paper URL: [http://arxiv.org/abs/2204.08363v1](http://arxiv.org/abs/2204.08363v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Neutrinos are guaranteed to be observable from the next galactic supernova
(SN). Optical light and gravitational waves are also observable, but may be
difficult to observe if the location of the SN in the galaxy or the details of
the explosion are unsuitable. The key to observing the next supernova is to
first use neutrinos to understand various physical quantities and then link
them to other signals. In this paper, we present Monte Carlo sampling
calculations of neutrino events from galactic supernova explosions observed
with Super-Kamiokande. The analytical solution of neutrino emission, which
represents the long-term evolution of neutrino-light curve from supernovae, is
used as a theoretical template. It gives the event rate and event spectrum
through inverse beta decay interactions with explicit model parameter
dependence. Parameter estimation is performed on these simulated sample data by
fitting least squares using the analytical solution. The results show that the
mass, radius and total energy of a remnant neutron star produced by a SN can be
determined with an accuracy of $\sim 0.1M_\odot$, $\sim 1$ km, and $\sim
10^{51}$ erg, respectively, for a galactic SN at 8 kpc.

### Title: Extracting Targeted Training Data from ASR Models, and How to Mitigate It
* Paper ID: 2204.08345v1
* Paper URL: [http://arxiv.org/abs/2204.08345v1](http://arxiv.org/abs/2204.08345v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Recent work has designed methods to demonstrate that model updates in ASR
training can leak potentially sensitive attributes of the utterances used in
computing the updates. In this work, we design the first method to demonstrate
information leakage about training data from trained ASR models. We design
Noise Masking, a fill-in-the-blank style method for extracting targeted parts
of training data from trained ASR models. We demonstrate the success of Noise
Masking by using it in four settings for extracting names from the LibriSpeech
dataset used for training a SOTA Conformer model. In particular, we show that
we are able to extract the correct names from masked training utterances with
11.8% accuracy, while the model outputs some name from the train set 55.2% of
the time. Further, we show that even in a setting that uses synthetic audio and
partial transcripts from the test set, our method achieves 2.5% correct name
accuracy (47.7% any name success rate). Lastly, we design Word Dropout, a data
augmentation method that we show when used in training along with MTR, provides
comparable utility as the baseline, along with significantly mitigating
extraction via Noise Masking across the four evaluated settings.

### Title: One-Loop Hybrid Renormalization Matching Kernels for Quasi-Parton Distributions
* Paper ID: 2204.08343v1
* Paper URL: [http://arxiv.org/abs/2204.08343v1](http://arxiv.org/abs/2204.08343v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Large momentum effective theory allows extraction of hadron parton
distribution functions in lattice QCD by matching them to quark bilinear matrix
elements of hadrons with large momenta. We calculate the matching kernels for
the unpolarized, helicity, and transversity isovector parton distribution
functions and skewless generalized parton distributions of all hadrons in the
hybrid-RI/MOM scheme. This renormalization scheme uses RI/MOM when the Wilson
line length is less then $z_s$, otherwise a mass subtraction scheme is used. By
design, the non-hybrid scheme is recovered as $z_s \to \infty$. In the opposite
limit, $z \to 0$, the self renormalization scheme is obtained. When the
parameters $p_z^R=0$ and $\mu^R z_s \ll 1$, the hybrid-RI/MOM scheme coincides
with the hybrid-ratio scheme times the charge of the PDF. We also discuss the
subtlety related to the commutativity of Fourier transform and $\epsilon$
expansion in the $\overline{\text{MS}}$ scheme.

### Title: BSRT: Improving Burst Super-Resolution with Swin Transformer and Flow-Guided Deformable Alignment
* Paper ID: 2204.08332v1
* Paper URL: [http://arxiv.org/abs/2204.08332v1](http://arxiv.org/abs/2204.08332v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: This work addresses the Burst Super-Resolution (BurstSR) task using a new
architecture, which requires restoring a high-quality image from a sequence of
noisy, misaligned, and low-resolution RAW bursts. To overcome the challenges in
BurstSR, we propose a Burst Super-Resolution Transformer (BSRT), which can
significantly improve the capability of extracting inter-frame information and
reconstruction. To achieve this goal, we propose a Pyramid Flow-Guided
Deformable Convolution Network (Pyramid FG-DCN) and incorporate Swin
Transformer Blocks and Groups as our main backbone. More specifically, we
combine optical flows and deformable convolutions, hence our BSRT can handle
misalignment and aggregate the potential texture information in multi-frames
more efficiently. In addition, our Transformer-based structure can capture
long-range dependency to further improve the performance. The evaluation on
both synthetic and real-world tracks demonstrates that our approach achieves a
new state-of-the-art in BurstSR task. Further, our BSRT wins the championship
in the NTIRE2022 Burst Super-Resolution Challenge.

### Title: Application of Transfer Learning and Ensemble Learning in Image-level Classification for Breast Histopathology
* Paper ID: 2204.08311v1
* Paper URL: [http://arxiv.org/abs/2204.08311v1](http://arxiv.org/abs/2204.08311v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Background: Breast cancer has the highest prevalence in women globally. The
classification and diagnosis of breast cancer and its histopathological images
have always been a hot spot of clinical concern. In Computer-Aided Diagnosis
(CAD), traditional classification models mostly use a single network to extract
features, which has significant limitations. On the other hand, many networks
are trained and optimized on patient-level datasets, ignoring the application
of lower-level data labels.
  Method: This paper proposes a deep ensemble model based on image-level labels
for the binary classification of benign and malignant lesions of breast
histopathological images. First, the BreakHis dataset is randomly divided into
a training, validation and test set. Then, data augmentation techniques are
used to balance the number of benign and malignant samples. Thirdly,
considering the performance of transfer learning and the complementarity
between each network, VGG-16, Xception, Resnet-50, DenseNet-201 are selected as
the base classifiers.
  Result: In the ensemble network model with accuracy as the weight, the
image-level binary classification achieves an accuracy of $98.90\%$. In order
to verify the capabilities of our method, the latest Transformer and Multilayer
Perception (MLP) models have been experimentally compared on the same dataset.
Our model wins with a $5\%-20\%$ advantage, emphasizing the ensemble model's
far-reaching significance in classification tasks.
  Conclusion: This research focuses on improving the model's classification
performance with an ensemble algorithm. Transfer learning plays an essential
role in small datasets, improving training speed and accuracy. Our model has
outperformed many existing approaches in accuracy, providing a method for the
field of auxiliary medical diagnosis.

### Title: Cross-view Brain Decoding
* Paper ID: 2204.09564v1
* Paper URL: [http://arxiv.org/abs/2204.09564v1](http://arxiv.org/abs/2204.09564v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: How the brain captures the meaning of linguistic stimuli across multiple
views is still a critical open question in neuroscience. Consider three
different views of the concept apartment: (1) picture (WP) presented with the
target word label, (2) sentence (S) using the target word, and (3) word cloud
(WC) containing the target word along with other semantically related words.
Unlike previous efforts, which focus only on single view analysis, in this
paper, we study the effectiveness of brain decoding in a zero-shot cross-view
learning setup. Further, we propose brain decoding in the novel context of
cross-view-translation tasks like image captioning (IC), image tagging (IT),
keyword extraction (KE), and sentence formation (SF). Using extensive
experiments, we demonstrate that cross-view zero-shot brain decoding is
practical leading to ~0.68 average pairwise accuracy across view pairs. Also,
the decoded representations are sufficiently detailed to enable high accuracy
for cross-view-translation tasks with following pairwise accuracy: IC (78.0),
IT (83.0), KE (83.7) and SF (74.5). Analysis of the contribution of different
brain networks reveals exciting cognitive insights: (1) A high percentage of
visual voxels are involved in image captioning and image tagging tasks, and a
high percentage of language voxels are involved in the sentence formation and
keyword extraction tasks. (2) Zero-shot accuracy of the model trained on S view
and tested on WC view is better than same-view accuracy of the model trained
and tested on WC view.

### Title: Modx: Binary Level Partial Imported Third-Party Library Detection through Program Modularization and Semantic Matching
* Paper ID: 2204.08237v1
* Paper URL: [http://arxiv.org/abs/2204.08237v1](http://arxiv.org/abs/2204.08237v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: With the rapid growth of software, using third-party libraries (TPLs) has
become increasingly popular. The prosperity of the library usage has provided
the software engineers with handful of methods to facilitate and boost the
program development. Unfortunately, it also poses great challenges as it
becomes much more difficult to manage the large volume of libraries. Researches
and studies have been proposed to detect and understand the TPLs in the
software. However, most existing approaches rely on syntactic features, which
are not robust when these features are changed or deliberately hidden by the
adversarial parties. Moreover, these approaches typically model each of the
imported libraries as a whole, therefore, cannot be applied to scenarios where
the host software only partially uses the library code segments.
  To detect both fully and partially imported TPLs at the semantic level, we
propose ModX, a framework that leverages novel program modularization
techniques to decompose the program into finegrained functionality-based
modules. By extracting both syntactic and semantic features, it measures the
distance between modules to detect similar library module reuse in the program.
Experimental results show that ModX outperforms other modularization tools by
distinguishing more coherent program modules with 353% higher module quality
scores and beats other TPL detection tools with on average 17% better in
precision and 8% better in recall.

### Title: Empirical Evaluation and Theoretical Analysis for Representation Learning: A Survey
* Paper ID: 2204.08226v1
* Paper URL: [http://arxiv.org/abs/2204.08226v1](http://arxiv.org/abs/2204.08226v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Representation learning enables us to automatically extract generic feature
representations from a dataset to solve another machine learning task.
Recently, extracted feature representations by a representation learning
algorithm and a simple predictor have exhibited state-of-the-art performance on
several machine learning tasks. Despite its remarkable progress, there exist
various ways to evaluate representation learning algorithms depending on the
application because of the flexibility of representation learning. To
understand the current representation learning, we review evaluation methods of
representation learning algorithms and theoretical analyses. On the basis of
our evaluation survey, we also discuss the future direction of representation
learning. Note that this survey is the extended version of Nozawa and Sato
(2022).

### Title: OMG: Observe Multiple Granularities for Natural Language-Based Vehicle Retrieval
* Paper ID: 2204.08209v1
* Paper URL: [http://arxiv.org/abs/2204.08209v1](http://arxiv.org/abs/2204.08209v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Retrieving tracked-vehicles by natural language descriptions plays a critical
role in smart city construction. It aims to find the best match for the given
texts from a set of tracked vehicles in surveillance videos. Existing works
generally solve it by a dual-stream framework, which consists of a text
encoder, a visual encoder and a cross-modal loss function. Although some
progress has been made, they failed to fully exploit the information at various
levels of granularity. To tackle this issue, we propose a novel framework for
the natural language-based vehicle retrieval task, OMG, which Observes Multiple
Granularities with respect to visual representation, textual representation and
objective functions. For the visual representation, target features, context
features and motion features are encoded separately. For the textual
representation, one global embedding, three local embeddings and a color-type
prompt embedding are extracted to represent various granularities of semantic
features. Finally, the overall framework is optimized by a cross-modal
multi-granularity contrastive loss function. Experiments demonstrate the
effectiveness of our method. Our OMG significantly outperforms all previous
methods and ranks the 9th on the 6th AI City Challenge Track2. The codes are
available at https://github.com/dyhBUPT/OMG.

### Title: Phishing Fraud Detection on Ethereum using Graph Neural Network
* Paper ID: 2204.08194v1
* Paper URL: [http://arxiv.org/abs/2204.08194v1](http://arxiv.org/abs/2204.08194v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Blockchain has widespread applications in the financial field but has also
attracted increasing cybercrimes. Recently, phishing fraud has emerged as a
major threat to blockchain security, calling for the development of effective
regulatory strategies. Nowadays network science has been widely used in
modeling Ethereum transaction data, further introducing the network
representation learning technology to analyze the transaction patterns. In this
paper, we consider phishing detection as a graph classification task and
propose an end-to-end Phishing Detection Graph Neural Network framework
(PDGNN). Specifically, we first construct a lightweight Ethereum transaction
network and extract transaction subgraphs of collected phishing accounts. Then
we propose an end-to-end detection model based on Chebyshev-GCN to precisely
distinguish between normal and phishing accounts. Extensive experiments on five
Ethereum datasets demonstrate that our PDGNN significantly outperforms general
phishing detection methods and scales well in large transaction networks.

### Title: Cosmic microwave background spectral distortions from Rayleigh scattering at second order
* Paper ID: 2204.08177v1
* Paper URL: [http://arxiv.org/abs/2204.08177v1](http://arxiv.org/abs/2204.08177v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Cosmic microwave background (CMB) spectral distortion from Rayleigh
scattering is calculated for the first time in rigorous second-order
cosmological perturbation theory. The new spectral distortion is sensitive to
acoustic dissipation at $10^{-2}<k{\rm Mpc}/h<1$, which slightly extends the
scale constrained by the CMB anisotropies. The spectral shape is different from
either temperature perturbations or any other traditional spectral distortions
from Compton scattering, such as $y$ and $\mu$. The new spectral distortion is
not formed in the late Universe, unlike the thermal Sunyaev-Zel'dovich effect
degenerated with the primordial $y$ distortions since photons must be hot for
Rayleigh scattering. Therefore, ideal measurements can distinguish the signal
from the other effects and extract new information during recombination.
Assuming cosmological parameters consistent with the recent CMB anisotropy
measurements, we find the new spectral distortion is $6.5\times 10^{-3}$Jy/str,
which is one order of magnitude smaller than the currently proposed target
sensitivity range of voyage 2050.

### Title: End-to-end Weakly-supervised Multiple 3D Hand Mesh Reconstruction from Single Image
* Paper ID: 2204.08154v1
* Paper URL: [http://arxiv.org/abs/2204.08154v1](http://arxiv.org/abs/2204.08154v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: In this paper, we consider the challenging task of simultaneously locating
and recovering multiple hands from single 2D image. Previous studies either
focus on single hand reconstruction or solve this problem in a multi-stage way.
Moreover, the conventional two-stage pipeline firstly detects hand areas, and
then estimates 3D hand pose from each cropped patch. To reduce the
computational redundancy in preprocessing and feature extraction, we propose a
concise but efficient single-stage pipeline. Specifically, we design a
multi-head auto-encoder structure for multi-hand reconstruction, where each
head network shares the same feature map and outputs the hand center, pose and
texture, respectively. Besides, we adopt a weakly-supervised scheme to
alleviate the burden of expensive 3D real-world data annotations. To this end,
we propose a series of losses optimized by a stage-wise training scheme, where
a multi-hand dataset with 2D annotations is generated based on the publicly
available single hand datasets. In order to further improve the accuracy of the
weakly supervised model, we adopt several feature consistency constraints in
both single and multiple hand settings. Specifically, the keypoints of each
hand estimated from local features should be consistent with the re-projected
points predicted from global features. Extensive experiments on public
benchmarks including FreiHAND, HO3D, InterHand2.6M and RHD demonstrate that our
method outperforms the state-of-the-art model-based methods in both
weakly-supervised and fully-supervised manners.

### Title: AI for human assessment: What do professional assessors need?
* Paper ID: 2204.08471v1
* Paper URL: [http://arxiv.org/abs/2204.08471v1](http://arxiv.org/abs/2204.08471v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: We present our case study that aims to help professional assessors make
decisions in human assessment, in which they conduct interviews with assessees
and evaluate their suitability for certain job roles. Our workshop with two
industrial assessors revealed that a computational system that can extract
nonverbal cues of assesses from interview videos would be beneficial to
assessors in terms of supporting their decision making. In response, we
developed such a system based on an unsupervised anomaly detection algorithm
using multimodal behavioral features such as facial keypoints, pose, head pose,
and gaze. Moreover, we enabled the system to output how much each feature
contributed to the outlierness of the detected cues with the purpose of
enhancing its interpretability. We then conducted a preliminary study to
examine the validity of the system's output by using 20 actual assessment
interview videos and involving the two assessors. The results suggested the
advantages of using unsupervised anomaly detection in an interpretable manner
by illustrating the informativeness of its outputs for assessors. Our approach,
which builds on top of the idea of separation of observation and interpretation
in human-AI teaming, will facilitate human decision making in highly contextual
domains, such as human assessment, while keeping their trust in the system.

### Title: A Deep Learning Galerkin Method for the Closed-Loop Geothermal System
* Paper ID: 2204.08139v1
* Paper URL: [http://arxiv.org/abs/2204.08139v1](http://arxiv.org/abs/2204.08139v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: There has been an arising trend of adopting deep learning methods to study
partial differential equations (PDEs). This article is to propose a Deep
Learning Galerkin Method (DGM) for the closed-loop geothermal system, which is
a new coupled multi-physics PDEs and mainly consists of a framework of
underground heat exchange pipelines to extract the geothermal heat from the
geothermal reservoir. This method is a natural combination of Galerkin Method
and machine learning with the solution approximated by a neural network instead
of a linear combination of basis functions. We train the neural network by
randomly sampling the spatiotemporal points and minimize loss function to
satisfy the differential operators, initial condition, boundary and interface
conditions. Moreover, the approximate ability of the neural network is proved
by the convergence of the loss function and the convergence of the neural
network to the exact solution in L^2 norm under certain conditions. Finally,
some numerical examples are carried out to demonstrate the approximation
ability of the neural networks intuitively.

### Title: Ingredient Extraction from Text in the Recipe Domain
* Paper ID: 2204.08137v1
* Paper URL: [http://arxiv.org/abs/2204.08137v1](http://arxiv.org/abs/2204.08137v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: In recent years, there has been an increase in the number of devices with
virtual assistants (e.g: Siri, Google Home, Alexa) in our living rooms and
kitchens. As a result of this, these devices receive several queries about
recipes. All these queries will contain terms relating to a "recipe-domain"
i.e: they will contain dish-names, ingredients, cooking times, dietary
preferences etc. Extracting these recipe-relevant aspects from the query thus
becomes important when it comes to addressing the user's information need. Our
project focuses on extracting ingredients from such plain-text user utterances.
Our best performing model was a fine-tuned BERT which achieved an F1-score of
$95.01$. We have released all our code in a GitHub repository.

### Title: Intermittency of turbulent velocity and scalar fields using 3D local averaging
* Paper ID: 2204.08132v1
* Paper URL: [http://arxiv.org/abs/2204.08132v1](http://arxiv.org/abs/2204.08132v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: An efficient approach for extracting 3D local averages in spherical
subdomains is proposed and applied to study the intermittency of small-scale
velocity and scalar fields in direct numerical simulations of isotropic
turbulence. We focus on the inertial-range scaling exponents of locally
averaged energy dissipation rate, enstrophy and scalar dissipation rate
corresponding to the mixing of a passive scalar $\theta$ in the presence of a
uniform mean gradient. The Taylor-scale Reynolds number $R_\lambda$ goes up to
$1300$, and the Schmidt number $Sc$ up to $512$ (albeit at smaller
$R_\lambda$). The intermittency exponent of the energy dissipation rate is $\mu
\approx 0.23$, whereas that of enstrophy is slightly larger; trends with
$R_\lambda$ suggest that this will be the case even at extremely large
$R_\lambda$. The intermittency exponent of the scalar dissipation rate is
$\mu_\theta \approx 0.35$ for $Sc=1$. These findings are in essential agreement
with previously reported results in the literature. We further show that
$\mu_\theta$ decreases monotonically with increasing $Sc$, either as $1/\log
Sc$ or a weak power law, suggesting that $\mu_\theta \to 0$ as $Sc \to \infty$,
reaffirming recent results on the breakdown of scalar dissipation anomaly in
this limit.

### Title: Less is More: Learning to Refine Dialogue History for Personalized Dialogue Generation
* Paper ID: 2204.08128v1
* Paper URL: [http://arxiv.org/abs/2204.08128v1](http://arxiv.org/abs/2204.08128v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Personalized dialogue systems explore the problem of generating responses
that are consistent with the user's personality, which has raised much
attention in recent years. Existing personalized dialogue systems have tried to
extract user profiles from dialogue history to guide personalized response
generation. Since the dialogue history is usually long and noisy, most existing
methods truncate the dialogue history to model the user's personality. Such
methods can generate some personalized responses, but a large part of dialogue
history is wasted, leading to sub-optimal performance of personalized response
generation. In this work, we propose to refine the user dialogue history on a
large scale, based on which we can handle more dialogue history and obtain more
abundant and accurate persona information. Specifically, we design an MSP model
which consists of three personal information refiners and a personalized
response generator. With these multi-level refiners, we can sparsely extract
the most valuable information (tokens) from the dialogue history and leverage
other similar users' data to enhance personalization. Experimental results on
two real-world datasets demonstrate the superiority of our model in generating
more informative and personalized responses.

