# extraction

## 04-20

### Title: Constraining spontaneous black hole scalarization in scalar-tensor-Gauss-Bonnet theories with current gravitational-wave data
* Paper ID: 2204.09038v1
* Paper URL: [http://arxiv.org/abs/2204.09038v1](http://arxiv.org/abs/2204.09038v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: We examine the constraining power of current gravitational-wave data on
scalar-tensor-Gauss-Bonnet theories that allow for the spontaneous
scalarization of black holes. In the fiducial model that we consider, a slowly
rotating black hole must scalarize if its size is comparable to the new length
scale $\lambda$ that the theory introduces, although rapidly rotating black
holes of any mass are effectively indistinguishable from their counterparts in
general relativity. With this in mind, we use the gravitational-wave event
GW190814$\,\unicode{x2014}\,$whose primary black hole has a spin that is
bounded to be small, and whose signal shows no evidence of a scalarized
primary$\,\unicode{x2014}\,$to rule out a narrow region of the parameter space.
In particular, we find that values of ${\lambda \in [56, 96]~M_\odot}$ are
strongly disfavored with a Bayes factor of $0.1$ or less. We also include a
second event, GW151226, in our analysis to illustrate what information can be
extracted when the spins of both components are poorly measured.

### Title: Per-clip adaptive Lagrangian multiplier optimisation with low-resolution proxies
* Paper ID: 2204.08966v1
* Paper URL: [http://arxiv.org/abs/2204.08966v1](http://arxiv.org/abs/2204.08966v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: This work focuses on reducing the computational cost of repeated video
encodes by using a lower resolution clip as a proxy. Features extracted from
the low resolution clip are used to learn an optimal lagrange multiplier for
rate control on the original resolution clip. In addition to reducing the
computational cost and encode time by using lower resolution clips, we also
investigate the use of older, but faster codecs such as H.264 to create
proxies. This work shows that the computational load is reduced by 22 times
using 144p proxies. Our tests are based on the YouTube UGC dataset, hence our
results are based on a practical instance of the adaptive bitrate encoding
problem. Further improvements are possible, by optimising the placement and
sparsity of operating points required for the rate distortion curves.

### Title: Adaptive measurement filter: efficient strategy for optimal estimation of quantum Markov chains
* Paper ID: 2204.08964v1
* Paper URL: [http://arxiv.org/abs/2204.08964v1](http://arxiv.org/abs/2204.08964v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Continuous-time measurements are instrumental for a multitude of tasks in
quantum engineering and quantum control, including the estimation of dynamical
parameters of open quantum systems monitored through the environment. However,
such measurements do not extract the maximum amount of information available in
the output state, so finding alternative optimal measurement strategies is a
major open problem.
  In this paper we solve this problem in the setting of discrete-time
input-output quantum Markov chains. We present an efficient algorithm for
optimal estimation of one-dimensional dynamical parameters which consists of an
iterative procedure for updating a `measurement filter' operator and
determining successive measurement bases for the output units. A key ingredient
of the scheme is the use of a coherent quantum absorber as a way to
post-process the output after the interaction with the system. This is designed
adaptively such that the joint system and absorber stationary state is pure at
a reference parameter value. The scheme offers an exciting prospect for optimal
continuous-time adaptive measurements, but more work is needed to find
realistic practical implementations.

### Title: MANIQA: Multi-dimension Attention Network for No-Reference Image Quality Assessment
* Paper ID: 2204.08958v1
* Paper URL: [http://arxiv.org/abs/2204.08958v1](http://arxiv.org/abs/2204.08958v1)
* Updated Date: 2022-04-19
* Code URL: [https://github.com/iigroup/maniqa](https://github.com/iigroup/maniqa)
* Summary: No-Reference Image Quality Assessment (NR-IQA) aims to assess the perceptual
quality of images in accordance with human subjective perception.
Unfortunately, existing NR-IQA methods are far from meeting the needs of
predicting accurate quality scores on GAN-based distortion images. To this end,
we propose Multi-dimension Attention Network for no-reference Image Quality
Assessment (MANIQA) to improve the performance on GAN-based distortion. We
firstly extract features via ViT, then to strengthen global and local
interactions, we propose the Transposed Attention Block (TAB) and the Scale
Swin Transformer Block (SSTB). These two modules apply attention mechanisms
across the channel and spatial dimension, respectively. In this
multi-dimensional manner, the modules cooperatively increase the interaction
among different regions of images globally and locally. Finally, a dual branch
structure for patch-weighted quality prediction is applied to predict the final
score depending on the weight of each patch's score. Experimental results
demonstrate that MANIQA outperforms state-of-the-art methods on four standard
datasets (LIVE, TID2013, CSIQ, and KADID-10K) by a large margin. Besides, our
method ranked first place in the final testing phase of the NTIRE 2022
Perceptual Image Quality Assessment Challenge Track 2: No-Reference. Codes and
models are available at https://github.com/IIGROUP/MANIQA.

### Title: Seculator: A Fast and Secure Neural Processing Unit
* Paper ID: 2204.08951v1
* Paper URL: [http://arxiv.org/abs/2204.08951v1](http://arxiv.org/abs/2204.08951v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Securing deep neural networks (DNNs) is a problem of significant interest
since an ML model incorporates high-quality intellectual property, features of
data sets painstakingly collated by mechanical turks, and novel methods of
training on large cluster computers. Sadly, attacks to extract model parameters
are on the rise, and thus designers are being forced to create architectures
for securing such models. State-of-the-art proposals in this field take the
deterministic memory access patterns of such networks into cognizance (albeit
partially), group a set of memory blocks into a tile, and maintain state at the
level of tiles (to reduce storage space). For providing integrity guarantees
(tamper avoidance), they don't propose any significant optimizations, and still
maintain block-level state.
  We observe that it is possible to exploit the deterministic memory access
patterns of DNNs even further, and maintain state information for only the
current tile and current layer, which may comprise a large number of tiles.
This reduces the storage space, reduces the number of memory accesses,
increases performance, and simplifies the design without sacrificing any
security guarantees. The key techniques in our proposed accelerator
architecture, Seculator, are to encode memory access patterns to create a small
HW-based tile version number generator for a given layer, and to store
layer-level MACs. We completely eliminate the need for having a MAC cache and a
tile version number store (as used in related work). We show that using
intelligently-designed mathematical operations, these structures are not
required. By reducing such overheads, we show a speedup of 16% over the closest
competing work.

### Title: Global-and-Local Collaborative Learning for Co-Salient Object Detection
* Paper ID: 2204.08917v1
* Paper URL: [http://arxiv.org/abs/2204.08917v1](http://arxiv.org/abs/2204.08917v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: The goal of co-salient object detection (CoSOD) is to discover salient
objects that commonly appear in a query group containing two or more relevant
images. Therefore, how to effectively extract inter-image correspondence is
crucial for the CoSOD task. In this paper, we propose a global-and-local
collaborative learning architecture, which includes a global correspondence
modeling (GCM) and a local correspondence modeling (LCM) to capture
comprehensive inter-image corresponding relationship among different images
from the global and local perspectives. Firstly, we treat different images as
different time slices and use 3D convolution to integrate all intra features
intuitively, which can more fully extract the global group semantics. Secondly,
we design a pairwise correlation transformation (PCT) to explore similarity
correspondence between pairwise images and combine the multiple local pairwise
correspondences to generate the local inter-image relationship. Thirdly, the
inter-image relationships of the GCM and LCM are integrated through a
global-and-local correspondence aggregation (GLA) module to explore more
comprehensive inter-image collaboration cues. Finally, the intra- and
inter-features are adaptively integrated by an intra-and-inter weighting fusion
(AEWF) module to learn co-saliency features and predict the co-saliency map.
The proposed GLNet is evaluated on three prevailing CoSOD benchmark datasets,
demonstrating that our model trained on a small dataset (about 3k images) still
outperforms eleven state-of-the-art competitors trained on some large datasets
(about 8k-200k images).

### Title: Self-Calibrated Efficient Transformer for Lightweight Super-Resolution
* Paper ID: 2204.08913v1
* Paper URL: [http://arxiv.org/abs/2204.08913v1](http://arxiv.org/abs/2204.08913v1)
* Updated Date: 2022-04-19
* Code URL: [https://github.com/alexzou14/scet](https://github.com/alexzou14/scet)
* Summary: Recently, deep learning has been successfully applied to the single-image
super-resolution (SISR) with remarkable performance. However, most existing
methods focus on building a more complex network with a large number of layers,
which can entail heavy computational costs and memory storage. To address this
problem, we present a lightweight Self-Calibrated Efficient Transformer (SCET)
network to solve this problem. The architecture of SCET mainly consists of the
self-calibrated module and efficient transformer block, where the
self-calibrated module adopts the pixel attention mechanism to extract image
features effectively. To further exploit the contextual information from
features, we employ an efficient transformer to help the network obtain similar
features over long distances and thus recover sufficient texture details. We
provide comprehensive results on different settings of the overall network. Our
proposed method achieves more remarkable performance than baseline methods. The
source code and pre-trained models are available at
https://github.com/AlexZou14/SCET.

### Title: Adaptable Semantic Compression and Resource Allocation for Task-Oriented Communications
* Paper ID: 2204.08910v1
* Paper URL: [http://arxiv.org/abs/2204.08910v1](http://arxiv.org/abs/2204.08910v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Task-oriented communication is a new paradigm that aims at providing
efficient connectivity for accomplishing intelligent tasks rather than the
reception of every transmitted bit. In this paper, a deep learning-based
task-oriented communication architecture is proposed where the user extracts,
compresses and transmits semantics in an end-to-end (E2E) manner. Furthermore,
an approach is proposed to compress the semantics according to their importance
relevant to the task, namely, adaptable semantic compression (ASC). Assuming a
delay-intolerant system, supporting multiple users indicates a problem that
executing with the higher compression ratio requires fewer channel resources
but leads to the distortion of semantics, while executing with the lower
compression ratio requires more channel resources and thus may lead to a
transmission failure due to delay constraint. To solve the problem, both
compression ratio and resource allocation are optimized for the task-oriented
communication system to maximize the success probability of tasks.
Specifically, due to the nonconvexity of the problem, we propose a compression
ratio and resource allocation (CRRA) algorithm by separating the problem into
two subproblems and solving iteratively to obtain the convergent solution.
Furthermore, considering the scenarios where users have various service levels,
a compression ratio, resource allocation, and user selection (CRRAUS) algorithm
is proposed to deal with the problem. In CRRAUS, users are adaptively selected
to complete the corresponding intelligent tasks based on branch and bound
method at the expense of higher algorithm complexity compared with CRRA.
Simulation results show that the proposed CRRA and CRRAUS algorithms can obtain
at least 15% and 10% success gains over baseline algorithms, respectively.

### Title: Distributional Transform Based Information Reconciliation
* Paper ID: 2204.08891v1
* Paper URL: [http://arxiv.org/abs/2204.08891v1](http://arxiv.org/abs/2204.08891v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: In this paper we present an information reconciliation protocol designed for
Continuous-Variable QKD using the Distributional Transform. By combining tools
from copula and information theories, we present a method for extracting
independent symmetric Bernoulli bits for Gaussian modulated CVQKD protocols,
which we called the Distributional Transform Expansion (DTE). We derived the
expressions for the maximum reconciliation efficiency for both homodyne and
heterodyne measurement, which, for the last one, efficiency greater than 0.9 is
achievable at signal to noise ratio lower than -3.6 dB

### Title: Cross-Lingual Phrase Retrieval
* Paper ID: 2204.08887v1
* Paper URL: [http://arxiv.org/abs/2204.08887v1](http://arxiv.org/abs/2204.08887v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Cross-lingual retrieval aims to retrieve relevant text across languages.
Current methods typically achieve cross-lingual retrieval by learning
language-agnostic text representations in word or sentence level. However, how
to learn phrase representations for cross-lingual phrase retrieval is still an
open problem. In this paper, we propose XPR, a cross-lingual phrase retriever
that extracts phrase representations from unlabeled example sentences.
Moreover, we create a large-scale cross-lingual phrase retrieval dataset, which
contains 65K bilingual phrase pairs and 4.2M example sentences in 8
English-centric language pairs. Experimental results show that XPR outperforms
state-of-the-art baselines which utilize word-level or sentence-level
representations. XPR also shows impressive zero-shot transferability that
enables the model to perform retrieval in an unseen language pair during
training. Our dataset, code, and trained models are publicly available at
www.github.com/cwszz/XPR/.

### Title: Antipatterns in Software Classification Taxonomies
* Paper ID: 2204.08880v1
* Paper URL: [http://arxiv.org/abs/2204.08880v1](http://arxiv.org/abs/2204.08880v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Empirical results in software engineering have long started to show that
findings are unlikely to be applicable to all software systems, or any domain:
results need to be evaluated in specified contexts, and limited to the type of
systems that they were extracted from. This is a known issue, and requires the
establishment of a classification of software types.
  This paper makes two contributions: the first is to evaluate the quality of
the current software classifications landscape. The second is to perform a case
study showing how to create a classification of software types using a curated
set of software systems.
  Our contributions show that existing, and very likely even new,
classification attempts are deemed to fail for one or more issues, that we
named as the `antipatterns' of software classification tasks. We collected 7 of
these antipatterns that emerge from both our case study, and the existing
classifications.
  These antipatterns represent recurring issues in a classification, so we
discuss practical ways to help researchers avoid these pitfalls. It becomes
clear that classification attempts must also face the daunting task of
formulating a taxonomy of software types, with the objective of establishing a
hierarchy of categories in a classification.

### Title: Core Box Image Recognition and its Improvement with a New Augmentation Technique
* Paper ID: 2204.08853v1
* Paper URL: [http://arxiv.org/abs/2204.08853v1](http://arxiv.org/abs/2204.08853v1)
* Updated Date: 2022-04-19
* Code URL: [https://github.com/beeugene/templateartification](https://github.com/beeugene/templateartification)
* Summary: Most methods for automated full-bore rock core image analysis (description,
colour, properties distribution, etc.) are based on separate core column
analyses. The core is usually imaged in a box because of the significant amount
of time taken to get an image for each core column. The work presents an
innovative method and algorithm for core columns extraction from core boxes.
The conditions for core boxes imaging may differ tremendously. Such differences
are disastrous for machine learning algorithms which need a large dataset
describing all possible data variations. Still, such images have some standard
features - a box and core. Thus, we can emulate different environments with a
unique augmentation described in this work. It is called template-like
augmentation (TLA). The method is described and tested on various environments,
and results are compared on an algorithm trained on both 'traditional' data and
a mix of traditional and TLA data. The algorithm trained with TLA data provides
better metrics and can detect core on most new images, unlike the algorithm
trained on data without TLA. The algorithm for core column extraction
implemented in an automated core description system speeds up the core box
processing by a factor of 20.

### Title: C(X) determines X -- an inherent theory
* Paper ID: 2204.08833v1
* Paper URL: [http://arxiv.org/abs/2204.08833v1](http://arxiv.org/abs/2204.08833v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: One of the fundamental problem in rings of continuous function is to extract
those spaces for which C(X) determines X, that is to investigate X and Y such
that C(X) isomorphic with C(Y ) implies X homeomorphic with Y . The development
started back from Tychono? who first pointed out inevitability of Tychono?
space in this category of problem. Later S.Banach and M. Stone proved
independently with slight variance, that if X is compact Hausdor? space, C(X)
also determine X. Their works were maximally extended by E. Hewitt by
introducing realcompact spaces and later Melvin Henriksen and Biswajit Mitra
solved the problem for locally compact and nearly realcompact spaces. In this
paper we tried to develop an inherent theory of this problem to cover up all
the works in the literature introducing a notion so called P-compact spaces.

### Title: Coulomb-Nuclear Interference: Theory and Practice for pp-Scattering at 13 TeV
* Paper ID: 2204.08815v1
* Paper URL: [http://arxiv.org/abs/2204.08815v1](http://arxiv.org/abs/2204.08815v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: We provide a detailed reconsideration of the theoretical basis for the
treatment of Coulomb-nuclear interference (CNI) and a corresponding thorough
analysis of the procedure of extraction of the basic parameters $\rho^{~pp},
\sigma_{tot}^{~pp}$ and $B^{~pp}$ from the TOTEM data at $\sqrt{s} = 13$ TeV. A
more substantiated account of CNI, as well as an in-depth statistical analysis
of the TOTEM data at low transferred momenta, give results that differ from
those published by the TOTEM collaboration.

### Title: SmartSales: Sales Script Extraction and Analysis from Sales Chatlog
* Paper ID: 2204.08811v1
* Paper URL: [http://arxiv.org/abs/2204.08811v1](http://arxiv.org/abs/2204.08811v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: In modern sales applications, automatic script extraction and management
greatly decrease the need for human labor to collect the winning sales scripts,
which largely boost the success rate for sales and can be shared across the
sales teams. In this work, we present the SmartSales system to serve both the
sales representatives and managers to attain the sales insights from the
large-scale sales chatlog. SmartSales consists of three modules: 1) Customer
frequently asked questions (FAQ) extraction aims to enrich the FAQ knowledge
base by harvesting high quality customer question-answer pairs from the
chatlog. 2) Customer objection response assists the salespeople to figure out
the typical customer objections and corresponding winning sales scripts, as
well as search for proper sales responses for a certain customer objection. 3)
Sales manager dashboard helps sales managers to monitor whether a specific
sales representative or team follows the sales standard operating procedures
(SOP). The proposed prototype system is empowered by the state-of-the-art
conversational intelligence techniques and has been running on the Tencent
Cloud to serve the sales teams from several different areas.

### Title: Two-Stream Graph Convolutional Network for Intra-oral Scanner Image Segmentation
* Paper ID: 2204.08797v1
* Paper URL: [http://arxiv.org/abs/2204.08797v1](http://arxiv.org/abs/2204.08797v1)
* Updated Date: 2022-04-19
* Code URL: [https://github.com/zhanglingming1/tsgcnet](https://github.com/zhanglingming1/tsgcnet)
* Summary: Precise segmentation of teeth from intra-oral scanner images is an essential
task in computer-aided orthodontic surgical planning. The state-of-the-art deep
learning-based methods often simply concatenate the raw geometric attributes
(i.e., coordinates and normal vectors) of mesh cells to train a single-stream
network for automatic intra-oral scanner image segmentation. However, since
different raw attributes reveal completely different geometric information, the
naive concatenation of different raw attributes at the (low-level) input stage
may bring unnecessary confusion in describing and differentiating between mesh
cells, thus hampering the learning of high-level geometric representations for
the segmentation task. To address this issue, we design a two-stream graph
convolutional network (i.e., TSGCN), which can effectively handle inter-view
confusion between different raw attributes to more effectively fuse their
complementary information and learn discriminative multi-view geometric
representations. Specifically, our TSGCN adopts two input-specific
graph-learning streams to extract complementary high-level geometric
representations from coordinates and normal vectors, respectively. Then, these
single-view representations are further fused by a self-attention module to
adaptively balance the contributions of different views in learning more
discriminative multi-view representations for accurate and fully automatic
tooth segmentation. We have evaluated our TSGCN on a real-patient dataset of
dental (mesh) models acquired by 3D intraoral scanners. Experimental results
show that our TSGCN significantly outperforms state-of-the-art methods in 3D
tooth (surface) segmentation. Github:
https://github.com/ZhangLingMing1/TSGCNet.

### Title: Enhancing CTR Prediction with Context-Aware Feature Representation Learning
* Paper ID: 2204.08758v1
* Paper URL: [http://arxiv.org/abs/2204.08758v1](http://arxiv.org/abs/2204.08758v1)
* Updated Date: 2022-04-19
* Code URL: [https://github.com/frnetnetwork/frnet](https://github.com/frnetnetwork/frnet)
* Summary: CTR prediction has been widely used in the real world. Many methods model
feature interaction to improve their performance. However, most methods only
learn a fixed representation for each feature without considering the varying
importance of each feature under different contexts, resulting in inferior
performance. Recently, several methods tried to learn vector-level weights for
feature representations to address the fixed representation issue. However,
they only produce linear transformations to refine the fixed feature
representations, which are still not flexible enough to capture the varying
importance of each feature under different contexts. In this paper, we propose
a novel module named Feature Refinement Network (FRNet), which learns
context-aware feature representations at bit-level for each feature in
different contexts. FRNet consists of two key components: 1) Information
Extraction Unit (IEU), which captures contextual information and cross-feature
relationships to guide context-aware feature refinement; and 2) Complementary
Selection Gate (CSGate), which adaptively integrates the original and
complementary feature representations learned in IEU with bit-level weights.
Notably, FRNet is orthogonal to existing CTR methods and thus can be applied in
many existing methods to boost their performance. Comprehensive experiments are
conducted to verify the effectiveness, efficiency, and compatibility of FRNet.

### Title: Near K-Edge Photoionization and Photoabsorption of Singly, Doubly, and Triply Charged Silicon Ions
* Paper ID: 2204.08750v1
* Paper URL: [http://arxiv.org/abs/2204.08750v1](http://arxiv.org/abs/2204.08750v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Experimental and theoretical results are presented for double, triple, and
quadruple photoionization of Si$^+$ and Si$^{2+}$ ions and for double
photoionization of Si$^{3+}$ ions by a single photon. The experiments employed
the photon-ion merged-beams technique at a synchrotron light source. The
experimental photon-energy range 1835--1900 eV comprises resonances associated
with the excitation of a $1s$ electron to higher subshells and subsequent
autoionization. Energies, widths, and strengths of these resonances are
extracted from high-resolution photoionization measurements, and the core-hole
lifetime of K-shell ionized neutral silicon is inferred. In addition,
theoretical cross sections for photoabsorption and multiple photoionization
were obtained from large-scale Multi-Configuration Dirac-Hartree-Fock (MCDHF)
calculations. The present calculations agree with the experiment much better
than previously published theoretical results. The importance of an accurate
energy calibration of laboratory data is pointed out. The present benchmark
results are particularly useful for discriminating between silicon absorption
in the gaseous and in the solid component (dust grains) of the interstellar
medium.

### Title: Multi-View Spatial-Temporal Network for Continuous Sign Language Recognition
* Paper ID: 2204.08747v1
* Paper URL: [http://arxiv.org/abs/2204.08747v1](http://arxiv.org/abs/2204.08747v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Sign language is a beautiful visual language and is also the primary language
used by speaking and hearing-impaired people. However, sign language has many
complex expressions, which are difficult for the public to understand and
master. Sign language recognition algorithms will significantly facilitate
communication between hearing-impaired people and normal people. Traditional
continuous sign language recognition often uses a sequence learning method
based on Convolutional Neural Network (CNN) and Long Short-Term Memory Network
(LSTM). These methods can only learn spatial and temporal features separately,
which cannot learn the complex spatial-temporal features of sign language. LSTM
is also difficult to learn long-term dependencies. To alleviate these problems,
this paper proposes a multi-view spatial-temporal continuous sign language
recognition network. The network consists of three parts. The first part is a
Multi-View Spatial-Temporal Feature Extractor Network (MSTN), which can
directly extract the spatial-temporal features of RGB and skeleton data; the
second is a sign language encoder network based on Transformer, which can learn
long-term dependencies; the third is a Connectionist Temporal Classification
(CTC) decoder network, which is used to predict the whole meaning of the
continuous sign language. Our algorithm is tested on two public sign language
datasets SLR-100 and PHOENIX-Weather 2014T (RWTH). As a result, our method
achieves excellent performance on both datasets. The word error rate on the
SLR-100 dataset is 1.9%, and the word error rate on the RWTHPHOENIX-Weather
dataset is 22.8%.

### Title: Scaling relations of z~0.25-1.5 galaxies in various environments from the morpho-kinematic analysis of the MAGIC sample
* Paper ID: 2204.08724v1
* Paper URL: [http://arxiv.org/abs/2204.08724v1](http://arxiv.org/abs/2204.08724v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: The evolution of galaxies is influenced by many physical processes which may
vary depending on their environment. We combine Hubble Space Telescope (HST)
and Multi-Unit Spectroscopic Explorer (MUSE) data of galaxies at 0.25<z<1.5 to
probe the impact of environment on the size-mass relation, the Main Sequence
(MS) and the Tully-Fisher relation (TFR).
  We perform a morpho-kinematic modelling of 593 [Oii] emitters in various
environments in the COSMOS area from the MUSE-gAlaxy Groups In Cosmos (MAGIC)
survey. The HST F814W images are modelled with a bulge-disk decomposition to
estimate their bulge-disk ratio, effective radius and disk inclination. We use
the [Oii]{\lambda}{\lambda}3727, 3729 doublet to extract the ionised gas
kinematic maps from the MUSE cubes, and we model them for a sample of 146 [Oii]
emitters, with bulge and disk components constrained from morphology and a dark
matter halo.
  We find an offset of 0.03 dex on the size-mass relation zero point between
the field and the large structure subsamples, with a richness threshold of N=10
to separate between small and large structures, and of 0.06 dex with N=20.
Similarly, we find a 0.1 dex difference on the MS with N=10 and 0.15 dex with
N=20. These results suggest that galaxies in massive structures are smaller by
14% and have star formation rates reduced by a factor of 1.3-1.5 with respect
to field galaxies at z=0.7. Finally, we do not find any impact of the
environment on the TFR, except when using N=20 with an offset of 0.04 dex. We
discard the effect of quenching for the largest structures that would lead to
an offset in the opposite direction. We find that, at z=0.7, if quenching
impacts the mass budget of galaxies in structures, these galaxies would have
been affected quite recently, for roughly 0.7-1.5 Gyr. This result holds when
including the gas mass, but vanishes once we include the asymmetric drift
correction.

### Title: NAFSSR: Stereo Image Super-Resolution Using NAFNet
* Paper ID: 2204.08714v1
* Paper URL: [http://arxiv.org/abs/2204.08714v1](http://arxiv.org/abs/2204.08714v1)
* Updated Date: 2022-04-19
* Code URL: [https://github.com/megvii-research/NAFNet](https://github.com/megvii-research/NAFNet)
* Summary: Stereo image super-resolution aims at enhancing the quality of
super-resolution results by utilizing the complementary information provided by
binocular systems. To obtain reasonable performance, most methods focus on
finely designing modules, loss functions, and etc. to exploit information from
another viewpoint. This has the side effect of increasing system complexity,
making it difficult for researchers to evaluate new ideas and compare methods.
This paper inherits a strong and simple image restoration model, NAFNet, for
single-view feature extraction and extends it by adding cross attention modules
to fuse features between views to adapt to binocular scenarios. The proposed
baseline for stereo image super-resolution is noted as NAFSSR. Furthermore,
training/testing strategies are proposed to fully exploit the performance of
NAFSSR. Extensive experiments demonstrate the effectiveness of our method. In
particular, NAFSSR outperforms the state-of-the-art methods on the KITTI 2012,
KITTI 2015, Middlebury, and Flickr1024 datasets. With NAFSSR, we won 1st place
in the NTIRE 2022 Stereo Image Super-resolution Challenge. Codes and models
will be released at https://github.com/megvii-research/NAFNet.

### Title: Two-level Quantum Walkers on Directed Graphs II: An Application to qRAM
* Paper ID: 2204.08709v1
* Paper URL: [http://arxiv.org/abs/2204.08709v1](http://arxiv.org/abs/2204.08709v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: This is the second paper in a series of two. Using a multi-particle
continuous-time quantum walk with two internal states, which has been
formulated in the first paper (arXiv:2112.08119), we physically implement a
quantum random access memory (qRAM). Data with address information are
dual-rail encoded into quantum walkers. The walkers pass through perfect binary
trees to access the designated memory cells and copy the data stored in the
cells. A roundabout gate allocated at each node serves as a router to move the
walker from the parent node to one of two child nodes, depending on the
internal state of the walker. In this process, the address information is
sequentially encoded into the internal states so that the walkers are
adequately delivered to the target cells. The present qRAM, which processes
$2^n$ $m$-qubit data, is implemented in a quantum circuit of depth
$O(n\log(n+m))$ and requires $O(n+m)$ qubit resources. This is more efficient
than the conventional bucket-brigade qRAM that requires $O(n^2+nm)$ steps and
$O(2^{n}+m)$ qubit resources for processing. Moreover, since the walkers are
not entangled with any device on the binary trees, the cost of maintaining
coherence could be reduced. Notably, by simply passing quantum walkers through
binary trees, data can be automatically extracted in a quantum superposition
state. In other words, any time-dependent control is not required.

### Title: Unsupervised Contrastive Hashing for Cross-Modal Retrieval in Remote Sensing
* Paper ID: 2204.08707v1
* Paper URL: [http://arxiv.org/abs/2204.08707v1](http://arxiv.org/abs/2204.08707v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: The development of cross-modal retrieval systems that can search and retrieve
semantically relevant data across different modalities based on a query in any
modality has attracted great attention in remote sensing (RS). In this paper,
we focus our attention on cross-modal text-image retrieval, where queries from
one modality (e.g., text) can be matched to archive entries from another (e.g.,
image). Most of the existing cross-modal text-image retrieval systems in RS
require a high number of labeled training samples and also do not allow fast
and memory-efficient retrieval. These issues limit the applicability of the
existing cross-modal retrieval systems for large-scale applications in RS. To
address this problem, in this paper we introduce a novel unsupervised
cross-modal contrastive hashing (DUCH) method for text-image retrieval in RS.
To this end, the proposed DUCH is made up of two main modules: 1) feature
extraction module, which extracts deep representations of two modalities; 2)
hashing module that learns to generate cross-modal binary hash codes from the
extracted representations. We introduce a novel multi-objective loss function
including: i) contrastive objectives that enable similarity preservation in
intra- and inter-modal similarities; ii) an adversarial objective that is
enforced across two modalities for cross-modal representation consistency; and
iii) binarization objectives for generating hash codes. Experimental results
show that the proposed DUCH outperforms state-of-the-art methods. Our code is
publicly available at https://git.tu-berlin.de/rsim/duch.

### Title: Multi-shot Solution Prediction for Combinatorial Optimization
* Paper ID: 2204.08700v1
* Paper URL: [http://arxiv.org/abs/2204.08700v1](http://arxiv.org/abs/2204.08700v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: This paper aims to predict optimal solutions for combinatorial optimization
problems (COPs) via machine learning (ML). To find high-quality solutions
efficiently, existing methods use a ML model to predict the optimal solution
and use the ML prediction to guide the search. Prediction of the optimal
solution to sufficient accuracy is critical, however it is challenging due to
the high complexity of COPs. Nevertheless, these existing methods are
single-shot, i.e., predicting the optimal solution only for once. This paper
proposes a framework that enables a ML model to predict the optimal solution in
multiple shots, namely multi-shot solution prediction (MSSP), which can improve
the quality of a ML prediction by harnessing feedback from search.
Specifically, we employ a set of statistical measures as features, to extract
useful information from feasible solutions found by the search method and
inform the ML model as to which value a decision variable is likely to take in
high-quality solutions. Our experiments on three NP-hard COPs show that MSSP
improves the quality of a ML prediction substantially and achieves competitive
results as compared with other search methods in terms of solution quality.
Furthermore, we demonstrate that MSSP can be used as a pricing heuristic for
column generation, to boost a branch-and-price algorithm for solving the graph
coloring problem.

### Title: A generalized echo squeezing protocol with near-Heisenberg limit sensitivity and strong robustness against excess noise and variation in squeezing parameter
* Paper ID: 2204.08681v1
* Paper URL: [http://arxiv.org/abs/2204.08681v1](http://arxiv.org/abs/2204.08681v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: We present a generalized echo squeezing protocol (GESP) as a generalization
of the Schr\"odinger cat state protocol (SCSP) with the value of the squeezing
parameter being an arbitrary number rather than pi/2. We show analytically that
over a broad range of the squeezing parameter the sensitivity reaches the
Heisenberg limit within a factor of root-2. For a large number of particles, N,
this plateau interval is almost the whole range from zero to pi/2, and the
sensitivity is independent of the parity of N. Therefore, it is possible to
operate a sensor over wide interval of the squeezing parameter without changing
the sensitivity. This is to be contrasted with the conventional echo squeezing
protocol (CESP) which only works for a very small interval of the squeezing
parameter. We also show that, in contrast to the CESP, the sensitivity of the
GESP is close to the quantum Cram\'er-Rao bound over the whole range of the
squeezing parameter, indicating that the phase shift information is
near-optimally extracted. We find that the enhancement in sensitivity in the
case of the GESP is due to a combination of two parameters: the phase
magnification (PMF) and the noise amplification factor (NAF). As the value of
the squeezing parameter increases, both PMF and NAF increase, while keeping the
ratio of PMF/NAF essentially constant, yielding a net enhancement of
sensitivity that at the Heisenberg limit within a factor of root-2 over the
whole plateau interval. An important consequence of this behavior is that the
robustness of the GESP against excess noise easily exceeds that of the CESP for
a broad range of values of the squeezing parameter. As such, in the context of
an experimental study, it should be possible to achieve a net enhancement in
sensitivity higher than that for the CESP, under typical conditions where the
excess noise exceeds the unsqueezed quantum projection noise.

### Title: The Electromagnetic Characteristics of the Tianlai Cylindrical Pathfinder Array
* Paper ID: 2204.08632v1
* Paper URL: [http://arxiv.org/abs/2204.08632v1](http://arxiv.org/abs/2204.08632v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: A great challenge for 21 cm intensity mapping experiments is the strong
foreground radiation which is orders of magnitude brighter than the 21cm
signal. Removal of the foreground takes advantage of the fact that its
frequency spectrum is smooth while the redshifted 21cm signal spectrum is
stochastic. However, a complication is the non-smoothness of the instrument
response. This paper describes the electromagnetic simulation of the Tianlai
cylinder array, a pathfinder for 21 cm intensity mapping experiments. Due to
the vast scales involved, a direct simulation requires large amount of
computing resources. We have made the simulation practical by using a
combination of methods: first simulate a single feed, then an array of feed
units, finally with the feed array and a cylindrical reflector together, to
obtain the response for a single cylinder. We studied its radiation pattern,
bandpass response and the effects of mutual coupling between feed units, and
compared the results with observation. Many features seen in the measurement
result are well reproduced in the simulation, especially the oscillatory
features which are associated with the standing waves on the reflector. The
mutual coupling between feed units is quantified with S-parameters, which
decrease as the distance between the two feeds increases. Based on the
simulated S-parameters, we estimate the correlated noise which has been seen in
the visibility data, the results show very good agreement with the data in both
magnitude and frequency structures. These results provide useful insights on
the problem of 21cm signal extraction for real instruments.

### Title: A Subject-Independent Brain-Computer Interface Framework Based on Supervised Autoencoder
* Paper ID: 2204.08626v1
* Paper URL: [http://arxiv.org/abs/2204.08626v1](http://arxiv.org/abs/2204.08626v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: A calibration procedure is required in motor imagery-based brain-computer
interface (MI-BCI) to tune the system for new users. This procedure is
time-consuming and prevents na\"ive users from using the system immediately.
Developing a subject-independent MI-BCI system to reduce the calibration phase
is still challenging due to the subject-dependent characteristics of the MI
signals. Many algorithms based on machine learning and deep learning have been
developed to extract high-level features from the MI signals to improve the
subject-to-subject generalization of a BCI system. However, these methods are
based on supervised learning and extract features useful for discriminating
various MI signals. Hence, these approaches cannot find the common underlying
patterns in the MI signals and their generalization level is limited. This
paper proposes a subject-independent MI-BCI based on a supervised autoencoder
(SAE) to circumvent the calibration phase. The suggested framework is validated
on dataset 2a from BCI competition IV. The simulation results show that our
SISAE model outperforms the conventional and widely used BCI algorithms, common
spatial and filter bank common spatial patterns, in terms of the mean Kappa
value, in eight out of nine subjects.

### Title: Is the Contralateral Delay Activity (CDA) a robust neural correlate for Visual Working Memory (VWM) tasks? A reproducibility study
* Paper ID: 2204.08578v1
* Paper URL: [http://arxiv.org/abs/2204.08578v1](http://arxiv.org/abs/2204.08578v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Visual working memory (VWM) allows us to actively store, update and
manipulate visual information surrounding us. While the underlying neural
mechanisms of VWM remain unclear, contralateral delay activity (CDA), a
sustained negativity over the hemisphere contralateral to the positions of
visual items to be remembered, is often used to study VWM. To investigate if
the CDA is a robust neural correlate for VWM tasks, we reproduced eight
CDA-related studies with a publicly accessible EEG dataset. We used the raw EEG
data from these eight studies and analyzed all of them with the same basic
pipeline to extract CDA. We were able to reproduce the results from all the
studies and show that with a basic automated EEG pipeline we can extract a
clear CDA signal. We share insights from the trends observed across the studies
and raise some questions about the CDA decay and the CDA during the recall
phase, which surprisingly, none of the eight studies did address. Finally, we
also provide reproducibility recommendations based on our experience and
challenges in reproducing these studies.

### Title: Quantum Computation of Hydrogen Bond Dynamics and Vibrational Spectra
* Paper ID: 2204.08571v1
* Paper URL: [http://arxiv.org/abs/2204.08571v1](http://arxiv.org/abs/2204.08571v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Calculating the observable properties of chemical systems is often
classically intractable, and is widely viewed as a promising application of
quantum information processing. This is because a full description of chemical
behavior relies upon the complex interplay of quantum-mechanical electrons and
nuclei, demanding an exponential scaling of computational resources with system
size. While considerable progress has been made in mapping electronic-structure
calculations to quantum hardware, these approaches are unsuitable for
describing the quantum dynamics of nuclei, proton- and hydrogen-transfer
processes, or the vibrational spectra of molecules. Here, we use the QSCOUT
ion-trap quantum computer to determine the quantum dynamics and vibrational
properties of a shared proton within a short-strong hydrogen-bonded system. For
a range of initial states, we experimentally drive the ion-trap system to
emulate the quantum trajectory of the shared proton wavepacket as it evolves
along the potential surface generated by the nuclear frameworks and electronic
structure. We then extract the characteristic vibrational frequencies for the
shared proton motion to spectroscopic accuracy and determine all energy
eigenvalues of the system Hamiltonian to > 99.9% fidelity. Our approach offers
a new paradigm for studying the quantum chemical dynamics and vibrational
spectra of molecules, and when combined with quantum algorithms for electronic
structure, opens the possibility to describe the complete behavior of molecules
using exclusively quantum computation techniques.

### Title: Learning Similarity Preserving Binary Codes for Recommender Systems
* Paper ID: 2204.08569v1
* Paper URL: [http://arxiv.org/abs/2204.08569v1](http://arxiv.org/abs/2204.08569v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Hashing-based Recommender Systems (RSs) are widely studied to provide
scalable services. The existing methods for the systems combine three modules
to achieve efficiency: feature extraction, interaction modeling, and
binarization. In this paper, we study an unexplored module combination for the
hashing-based recommender systems, namely Compact Cross-Similarity Recommender
(CCSR). Inspired by cross-modal retrieval, CCSR utilizes Maximum a Posteriori
similarity instead of matrix factorization and rating reconstruction to model
interactions between users and items. We conducted experiments on MovieLens1M,
Amazon product review, Ichiba purchase dataset and confirmed CCSR outperformed
the existing matrix factorization-based methods. On the Movielens1M dataset,
the absolute performance improvements are up to 15.69% in NDCG and 4.29% in
Recall. In addition, we extensively studied three binarization modules: $sign$,
scaled tanh, and sign-scaled tanh. The result demonstrated that although
differentiable scaled tanh is popular in recent discrete feature learning
literature, a huge performance drop occurs when outputs of scaled $tanh$ are
forced to be binary.

### Title: Automated Audio Captioning using Audio Event Clues
* Paper ID: 2204.08567v1
* Paper URL: [http://arxiv.org/abs/2204.08567v1](http://arxiv.org/abs/2204.08567v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Audio captioning is an important research area that aims to generate
meaningful descriptions for audio clips. Most of the existing research extracts
acoustic features of audio clips as input to encoder-decoder and transformer
architectures to produce the captions in a sequence-to-sequence manner. Due to
data insufficiency and the architecture's inadequate learning capacity,
additional information is needed to generate natural language sentences, as
well as acoustic features. To address these problems, an encoder-decoder
architecture is proposed that learns from both acoustic features and extracted
audio event labels as inputs. The proposed model is based on pre-trained
acoustic features and audio event detection. Various experiments used different
acoustic features, word embedding models, audio event label extraction methods,
and implementation configurations to show which combinations have better
performance on the audio captioning task. Results of the extensive experiments
on multiple datasets show that using audio event labels with the acoustic
features improves the recognition performance and the proposed method either
outperforms or achieves competitive results with the state-of-the-art models.

### Title: Star formation in disk galaxies and its relation with spiral structure in numerical simulations
* Paper ID: 2204.08560v1
* Paper URL: [http://arxiv.org/abs/2204.08560v1](http://arxiv.org/abs/2204.08560v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: The spiral structure of a spiral galaxy can be seen through different
observational tracers such as the dust in the interstellar medium, the free
electrons in ionized regions, the molecular gas, or the atomic hydrogen in
H{\alpha} regions. In this work, we use an N-body simulation with
Magnetohydrodynamics (MHD) to investigate the spiral pattern and the star
formation activity in the gas component of a disk galaxy. Some of the questions
that we tackle include: how are galaxies observed through the different
properties of the gas? Does the spiral structure of the galaxy change when we
trace it with the different properties of the gas? Do the spiral arms in the
simulation change its shape and width depending on what property we are
"looking" through? Can we somehow model the shape of the arms to measure their
width consistently? Does this model apply to all the properties? To answer
these questions, we developed a method for the identification and extraction of
the spiral structure in a disk galaxy. Using the results of this procedure, we
further investigate the features of the spiral pattern through the different
properties of the gas, with special attention to the star formation activity
and how it behaves along and across the spiral structure.

### Title: Correlation between Unconscious Mouse Actions and Human Cognitive Workload
* Paper ID: 2204.08559v1
* Paper URL: [http://arxiv.org/abs/2204.08559v1](http://arxiv.org/abs/2204.08559v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Unconscious behaviors are one of the indicators of the human perception
process from a psychological perspective. As a result of perception responses,
hand gestures show behavioral responses from given stimuli. Mouse usages in
Human-Computer Interaction (HCI) show hand gestures that individuals perceive
information processing. This paper presents an investigation of the correlation
between unconscious mouse actions and human cognitive workload. We extracted
mouse behaviors from a Robot Operating System (ROS) file-based dataset that
user responses are reproducible. We analyzed redundant mouse movements to
complete a dual $n$-back game by solely pressing the left and right buttons.
Starting from a hypothesis that unconscious mouse behaviors predict different
levels of cognitive loads, we statistically analyzed mouse movements. We also
validated mouse behaviors with other modalities in the dataset, including
self-questionnaire and eye blinking results. As a result, we found that mouse
behaviors that occur unconsciously and human cognitive workload correlate.

### Title: Learning to Retrieve Relevant Experiences for Motion Planning
* Paper ID: 2204.08550v1
* Paper URL: [http://arxiv.org/abs/2204.08550v1](http://arxiv.org/abs/2204.08550v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Recent work has demonstrated that motion planners' performance can be
significantly improved by retrieving past experiences from a database.
Typically, the experience database is queried for past similar problems using a
similarity function defined over the motion planning problems. However, to
date, most works rely on simple hand-crafted similarity functions and fail to
generalize outside their corresponding training dataset. To address this
limitation, we propose (FIRE), a framework that extracts local representations
of planning problems and learns a similarity function over them. To generate
the training data we introduce a novel self-supervised method that identifies
similar and dissimilar pairs of local primitives from past solution paths. With
these pairs, a Siamese network is trained with the contrastive loss and the
similarity function is realized in the network's latent space. We evaluate FIRE
on an 8-DOF manipulator in five categories of motion planning problems with
sensed environments. Our experiments show that FIRE retrieves relevant
experiences which can informatively guide sampling-based planners even in
problems outside its training distribution, outperforming other baselines.

### Title: Influence of the presence of multiple resonances on material parameter determination using broadband ferromagnetic resonance spectroscopy
* Paper ID: 2204.08500v1
* Paper URL: [http://arxiv.org/abs/2204.08500v1](http://arxiv.org/abs/2204.08500v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: The influence of the presence of multiple resonances in ferromagnetic
resonance spectra on extracted material parameters is investigated using
numerical simulations. Our results show that the systematic error of assuming
an incorrect number of resonances for a material can lead to the extraction of
material parameters that significantly deviate from any of the true material
parameters. When noise is present in experimental ferromagnetic resonance
spectra increasing the frequency range of the broadband characterization can
significantly reduce the error-margins when the data is analyzed assuming the
correct number of resonances present in the material. For the cases
investigated in this study it was found that analyzing the data using a single
resonance results in extracted gyromagnetic ratios and effective magnetization
parameters that are consistent with the weighted average of the true material
parameters. We further provide a cautionary example regarding the extraction of
the inhomogeneous linewidth broadening and damping parameters of materials that
contain an unknown number of resonances.

### Title: Exploring Dimensionality Reduction Techniques in Multilingual Transformers
* Paper ID: 2204.08415v1
* Paper URL: [http://arxiv.org/abs/2204.08415v1](http://arxiv.org/abs/2204.08415v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Both in scientific literature and in industry,, Semantic and context-aware
Natural Language Processing-based solutions have been gaining importance in
recent years. The possibilities and performance shown by these models when
dealing with complex Language Understanding tasks is unquestionable, from
conversational agents to the fight against disinformation in social networks.
In addition, considerable attention is also being paid to developing
multilingual models to tackle the language bottleneck. The growing need to
provide more complex models implementing all these features has been
accompanied by an increase in their size, without being conservative in the
number of dimensions required. This paper aims to give a comprehensive account
of the impact of a wide variety of dimensional reduction techniques on the
performance of different state-of-the-art multilingual Siamese Transformers,
including unsupervised dimensional reduction techniques such as linear and
nonlinear feature extraction, feature selection, and manifold techniques. In
order to evaluate the effects of these techniques, we considered the
multilingual extended version of Semantic Textual Similarity Benchmark (mSTSb)
and two different baseline approaches, one using the pre-trained version of
several models and another using their fine-tuned STS version. The results
evidence that it is possible to achieve an average reduction in the number of
dimensions of $91.58\% \pm 2.59\%$ and $54.65\% \pm 32.20\%$, respectively.
This work has also considered the consequences of dimensionality reduction for
visualization purposes. The results of this study will significantly contribute
to the understanding of how different tuning approaches affect performance on
semantic-aware tasks and how dimensional reduction techniques deal with the
high-dimensional embeddings computed for the STS task and their potential for
highly demanding NLP tasks

### Title: Robust, Nonparametric, Efficient Decomposition of Spectral Peaks under Distortion and Interference
* Paper ID: 2204.08411v1
* Paper URL: [http://arxiv.org/abs/2204.08411v1](http://arxiv.org/abs/2204.08411v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: We propose a decomposition method for the spectral peaks in an observed
frequency spectrum, which is efficiently acquired by utilizing the Fast Fourier
Transform. In contrast to the traditional methods of waveform fitting on the
spectrum, we optimize the problem from a more robust perspective. We model the
peaks in spectrum as pseudo-symmetric functions, where the only constraint is a
nonincreasing behavior around a central frequency when the distance increases.
Our approach is more robust against arbitrary distortion, interference and
noise on the spectrum that may be caused by an observation system. The time
complexity of our method is linear, i.e., $O(N)$ per extracted spectral peak.
Moreover, the decomposed spectral peaks show a pseudo-orthogonal behavior,
where they conform to a power preserving equality.

### Title: Multiple-environment Self-adaptive Network for Aerial-view Geo-localization
* Paper ID: 2204.08381v1
* Paper URL: [http://arxiv.org/abs/2204.08381v1](http://arxiv.org/abs/2204.08381v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Aerial-view geo-localization tends to determine an unknown position through
matching the drone-view image with the geo-tagged satellite-view image. This
task is mostly regarded as an image retrieval problem. The key underpinning
this task is to design a series of deep neural networks to learn discriminative
image descriptors. However, existing methods meet large performance drops under
realistic weather, such as rain and fog, since they do not take the domain
shift between the training data and multiple test environments into
consideration. To minor this domain gap, we propose a Multiple-environment
Self-adaptive Network (MuSe-Net) to dynamically adjust the domain shift caused
by environmental changing. In particular, MuSe-Net employs a two-branch neural
network containing one multiple-environment style extraction network and one
self-adaptive feature extraction network. As the name implies, the
multiple-environment style extraction network is to extract the
environment-related style information, while the self-adaptive feature
extraction network utilizes an adaptive modulation module to dynamically
minimize the environment-related style gap. Extensive experiments on two
widely-used benchmarks, i.e., University-1652 and CVUSA, demonstrate that the
proposed MuSe-Net achieves a competitive result for geo-localization in
multiple environments. Furthermore, we observe that the proposed method also
shows great potential to the unseen extreme weather, such as mixing the fog,
rain and snow.

### Title: The role of the bile salt surfactant sodium deoxycholate in aqueous two-phase separation of single-wall carbon nanotubes revealed by systematic parameter variations
* Paper ID: 2204.08379v1
* Paper URL: [http://arxiv.org/abs/2204.08379v1](http://arxiv.org/abs/2204.08379v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Aqueous two-phase (ATP) extraction has been demonstrated as a fast, scalable,
and effective separation technique to sort single-wall carbon nanotubes
(SWCNTs) according to their diameter and chiral structure. The exact mechanism
behind the chirality-dependent migration of SWCNTs between the two phases is
however not completely understood, and depends on many parameters (e.g., choice
of surfactants and their concentration, pH, temperature, ...), making it
difficult to optimize the multivariable parameter space. In this work, we
present a systematic study of the choice and concentration of specific
surfactants on the ATP sorting, by performing a series of single-step ATP
separations in which each time only one parameter is systematically varied,
while monitoring the structure-specific migration of every SWCNT chirality
between both phases with detailed wavelength-dependent spectroscopy. These
systematic studies reveal that the diameter-dependent stacking of a discrete
number of sodium deoxycholate molecules fitting around the SWCNT circumference
determines the separation order in the form of a periodically modulated pattern
as a function of SWCNT diameter. Addition of cosurfactants can be used to
compete with the bile salt surfactant to enhance the separation yields, but
does not affect the sorting order. The results are afterwards directly applied
to predict the parameters required to separate specific chiral structures in
just two ATP steps.

### Title: Observing Supernova Neutrino Light Curves with Super-Kamiokande. III. Extraction of Mass and Radius of Neutron Stars from Synthetic Data
* Paper ID: 2204.08363v1
* Paper URL: [http://arxiv.org/abs/2204.08363v1](http://arxiv.org/abs/2204.08363v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Neutrinos are guaranteed to be observable from the next galactic supernova
(SN). Optical light and gravitational waves are also observable, but may be
difficult to observe if the location of the SN in the galaxy or the details of
the explosion are unsuitable. The key to observing the next supernova is to
first use neutrinos to understand various physical quantities and then link
them to other signals. In this paper, we present Monte Carlo sampling
calculations of neutrino events from galactic supernova explosions observed
with Super-Kamiokande. The analytical solution of neutrino emission, which
represents the long-term evolution of neutrino-light curve from supernovae, is
used as a theoretical template. It gives the event rate and event spectrum
through inverse beta decay interactions with explicit model parameter
dependence. Parameter estimation is performed on these simulated sample data by
fitting least squares using the analytical solution. The results show that the
mass, radius and total energy of a remnant neutron star produced by a SN can be
determined with an accuracy of $\sim 0.1M_\odot$, $\sim 1$ km, and $\sim
10^{51}$ erg, respectively, for a galactic SN at 8 kpc.

### Title: Extracting Targeted Training Data from ASR Models, and How to Mitigate It
* Paper ID: 2204.08345v1
* Paper URL: [http://arxiv.org/abs/2204.08345v1](http://arxiv.org/abs/2204.08345v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Recent work has designed methods to demonstrate that model updates in ASR
training can leak potentially sensitive attributes of the utterances used in
computing the updates. In this work, we design the first method to demonstrate
information leakage about training data from trained ASR models. We design
Noise Masking, a fill-in-the-blank style method for extracting targeted parts
of training data from trained ASR models. We demonstrate the success of Noise
Masking by using it in four settings for extracting names from the LibriSpeech
dataset used for training a SOTA Conformer model. In particular, we show that
we are able to extract the correct names from masked training utterances with
11.8% accuracy, while the model outputs some name from the train set 55.2% of
the time. Further, we show that even in a setting that uses synthetic audio and
partial transcripts from the test set, our method achieves 2.5% correct name
accuracy (47.7% any name success rate). Lastly, we design Word Dropout, a data
augmentation method that we show when used in training along with MTR, provides
comparable utility as the baseline, along with significantly mitigating
extraction via Noise Masking across the four evaluated settings.

### Title: One-Loop Hybrid Renormalization Matching Kernels for Quasi-Parton Distributions
* Paper ID: 2204.08343v1
* Paper URL: [http://arxiv.org/abs/2204.08343v1](http://arxiv.org/abs/2204.08343v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Large momentum effective theory allows extraction of hadron parton
distribution functions in lattice QCD by matching them to quark bilinear matrix
elements of hadrons with large momenta. We calculate the matching kernels for
the unpolarized, helicity, and transversity isovector parton distribution
functions and skewless generalized parton distributions of all hadrons in the
hybrid-RI/MOM scheme. This renormalization scheme uses RI/MOM when the Wilson
line length is less then $z_s$, otherwise a mass subtraction scheme is used. By
design, the non-hybrid scheme is recovered as $z_s \to \infty$. In the opposite
limit, $z \to 0$, the self renormalization scheme is obtained. When the
parameters $p_z^R=0$ and $\mu^R z_s \ll 1$, the hybrid-RI/MOM scheme coincides
with the hybrid-ratio scheme times the charge of the PDF. We also discuss the
subtlety related to the commutativity of Fourier transform and $\epsilon$
expansion in the $\overline{\text{MS}}$ scheme.

### Title: BSRT: Improving Burst Super-Resolution with Swin Transformer and Flow-Guided Deformable Alignment
* Paper ID: 2204.08332v1
* Paper URL: [http://arxiv.org/abs/2204.08332v1](http://arxiv.org/abs/2204.08332v1)
* Updated Date: 2022-04-18
* Code URL: [https://github.com/algolzw/bsrt](https://github.com/algolzw/bsrt)
* Summary: This work addresses the Burst Super-Resolution (BurstSR) task using a new
architecture, which requires restoring a high-quality image from a sequence of
noisy, misaligned, and low-resolution RAW bursts. To overcome the challenges in
BurstSR, we propose a Burst Super-Resolution Transformer (BSRT), which can
significantly improve the capability of extracting inter-frame information and
reconstruction. To achieve this goal, we propose a Pyramid Flow-Guided
Deformable Convolution Network (Pyramid FG-DCN) and incorporate Swin
Transformer Blocks and Groups as our main backbone. More specifically, we
combine optical flows and deformable convolutions, hence our BSRT can handle
misalignment and aggregate the potential texture information in multi-frames
more efficiently. In addition, our Transformer-based structure can capture
long-range dependency to further improve the performance. The evaluation on
both synthetic and real-world tracks demonstrates that our approach achieves a
new state-of-the-art in BurstSR task. Further, our BSRT wins the championship
in the NTIRE2022 Burst Super-Resolution Challenge.

### Title: Application of Transfer Learning and Ensemble Learning in Image-level Classification for Breast Histopathology
* Paper ID: 2204.08311v1
* Paper URL: [http://arxiv.org/abs/2204.08311v1](http://arxiv.org/abs/2204.08311v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Background: Breast cancer has the highest prevalence in women globally. The
classification and diagnosis of breast cancer and its histopathological images
have always been a hot spot of clinical concern. In Computer-Aided Diagnosis
(CAD), traditional classification models mostly use a single network to extract
features, which has significant limitations. On the other hand, many networks
are trained and optimized on patient-level datasets, ignoring the application
of lower-level data labels.
  Method: This paper proposes a deep ensemble model based on image-level labels
for the binary classification of benign and malignant lesions of breast
histopathological images. First, the BreakHis dataset is randomly divided into
a training, validation and test set. Then, data augmentation techniques are
used to balance the number of benign and malignant samples. Thirdly,
considering the performance of transfer learning and the complementarity
between each network, VGG-16, Xception, Resnet-50, DenseNet-201 are selected as
the base classifiers.
  Result: In the ensemble network model with accuracy as the weight, the
image-level binary classification achieves an accuracy of $98.90\%$. In order
to verify the capabilities of our method, the latest Transformer and Multilayer
Perception (MLP) models have been experimentally compared on the same dataset.
Our model wins with a $5\%-20\%$ advantage, emphasizing the ensemble model's
far-reaching significance in classification tasks.
  Conclusion: This research focuses on improving the model's classification
performance with an ensemble algorithm. Transfer learning plays an essential
role in small datasets, improving training speed and accuracy. Our model has
outperformed many existing approaches in accuracy, providing a method for the
field of auxiliary medical diagnosis.

### Title: Differentiable Time-Frequency Scattering in Kymatio
* Paper ID: 2204.08269v2
* Paper URL: [http://arxiv.org/abs/2204.08269v2](http://arxiv.org/abs/2204.08269v2)
* Updated Date: 2022-04-19
* Code URL: [https://github.com/rastegah/kymatio-jtfs](https://github.com/rastegah/kymatio-jtfs)
* Summary: Joint time-frequency scattering (JTFS) is a convolutional operator in the
time-frequency domain which extracts spectrotemporal modulations at various
rates and scales. It offers an idealized model of spectrotemporal receptive
fields (STRF) in the primary auditory cortex, and thus may serve as a
biological plausible surrogate for human perceptual judgments at the scale of
isolated audio events. Yet, prior implementations of JTFS and STRF have
remained outside of the standard toolkit of perceptual similarity measures and
evaluation methods for audio generation. We trace this issue down to three
limitations: differentiability, speed, and flexibility. In this paper, we
present an implementation of time-frequency scattering in Kymatio, an
open-source Python package for scattering transforms. Unlike prior
implementations, Kymatio accommodates NumPy and PyTorch as backends and is thus
portable on both CPU and GPU. We demonstrate the usefulness of JTFS in Kymatio
via three applications: unsupervised manifold learning of spectrotemporal
modulations, supervised classification of musical instruments, and texture
resynthesis of bioacoustic sounds.

### Title: Modx: Binary Level Partial Imported Third-Party Library Detection through Program Modularization and Semantic Matching
* Paper ID: 2204.08237v1
* Paper URL: [http://arxiv.org/abs/2204.08237v1](http://arxiv.org/abs/2204.08237v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: With the rapid growth of software, using third-party libraries (TPLs) has
become increasingly popular. The prosperity of the library usage has provided
the software engineers with handful of methods to facilitate and boost the
program development. Unfortunately, it also poses great challenges as it
becomes much more difficult to manage the large volume of libraries. Researches
and studies have been proposed to detect and understand the TPLs in the
software. However, most existing approaches rely on syntactic features, which
are not robust when these features are changed or deliberately hidden by the
adversarial parties. Moreover, these approaches typically model each of the
imported libraries as a whole, therefore, cannot be applied to scenarios where
the host software only partially uses the library code segments.
  To detect both fully and partially imported TPLs at the semantic level, we
propose ModX, a framework that leverages novel program modularization
techniques to decompose the program into finegrained functionality-based
modules. By extracting both syntactic and semantic features, it measures the
distance between modules to detect similar library module reuse in the program.
Experimental results show that ModX outperforms other modularization tools by
distinguishing more coherent program modules with 353% higher module quality
scores and beats other TPL detection tools with on average 17% better in
precision and 8% better in recall.

### Title: Empirical Evaluation and Theoretical Analysis for Representation Learning: A Survey
* Paper ID: 2204.08226v1
* Paper URL: [http://arxiv.org/abs/2204.08226v1](http://arxiv.org/abs/2204.08226v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Representation learning enables us to automatically extract generic feature
representations from a dataset to solve another machine learning task.
Recently, extracted feature representations by a representation learning
algorithm and a simple predictor have exhibited state-of-the-art performance on
several machine learning tasks. Despite its remarkable progress, there exist
various ways to evaluate representation learning algorithms depending on the
application because of the flexibility of representation learning. To
understand the current representation learning, we review evaluation methods of
representation learning algorithms and theoretical analyses. On the basis of
our evaluation survey, we also discuss the future direction of representation
learning. Note that this survey is the extended version of Nozawa and Sato
(2022).

### Title: OMG: Observe Multiple Granularities for Natural Language-Based Vehicle Retrieval
* Paper ID: 2204.08209v1
* Paper URL: [http://arxiv.org/abs/2204.08209v1](http://arxiv.org/abs/2204.08209v1)
* Updated Date: 2022-04-18
* Code URL: [https://github.com/dyhbupt/omg](https://github.com/dyhbupt/omg)
* Summary: Retrieving tracked-vehicles by natural language descriptions plays a critical
role in smart city construction. It aims to find the best match for the given
texts from a set of tracked vehicles in surveillance videos. Existing works
generally solve it by a dual-stream framework, which consists of a text
encoder, a visual encoder and a cross-modal loss function. Although some
progress has been made, they failed to fully exploit the information at various
levels of granularity. To tackle this issue, we propose a novel framework for
the natural language-based vehicle retrieval task, OMG, which Observes Multiple
Granularities with respect to visual representation, textual representation and
objective functions. For the visual representation, target features, context
features and motion features are encoded separately. For the textual
representation, one global embedding, three local embeddings and a color-type
prompt embedding are extracted to represent various granularities of semantic
features. Finally, the overall framework is optimized by a cross-modal
multi-granularity contrastive loss function. Experiments demonstrate the
effectiveness of our method. Our OMG significantly outperforms all previous
methods and ranks the 9th on the 6th AI City Challenge Track2. The codes are
available at https://github.com/dyhBUPT/OMG.

### Title: Phishing Fraud Detection on Ethereum using Graph Neural Network
* Paper ID: 2204.08194v1
* Paper URL: [http://arxiv.org/abs/2204.08194v1](http://arxiv.org/abs/2204.08194v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Blockchain has widespread applications in the financial field but has also
attracted increasing cybercrimes. Recently, phishing fraud has emerged as a
major threat to blockchain security, calling for the development of effective
regulatory strategies. Nowadays network science has been widely used in
modeling Ethereum transaction data, further introducing the network
representation learning technology to analyze the transaction patterns. In this
paper, we consider phishing detection as a graph classification task and
propose an end-to-end Phishing Detection Graph Neural Network framework
(PDGNN). Specifically, we first construct a lightweight Ethereum transaction
network and extract transaction subgraphs of collected phishing accounts. Then
we propose an end-to-end detection model based on Chebyshev-GCN to precisely
distinguish between normal and phishing accounts. Extensive experiments on five
Ethereum datasets demonstrate that our PDGNN significantly outperforms general
phishing detection methods and scales well in large transaction networks.

### Title: Cosmic microwave background spectral distortions from Rayleigh scattering at second order
* Paper ID: 2204.08177v1
* Paper URL: [http://arxiv.org/abs/2204.08177v1](http://arxiv.org/abs/2204.08177v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Cosmic microwave background (CMB) spectral distortion from Rayleigh
scattering is calculated for the first time in rigorous second-order
cosmological perturbation theory. The new spectral distortion is sensitive to
acoustic dissipation at $10^{-2}<k{\rm Mpc}/h<1$, which slightly extends the
scale constrained by the CMB anisotropies. The spectral shape is different from
either temperature perturbations or any other traditional spectral distortions
from Compton scattering, such as $y$ and $\mu$. The new spectral distortion is
not formed in the late Universe, unlike the thermal Sunyaev-Zel'dovich effect
degenerated with the primordial $y$ distortions since photons must be hot for
Rayleigh scattering. Therefore, ideal measurements can distinguish the signal
from the other effects and extract new information during recombination.
Assuming cosmological parameters consistent with the recent CMB anisotropy
measurements, we find the new spectral distortion is $6.5\times 10^{-3}$Jy/str,
which is one order of magnitude smaller than the currently proposed target
sensitivity range of voyage 2050.

### Title: End-to-end Weakly-supervised Multiple 3D Hand Mesh Reconstruction from Single Image
* Paper ID: 2204.08154v1
* Paper URL: [http://arxiv.org/abs/2204.08154v1](http://arxiv.org/abs/2204.08154v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: In this paper, we consider the challenging task of simultaneously locating
and recovering multiple hands from single 2D image. Previous studies either
focus on single hand reconstruction or solve this problem in a multi-stage way.
Moreover, the conventional two-stage pipeline firstly detects hand areas, and
then estimates 3D hand pose from each cropped patch. To reduce the
computational redundancy in preprocessing and feature extraction, we propose a
concise but efficient single-stage pipeline. Specifically, we design a
multi-head auto-encoder structure for multi-hand reconstruction, where each
head network shares the same feature map and outputs the hand center, pose and
texture, respectively. Besides, we adopt a weakly-supervised scheme to
alleviate the burden of expensive 3D real-world data annotations. To this end,
we propose a series of losses optimized by a stage-wise training scheme, where
a multi-hand dataset with 2D annotations is generated based on the publicly
available single hand datasets. In order to further improve the accuracy of the
weakly supervised model, we adopt several feature consistency constraints in
both single and multiple hand settings. Specifically, the keypoints of each
hand estimated from local features should be consistent with the re-projected
points predicted from global features. Extensive experiments on public
benchmarks including FreiHAND, HO3D, InterHand2.6M and RHD demonstrate that our
method outperforms the state-of-the-art model-based methods in both
weakly-supervised and fully-supervised manners.

### Title: AI for human assessment: What do professional assessors need?
* Paper ID: 2204.08471v1
* Paper URL: [http://arxiv.org/abs/2204.08471v1](http://arxiv.org/abs/2204.08471v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: We present our case study that aims to help professional assessors make
decisions in human assessment, in which they conduct interviews with assessees
and evaluate their suitability for certain job roles. Our workshop with two
industrial assessors revealed that a computational system that can extract
nonverbal cues of assesses from interview videos would be beneficial to
assessors in terms of supporting their decision making. In response, we
developed such a system based on an unsupervised anomaly detection algorithm
using multimodal behavioral features such as facial keypoints, pose, head pose,
and gaze. Moreover, we enabled the system to output how much each feature
contributed to the outlierness of the detected cues with the purpose of
enhancing its interpretability. We then conducted a preliminary study to
examine the validity of the system's output by using 20 actual assessment
interview videos and involving the two assessors. The results suggested the
advantages of using unsupervised anomaly detection in an interpretable manner
by illustrating the informativeness of its outputs for assessors. Our approach,
which builds on top of the idea of separation of observation and interpretation
in human-AI teaming, will facilitate human decision making in highly contextual
domains, such as human assessment, while keeping their trust in the system.

### Title: A Deep Learning Galerkin Method for the Closed-Loop Geothermal System
* Paper ID: 2204.08139v1
* Paper URL: [http://arxiv.org/abs/2204.08139v1](http://arxiv.org/abs/2204.08139v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: There has been an arising trend of adopting deep learning methods to study
partial differential equations (PDEs). This article is to propose a Deep
Learning Galerkin Method (DGM) for the closed-loop geothermal system, which is
a new coupled multi-physics PDEs and mainly consists of a framework of
underground heat exchange pipelines to extract the geothermal heat from the
geothermal reservoir. This method is a natural combination of Galerkin Method
and machine learning with the solution approximated by a neural network instead
of a linear combination of basis functions. We train the neural network by
randomly sampling the spatiotemporal points and minimize loss function to
satisfy the differential operators, initial condition, boundary and interface
conditions. Moreover, the approximate ability of the neural network is proved
by the convergence of the loss function and the convergence of the neural
network to the exact solution in L^2 norm under certain conditions. Finally,
some numerical examples are carried out to demonstrate the approximation
ability of the neural networks intuitively.

### Title: Ingredient Extraction from Text in the Recipe Domain
* Paper ID: 2204.08137v1
* Paper URL: [http://arxiv.org/abs/2204.08137v1](http://arxiv.org/abs/2204.08137v1)
* Updated Date: 2022-04-18
* Code URL: [https://github.com/ArkinDharawat/ingredient_extraction](https://github.com/ArkinDharawat/ingredient_extraction)
* Summary: In recent years, there has been an increase in the number of devices with
virtual assistants (e.g: Siri, Google Home, Alexa) in our living rooms and
kitchens. As a result of this, these devices receive several queries about
recipes. All these queries will contain terms relating to a "recipe-domain"
i.e: they will contain dish-names, ingredients, cooking times, dietary
preferences etc. Extracting these recipe-relevant aspects from the query thus
becomes important when it comes to addressing the user's information need. Our
project focuses on extracting ingredients from such plain-text user utterances.
Our best performing model was a fine-tuned BERT which achieved an F1-score of
$95.01$. We have released all our code in a GitHub repository.

### Title: Intermittency of turbulent velocity and scalar fields using 3D local averaging
* Paper ID: 2204.08132v1
* Paper URL: [http://arxiv.org/abs/2204.08132v1](http://arxiv.org/abs/2204.08132v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: An efficient approach for extracting 3D local averages in spherical
subdomains is proposed and applied to study the intermittency of small-scale
velocity and scalar fields in direct numerical simulations of isotropic
turbulence. We focus on the inertial-range scaling exponents of locally
averaged energy dissipation rate, enstrophy and scalar dissipation rate
corresponding to the mixing of a passive scalar $\theta$ in the presence of a
uniform mean gradient. The Taylor-scale Reynolds number $R_\lambda$ goes up to
$1300$, and the Schmidt number $Sc$ up to $512$ (albeit at smaller
$R_\lambda$). The intermittency exponent of the energy dissipation rate is $\mu
\approx 0.23$, whereas that of enstrophy is slightly larger; trends with
$R_\lambda$ suggest that this will be the case even at extremely large
$R_\lambda$. The intermittency exponent of the scalar dissipation rate is
$\mu_\theta \approx 0.35$ for $Sc=1$. These findings are in essential agreement
with previously reported results in the literature. We further show that
$\mu_\theta$ decreases monotonically with increasing $Sc$, either as $1/\log
Sc$ or a weak power law, suggesting that $\mu_\theta \to 0$ as $Sc \to \infty$,
reaffirming recent results on the breakdown of scalar dissipation anomaly in
this limit.

### Title: Less is More: Learning to Refine Dialogue History for Personalized Dialogue Generation
* Paper ID: 2204.08128v1
* Paper URL: [http://arxiv.org/abs/2204.08128v1](http://arxiv.org/abs/2204.08128v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Personalized dialogue systems explore the problem of generating responses
that are consistent with the user's personality, which has raised much
attention in recent years. Existing personalized dialogue systems have tried to
extract user profiles from dialogue history to guide personalized response
generation. Since the dialogue history is usually long and noisy, most existing
methods truncate the dialogue history to model the user's personality. Such
methods can generate some personalized responses, but a large part of dialogue
history is wasted, leading to sub-optimal performance of personalized response
generation. In this work, we propose to refine the user dialogue history on a
large scale, based on which we can handle more dialogue history and obtain more
abundant and accurate persona information. Specifically, we design an MSP model
which consists of three personal information refiners and a personalized
response generator. With these multi-level refiners, we can sparsely extract
the most valuable information (tokens) from the dialogue history and leverage
other similar users' data to enhance personalization. Experimental results on
two real-world datasets demonstrate the superiority of our model in generating
more informative and personalized responses.

