### Title: Persistent homology in cosmic shear II: A tomographic analysis of DES-Y1
* Paper ID: 2204.11831v1
* Paper URL: [http://arxiv.org/abs/2204.11831v1](http://arxiv.org/abs/2204.11831v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: We demonstrate how to use persistent homology for cosmological parameter
inference in a tomographic cosmic shear survey. We obtain the first
cosmological parameter constraints from persistent homology by applying our
method to the first-year data of the Dark Energy Survey.
  To obtain these constraints, we analyse the topological structure of the
matter distribution by extracting persistence diagrams from signal-to-noise
maps of aperture masses. This presents a natural extension to the widely used
peak count statistics. Extracting the persistence diagrams from the
cosmo-SLICS, a suite of $N$-body simulations with variable cosmological
parameters, we interpolate the signal using Gaussian Processes and marginalise
over the most relevant systematic effects, including intrinsic alignments and
baryonic effects.
  We find for the structure growth parameter $S_8=0.747^{+0.025}_{-0.031}$,
which is in full agreement with other late-time probes. We also constrain the
intrinsic alignment parameter to $A=1.54\pm 0.52$, ruling out the case of no
intrinsic alignments at a $3\sigma$-level.

### Title: Skill-based Meta-Reinforcement Learning
* Paper ID: 2204.11828v1
* Paper URL: [http://arxiv.org/abs/2204.11828v1](http://arxiv.org/abs/2204.11828v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: While deep reinforcement learning methods have shown impressive results in
robot learning, their sample inefficiency makes the learning of complex,
long-horizon behaviors with real robot systems infeasible. To mitigate this
issue, meta-reinforcement learning methods aim to enable fast learning on novel
tasks by learning how to learn. Yet, the application has been limited to
short-horizon tasks with dense rewards. To enable learning long-horizon
behaviors, recent works have explored leveraging prior experience in the form
of offline datasets without reward or task annotations. While these approaches
yield improved sample efficiency, millions of interactions with environments
are still required to solve complex tasks. In this work, we devise a method
that enables meta-learning on long-horizon, sparse-reward tasks, allowing us to
solve unseen target tasks with orders of magnitude fewer environment
interactions. Our core idea is to leverage prior experience extracted from
offline datasets during meta-learning. Specifically, we propose to (1) extract
reusable skills and a skill prior from offline datasets, (2) meta-train a
high-level policy that learns to efficiently compose learned skills into
long-horizon behaviors, and (3) rapidly adapt the meta-trained policy to solve
an unseen target task. Experimental results on continuous control tasks in
navigation and manipulation demonstrate that the proposed method can
efficiently solve long-horizon novel target tasks by combining the strengths of
meta-learning and the usage of offline datasets, while prior approaches in RL,
meta-RL, and multi-task RL require substantially more environment interactions
to solve the tasks.

### Title: Performer: A Novel PPG to ECG Reconstruction Transformer For a Digital Biomarker of Cardiovascular Disease Detection
* Paper ID: 2204.11795v1
* Paper URL: [http://arxiv.org/abs/2204.11795v1](http://arxiv.org/abs/2204.11795v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Cardiovascular diseases (CVDs) have become the top one cause of death;
three-quarters of these deaths occur in lower-income communities.
Electrocardiography (ECG), an electrical measurement capturing the cardiac
activities, is a gold-standard to diagnose CVDs. However, ECG is infeasible for
continuous cardiac monitoring due to its requirement for user participation.
Meanwhile, photoplethysmography (PPG) is easy to collect, but the limited
accuracy constrains its clinical usage. In this research, a novel
Transformer-based architecture, Performer, is invented to reconstruct ECG from
PPG and to create a novel digital biomarker, PPG along with its reconstructed
ECG, as multiple modalities for CVD detection. This architecture, for the first
time, performs Transformer sequence to sequence translation on biomedical
waveforms, while also utilizing the advantages of the easily accessible PPG and
the well-studied base of ECG. Shifted Patch-based Attention (SPA) is created to
maximize the signal features by fetching the various sequence lengths as
hierarchical stages into the training while also capturing cross-patch
connections through the shifted patch mechanism. This architecture generates a
state-of-the-art performance of 0.29 RMSE for reconstructing ECG from PPG,
achieving an average of 95.9% diagnosis for CVDs on the MIMIC III dataset and
75.9% for diabetes on the PPG-BP dataset. Performer, along with its novel
digital biomarker, offers a low-cost and non-invasive solution for continuous
cardiac monitoring, only requiring the easily extractable PPG data to
reconstruct the not-as-accessible ECG data. As a prove of concept, an earring
wearable, named PEARL (prototype), is designed to scale up the point-of-care
(POC) healthcare system.

### Title: SyntaSpeech: Syntax-Aware Generative Adversarial Text-to-Speech
* Paper ID: 2204.11792v1
* Paper URL: [http://arxiv.org/abs/2204.11792v1](http://arxiv.org/abs/2204.11792v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: The recent progress in non-autoregressive text-to-speech (NAR-TTS) has made
fast and high-quality speech synthesis possible. However, current NAR-TTS
models usually use phoneme sequence as input and thus cannot understand the
tree-structured syntactic information of the input sequence, which hurts the
prosody modeling. To this end, we propose SyntaSpeech, a syntax-aware and
light-weight NAR-TTS model, which integrates tree-structured syntactic
information into the prosody modeling modules in PortaSpeech
\cite{ren2021portaspeech}. Specifically, 1) We build a syntactic graph based on
the dependency tree of the input sentence, then process the text encoding with
a syntactic graph encoder to extract the syntactic information. 2) We
incorporate the extracted syntactic encoding with PortaSpeech to improve the
prosody prediction. 3) We introduce a multi-length discriminator to replace the
flow-based post-net in PortaSpeech, which simplifies the training pipeline and
improves the inference speed, while keeping the naturalness of the generated
audio. Experiments on three datasets not only show that the tree-structured
syntactic information grants SyntaSpeech the ability to synthesize better audio
with expressive prosody, but also demonstrate the generalization ability of
SyntaSpeech to adapt to multiple languages and multi-speaker text-to-speech.
Ablation studies demonstrate the necessity of each component in SyntaSpeech.
Source code and audio samples are available at https://syntaspeech.github.io

### Title: Five key exoplanet questions answered via the analysis of 25 hot Jupiter atmospheres in eclipse
* Paper ID: 2204.11729v1
* Paper URL: [http://arxiv.org/abs/2204.11729v1](http://arxiv.org/abs/2204.11729v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Population studies of exoplanets are key to unlocking their statistical
properties. So far the inferred properties have been mostly limited to
planetary, orbital and stellar parameters extracted from, e.g., Kepler, radial
velocity, and GAIA data. More recently an increasing number of exoplanet
atmospheres have been observed in detail from space and the ground. Generally,
however, these atmospheric studies have focused on individual planets, with the
exception of a couple of works which have detected the presence of water vapor
and clouds in populations of gaseous planets via transmission spectroscopy.
Here, using a suite of retrieval tools, we analyse spectroscopic and
photometric data of 25 hot Jupiters, obtained with the Hubble and Spitzer Space
Telescopes via the eclipse technique. By applying the tools uniformly across
the entire set of 25 planets, we extract robust trends in the thermal structure
and chemical properties of hot Jupiters not obtained in past studies. With the
recent launch of JWST and the upcoming missions Twinkle, and Ariel, population
based studies of exoplanet atmospheres, such as the one presented here, will be
a key approach to understanding planet characteristics, formation, and
evolution in our galaxy.

### Title: Visibility graphs of animal foraging trajectories
* Paper ID: 2204.11690v1
* Paper URL: [http://arxiv.org/abs/2204.11690v1](http://arxiv.org/abs/2204.11690v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: The study of self-propelled particles is a fast-growing research topic where
biologically inspired movement is increasingly becoming of much interest. A
relevant example is the collective motion of social insects, whose variety and
complexity offer fertile grounds for theoretical abstractions. It has been
demonstrated that the collective motion involved in the searching behavior of
termites is consistent with self-similarity, anomalous diffusion and L\'evy
walks. In this work, we use visibility graphs -- a method that maps time series
into graphs and quantifies the signal complexity via graph topological metrics
-- in the context of social insects foraging trajectories extracted from
experiments. Our analysis indicates that the patterns observed for isolated
termites change qualitatively when the termite density is increased, and such
change cannot be explained by jamming effects only, pointing to collective
effects emerging due to non-trivial foraging interactions between insects as
the cause. Moreover, we find that such an onset of complexity is maximized for
intermediate termite densities.

### Title: $WSe_2$ as transparent top gate for near-field experiments
* Paper ID: 2204.11666v1
* Paper URL: [http://arxiv.org/abs/2204.11666v1](http://arxiv.org/abs/2204.11666v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Independent control of carrier density and out-of-plane displacement field is
essential for accessing novel phenomena in two-dimensional material
heterostructures. While this is achieved with independent top and bottom
metallic gate electrodes in transport experiments, it remains a challenge for
near-field optical studies as the top electrode interferes with the optical
path. Here, we systematically characterize the requirements for a material to
be used as top-gate electrode, and demonstrate experimentally that few-layer
WSe_2 can be used as a transparent, ambipolar top gate electrode in infrared
near-field microscopy. We perform nano-imaging of plasmons in a bilayer
graphene heterostructure and tune the plasmon wavelength using a trilayer WSe_2
gate, achieving a density modulation amplitude exceeding 2 10^{12} cm^{-2}.
Moreover, the observed ambipolar gate-voltage response allows to extract the
energy gap of WSe_2 yielding a value of 1.05 eV. Our results will provide an
additional tuning knob to cryogenic near-field experiments on emerging
phenomena in two-dimensional materials and moir\'e material heterostructures.

### Title: A simple analytical model of magnetic jets
* Paper ID: 2204.11637v1
* Paper URL: [http://arxiv.org/abs/2204.11637v1](http://arxiv.org/abs/2204.11637v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: We propose a simple analytical jet model of magnetic jets, utilizing
conservation laws and some results of published GRMHD jet simulations, and
consider radially-averaged profiles of the physical quantities. We take into
account conversion of the magnetic energy flux to bulk acceleration in jets
formed around rotating black holes assuming the mass continuity equation and
constant jet power, leading to the Bernoulli equation. For assumed profiles of
the bulk Lorentz factor and the radius, this gives the profile of toroidal
magnetic field component along the jet. We then consider the case where the
poloidal field component is connected to a rotating black hole surrounded by an
accretion disc. The formalism recovers the standard formula for the power
extracted from a rotating black hole. We find that the poloidal field strength
dominates over the toroidal one in the comoving frame up to large distances,
which means that jets should be more stable to current-driven kink modes. The
resulting magnetic field profiles can then be used to calculate the jet
synchrotron emission.

### Title: MLO: Multi-Object Tracking and Lidar Odometry in Dynamic Envirnoment
* Paper ID: 2204.11621v1
* Paper URL: [http://arxiv.org/abs/2204.11621v1](http://arxiv.org/abs/2204.11621v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: The SLAM system built on the static scene assumption will introduce
significant estimation errors when a large number of moving objects appear in
the field of view. Tracking and maintaining semantic objects is beneficial to
understand the scene and provide rich decision information for planning and
control modules. This paper introduces MLO, a multi-object Lidar odometry which
tracks ego-motion and movable objects with only the lidar sensor. First, it
achieves information extraction of foreground movable objects, surface road,
and static background features based on geometry and object fusion perception
module. While robustly estimating ego-motion, it accomplishes multi-object
tracking through the least-squares method fused by 3D bounding boxes and
geometric point clouds. Then, a continuous 4D semantic object map on the
timeline can be created. Our approach is evaluated qualitatively and
quantitatively under different scenarios on the public KITTI dataset. The
experiment results show that the ego localization accuracy of MLO is better
than A-LOAM system in highly dynamic, unstructured, and unknown semantic
scenes. Meanwhile, the multi-object tracking method with semantic-geometry
fusion also has apparent advantages in accuracy and tracking robustness
compared with the single method.

### Title: Thermalization and prethermalization in the soft-wall AdS/QCD model
* Paper ID: 2204.11604v1
* Paper URL: [http://arxiv.org/abs/2204.11604v1](http://arxiv.org/abs/2204.11604v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: The real-time dynamics of chiral phase transition is investigated in a
two-flavor ($N_f=2$) soft-wall AdS/QCD model. To understand the dynamics of
thermalization, we quench the system from initial states deviating from the
equilibrium states. Then, we solve the nonequilibrium evolution of the order
parameter (chiral condensate $\langle \sigma\equiv\bar{q}q\rangle$). It is
shown that the system undergoes an exponential relaxation at temperatures away
from the critical temperature $T_c$. The relaxation time diverges at $T_c$,
presenting a typical behavior of critical slowing down. Numerically, we extract
the dynamic exponent $z$, and get $z\approx 2$ by fitting the scaling behavior
$\sigma\simeq t^{-\beta/(\nu z)}$, where the mean-field equilibrium critical
exponents ($\beta=1/2, \nu=1/2$ and $\delta=3$) have been applied. More
interestingly, it is remarked that, for a large class of initial states, the
system would linger over a quasi-steady state for a certain period of time
before the thermalization. It is suggested that the interesting phenomenon,
known as prethermalization, has been observed in the framework of holographic
models. In such prethermal stage, we verify that the system is characterized by
a universal dynamical scaling law and described by the initial-slip exponent
$\theta=0$.

### Title: Adversarial Filtering Modeling on Long-term User Behavior Sequences for Click-Through Rate Prediction
* Paper ID: 2204.11587v1
* Paper URL: [http://arxiv.org/abs/2204.11587v1](http://arxiv.org/abs/2204.11587v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Rich user behavior information is of great importance for capturing and
understanding user interest in click-through rate (CTR) prediction. To improve
the richness, collecting long-term behaviors becomes a typical approach in
academy and industry but at the cost of increasing online storage and latency.
Recently, researchers have proposed several approaches to shorten long-term
behavior sequence and then model user interests. These approaches reduce online
cost efficiently but do not well handle the noisy information in long-term user
behavior, which may deteriorate the performance of CTR prediction
significantly. To obtain better cost/performance trade-off, we propose a novel
Adversarial Filtering Model (ADFM) to model long-term user behavior. ADFM uses
a hierarchical aggregation representation to compress raw behavior sequence and
then learns to remove useless behavior information with an adversarial
filtering mechanism. The selected user behaviors are fed into interest
extraction module for CTR prediction. Experimental results on public datasets
and industrial dataset demonstrate that our method achieves significant
improvements over state-of-the-art models.

### Title: Goal-driven Self-Attentive Recurrent Networks for Trajectory Prediction
* Paper ID: 2204.11561v1
* Paper URL: [http://arxiv.org/abs/2204.11561v1](http://arxiv.org/abs/2204.11561v1)
* Updated Date: 2022-04-25
* Code URL: [https://github.com/luigifilippochiara/Goal-SAR](https://github.com/luigifilippochiara/Goal-SAR)
* Summary: Human trajectory forecasting is a key component of autonomous vehicles,
social-aware robots and advanced video-surveillance applications. This
challenging task typically requires knowledge about past motion, the
environment and likely destination areas. In this context, multi-modality is a
fundamental aspect and its effective modeling can be beneficial to any
architecture. Inferring accurate trajectories is nevertheless challenging, due
to the inherently uncertain nature of the future. To overcome these
difficulties, recent models use different inputs and propose to model human
intentions using complex fusion mechanisms. In this respect, we propose a
lightweight attention-based recurrent backbone that acts solely on past
observed positions. Although this backbone already provides promising results,
we demonstrate that its prediction accuracy can be improved considerably when
combined with a scene-aware goal-estimation module. To this end, we employ a
common goal module, based on a U-Net architecture, which additionally extracts
semantic information to predict scene-compliant destinations. We conduct
extensive experiments on publicly-available datasets (i.e. SDD, inD, ETH/UCY)
and show that our approach performs on par with state-of-the-art techniques
while reducing model complexity.

### Title: Regularized 3D spectroscopy with CubeFit: method and application to the Galactic Center Circumnuclear disk
* Paper ID: 2204.11539v1
* Paper URL: [http://arxiv.org/abs/2204.11539v1](http://arxiv.org/abs/2204.11539v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: The Galactic Center black hole and the nuclear star cluster are surrounded by
a clumpy ring of gas and dust (the circumnuclear disk, CND) that rotates about
them at a standoff distance of ~1.5 pc. The mass and density of individual
clumps in the CND are disputed. We seek to use H$_2$ to characterize the clump
size distribution and to investigate the morphology and dynamics of the
interface between the ionized interior layer of the CND and the molecular
reservoir lying further out (corresponding to the inner rim of the CND,
illuminated in ultraviolet light by the central star cluster). We have observed
two fields of approximately 20"x20" in the CND at near-infrared wavelengths
with the OSIRIS spectro-imager at the Keck Observatory. These two fields,
located at the approaching and receding nodes of the CND, best display this
interface. Our data cover two H$_2$ lines as well as the Br$\gamma$ line
(tracing H ii). We have developed the tool CubeFit, an original method to
extract maps of continuous physical parameters (such as velocity field and
velocity dispersion) from integral-field spectroscopy data, using
regularization to largely preserve spatial resolution in regions of low
signal-to-noise ratio. This original method enables us to isolate compact,
bright features in the interstellar medium of the CND. Several clumps in the
southwestern field assume the appearance of filaments, many of which are
parallel to each other. We conclude that these clumps cannot be
self-gravitating.

### Title: Quantum kinetic theory for dynamical spin polarization from QED-type interaction
* Paper ID: 2204.11519v1
* Paper URL: [http://arxiv.org/abs/2204.11519v1](http://arxiv.org/abs/2204.11519v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: We investigate the dynamical spin polarization of a massless electron probing
an electron plasma in locally thermal equilibrium via the Moller scattering
from the quantum kinetic theory. We derive an axial kinetic equation
delineating the dynamical spin evolution in the presence of the collision term
with quantum corrections up to $\mathcal{O}(\hbar)$ and the leading-logarithmic
order in coupling by using the hard-thermal-loop (HTL) approximation, from
which we extract the spin-polarization rate induced by the spacetime gradients
of the medium. When the electron probe approaches local equilibrium, we further
simplify the collision term into a relaxation-time expression. Our kinetic
equation may be implemented in the future numerical simulations for dynamical
spin polarization.

### Title: Go Wide or Go Deep: Levering Watermarking Performance with Computational Cost for Specific Images
* Paper ID: 2204.11513v1
* Paper URL: [http://arxiv.org/abs/2204.11513v1](http://arxiv.org/abs/2204.11513v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Digital watermarking has been widely studied for the protection of
intellectual property. Traditional watermarking schemes often design in a
"wider" rule, which applies one general embedding mechanism to all images. But
this will limit the scheme into a robustness-invisibility trade-off, where the
improvements of robustness can only be achieved by the increase of embedding
intensity thus causing the visual quality decay. However, a new scenario comes
out at this stage that many businesses wish to give high level protection to
specific valuable images, which requires high robustness and high visual
quality at the same time. Such scenario makes the watermarking schemes should
be designed in a "deeper" way which makes the embedding mechanism customized to
specific images. To achieve so, we break the robustness-invisibility trade-off
by introducing computation cost in, and propose a novel auto-decoder-like
image-specified watermarking framework (ISMark). Based on ISMark, the strong
robustness and high visual quality for specific images can be both achieved. In
detail, we apply an optimization procedure (OPT) to replace the traditional
embedding mechanism. Unlike existing schemes that embed watermarks using a
learned encoder, OPT regards the cover image as the optimizable parameters to
minimize the extraction error of the decoder, thus the features of each
specified image can be effectively exploited to achieve superior performance.
Extensive experiments indicate that ISMark outperforms the state-of-the-art
methods by a large margin, which improves the average bit error rate by 4.64%
(from 4.86% to 0.22%) and PSNR by 2.20dB (from 32.50dB to 34.70dB).

### Title: A Spatio-Temporal Multilayer Perceptron for Gesture Recognition
* Paper ID: 2204.11511v1
* Paper URL: [http://arxiv.org/abs/2204.11511v1](http://arxiv.org/abs/2204.11511v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Gesture recognition is essential for the interaction of autonomous vehicles
with humans. While the current approaches focus on combining several modalities
like image features, keypoints and bone vectors, we present neural network
architecture that delivers state-of-the-art results only with body skeleton
input data. We propose the spatio-temporal multilayer perceptron for gesture
recognition in the context of autonomous vehicles. Given 3D body poses over
time, we define temporal and spatial mixing operations to extract features in
both domains. Additionally, the importance of each time step is re-weighted
with Squeeze-and-Excitation layers. An extensive evaluation of the TCG and
Drive&Act datasets is provided to showcase the promising performance of our
approach. Furthermore, we deploy our model to our autonomous vehicle to show
its real-time capability and stable execution.

### Title: SwinFuse: A Residual Swin Transformer Fusion Network for Infrared and Visible Images
* Paper ID: 2204.11436v1
* Paper URL: [http://arxiv.org/abs/2204.11436v1](http://arxiv.org/abs/2204.11436v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: The existing deep learning fusion methods mainly concentrate on the
convolutional neural networks, and few attempts are made with transformer.
Meanwhile, the convolutional operation is a content-independent interaction
between the image and convolution kernel, which may lose some important
contexts and further limit fusion performance. Towards this end, we present a
simple and strong fusion baseline for infrared and visible images,
namely\textit{ Residual Swin Transformer Fusion Network}, termed as SwinFuse.
Our SwinFuse includes three parts: the global feature extraction, fusion layer
and feature reconstruction. In particular, we build a fully attentional feature
encoding backbone to model the long-range dependency, which is a pure
transformer network and has a stronger representation ability compared with the
convolutional neural networks. Moreover, we design a novel feature fusion
strategy based on $L_{1}$-norm for sequence matrices, and measure the
corresponding activity levels from row and column vector dimensions, which can
well retain competitive infrared brightness and distinct visible details.
Finally, we testify our SwinFuse with nine state-of-the-art traditional and
deep learning methods on three different datasets through subjective
observations and objective comparisons, and the experimental results manifest
that the proposed SwinFuse obtains surprising fusion performance with strong
generalization ability and competitive computational efficiency. The code will
be available at https://github.com/Zhishe-Wang/SwinFuse.

### Title: Surpassing the Human Accuracy: Detecting Gallbladder Cancer from USG Images with Curriculum Learning
* Paper ID: 2204.11433v1
* Paper URL: [http://arxiv.org/abs/2204.11433v1](http://arxiv.org/abs/2204.11433v1)
* Updated Date: 2022-04-25
* Code URL: [https://github.com/sbasu276/GBCNet](https://github.com/sbasu276/GBCNet)
* Summary: We explore the potential of CNN-based models for gallbladder cancer (GBC)
detection from ultrasound (USG) images as no prior study is known. USG is the
most common diagnostic modality for GB diseases due to its low cost and
accessibility. However, USG images are challenging to analyze due to low image
quality, noise, and varying viewpoints due to the handheld nature of the
sensor. Our exhaustive study of state-of-the-art (SOTA) image classification
techniques for the problem reveals that they often fail to learn the salient GB
region due to the presence of shadows in the USG images. SOTA object detection
techniques also achieve low accuracy because of spurious textures due to noise
or adjacent organs. We propose GBCNet to tackle the challenges in our problem.
GBCNet first extracts the regions of interest (ROIs) by detecting the GB (and
not the cancer), and then uses a new multi-scale, second-order pooling
architecture specializing in classifying GBC. To effectively handle spurious
textures, we propose a curriculum inspired by human visual acuity, which
reduces the texture biases in GBCNet. Experimental results demonstrate that
GBCNet significantly outperforms SOTA CNN models, as well as the expert
radiologists. Our technical innovations are generic to other USG image analysis
tasks as well. Hence, as a validation, we also show the efficacy of GBCNet in
detecting breast cancer from USG images. Project page with source code, trained
models, and data is available at https://gbc-iitd.github.io/gbcnet

### Title: Personal Research Knowledge Graphs
* Paper ID: 2204.11428v1
* Paper URL: [http://arxiv.org/abs/2204.11428v1](http://arxiv.org/abs/2204.11428v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Maintaining research-related information in an organized manner can be
challenging for a researcher. In this paper, we envision personal research
knowledge graphs (PRKGs) as a means to represent structured information about
the research activities of a researcher. PRKGs can be used to power intelligent
personal assistants, and personalize various applications. We explore what
entities and relations could be potentially included in a PRKG, how to extract
them from various sources, and how to share a PRKG within a research group.

### Title: It Takes Two Flints to Make a Fire: Multitask Learning of Neural Relation and Explanation Classifiers
* Paper ID: 2204.11424v1
* Paper URL: [http://arxiv.org/abs/2204.11424v1](http://arxiv.org/abs/2204.11424v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: We propose an explainable approach for relation extraction that mitigates the
tension between generalization and explainability by jointly training for the
two goals. Our approach uses a multi-task learning architecture, which jointly
trains a classifier for relation extraction, and a sequence model that labels
words in the context of the relation that explain the decisions of the relation
classifier. We also convert the model outputs to rules to bring global
explanations to this approach. This sequence model is trained using a hybrid
strategy: supervised, when supervision from pre-existing patterns is available,
and semi-supervised otherwise. In the latter situation, we treat the sequence
model's labels as latent variables, and learn the best assignment that
maximizes the performance of the relation classifier. We evaluate the proposed
approach on the two datasets and show that the sequence model provides labels
that serve as accurate explanations for the relation classifier's decisions,
and, importantly, that the joint training generally improves the performance of
the relation classifier. We also evaluate the performance of the generated
rules and show that the new rules are great add-on to the manual rules and
bring the rule-based system much closer to the neural models.

### Title: Audio-Visual Scene Classification Using A Transfer Learning Based Joint Optimization Strategy
* Paper ID: 2204.11420v1
* Paper URL: [http://arxiv.org/abs/2204.11420v1](http://arxiv.org/abs/2204.11420v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Recently, audio-visual scene classification (AVSC) has attracted increasing
attention from multidisciplinary communities. Previous studies tended to adopt
a pipeline training strategy, which uses well-trained visual and acoustic
encoders to extract high-level representations (embeddings) first, then
utilizes them to train the audio-visual classifier. In this way, the extracted
embeddings are well suited for uni-modal classifiers, but not necessarily
suited for multi-modal ones. In this paper, we propose a joint training
framework, using the acoustic features and raw images directly as inputs for
the AVSC task. Specifically, we retrieve the bottom layers of pre-trained image
models as visual encoder, and jointly optimize the scene classifier and 1D-CNN
based acoustic encoder during training. We evaluate the approach on the
development dataset of TAU Urban Audio-Visual Scenes 2021. The experimental
results show that our proposed approach achieves significant improvement over
the conventional pipeline training strategy. Moreover, our best single system
outperforms previous state-of-the-art methods, yielding a log loss of 0.1517
and accuracy of 94.59% on the official test fold.

### Title: Back-ends Selection for Deep Speaker Embeddings
* Paper ID: 2204.11403v1
* Paper URL: [http://arxiv.org/abs/2204.11403v1](http://arxiv.org/abs/2204.11403v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Probabilistic Linear Discriminant Analysis (PLDA) was the dominant and
necessary back-end for early speaker recognition approaches, like i-vector and
x-vector. However, with the development of neural networks and margin-based
loss functions, we can obtain deep speaker embeddings (DSEs), which have
advantages of increased inter-class separation and smaller intra-class
distances. In this case, PLDA seems unnecessary or even counterproductive for
the discriminative embeddings, and cosine similarity scoring (Cos) achieves
better performance than PLDA in some situations. Motivated by this, in this
paper, we systematically explore how to select back-ends (Cos or PLDA) for deep
speaker embeddings to achieve better performance in different situations. By
analyzing PLDA and the properties of DSEs extracted from models with different
numbers of segment-level layers, we make the conjecture that Cos is better in
same-domain situations and PLDA is better in cross-domain situations. We
conduct experiments on VoxCeleb and NIST SRE datasets in four application
situations, single-/multi-domain training and same-/cross-domain test, to
validate our conjecture and briefly explain why back-ends adaption algorithms
work.

### Title: Financial data analysis application via multi-strategy text processing
* Paper ID: 2204.11394v1
* Paper URL: [http://arxiv.org/abs/2204.11394v1](http://arxiv.org/abs/2204.11394v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Maintaining financial system stability is critical to economic development,
and early identification of risks and opportunities is essential. The financial
industry contains a wide variety of data, such as financial statements,
customer information, stock trading data, news, etc. Massive heterogeneous data
calls for intelligent algorithms for machines to process and understand. This
paper mainly focuses on the stock trading data and news about China A-share
companies. We present a financial data analysis application, Financial Quotient
Porter, designed to combine textual and numerical data by using a
multi-strategy data mining approach. Additionally, we present our efforts and
plans in deep learning financial text processing application scenarios using
natural language processing (NLP) and knowledge graph (KG) technologies. Based
on KG technology, risks and opportunities can be identified from heterogeneous
data. NLP technology can be used to extract entities, relations, and events
from unstructured text, and analyze market sentiment. Experimental results show
market sentiments towards a company and an industry, as well as news-level
associations between companies.

### Title: Real-time Speech Emotion Recognition Based on Syllable-Level Feature Extraction
* Paper ID: 2204.11382v1
* Paper URL: [http://arxiv.org/abs/2204.11382v1](http://arxiv.org/abs/2204.11382v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Speech emotion recognition systems have high prediction latency because of
the high computational requirements for deep learning models and low
generalizability mainly because of the poor reliability of emotional
measurements across multiple corpora. To solve these problems, we present a
speech emotion recognition system based on a reductionist approach of
decomposing and analyzing syllable-level features. Mel-spectrogram of an audio
stream is decomposed into syllable-level components, which are then analyzed to
extract statistical features. The proposed method uses formant attention,
noise-gate filtering, and rolling normalization contexts to increase feature
processing speed and tolerance to adversity. A set of syllable-level formant
features is extracted and fed into a single hidden layer neural network that
makes predictions for each syllable as opposed to the conventional approach of
using a sophisticated deep learner to make sentence-wide predictions. The
syllable level predictions help to achieve the real-time latency and lower the
aggregated error in utterance level cross-corpus predictions. The experiments
on IEMOCAP (IE), MSP-Improv (MI), and RAVDESS (RA) databases show that the
method archives real-time latency while predicting with state-of-the-art
cross-corpus unweighted accuracy of 47.6% for IE to MI and 56.2% for MI to IE.

### Title: Message Flow Analysis with Complex Causal Links for Distributed ROS 2 Systems
* Paper ID: 2204.10208v2
* Paper URL: [http://arxiv.org/abs/2204.10208v2](http://arxiv.org/abs/2204.10208v2)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Distributed robotic systems rely heavily on publish-subscribe frameworks,
such as ROS, to efficiently implement modular computation graphs. The ROS 2
executor, a high-level task scheduler which handles messages internally, is a
performance bottleneck. In previous work, we presented ros2_tracing, a
framework with instrumentation and tools for real-time tracing of ROS 2. We now
extend on that instrumentation and leverage the tracing tools to propose an
analysis and visualization of the flow of messages across distributed ROS 2
systems. Our proposed method detects one-to-many and many-to-many causal links
between input and output messages, including indirect causal links through
simple user-level annotations. We validate our method on both synthetic and
real robotic systems, and demonstrate its low runtime overhead. Moreover, the
underlying intermediate execution representation database can be further
leveraged to extract additional metrics and high-level results. This can
provide valuable timing and scheduling information to further study and improve
the ROS 2 executor as well as optimize any ROS 2 system. The source code is
available at: https://github.com/christophebedard/ros2-message-flow-analysis.

### Title: Working memory inspired hierarchical video decomposition with transformative representations
* Paper ID: 2204.10105v2
* Paper URL: [http://arxiv.org/abs/2204.10105v2](http://arxiv.org/abs/2204.10105v2)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Video decomposition is very important to extract moving foreground objects
from complex backgrounds in computer vision, machine learning, and medical
imaging, e.g., extracting moving contrast-filled vessels from the complex and
noisy backgrounds of X-ray coronary angiography (XCA). However, the challenges
caused by dynamic backgrounds, overlapping heterogeneous environments and
complex noises still exist in video decomposition. To solve these problems,
this study is the first to introduce a flexible visual working memory model in
video decomposition tasks to provide interpretable and high-performance
hierarchical deep architecture, integrating the transformative representations
between sensory and control layers from the perspective of visual and cognitive
neuroscience. Specifically, robust PCA unrolling networks acting as a
structure-regularized sensor layer decompose XCA into sparse/low-rank
structured representations to separate moving contrast-filled vessels from
noisy and complex backgrounds. Then, patch recurrent convolutional LSTM
networks with a backprojection module embody unstructured random
representations of the control layer in working memory, recurrently projecting
spatiotemporally decomposed nonlocal patches into orthogonal subspaces for
heterogeneous vessel retrieval and interference suppression. This video
decomposition deep architecture effectively restores the heterogeneous profiles
of intensity and the geometries of moving objects against the complex
background interferences. Experiments show that the proposed method
significantly outperforms state-of-the-art methods in accurate moving
contrast-filled vessel extraction with excellent flexibility and computational
efficiency.

### Title: Normalization procedure for obtaining the local density of states from high-bias scanning tunneling spectroscopy
* Paper ID: 2204.09929v2
* Paper URL: [http://arxiv.org/abs/2204.09929v2](http://arxiv.org/abs/2204.09929v2)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Differential conductance spectroscopy performed in the high bias regime -- in
which the applied voltage exceeds the sample work function -- is a poor measure
of the local density of states due to the effects of the changing tunnel
barrier. Additionally, the large applied voltage oftentimes makes
constant-height measurement experimentally impractical, lending
constant-current spectroscopy an advantageous edge; but the differential
conductance in that case is even further removed from the local density of
states due to the changing tip height. Here, we present a normalization scheme
for extracting the local density of states from high bias scanning tunneling
spectroscopy, obtained in either constant-current or constant-height mode. We
extend this model to account for the effects of the in-plane momentum of the
probed states to the overall current. We demonstrate the validity of the
proposed scheme by applying it to laterally confined field-emission resonances,
which appear as peak-shaped spectroscopic features with a well-defined in-plane
momentum.

### Title: Ergomagnetosphere, Ejection Disc, Magnetopause in M87. I Global Flow of Mass, Angular Momentum, Energy and Current
* Paper ID: 2204.11995v1
* Paper URL: [http://arxiv.org/abs/2204.11995v1](http://arxiv.org/abs/2204.11995v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: We interpret the 1.3mm VLBI observations made by the Event Horizon Telescope
of the black hole in M87. It is proposed that, instead of being a torus of
accreting gas, the ring is a rotating, magnetically-dominated ergomagnetosphere
that can transmit electromagnetic angular momentum and energy outward to the
disc through a combination of large scale magnetic torque and small scale
instabilities. It is further proposed that energy can be extracted by magnetic
flux threading the ergosphere through the efficient emission of long wavelength
electromagnetic disturbances onto negative energy orbits, when the invariant
$B^2-E^2$ becomes negative. In this way, the spinning black hole and its
ergosphere not only power the jets but also the ejection disc so as to drive
away most of the gas supplied near the Bondi radius. This outflow takes the
form of a MHD wind, extending over many decades of radius, with a
unidirectional magnetic field, that is collimated by the infalling gas across a
magnetopause. This wind, in turn, collimates the relativistic jets and the
emission observed from the jet sheath may be associated with a return current.
A model for the global flow of mass, angular momentum, energy and current, on
scales from the horizon to the Bondi radius, is presented and discussed.

### Title: End-to-end Mapping in Heterogeneous Systems Using Graph Representation Learning
* Paper ID: 2204.11981v1
* Paper URL: [http://arxiv.org/abs/2204.11981v1](http://arxiv.org/abs/2204.11981v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: To enable heterogeneous computing systems with autonomous programming and
optimization capabilities, we propose a unified, end-to-end, programmable graph
representation learning (PGL) framework that is capable of mining the
complexity of high-level programs down to the universal intermediate
representation, extracting the specific computational patterns and predicting
which code segments would run best on a specific core in heterogeneous hardware
platforms. The proposed framework extracts multi-fractal topological features
from code graphs, utilizes graph autoencoders to learn how to partition the
graph into computational kernels, and exploits graph neural networks (GNN) to
predict the correct assignment to a processor type. In the evaluation, we
validate the PGL framework and demonstrate a maximum speedup of 6.42x compared
to the thread-based execution, and 2.02x compared to the state-of-the-art
technique.

### Title: Rapid detection of SARS-CoV-2 nucleocapsid protein using dual-comb biosensing
* Paper ID: 2204.11954v1
* Paper URL: [http://arxiv.org/abs/2204.11954v1](http://arxiv.org/abs/2204.11954v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Testing of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is
essential along with vaccination and inactivation to fight against the
coronavirus disease 2019 (COVID-19) pandemic. Reverse-transcription polymerase
chain reaction (RT-PCR), based on reverse transcription of RNA into DNA and
amplification of specific DNA targets, is the current standard for COVID-19
testing; however, it hampers from laborious and time-consuming multiple steps.
If the testing is largely simplified and shortened, it will be a powerful
deterrent to the spread of COVID-19. Here we demonstrate the optical biosensing
based on optical frequency comb (OFC), enabling the rapid detection of
SARS-CoV-2 nucleocapsid protein. The virus-concentration-dependent optical
spectral shift caused by antigen-antibody interaction and
multimode-interference fiber sensor is transformed into a photonic
radio-frequency (RF) shift by coherent frequency link between optical and RF
regions in OFC, benefiting from high precision, rapid, simple, and low cost in
electric frequency measurements. Furthermore, the active-dummy compensation of
temperature drift with dual-comb configuration extracts the imperceptible
change of virus-concentration-dependent signal from the large background signal
that changes moment by moment. Such the dual-comb biosensing has a potential to
reduce the testing time down of COVID-19 to a few tens minute, which is one
order of magnitude shorter than that of RT-PCR (typically, 5 hours).
Furthermore, it will be applied for sensitive sensing of not only virus of
emerging and re-emerging infectious diseases but also RNA, bio-marker, and
endocrine disruptor by selecting the surface modification of biomolecule
interaction.

### Title: Boosting mono-jet searches with model-agnostic machine learning
* Paper ID: 2204.11889v1
* Paper URL: [http://arxiv.org/abs/2204.11889v1](http://arxiv.org/abs/2204.11889v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: We show how weakly supervised machine learning can improve the sensitivity of
LHC mono-jet searches to new physics models with anomalous jet dynamics. The
Classification Without Labels (CWoLa) method is used to extract all the
information available from low-level detector information without any reference
to specific new physics models. For the example of a strongly interacting dark
matter model, we employ simulated data to show that the discovery potential of
an existing generic search can be boosted considerably.

### Title: Persistent homology in cosmic shear II: A tomographic analysis of DES-Y1
* Paper ID: 2204.11831v1
* Paper URL: [http://arxiv.org/abs/2204.11831v1](http://arxiv.org/abs/2204.11831v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: We demonstrate how to use persistent homology for cosmological parameter
inference in a tomographic cosmic shear survey. We obtain the first
cosmological parameter constraints from persistent homology by applying our
method to the first-year data of the Dark Energy Survey.
  To obtain these constraints, we analyse the topological structure of the
matter distribution by extracting persistence diagrams from signal-to-noise
maps of aperture masses. This presents a natural extension to the widely used
peak count statistics. Extracting the persistence diagrams from the
cosmo-SLICS, a suite of $N$-body simulations with variable cosmological
parameters, we interpolate the signal using Gaussian Processes and marginalise
over the most relevant systematic effects, including intrinsic alignments and
baryonic effects.
  We find for the structure growth parameter $S_8=0.747^{+0.025}_{-0.031}$,
which is in full agreement with other late-time probes. We also constrain the
intrinsic alignment parameter to $A=1.54\pm 0.52$, ruling out the case of no
intrinsic alignments at a $3\sigma$-level.

### Title: Skill-based Meta-Reinforcement Learning
* Paper ID: 2204.11828v1
* Paper URL: [http://arxiv.org/abs/2204.11828v1](http://arxiv.org/abs/2204.11828v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: While deep reinforcement learning methods have shown impressive results in
robot learning, their sample inefficiency makes the learning of complex,
long-horizon behaviors with real robot systems infeasible. To mitigate this
issue, meta-reinforcement learning methods aim to enable fast learning on novel
tasks by learning how to learn. Yet, the application has been limited to
short-horizon tasks with dense rewards. To enable learning long-horizon
behaviors, recent works have explored leveraging prior experience in the form
of offline datasets without reward or task annotations. While these approaches
yield improved sample efficiency, millions of interactions with environments
are still required to solve complex tasks. In this work, we devise a method
that enables meta-learning on long-horizon, sparse-reward tasks, allowing us to
solve unseen target tasks with orders of magnitude fewer environment
interactions. Our core idea is to leverage prior experience extracted from
offline datasets during meta-learning. Specifically, we propose to (1) extract
reusable skills and a skill prior from offline datasets, (2) meta-train a
high-level policy that learns to efficiently compose learned skills into
long-horizon behaviors, and (3) rapidly adapt the meta-trained policy to solve
an unseen target task. Experimental results on continuous control tasks in
navigation and manipulation demonstrate that the proposed method can
efficiently solve long-horizon novel target tasks by combining the strengths of
meta-learning and the usage of offline datasets, while prior approaches in RL,
meta-RL, and multi-task RL require substantially more environment interactions
to solve the tasks.

### Title: Low-dimensional representation of infant and adult vocalization acoustics
* Paper ID: 2204.12279v1
* Paper URL: [http://arxiv.org/abs/2204.12279v1](http://arxiv.org/abs/2204.12279v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: During the first years of life, infant vocalizations change considerably, as
infants develop the vocalization skills that enable them to produce speech
sounds. Characterizations based on specific acoustic features, protophone
categories, or phonetic transcription are able to provide a representation of
the sounds infants make at different ages and in different contexts but do not
fully describe how sounds are perceived by listeners, can be inefficient to
obtain at large scales, and are difficult to visualize in two dimensions
without additional statistical processing. Machine-learning-based approaches
provide the opportunity to complement these characterizations with purely
data-driven representations of infant sounds. Here, we use spectral features
extraction and unsupervised machine learning, specifically Uniform Manifold
Approximation (UMAP), to obtain a novel 2-dimensional spatial representation of
infant and caregiver vocalizations extracted from day-long home recordings.
UMAP yields a continuous and well-distributed space conducive to certain
analyses of infant vocal development. For instance, we found that the
dispersion of infant vocalization acoustics within the 2-D space over a day
increased from 3 to 9 months, and then decreased from 9 to 18 months. The
method also permits analysis of similarity between infant and adult
vocalizations, which also shows changes with infant age.

### Title: SyntaSpeech: Syntax-Aware Generative Adversarial Text-to-Speech
* Paper ID: 2204.11792v1
* Paper URL: [http://arxiv.org/abs/2204.11792v1](http://arxiv.org/abs/2204.11792v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: The recent progress in non-autoregressive text-to-speech (NAR-TTS) has made
fast and high-quality speech synthesis possible. However, current NAR-TTS
models usually use phoneme sequence as input and thus cannot understand the
tree-structured syntactic information of the input sequence, which hurts the
prosody modeling. To this end, we propose SyntaSpeech, a syntax-aware and
light-weight NAR-TTS model, which integrates tree-structured syntactic
information into the prosody modeling modules in PortaSpeech
\cite{ren2021portaspeech}. Specifically, 1) We build a syntactic graph based on
the dependency tree of the input sentence, then process the text encoding with
a syntactic graph encoder to extract the syntactic information. 2) We
incorporate the extracted syntactic encoding with PortaSpeech to improve the
prosody prediction. 3) We introduce a multi-length discriminator to replace the
flow-based post-net in PortaSpeech, which simplifies the training pipeline and
improves the inference speed, while keeping the naturalness of the generated
audio. Experiments on three datasets not only show that the tree-structured
syntactic information grants SyntaSpeech the ability to synthesize better audio
with expressive prosody, but also demonstrate the generalization ability of
SyntaSpeech to adapt to multiple languages and multi-speaker text-to-speech.
Ablation studies demonstrate the necessity of each component in SyntaSpeech.
Source code and audio samples are available at https://syntaspeech.github.io

### Title: Information Retrieval in Friction Stir Welding of Aluminum Alloys by using Natural Language Processing based Algorithms
* Paper ID: 2204.12309v1
* Paper URL: [http://arxiv.org/abs/2204.12309v1](http://arxiv.org/abs/2204.12309v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Text summarization is a technique for condensing a big piece of text into a
few key elements that give a general impression of the content. When someone
requires a quick and precise summary of a large amount of information, it
becomes vital. If done manually, summarizing text can be costly and
time-consuming. Natural Language Processing (NLP) is the sub-division of
Artificial Intelligence that narrows down the gap between technology and human
cognition by extracting the relevant information from the pile of data. In the
present work, scientific information regarding the Friction Stir Welding of
Aluminum alloys was collected from the abstract of scholarly research papers.
For extracting the relevant information from these research abstracts four
Natural Language Processing based algorithms i.e. Latent Semantic Analysis
(LSA), Luhn Algorithm, Lex Rank Algorithm, and KL-Algorithm were used. In order
to evaluate the accuracy score of these algorithms, Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) was used. The results showed that the Luhn
Algorithm resulted in the highest f1-Score of 0.413 in comparison to other
algorithms.

### Title: Five key exoplanet questions answered via the analysis of 25 hot Jupiter atmospheres in eclipse
* Paper ID: 2204.11729v1
* Paper URL: [http://arxiv.org/abs/2204.11729v1](http://arxiv.org/abs/2204.11729v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Population studies of exoplanets are key to unlocking their statistical
properties. So far the inferred properties have been mostly limited to
planetary, orbital and stellar parameters extracted from, e.g., Kepler, radial
velocity, and GAIA data. More recently an increasing number of exoplanet
atmospheres have been observed in detail from space and the ground. Generally,
however, these atmospheric studies have focused on individual planets, with the
exception of a couple of works which have detected the presence of water vapor
and clouds in populations of gaseous planets via transmission spectroscopy.
Here, using a suite of retrieval tools, we analyse spectroscopic and
photometric data of 25 hot Jupiters, obtained with the Hubble and Spitzer Space
Telescopes via the eclipse technique. By applying the tools uniformly across
the entire set of 25 planets, we extract robust trends in the thermal structure
and chemical properties of hot Jupiters not obtained in past studies. With the
recent launch of JWST and the upcoming missions Twinkle, and Ariel, population
based studies of exoplanet atmospheres, such as the one presented here, will be
a key approach to understanding planet characteristics, formation, and
evolution in our galaxy.

### Title: Visibility graphs of animal foraging trajectories
* Paper ID: 2204.11690v1
* Paper URL: [http://arxiv.org/abs/2204.11690v1](http://arxiv.org/abs/2204.11690v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: The study of self-propelled particles is a fast-growing research topic where
biologically inspired movement is increasingly becoming of much interest. A
relevant example is the collective motion of social insects, whose variety and
complexity offer fertile grounds for theoretical abstractions. It has been
demonstrated that the collective motion involved in the searching behavior of
termites is consistent with self-similarity, anomalous diffusion and L\'evy
walks. In this work, we use visibility graphs -- a method that maps time series
into graphs and quantifies the signal complexity via graph topological metrics
-- in the context of social insects foraging trajectories extracted from
experiments. Our analysis indicates that the patterns observed for isolated
termites change qualitatively when the termite density is increased, and such
change cannot be explained by jamming effects only, pointing to collective
effects emerging due to non-trivial foraging interactions between insects as
the cause. Moreover, we find that such an onset of complexity is maximized for
intermediate termite densities.

### Title: $WSe_2$ as transparent top gate for near-field experiments
* Paper ID: 2204.11666v1
* Paper URL: [http://arxiv.org/abs/2204.11666v1](http://arxiv.org/abs/2204.11666v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Independent control of carrier density and out-of-plane displacement field is
essential for accessing novel phenomena in two-dimensional material
heterostructures. While this is achieved with independent top and bottom
metallic gate electrodes in transport experiments, it remains a challenge for
near-field optical studies as the top electrode interferes with the optical
path. Here, we systematically characterize the requirements for a material to
be used as top-gate electrode, and demonstrate experimentally that few-layer
WSe_2 can be used as a transparent, ambipolar top gate electrode in infrared
near-field microscopy. We perform nano-imaging of plasmons in a bilayer
graphene heterostructure and tune the plasmon wavelength using a trilayer WSe_2
gate, achieving a density modulation amplitude exceeding 2 10^{12} cm^{-2}.
Moreover, the observed ambipolar gate-voltage response allows to extract the
energy gap of WSe_2 yielding a value of 1.05 eV. Our results will provide an
additional tuning knob to cryogenic near-field experiments on emerging
phenomena in two-dimensional materials and moir\'e material heterostructures.

### Title: GDGRU-DTA: Predicting Drug-Target Binding Affinity Based on GNN and Double GRU
* Paper ID: 2204.11857v1
* Paper URL: [http://arxiv.org/abs/2204.11857v1](http://arxiv.org/abs/2204.11857v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: The work for predicting drug and target affinity(DTA) is crucial for drug
development and repurposing. In this work, we propose a novel method called
GDGRU-DTA to predict the binding affinity between drugs and targets, which is
based on GraphDTA, but we consider that protein sequences are long sequences,
so simple CNN cannot capture the context dependencies in protein sequences
well. Therefore, we improve it by interpreting the protein sequences as time
series and extracting their features using Gate Recurrent Unit(GRU) and
Bidirectional Gate Recurrent Unit(BiGRU). For the drug, our processing method
is similar to that of GraphDTA, but uses two different graph convolution
methods. Subsequently, the representation of drugs and proteins are
concatenated for final prediction. We evaluate the proposed model on two
benchmark datasets. Our model outperforms some state-of-the-art deep learning
methods, and the results demonstrate the feasibility and excellent feature
capture ability of our model.

### Title: A simple analytical model of magnetic jets
* Paper ID: 2204.11637v1
* Paper URL: [http://arxiv.org/abs/2204.11637v1](http://arxiv.org/abs/2204.11637v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: We propose a simple analytical jet model of magnetic jets, utilizing
conservation laws and some results of published GRMHD jet simulations, and
consider radially-averaged profiles of the physical quantities. We take into
account conversion of the magnetic energy flux to bulk acceleration in jets
formed around rotating black holes assuming the mass continuity equation and
constant jet power, leading to the Bernoulli equation. For assumed profiles of
the bulk Lorentz factor and the radius, this gives the profile of toroidal
magnetic field component along the jet. We then consider the case where the
poloidal field component is connected to a rotating black hole surrounded by an
accretion disc. The formalism recovers the standard formula for the power
extracted from a rotating black hole. We find that the poloidal field strength
dominates over the toroidal one in the comoving frame up to large distances,
which means that jets should be more stable to current-driven kink modes. The
resulting magnetic field profiles can then be used to calculate the jet
synchrotron emission.

### Title: MLO: Multi-Object Tracking and Lidar Odometry in Dynamic Envirnoment
* Paper ID: 2204.11621v1
* Paper URL: [http://arxiv.org/abs/2204.11621v1](http://arxiv.org/abs/2204.11621v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: The SLAM system built on the static scene assumption will introduce
significant estimation errors when a large number of moving objects appear in
the field of view. Tracking and maintaining semantic objects is beneficial to
understand the scene and provide rich decision information for planning and
control modules. This paper introduces MLO, a multi-object Lidar odometry which
tracks ego-motion and movable objects with only the lidar sensor. First, it
achieves information extraction of foreground movable objects, surface road,
and static background features based on geometry and object fusion perception
module. While robustly estimating ego-motion, it accomplishes multi-object
tracking through the least-squares method fused by 3D bounding boxes and
geometric point clouds. Then, a continuous 4D semantic object map on the
timeline can be created. Our approach is evaluated qualitatively and
quantitatively under different scenarios on the public KITTI dataset. The
experiment results show that the ego localization accuracy of MLO is better
than A-LOAM system in highly dynamic, unstructured, and unknown semantic
scenes. Meanwhile, the multi-object tracking method with semantic-geometry
fusion also has apparent advantages in accuracy and tracking robustness
compared with the single method.

### Title: Thermalization and prethermalization in the soft-wall AdS/QCD model
* Paper ID: 2204.11604v1
* Paper URL: [http://arxiv.org/abs/2204.11604v1](http://arxiv.org/abs/2204.11604v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: The real-time dynamics of chiral phase transition is investigated in a
two-flavor ($N_f=2$) soft-wall AdS/QCD model. To understand the dynamics of
thermalization, we quench the system from initial states deviating from the
equilibrium states. Then, we solve the nonequilibrium evolution of the order
parameter (chiral condensate $\langle \sigma\equiv\bar{q}q\rangle$). It is
shown that the system undergoes an exponential relaxation at temperatures away
from the critical temperature $T_c$. The relaxation time diverges at $T_c$,
presenting a typical behavior of critical slowing down. Numerically, we extract
the dynamic exponent $z$, and get $z\approx 2$ by fitting the scaling behavior
$\sigma\simeq t^{-\beta/(\nu z)}$, where the mean-field equilibrium critical
exponents ($\beta=1/2, \nu=1/2$ and $\delta=3$) have been applied. More
interestingly, it is remarked that, for a large class of initial states, the
system would linger over a quasi-steady state for a certain period of time
before the thermalization. It is suggested that the interesting phenomenon,
known as prethermalization, has been observed in the framework of holographic
models. In such prethermal stage, we verify that the system is characterized by
a universal dynamical scaling law and described by the initial-slip exponent
$\theta=0$.

### Title: Goal-driven Self-Attentive Recurrent Networks for Trajectory Prediction
* Paper ID: 2204.11561v1
* Paper URL: [http://arxiv.org/abs/2204.11561v1](http://arxiv.org/abs/2204.11561v1)
* Updated Date: 2022-04-25
* Code URL: [https://github.com/luigifilippochiara/Goal-SAR](https://github.com/luigifilippochiara/Goal-SAR)
* Summary: Human trajectory forecasting is a key component of autonomous vehicles,
social-aware robots and advanced video-surveillance applications. This
challenging task typically requires knowledge about past motion, the
environment and likely destination areas. In this context, multi-modality is a
fundamental aspect and its effective modeling can be beneficial to any
architecture. Inferring accurate trajectories is nevertheless challenging, due
to the inherently uncertain nature of the future. To overcome these
difficulties, recent models use different inputs and propose to model human
intentions using complex fusion mechanisms. In this respect, we propose a
lightweight attention-based recurrent backbone that acts solely on past
observed positions. Although this backbone already provides promising results,
we demonstrate that its prediction accuracy can be improved considerably when
combined with a scene-aware goal-estimation module. To this end, we employ a
common goal module, based on a U-Net architecture, which additionally extracts
semantic information to predict scene-compliant destinations. We conduct
extensive experiments on publicly-available datasets (i.e. SDD, inD, ETH/UCY)
and show that our approach performs on par with state-of-the-art techniques
while reducing model complexity.

### Title: Regularized 3D spectroscopy with CubeFit: method and application to the Galactic Center Circumnuclear disk
* Paper ID: 2204.11539v1
* Paper URL: [http://arxiv.org/abs/2204.11539v1](http://arxiv.org/abs/2204.11539v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: The Galactic Center black hole and the nuclear star cluster are surrounded by
a clumpy ring of gas and dust (the circumnuclear disk, CND) that rotates about
them at a standoff distance of ~1.5 pc. The mass and density of individual
clumps in the CND are disputed. We seek to use H$_2$ to characterize the clump
size distribution and to investigate the morphology and dynamics of the
interface between the ionized interior layer of the CND and the molecular
reservoir lying further out (corresponding to the inner rim of the CND,
illuminated in ultraviolet light by the central star cluster). We have observed
two fields of approximately 20"x20" in the CND at near-infrared wavelengths
with the OSIRIS spectro-imager at the Keck Observatory. These two fields,
located at the approaching and receding nodes of the CND, best display this
interface. Our data cover two H$_2$ lines as well as the Br$\gamma$ line
(tracing H ii). We have developed the tool CubeFit, an original method to
extract maps of continuous physical parameters (such as velocity field and
velocity dispersion) from integral-field spectroscopy data, using
regularization to largely preserve spatial resolution in regions of low
signal-to-noise ratio. This original method enables us to isolate compact,
bright features in the interstellar medium of the CND. Several clumps in the
southwestern field assume the appearance of filaments, many of which are
parallel to each other. We conclude that these clumps cannot be
self-gravitating.

### Title: Quantum kinetic theory for dynamical spin polarization from QED-type interaction
* Paper ID: 2204.11519v1
* Paper URL: [http://arxiv.org/abs/2204.11519v1](http://arxiv.org/abs/2204.11519v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: We investigate the dynamical spin polarization of a massless electron probing
an electron plasma in locally thermal equilibrium via the Moller scattering
from the quantum kinetic theory. We derive an axial kinetic equation
delineating the dynamical spin evolution in the presence of the collision term
with quantum corrections up to $\mathcal{O}(\hbar)$ and the leading-logarithmic
order in coupling by using the hard-thermal-loop (HTL) approximation, from
which we extract the spin-polarization rate induced by the spacetime gradients
of the medium. When the electron probe approaches local equilibrium, we further
simplify the collision term into a relaxation-time expression. Our kinetic
equation may be implemented in the future numerical simulations for dynamical
spin polarization.

### Title: Go Wide or Go Deep: Levering Watermarking Performance with Computational Cost for Specific Images
* Paper ID: 2204.11513v1
* Paper URL: [http://arxiv.org/abs/2204.11513v1](http://arxiv.org/abs/2204.11513v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Digital watermarking has been widely studied for the protection of
intellectual property. Traditional watermarking schemes often design in a
"wider" rule, which applies one general embedding mechanism to all images. But
this will limit the scheme into a robustness-invisibility trade-off, where the
improvements of robustness can only be achieved by the increase of embedding
intensity thus causing the visual quality decay. However, a new scenario comes
out at this stage that many businesses wish to give high level protection to
specific valuable images, which requires high robustness and high visual
quality at the same time. Such scenario makes the watermarking schemes should
be designed in a "deeper" way which makes the embedding mechanism customized to
specific images. To achieve so, we break the robustness-invisibility trade-off
by introducing computation cost in, and propose a novel auto-decoder-like
image-specified watermarking framework (ISMark). Based on ISMark, the strong
robustness and high visual quality for specific images can be both achieved. In
detail, we apply an optimization procedure (OPT) to replace the traditional
embedding mechanism. Unlike existing schemes that embed watermarks using a
learned encoder, OPT regards the cover image as the optimizable parameters to
minimize the extraction error of the decoder, thus the features of each
specified image can be effectively exploited to achieve superior performance.
Extensive experiments indicate that ISMark outperforms the state-of-the-art
methods by a large margin, which improves the average bit error rate by 4.64%
(from 4.86% to 0.22%) and PSNR by 2.20dB (from 32.50dB to 34.70dB).

### Title: A Spatio-Temporal Multilayer Perceptron for Gesture Recognition
* Paper ID: 2204.11511v1
* Paper URL: [http://arxiv.org/abs/2204.11511v1](http://arxiv.org/abs/2204.11511v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Gesture recognition is essential for the interaction of autonomous vehicles
with humans. While the current approaches focus on combining several modalities
like image features, keypoints and bone vectors, we present neural network
architecture that delivers state-of-the-art results only with body skeleton
input data. We propose the spatio-temporal multilayer perceptron for gesture
recognition in the context of autonomous vehicles. Given 3D body poses over
time, we define temporal and spatial mixing operations to extract features in
both domains. Additionally, the importance of each time step is re-weighted
with Squeeze-and-Excitation layers. An extensive evaluation of the TCG and
Drive&Act datasets is provided to showcase the promising performance of our
approach. Furthermore, we deploy our model to our autonomous vehicle to show
its real-time capability and stable execution.

### Title: SwinFuse: A Residual Swin Transformer Fusion Network for Infrared and Visible Images
* Paper ID: 2204.11436v1
* Paper URL: [http://arxiv.org/abs/2204.11436v1](http://arxiv.org/abs/2204.11436v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: The existing deep learning fusion methods mainly concentrate on the
convolutional neural networks, and few attempts are made with transformer.
Meanwhile, the convolutional operation is a content-independent interaction
between the image and convolution kernel, which may lose some important
contexts and further limit fusion performance. Towards this end, we present a
simple and strong fusion baseline for infrared and visible images,
namely\textit{ Residual Swin Transformer Fusion Network}, termed as SwinFuse.
Our SwinFuse includes three parts: the global feature extraction, fusion layer
and feature reconstruction. In particular, we build a fully attentional feature
encoding backbone to model the long-range dependency, which is a pure
transformer network and has a stronger representation ability compared with the
convolutional neural networks. Moreover, we design a novel feature fusion
strategy based on $L_{1}$-norm for sequence matrices, and measure the
corresponding activity levels from row and column vector dimensions, which can
well retain competitive infrared brightness and distinct visible details.
Finally, we testify our SwinFuse with nine state-of-the-art traditional and
deep learning methods on three different datasets through subjective
observations and objective comparisons, and the experimental results manifest
that the proposed SwinFuse obtains surprising fusion performance with strong
generalization ability and competitive computational efficiency. The code will
be available at https://github.com/Zhishe-Wang/SwinFuse.

### Title: Surpassing the Human Accuracy: Detecting Gallbladder Cancer from USG Images with Curriculum Learning
* Paper ID: 2204.11433v1
* Paper URL: [http://arxiv.org/abs/2204.11433v1](http://arxiv.org/abs/2204.11433v1)
* Updated Date: 2022-04-25
* Code URL: [https://github.com/sbasu276/GBCNet](https://github.com/sbasu276/GBCNet)
* Summary: We explore the potential of CNN-based models for gallbladder cancer (GBC)
detection from ultrasound (USG) images as no prior study is known. USG is the
most common diagnostic modality for GB diseases due to its low cost and
accessibility. However, USG images are challenging to analyze due to low image
quality, noise, and varying viewpoints due to the handheld nature of the
sensor. Our exhaustive study of state-of-the-art (SOTA) image classification
techniques for the problem reveals that they often fail to learn the salient GB
region due to the presence of shadows in the USG images. SOTA object detection
techniques also achieve low accuracy because of spurious textures due to noise
or adjacent organs. We propose GBCNet to tackle the challenges in our problem.
GBCNet first extracts the regions of interest (ROIs) by detecting the GB (and
not the cancer), and then uses a new multi-scale, second-order pooling
architecture specializing in classifying GBC. To effectively handle spurious
textures, we propose a curriculum inspired by human visual acuity, which
reduces the texture biases in GBCNet. Experimental results demonstrate that
GBCNet significantly outperforms SOTA CNN models, as well as the expert
radiologists. Our technical innovations are generic to other USG image analysis
tasks as well. Hence, as a validation, we also show the efficacy of GBCNet in
detecting breast cancer from USG images. Project page with source code, trained
models, and data is available at https://gbc-iitd.github.io/gbcnet

### Title: Personal Research Knowledge Graphs
* Paper ID: 2204.11428v1
* Paper URL: [http://arxiv.org/abs/2204.11428v1](http://arxiv.org/abs/2204.11428v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Maintaining research-related information in an organized manner can be
challenging for a researcher. In this paper, we envision personal research
knowledge graphs (PRKGs) as a means to represent structured information about
the research activities of a researcher. PRKGs can be used to power intelligent
personal assistants, and personalize various applications. We explore what
entities and relations could be potentially included in a PRKG, how to extract
them from various sources, and how to share a PRKG within a research group.

### Title: It Takes Two Flints to Make a Fire: Multitask Learning of Neural Relation and Explanation Classifiers
* Paper ID: 2204.11424v1
* Paper URL: [http://arxiv.org/abs/2204.11424v1](http://arxiv.org/abs/2204.11424v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: We propose an explainable approach for relation extraction that mitigates the
tension between generalization and explainability by jointly training for the
two goals. Our approach uses a multi-task learning architecture, which jointly
trains a classifier for relation extraction, and a sequence model that labels
words in the context of the relation that explain the decisions of the relation
classifier. We also convert the model outputs to rules to bring global
explanations to this approach. This sequence model is trained using a hybrid
strategy: supervised, when supervision from pre-existing patterns is available,
and semi-supervised otherwise. In the latter situation, we treat the sequence
model's labels as latent variables, and learn the best assignment that
maximizes the performance of the relation classifier. We evaluate the proposed
approach on the two datasets and show that the sequence model provides labels
that serve as accurate explanations for the relation classifier's decisions,
and, importantly, that the joint training generally improves the performance of
the relation classifier. We also evaluate the performance of the generated
rules and show that the new rules are great add-on to the manual rules and
bring the rule-based system much closer to the neural models.

### Title: Audio-Visual Scene Classification Using A Transfer Learning Based Joint Optimization Strategy
* Paper ID: 2204.11420v1
* Paper URL: [http://arxiv.org/abs/2204.11420v1](http://arxiv.org/abs/2204.11420v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Recently, audio-visual scene classification (AVSC) has attracted increasing
attention from multidisciplinary communities. Previous studies tended to adopt
a pipeline training strategy, which uses well-trained visual and acoustic
encoders to extract high-level representations (embeddings) first, then
utilizes them to train the audio-visual classifier. In this way, the extracted
embeddings are well suited for uni-modal classifiers, but not necessarily
suited for multi-modal ones. In this paper, we propose a joint training
framework, using the acoustic features and raw images directly as inputs for
the AVSC task. Specifically, we retrieve the bottom layers of pre-trained image
models as visual encoder, and jointly optimize the scene classifier and 1D-CNN
based acoustic encoder during training. We evaluate the approach on the
development dataset of TAU Urban Audio-Visual Scenes 2021. The experimental
results show that our proposed approach achieves significant improvement over
the conventional pipeline training strategy. Moreover, our best single system
outperforms previous state-of-the-art methods, yielding a log loss of 0.1517
and accuracy of 94.59% on the official test fold.

### Title: Back-ends Selection for Deep Speaker Embeddings
* Paper ID: 2204.11403v1
* Paper URL: [http://arxiv.org/abs/2204.11403v1](http://arxiv.org/abs/2204.11403v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Probabilistic Linear Discriminant Analysis (PLDA) was the dominant and
necessary back-end for early speaker recognition approaches, like i-vector and
x-vector. However, with the development of neural networks and margin-based
loss functions, we can obtain deep speaker embeddings (DSEs), which have
advantages of increased inter-class separation and smaller intra-class
distances. In this case, PLDA seems unnecessary or even counterproductive for
the discriminative embeddings, and cosine similarity scoring (Cos) achieves
better performance than PLDA in some situations. Motivated by this, in this
paper, we systematically explore how to select back-ends (Cos or PLDA) for deep
speaker embeddings to achieve better performance in different situations. By
analyzing PLDA and the properties of DSEs extracted from models with different
numbers of segment-level layers, we make the conjecture that Cos is better in
same-domain situations and PLDA is better in cross-domain situations. We
conduct experiments on VoxCeleb and NIST SRE datasets in four application
situations, single-/multi-domain training and same-/cross-domain test, to
validate our conjecture and briefly explain why back-ends adaption algorithms
work.

### Title: Financial data analysis application via multi-strategy text processing
* Paper ID: 2204.11394v1
* Paper URL: [http://arxiv.org/abs/2204.11394v1](http://arxiv.org/abs/2204.11394v1)
* Updated Date: 2022-04-25
* Code URL: null
* Summary: Maintaining financial system stability is critical to economic development,
and early identification of risks and opportunities is essential. The financial
industry contains a wide variety of data, such as financial statements,
customer information, stock trading data, news, etc. Massive heterogeneous data
calls for intelligent algorithms for machines to process and understand. This
paper mainly focuses on the stock trading data and news about China A-share
companies. We present a financial data analysis application, Financial Quotient
Porter, designed to combine textual and numerical data by using a
multi-strategy data mining approach. Additionally, we present our efforts and
plans in deep learning financial text processing application scenarios using
natural language processing (NLP) and knowledge graph (KG) technologies. Based
on KG technology, risks and opportunities can be identified from heterogeneous
data. NLP technology can be used to extract entities, relations, and events
from unstructured text, and analyze market sentiment. Experimental results show
market sentiments towards a company and an industry, as well as news-level
associations between companies.

