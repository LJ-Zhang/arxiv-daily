### Title: Hybrid Facial Expression Recognition (FER2013) Model for Real-Time Emotion Classification and Prediction
* Paper ID: 2206.09509v1
* Paper URL: [http://arxiv.org/abs/2206.09509v1](http://arxiv.org/abs/2206.09509v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Facial Expression Recognition is a vital research topic in most fields
ranging from artificial intelligence and gaming to Human-Computer Interaction
(HCI) and Psychology. This paper proposes a hybrid model for Facial Expression
recognition, which comprises a Deep Convolutional Neural Network (DCNN) and
Haar Cascade deep learning architectures. The objective is to classify
real-time and digital facial images into one of the seven facial emotion
categories considered. The DCNN employed in this research has more
convolutional layers, ReLU Activation functions, and multiple kernels to
enhance filtering depth and facial feature extraction. In addition, a haar
cascade model was also mutually used to detect facial features in real-time
images and video frames. Grayscale images from the Kaggle repository (FER-2013)
and then exploited Graphics Processing Unit (GPU) computation to expedite the
training and validation process. Pre-processing and data augmentation
techniques are applied to improve training efficiency and classification
performance. The experimental results show a significantly improved
classification performance compared to state-of-the-art (SoTA) experiments and
research. Also, compared to other conventional models, this paper validates
that the proposed architecture is superior in classification performance with
an improvement of up to 6%, totaling up to 70% accuracy, and with less
execution time of 2098.8s.

### Title: DoG-HiT: A novel VLBI Multiscale Imaging Approach
* Paper ID: 2206.09501v1
* Paper URL: [http://arxiv.org/abs/2206.09501v1](http://arxiv.org/abs/2206.09501v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Reconstructing images from very long baseline interferometry (VLBI) data with
sparse sampling of the Fourier domain (uv-coverage) constitutes an ill-posed
deconvolution problem. It requires application of robust algorithms maximizing
the information extraction from all of the sampled spatial scales and
minimizing the influence of the unsampled scales on image quality. We develop a
new multiscale wavelet deconvolution algorithm DoG-HiT for imaging sparsely
sampled interferometric data which combines the difference of Gaussian (DoG)
wavelets and hard image thresholding (HiT). Based on DoG-HiT, we propose a
multi-step imaging pipeline for analysis of interferometric data. DoG-HiT
applies the compressed sensing approach to imaging by employing a flexible DoG
wavelet dictionary which is designed to adapt smoothly to the uv-coverage. It
uses closure properties as data fidelity terms only initially and perform
non-convex, non-smooth optimization by an amplitude conserving and total flux
conserving hard thresholding splitting. DoG-HiT calculates a multiresolution
support as a side product. The final reconstruction is refined through
self-calibration loops and imaging with amplitude and phase information applied
for the multiresolution support only. We demonstrate the stability of DoG-HiT
and benchmark its performance against image reconstructions made with CLEAN and
Regularized Maximum-Likelihood (RML) methods using synthetic data. The
comparison shows that DoG-HiT matches the superresolution achieved by the RML
reconstructions and surpasses the sensitivity to extended emission reached by
CLEAN. Application of regularized maximum likelihood methods outfitted with
flexible multiscale wavelet dictionaries to imaging of interferometric data
matches the performance of state-of-the art convex optimization imaging
algorithms and requires fewer prior and user defined constraints.

### Title: LordNet: Learning to Solve Parametric Partial Differential Equations without Simulated Data
* Paper ID: 2206.09418v1
* Paper URL: [http://arxiv.org/abs/2206.09418v1](http://arxiv.org/abs/2206.09418v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Neural operators, as a powerful approximation to the non-linear operators
between infinite-dimensional function spaces, have proved to be promising in
accelerating the solution of partial differential equations (PDE). However, it
requires a large amount of simulated data which can be costly to collect,
resulting in a chicken-egg dilemma and limiting its usage in solving PDEs. To
jump out of the dilemma, we propose a general data-free paradigm where the
neural network directly learns physics from the mean squared residual (MSR)
loss constructed by the discretized PDE. We investigate the physical
information in the MSR loss and identify the challenge that the neural network
must have the capacity to model the long range entanglements in the spatial
domain of the PDE, whose patterns vary in different PDEs. Therefore, we propose
the low-rank decomposition network (LordNet) which is tunable and also
efficient to model various entanglements. Specifically, LordNet learns a
low-rank approximation to the global entanglements with simple fully connected
layers, which extracts the dominant pattern with reduced computational cost.
The experiments on solving Poisson's equation and Navier-Stokes equation
demonstrate that the physical constraints by the MSR loss can lead to better
accuracy and generalization ability of the neural network. In addition, LordNet
outperforms other modern neural network architectures in both PDEs with the
fewest parameters and the fastest inference speed. For Navier-Stokes equation,
the learned operator is over 50 times faster than the finite difference
solution with the same computational resources.

### Title: Search for nonresonant Higgs boson pair production in final state with two bottom quarks and two tau leptons in proton-proton collisions at $\sqrt{s}$ = 13 TeV
* Paper ID: 2206.09401v1
* Paper URL: [http://arxiv.org/abs/2206.09401v1](http://arxiv.org/abs/2206.09401v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: A search for the nonresonant production of Higgs boson pairs (HH) via
gluon-gluon and vector boson fusion processes in final states with two bottom
quarks and two tau leptons is presented. The search uses data from
proton-proton collisions at a center-of-mass energy of $\sqrt{s}$ =13 TeV
recorded with the CMS detector at the LHC, corresponding to an integrated
luminosity of 138 fb$^{-1}$. Events in which at least one tau lepton decays
hadronically are considered and multiple machine learning techniques are used
to identify and extract the signal. The data are found to be consistent, within
uncertainties, with the standard model (SM) predictions. Upper limits on the HH
production cross section are set to constrain the parameter space for anomalous
Higgs boson couplings. The observed (expected) upper limit at 95% confidence
level corresponds to 3.3 (5.2) times the SM prediction for the inclusive HH
cross section and to 124 (154) times the SM prediction for the vector boson
fusion \HH cross section. At 95% confidence level, the Higgs field
self-coupling is constrained to be within -1.7 and 8.7 times the SM
expectation, and the coupling of two Higgs bosons to two vector bosons is
constrained to be within -0.4 and 2.6 times the SM expectation.

### Title: Privacy-Preserving Analytics on Decentralized Social Graphs: The Case of Eigendecomposition
* Paper ID: 2206.09388v1
* Paper URL: [http://arxiv.org/abs/2206.09388v1](http://arxiv.org/abs/2206.09388v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Analytics over social graphs allows to extract valuable knowledge and
insights for many fields like community detection, fraud detection, and
interest mining. In practice, decentralized social graphs frequently arise,
where the social graph is not available to a single entity and is decentralized
among a large number of users, each holding only a limited local view about the
whole graph. Collecting the local views for analytics of decentralized social
graphs raises critical privacy concerns, as they encode private information
about the social interactions among individuals. In this paper, we design,
implement, and evaluate PrivGED, a new system aimed at privacy-preserving
analytics over decentralized social graphs. PrivGED focuses on the support for
eigendecomposition, one popular and fundamental graph analytics task producing
eigenvalues/eigenvectors over the adjacency matrix of a social graph and
benefits various practical applications. PrivGED is built from a delicate
synergy of insights on graph analytics, lightweight cryptography, and
differential privacy, allowing users to securely contribute their local views
on a decentralized social graph for a cloud-based eigendecomposition analytics
service while gaining strong privacy protection. Extensive experiments over
real-world social graph datasets demonstrate that PrivGED achieves accuracy
comparable to the plaintext domain, with practically affordable performance
superior to prior art.

### Title: Label and Distribution-discriminative Dual Representation Learning for Out-of-Distribution Detection
* Paper ID: 2206.09387v1
* Paper URL: [http://arxiv.org/abs/2206.09387v1](http://arxiv.org/abs/2206.09387v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: To classify in-distribution samples, deep neural networks learn
label-discriminative representations, which, however, are not necessarily
distribution-discriminative according to the information bottleneck. Therefore,
trained networks could assign unexpected high-confidence predictions to
out-of-distribution samples drawn from distributions differing from that of
in-distribution samples. Specifically, networks extract the strongly
label-related information from in-distribution samples to learn the
label-discriminative representations but discard the weakly label-related
information. Accordingly, networks treat out-of-distribution samples with
minimum label-sensitive information as in-distribution samples. According to
the different informativeness properties of in- and out-of-distribution
samples, a Dual Representation Learning (DRL) method learns
distribution-discriminative representations that are weakly related to the
labeling of in-distribution samples and combines label- and
distribution-discriminative representations to detect out-of-distribution
samples. For a label-discriminative representation, DRL constructs the
complementary distribution-discriminative representation by an implicit
constraint, i.e., integrating diverse intermediate representations where an
intermediate representation less similar to the label-discriminative
representation owns a higher weight. Experiments show that DRL outperforms the
state-of-the-art methods for out-of-distribution detection.

### Title: A Self-Guided Framework for Radiology Report Generation
* Paper ID: 2206.09378v1
* Paper URL: [http://arxiv.org/abs/2206.09378v1](http://arxiv.org/abs/2206.09378v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Automatic radiology report generation is essential to computer-aided
diagnosis. Through the success of image captioning, medical report generation
has been achievable. However, the lack of annotated disease labels is still the
bottleneck of this area. In addition, the image-text data bias problem and
complex sentences make it more difficult to generate accurate reports. To
address these gaps, we pre-sent a self-guided framework (SGF), a suite of
unsupervised and supervised deep learning methods to mimic the process of human
learning and writing. In detail, our framework obtains the domain knowledge
from medical reports with-out extra disease labels and guides itself to extract
fined-grain visual features as-sociated with the text. Moreover, SGF
successfully improves the accuracy and length of medical report generation by
incorporating a similarity comparison mechanism that imitates the process of
human self-improvement through compar-ative practice. Extensive experiments
demonstrate the utility of our SGF in the majority of cases, showing its
superior performance over state-of-the-art meth-ods. Our results highlight the
capacity of the proposed framework to distinguish fined-grained visual details
between words and verify its advantage in generating medical reports.

### Title: Automatic Map Generation for Autonomous Driving System Testing
* Paper ID: 2206.09357v1
* Paper URL: [http://arxiv.org/abs/2206.09357v1](http://arxiv.org/abs/2206.09357v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: High-definition (HD) maps are essential in testing autonomous driving systems
(ADSs). HD maps essentially determine the potential diversity of the testing
scenarios. However, the current HD maps suffer from two main limitations: lack
of junction diversity in the publicly available HD maps and cost-consuming to
build a new HD map. Hence, in this paper, we propose, FEAT2MAP, to
automatically generate concise HD maps with scenario diversity guarantees.
FEAT2MAP focuses on junctions as they significantly influence scenario
diversity, especially in urban road networks. FEAT2MAP first defines a set of
features to characterize junctions. Then, FEAT2MAP extracts and samples
concrete junction features from a list of input HD maps or user-defined
requirements. Each junction feature generates a junction. Finally, FEAT2MAP
builds a map by connecting the junctions in a grid layout. To demonstrate the
effectiveness of FEAT2MAP, we conduct experiments with the public HD maps from
SVL and the open-source ADS Apollo. The results show that FEAT2MAP can (1)
generate new maps of reduced size while maintaining scenario diversity in terms
of the code coverage and motion states of the ADS under test, and (2) generate
new maps of increased scenario diversity by merging intersection features from
multiple maps or taking user inputs.

### Title: Extracting Hale Cycle Related Components from Cosmic-Ray Data Using Principal Component Analysis
* Paper ID: 2206.09350v1
* Paper URL: [http://arxiv.org/abs/2206.09350v1](http://arxiv.org/abs/2206.09350v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: We decompose the monthly cosmic-ray data, using several neutron monitor count
rates, of Cycles 19-24 with principal component analysis (PCA). We show using
different cycle limits that the first and second PC of cosmic-ray (CR) data
explain 77-79% and 13-15% of the total variation of the Oulu CR Cycles 20-24
(C20- C24), 73-77% and 13-17% of the variation of Hermanus C20-C24, and 74-78%
and 17-21% of the Climax C19-C22, respectively. The PC1 time series of the CR
Cycles 19-24 has only one peak in its power spectrum at the period 10.95 years,
which is the average solar cycle period for the interval SC19-SC24. The PC2
time series of the same cycles has a clear peak at period 21.90 (Hale cycle)
and another peak at 1/3 of that period with no peak at the solar cycle period.
We show that the PC2 of the CR is essential in explaining the differences in
the intensities of the even and odd cycles of the CR. The odd cycles have
positive phase in the first half and negative phase in the second half of their
PC2. This leads to slow decrease of the intensity in the beginning of the cycle
and at minimum for the odd cycles. On the contrary, for the even cycles the
phases are vice versa and this leads to faster decrease and more rapid recovery
in the CR intensity of the cycle. As a consequence the even cycles have more
peak-like structure. The only exceptions of this rule are Cycles 23 and 24 such
the former has almost zero line PC2, and the latter has similar PC2 than the
earlier odd cycles. These results are confirmed with skewness-kurtosis (S-K)
analysis. Furthermore, S-K shows that other even and odd cycles, except Cycle
21, are on the regression line with correlation coefficient 0.85. The Cycles 21
of all calculated eight stations are compactly located in the S -K coordinate
system and have smaller skewnesses and higher kurtoses than the odd Cycles 23.

### Title: Learning Multiscale Transformer Models for Sequence Generation
* Paper ID: 2206.09337v1
* Paper URL: [http://arxiv.org/abs/2206.09337v1](http://arxiv.org/abs/2206.09337v1)
* Updated Date: 2022-06-19
* Code URL: null
* Summary: Multiscale feature hierarchies have been witnessed the success in the
computer vision area. This further motivates researchers to design multiscale
Transformer for natural language processing, mostly based on the self-attention
mechanism. For example, restricting the receptive field across heads or
extracting local fine-grained features via convolutions. However, most of
existing works directly modeled local features but ignored the word-boundary
information. This results in redundant and ambiguous attention distributions,
which lacks of interpretability. In this work, we define those scales in
different linguistic units, including sub-words, words and phrases. We built a
multiscale Transformer model by establishing relationships among scales based
on word-boundary information and phrase-level prior knowledge. The proposed
\textbf{U}niversal \textbf{M}ulti\textbf{S}cale \textbf{T}ransformer, namely
\textsc{Umst}, was evaluated on two sequence generation tasks. Notably, it
yielded consistent performance gains over the strong baseline on several test
sets without sacrificing the efficiency.

