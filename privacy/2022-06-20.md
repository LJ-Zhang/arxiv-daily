### Title: Decentralized Distributed Learning with Privacy-Preserving Data Synthesis
* Paper ID: 2206.10048v1
* Paper URL: [http://arxiv.org/abs/2206.10048v1](http://arxiv.org/abs/2206.10048v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: In the medical field, multi-center collaborations are often sought to yield
more generalizable findings by leveraging the heterogeneity of patient and
clinical data. However, recent privacy regulations hinder the possibility to
share data, and consequently, to come up with machine learning-based solutions
that support diagnosis and prognosis. Federated learning (FL) aims at
sidestepping this limitation by bringing AI-based solutions to data owners and
only sharing local AI models, or parts thereof, that need then to be
aggregated. However, most of the existing federated learning solutions are
still at their infancy and show several shortcomings, from the lack of a
reliable and effective aggregation scheme able to retain the knowledge learned
locally to weak privacy preservation as real data may be reconstructed from
model updates. Furthermore, the majority of these approaches, especially those
dealing with medical data, relies on a centralized distributed learning
strategy that poses robustness, scalability and trust issues. In this paper we
present a decentralized distributed method that, exploiting concepts from
experience replay and generative adversarial research, effectively integrates
features from local nodes, providing models able to generalize across multiple
datasets while maintaining privacy. The proposed approach is tested on two
tasks - tuberculosis and melanoma classification - using multiple datasets in
order to simulate realistic non-i.i.d. data scenarios. Results show that our
approach achieves performance comparable to both standard (non-federated)
learning and federated methods in their centralized (thus, more favourable)
formulation.

### Title: QuAFL: Federated Averaging Can Be Both Asynchronous and Communication-Efficient
* Paper ID: 2206.10032v1
* Paper URL: [http://arxiv.org/abs/2206.10032v1](http://arxiv.org/abs/2206.10032v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Federated Learning (FL) is an emerging paradigm to enable the large-scale
distributed training of machine learning models, while still providing privacy
guarantees.
  In this work, we jointly address two of the main practical challenges when
scaling federated optimization to large node counts: the need for tight
synchronization between the central authority and individual computing nodes,
and the large communication cost of transmissions between the central server
and clients.
  Specifically, we present a new variant of the classic federated averaging
(FedAvg) algorithm, which supports both asynchronous communication and
communication compression. We provide a new analysis technique showing that, in
spite of these system relaxations, our algorithm essentially matches the best
known bounds for FedAvg, under reasonable parameter settings.
  On the experimental side, we show that our algorithm ensures fast practical
convergence for standard federated tasks.

### Title: Mitigating Data Heterogeneity in Federated Learning with Data Augmentation
* Paper ID: 2206.09979v1
* Paper URL: [http://arxiv.org/abs/2206.09979v1](http://arxiv.org/abs/2206.09979v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: Federated Learning (FL) is a prominent framework that enables training a
centralized model while securing user privacy by fusing local, decentralized
models. In this setting, one major obstacle is data heterogeneity, i.e., each
client having non-identically and independently distributed (non-IID) data.
This is analogous to the context of Domain Generalization (DG), where each
client can be treated as a different domain. However, while many approaches in
DG tackle data heterogeneity from the algorithmic perspective, recent evidence
suggests that data augmentation can induce equal or greater performance.
Motivated by this connection, we present federated versions of popular DG
algorithms, and show that by applying appropriate data augmentation, we can
mitigate data heterogeneity in the federated setting, and obtain higher
accuracy on unseen clients. Equipped with data augmentation, we can achieve
state-of-the-art performance using even the most basic Federated Averaging
algorithm, with much sparser communication.

### Title: SoteriaFL: A Unified Framework for Private Federated Learning with Communication Compression
* Paper ID: 2206.09888v1
* Paper URL: [http://arxiv.org/abs/2206.09888v1](http://arxiv.org/abs/2206.09888v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: To enable large-scale machine learning in bandwidth-hungry environments such
as wireless networks, significant progress has been made recently in designing
communication-efficient federated learning algorithms with the aid of
communication compression. On the other end, privacy-preserving, especially at
the client level, is another important desideratum that has not been addressed
simultaneously in the presence of advanced communication compression techniques
yet. In this paper, we propose a unified framework that enhances the
communication efficiency of private federated learning with communication
compression. Exploiting both general compression operators and local
differential privacy, we first examine a simple algorithm that applies
compression directly to differentially-private stochastic gradient descent, and
identify its limitations. We then propose a unified framework SoteriaFL for
private federated learning, which accommodates a general family of local
gradient estimators including popular stochastic variance-reduced gradient
methods and the state-of-the-art shifted compression scheme. We provide a
comprehensive characterization of its performance trade-offs in terms of
privacy, utility, and communication complexity, where SoteraFL is shown to
achieve better communication complexity without sacrificing privacy nor utility
than other private federated learning algorithms without communication
compression.

### Title: Privacy-aware Secure Region-based Handover for Small Cell Networks in 5G-enabled Mobile Communication
* Paper ID: 2206.09870v1
* Paper URL: [http://arxiv.org/abs/2206.09870v1](http://arxiv.org/abs/2206.09870v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: The 5G mobile communication network provides seamless communications between
users and service providers and promises to achieve several stringent
requirements, such as seamless mobility and massive connectivity. Although 5G
can offer numerous benefits, security and privacy issues still need to be
addressed. For example, the inclusion of small cell networks (SCN) into 5G
brings the network closer to the connected users, providing a better quality of
services (QoS), resulting in a significant increase in the number of Handover
procedures (HO), which will affect the security, latency and efficiency of the
network. It is then crucial to design a scheme that supports seamless handovers
through secure authentication to avoid the consequences of SCN. To address this
issue, this article proposes a secure region-based handover scheme with user
anonymity and an efficient revocation mechanism that supports seamless
connectivity for SCNs in 5G. In this context, we introduce three
privacy-preserving authentication protocols, i.e., initial authentication
protocol, intra-region handover protocol and inter-region handover protocol,
for dealing with three communication scenarios. To the best of our knowledge,
this is the first paper to consider the privacy and security in both the
intra-region and inter-region handover scenarios in 5G communication. Detailed
security and performance analysis of our proposed scheme is presented to show
that it is resilient against many security threats, is cost-effective in
computation and provides an efficient solution for the 5G enabled mobile
communication.

### Title: WiFi-based Spatiotemporal Human Action Perception
* Paper ID: 2206.09867v1
* Paper URL: [http://arxiv.org/abs/2206.09867v1](http://arxiv.org/abs/2206.09867v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: WiFi-based sensing for human activity recognition (HAR) has recently become a
hot topic as it brings great benefits when compared with video-based HAR, such
as eliminating the demands of line-of-sight (LOS) and preserving privacy.
Making the WiFi signals to 'see' the action, however, is quite coarse and thus
still in its infancy. An end-to-end spatiotemporal WiFi signal neural network
(STWNN) is proposed to enable WiFi-only sensing in both line-of-sight and
non-line-of-sight scenarios. Especially, the 3D convolution module is able to
explore the spatiotemporal continuity of WiFi signals, and the feature
self-attention module can explicitly maintain dominant features. In addition, a
novel 3D representation for WiFi signals is designed to preserve multi-scale
spatiotemporal information. Furthermore, a small wireless-vision dataset (WVAR)
is synchronously collected to extend the potential of STWNN to 'see' through
occlusions. Quantitative and qualitative results on WVAR and the other three
public benchmark datasets demonstrate the effectiveness of our approach on both
accuracy and shift consistency.

### Title: Performance-Oriented Design for Intelligent Reflecting Surface Assisted Federated Learning
* Paper ID: 2206.09578v1
* Paper URL: [http://arxiv.org/abs/2206.09578v1](http://arxiv.org/abs/2206.09578v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: To efficiently exploit the massive raw data that is pervading generated at
mobile edge networks, federated learning (FL) has emerged as a promising
distributed learning technique that was regarded as a substitute for
centralized learning operations. By collaboratively training a shared learning
model at edge devices, the raw data transmission and storage are bypassed via
the local computed parameters/gradients exchange in FL. Hence, FL can overcome
high communication latency and privacy issues. While the high dimensionality in
iterative updates (millions of parameters/gradients may be included in the
model training) still conflicts with the scarcity of communication resources.
Over-the-air computation (AirComp) has come into the spotlight recently which
profitably leverages the inherent superposition property of wireless channels
to perform efficient model aggeration. However, the model aggregation accuracy
is still severely damaged by the unfavorable wireless propagation channels. In
this paper, we harness the intelligent reflecting surface (IRS) to program the
wireless channel, thus acquiring a satisfying learning performance.
Specifically, a performance-oriented design scheme that directly minimizes the
optimality gap of the loss function is proposed to accelerate the convergence
of AirComp based FL. Firstly, we analyze the convergence behavior of the FL
procedure. Then, both offline and online design approaches are proposed based
on the obtained optimality gap. We adopt the block coordinate descent (BCD)
method to tackle the highly-intractable problem. Simulation results demonstrate
that such a performance-oriented design strategy can achieve higher test
accuracy than the conventional isolated mean square error (MSE) minimization
approach in FL.

### Title: Shuffle Gaussian Mechanism for Differential Privacy
* Paper ID: 2206.09569v1
* Paper URL: [http://arxiv.org/abs/2206.09569v1](http://arxiv.org/abs/2206.09569v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: We study Gaussian mechanism in the shuffle model of differential privacy
(DP). Particularly, we characterize the mechanism's R\'enyi differential
privacy (RDP), showing that it is of the form: $$ \epsilon(\lambda) \leq
\frac{1}{\lambda-1}\log\left(\frac{e^{-\lambda/2\sigma^2}}{n^\lambda}\sum_{\substack{k_1+\dotsc+k_n=\lambda;\\k_1,\dotsc,k_n\geq
0}}\binom{\lambda!}{k_1,\dotsc,k_n}e^{\sum_{i=1}^nk_i^2/2\sigma^2}\right) $$ We
further prove that the RDP is strictly upper-bounded by the Gaussian RDP
without shuffling. The shuffle Gaussian RDP is advantageous in composing
multiple DP mechanisms, where we demonstrate its improvement over the
state-of-the-art approximate DP composition theorems in privacy guarantees of
the shuffle model. Moreover, we extend our study to the subsampled shuffle
mechanism and the recently proposed shuffled check-in mechanism, which are
protocols geared towards distributed/federated learning. Finally, an empirical
study of these mechanisms is given to demonstrate the efficacy of employing
shuffle Gaussian mechanism under the distributed learning framework to
guarantee rigorous user privacy.

### Title: Towards Trustworthy Edge Intelligence: Insights from Voice-Activated Services
* Paper ID: 2206.09523v1
* Paper URL: [http://arxiv.org/abs/2206.09523v1](http://arxiv.org/abs/2206.09523v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: In an age of surveillance capitalism, anchoring the design of emerging smart
services in trustworthiness is urgent and important. Edge Intelligence, which
brings together the fields of AI and Edge computing, is a key enabling
technology for smart services. Trustworthy Edge Intelligence should thus be a
priority research concern. However, determining what makes Edge Intelligence
trustworthy is not straight forward. This paper examines requirements for
trustworthy Edge Intelligence in a concrete application scenario of
voice-activated services. We contribute to deepening the understanding of
trustworthiness in the emerging Edge Intelligence domain in three ways:
firstly, we propose a unified framing for trustworthy Edge Intelligence that
jointly considers trustworthiness attributes of AI and the IoT. Secondly, we
present research outputs of a tangible case study in voice-activated services
that demonstrates interdependencies between three important trustworthiness
attributes: privacy, security and fairness. Thirdly, based on the empirical and
analytical findings, we highlight challenges and open questions that present
important future research areas for trustworthy Edge Intelligence.

### Title: Walking to Hide: Privacy Amplification via Random Message Exchanges in Network
* Paper ID: 2206.09519v1
* Paper URL: [http://arxiv.org/abs/2206.09519v1](http://arxiv.org/abs/2206.09519v1)
* Updated Date: 2022-06-20
* Code URL: null
* Summary: The *shuffle model* is a powerful tool to amplify the privacy guarantees of
the *local model* of differential privacy. In contrast to the fully
decentralized manner of guaranteeing privacy in the local model, the shuffle
model requires a central, trusted shuffler. To avoid this central shuffler,
recent work of Liew et al. (2022) proposes shuffling locally randomized data in
a decentralized manner, via random walks on the communication network
constituted by the clients. The privacy amplification bound it thus provides
depends on the topology of the underlying communication network, even for
infinitely long random walks. It does not match the state-of-the-art privacy
amplification bound for the shuffle model (Feldman et al., 2021).
  In this work, we prove that the output of~$n$ clients' data, each perturbed
by an ${\epsilon}_0$-local randomizer, and shuffled by random walks with a
logarithmic number of steps, is $( {O} ( (1 - e^{-\epsilon_0} ) \sqrt{ (
e^{\epsilon_0} / n ) \ln (1 / \delta ) } ), O(\delta) )$-differentially
private. Importantly, this bound is independent of the topology of the
communication network, and asymptotically closes the gap between the privacy
amplification bounds for the network shuffle model (Liew et al., 2022) and the
shuffle model (Feldman et al., 2021). Our proof is based on a reduction to the
shuffle model, and an analysis of the distribution of random walks of finite
length. Building on this, we further show that if each client is sampled
independently with probability~$p$, the privacy guarantee of the network
shuffle model can be further improved to $( {O} ( (1 - e^{-\epsilon_0} )
\sqrt{p ( e^{\epsilon_0} / n ) \ln (1 / \delta ) } ) , O(\delta) )$.
Importantly, the subsampling is also performed in a fully decentralized manner
that does not require a trusted central entity; compared with related bounds in
prior work, our bound is stronger.

