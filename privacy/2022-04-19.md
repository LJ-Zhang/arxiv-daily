### Title: The 2020 Census Disclosure Avoidance System TopDown Algorithm
* Paper ID: 2204.08986v1
* Paper URL: [http://arxiv.org/abs/2204.08986v1](http://arxiv.org/abs/2204.08986v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: The Census TopDown Algorithm (TDA) is a disclosure avoidance system using
differential privacy for privacy-loss accounting. The algorithm ingests the
final, edited version of the 2020 Census data and the final tabulation
geographic definitions. The algorithm then creates noisy versions of key
queries on the data, referred to as measurements, using zero-Concentrated
Differential Privacy. Another key aspect of the TDA are invariants, statistics
that the Census Bureau has determined, as matter of policy, to exclude from the
privacy-loss accounting. The TDA post-processes the measurements together with
the invariants to produce a Microdata Detail File (MDF) that contains one
record for each person and one record for each housing unit enumerated in the
2020 Census. The MDF is passed to the 2020 Census tabulation system to produce
the 2020 Census Redistricting Data (P.L. 94-171) Summary File. This paper
describes the mathematics and testing of the TDA for this purpose.

### Title: Identifying organizations receiving personal data in Android Apps
* Paper ID: 2204.09495v1
* Paper URL: [http://arxiv.org/abs/2204.09495v1](http://arxiv.org/abs/2204.09495v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Many studies have demonstrated that mobile applications are common means to
collect massive amounts of personal data. This goes unnoticed by most users,
who are also unaware that many different organizations are receiving this data,
even from multiple apps in parallel. This paper assesses different techniques
to identify the organizations that are receiving personal data flows in the
Android ecosystem, namely the WHOIS service, SSL certificates inspection, and
privacy policy textual analysis. Based on our findings, we propose a fully
automated method that combines the most successful techniques, achieving a
94.73% precision score in identifying the recipient organization. We further
demonstrate our method by evaluating 1,000 Android apps and exposing the
corporations that collect the users' personal data.

### Title: Retrieval Enhanced Data Augmentation for Question Answering on Privacy Policies
* Paper ID: 2204.08952v1
* Paper URL: [http://arxiv.org/abs/2204.08952v1](http://arxiv.org/abs/2204.08952v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Prior studies in privacy policies frame the question answering (QA) tasks as
identifying the most relevant text segment or a list of sentences from the
policy document for a user query. However, annotating such a dataset is
challenging as it requires specific domain expertise (e.g., law academics).
Even if we manage a small-scale one, a bottleneck that remains is that the
labeled data are heavily imbalanced (only a few segments are relevant)
--limiting the gain in this domain. Therefore, in this paper, we develop a
novel data augmentation framework based on ensembling retriever models that
captures the relevant text segments from unlabeled policy documents and expand
the positive examples in the training set. In addition, to improve the
diversity and quality of the augmented data, we leverage multiple pre-trained
language models (LMs) and cascaded them with noise reduction oracles. Using our
augmented data on the PrivacyQA benchmark, we elevate the existing baseline by
a large margin (10\% F1) and achieve a new state-of-the-art F1 score of 50\%.
Our ablation studies provide further insights into the effectiveness of our
approach.

### Title: Invertible Mask Network for Face Privacy-Preserving
* Paper ID: 2204.08895v1
* Paper URL: [http://arxiv.org/abs/2204.08895v1](http://arxiv.org/abs/2204.08895v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Face privacy-preserving is one of the hotspots that arises dramatic interests
of research. However, the existing face privacy-preserving methods aim at
causing the missing of semantic information of face and cannot preserve the
reusability of original facial information. To achieve the naturalness of the
processed face and the recoverability of the original protected face, this
paper proposes face privacy-preserving method based on Invertible "Mask"
Network (IMN). In IMN, we introduce a Mask-net to generate "Mask" face firstly.
Then, put the "Mask" face onto the protected face and generate the masked face,
in which the masked face is indistinguishable from "Mask" face. Finally, "Mask"
face can be put off from the masked face and obtain the recovered face to the
authorized users, in which the recovered face is visually indistinguishable
from the protected face. The experimental results show that the proposed method
can not only effectively protect the privacy of the protected face, but also
almost perfectly recover the protected face from the masked face.

### Title: CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution
* Paper ID: 2204.08742v1
* Paper URL: [http://arxiv.org/abs/2204.08742v1](http://arxiv.org/abs/2204.08742v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: The migration of computation to the cloud has raised privacy concerns as
sensitive data becomes vulnerable to attacks since they need to be decrypted
for processing. Fully Homomorphic Encryption (FHE) mitigates this issue as it
enables meaningful computations to be performed directly on encrypted data.
Nevertheless, FHE is orders of magnitude slower than unencrypted computation,
which hinders its practicality and adoption. Therefore, improving FHE
performance is essential for its real world deployment. In this paper, we
present a year-long effort to design, implement, fabricate, and post-silicon
validate a hardware accelerator for Fully Homomorphic Encryption dubbed CoFHEE.
With a design area of $12mm^2$, CoFHEE aims to improve performance of
ciphertext multiplications, the most demanding arithmetic FHE operation, by
accelerating several primitive operations on polynomials, such as polynomial
additions and subtractions, Hadamard product, and Number Theoretic Transform.
CoFHEE supports polynomial degrees of up to $n = 2^{14}$ with a maximum
coefficient sizes of 128 bits, while it is capable of performing ciphertext
multiplications entirely on chip for $n \leq 2^{13}$. CoFHEE is fabricated in
55nm CMOS technology and achieves 250 MHz with our custom-built low-power
digital PLL design. In addition, our chip includes two communication interfaces
to the host machine: UART and SPI. This manuscript presents all steps and
design techniques in the ASIC development process, ranging from RTL design to
fabrication and validation. We evaluate our chip with performance and power
experiments and compare it against state-of-the-art software implementations
and other ASIC designs. Developed RTL files are available in an open-source
repository.

### Title: Toward Understanding the Use of Centralized Exchanges for Decentralized Cryptocurrency
* Paper ID: 2204.08664v1
* Paper URL: [http://arxiv.org/abs/2204.08664v1](http://arxiv.org/abs/2204.08664v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Cryptocurrency has been extensively studied as a decentralized financial
technology built on blockchain. However, there is a lack of understanding of
user experience with cryptocurrency exchanges, the main means for novice users
to interact with cryptocurrency. We conduct a qualitative study to provide a
panoramic view of user experience and security perception of exchanges. All 15
Chinese participants mainly use centralized exchanges (CEX) instead of
decentralized exchanges (DEX) to trade decentralized cryptocurrency, which is
paradoxical. A closer examination reveals that CEXes provide better usability
and charge lower transaction fee than DEXes. Country-specific security
perceptions are observed. Though DEXes provide better anonymity and privacy
protection, and are free of governmental regulation, these are not necessary
features for many participants. Based on the findings, we propose design
implications to make cryptocurrency trading more decentralized.

### Title: Poisons that are learned faster are more effective
* Paper ID: 2204.08615v1
* Paper URL: [http://arxiv.org/abs/2204.08615v1](http://arxiv.org/abs/2204.08615v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Imperceptible poisoning attacks on entire datasets have recently been touted
as methods for protecting data privacy. However, among a number of defenses
preventing the practical use of these techniques, early-stopping stands out as
a simple, yet effective defense. To gauge poisons' vulnerability to
early-stopping, we benchmark error-minimizing, error-maximizing, and synthetic
poisons in terms of peak test accuracy over 100 epochs and make a number of
surprising observations. First, we find that poisons that reach a low training
loss faster have lower peak test accuracy. Second, we find that a current
state-of-the-art error-maximizing poison is 7 times less effective when poison
training is stopped at epoch 8. Third, we find that stronger, more transferable
adversarial attacks do not make stronger poisons. We advocate for evaluating
poisons in terms of peak test accuracy.

