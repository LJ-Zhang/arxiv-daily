### Title: Unlocking High-Accuracy Differentially Private Image Classification through Scale
* Paper ID: 2204.13650v1
* Paper URL: [http://arxiv.org/abs/2204.13650v1](http://arxiv.org/abs/2204.13650v1)
* Updated Date: 2022-04-28
* Code URL: [https://github.com/deepmind/jax_privacy](https://github.com/deepmind/jax_privacy)
* Summary: Differential Privacy (DP) provides a formal privacy guarantee preventing
adversaries with access to a machine learning model from extracting information
about individual training points. Differentially Private Stochastic Gradient
Descent (DP-SGD), the most popular DP training method, realizes this protection
by injecting noise during training. However previous works have found that
DP-SGD often leads to a significant degradation in performance on standard
image classification benchmarks. Furthermore, some authors have postulated that
DP-SGD inherently performs poorly on large models, since the norm of the noise
required to preserve privacy is proportional to the model dimension. In
contrast, we demonstrate that DP-SGD on over-parameterized models can perform
significantly better than previously thought. Combining careful hyper-parameter
tuning with simple techniques to ensure signal propagation and improve the
convergence rate, we obtain a new SOTA on CIFAR-10 of 81.4% under (8,
10^{-5})-DP using a 40-layer Wide-ResNet, improving over the previous SOTA of
71.7%. When fine-tuning a pre-trained 200-layer Normalizer-Free ResNet, we
achieve a remarkable 77.1% top-1 accuracy on ImageNet under (1, 8*10^{-7})-DP,
and achieve 81.1% under (8, 8*10^{-7})-DP. This markedly exceeds the previous
SOTA of 47.9% under a larger privacy budget of (10, 10^{-6})-DP. We believe our
results are a significant step towards closing the accuracy gap between private
and non-private image classification.

### Title: EVI: Multilingual Spoken Dialogue Tasks and Dataset for Knowledge-Based Enrolment, Verification, and Identification
* Paper ID: 2204.13496v1
* Paper URL: [http://arxiv.org/abs/2204.13496v1](http://arxiv.org/abs/2204.13496v1)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: Knowledge-based authentication is crucial for task-oriented spoken dialogue
systems that offer personalised and privacy-focused services. Such systems
should be able to enrol (E), verify (V), and identify (I) new and recurring
users based on their personal information, e.g. postcode, name, and date of
birth. In this work, we formalise the three authentication tasks and their
evaluation protocols, and we present EVI, a challenging spoken multilingual
dataset with 5,506 dialogues in English, Polish, and French. Our proposed
models set the first competitive benchmarks, explore the challenges of
multilingual natural language processing of spoken dialogue, and set directions
for future research.

### Title: Federated Learning on Heterogeneous and Long-Tailed Data via Classifier Re-Training with Federated Features
* Paper ID: 2204.13399v1
* Paper URL: [http://arxiv.org/abs/2204.13399v1](http://arxiv.org/abs/2204.13399v1)
* Updated Date: 2022-04-28
* Code URL: [https://github.com/shangxinyi/creff-fl](https://github.com/shangxinyi/creff-fl)
* Summary: Federated learning (FL) provides a privacy-preserving solution for
distributed machine learning tasks. One challenging problem that severely
damages the performance of FL models is the co-occurrence of data heterogeneity
and long-tail distribution, which frequently appears in real FL applications.
In this paper, we reveal an intriguing fact that the biased classifier is the
primary factor leading to the poor performance of the global model. Motivated
by the above finding, we propose a novel and privacy-preserving FL method for
heterogeneous and long-tailed data via Classifier Re-training with Federated
Features (CReFF). The classifier re-trained on federated features can produce
comparable performance as the one re-trained on real data in a
privacy-preserving manner without information leakage of local data or class
distribution. Experiments on several benchmark datasets show that the proposed
CReFF is an effective solution to obtain a promising FL model under
heterogeneous and long-tailed data. Comparative results with the
state-of-the-art FL methods also validate the superiority of CReFF. Our code is
available at https://github.com/shangxinyi/CReFF-FL.

### Title: A Decision Model for Federated Learning Architecture Pattern Selection
* Paper ID: 2204.13291v1
* Paper URL: [http://arxiv.org/abs/2204.13291v1](http://arxiv.org/abs/2204.13291v1)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: Federated learning is growing fast in both academia and industry to resolve
data hungriness and privacy issues in machine learning. A federated learning
system being widely distributed with different components and stakeholders
requires software system design thinking. For instance, multiple patterns and
tactics have been summarised by researchers that cover various aspects, from
client management, training configuration, model deployment, etc. However, the
multitude of patterns leaves the designers confused about when and which
pattern to adopt or adapt. Therefore, in this paper, we present a set of
decision models to assist designers and architects who have limited knowledge
in federated learning, in selecting architectural patterns for federated
learning architecture design. Each decision model maps functional and
non-functional requirements of federated learning systems to a set of patterns.
we also clarify the trade-offs that may be implicit in the patterns. We
evaluated the decision model through a set of interviews with practitioners to
assess the correctness and usefulness in guiding the architecture design
process through various design decision options.

### Title: Resource-efficient domain adaptive pre-training for medical images
* Paper ID: 2204.13280v1
* Paper URL: [http://arxiv.org/abs/2204.13280v1](http://arxiv.org/abs/2204.13280v1)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: The deep learning-based analysis of medical images suffers from data scarcity
because of high annotation costs and privacy concerns. Researchers in this
domain have used transfer learning to avoid overfitting when using complex
architectures. However, the domain differences between pre-training and
downstream data hamper the performance of the downstream task. Some recent
studies have successfully used domain-adaptive pre-training (DAPT) to address
this issue. In DAPT, models are initialized with the generic dataset
pre-trained weights, and further pre-training is performed using a moderately
sized in-domain dataset (medical images). Although this technique achieved good
results for the downstream tasks in terms of accuracy and robustness, it is
computationally expensive even when the datasets for DAPT are moderately sized.
These compute-intensive techniques and models impact the environment negatively
and create an uneven playing field for researchers with limited resources. This
study proposed computationally efficient DAPT without compromising the
downstream accuracy and robustness. This study proposes three techniques for
this purpose, where the first (partial DAPT) performs DAPT on a subset of
layers. The second one adopts a hybrid strategy (hybrid DAPT) by performing
partial DAPT for a few epochs and then full DAPT for the remaining epochs. The
third technique performs DAPT on simplified variants of the base architecture.
The results showed that compared to the standard DAPT (full DAPT), the hybrid
DAPT technique achieved better performance on the development and external
datasets. In contrast, simplified architectures (after DAPT) achieved the best
robustness while achieving modest performance on the development dataset .

### Title: Shielding Federated Learning: Robust Aggregation with Adaptive Client Selection
* Paper ID: 2204.13256v1
* Paper URL: [http://arxiv.org/abs/2204.13256v1](http://arxiv.org/abs/2204.13256v1)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: Federated learning (FL) enables multiple clients to collaboratively train an
accurate global model while protecting clients' data privacy. However, FL is
susceptible to Byzantine attacks from malicious participants. Although the
problem has gained significant attention, existing defenses have several flaws:
the server irrationally chooses malicious clients for aggregation even after
they have been detected in previous rounds; the defenses perform ineffectively
against sybil attacks or in the heterogeneous data setting.
  To overcome these issues, we propose MAB-RFL, a new method for robust
aggregation in FL. By modelling the client selection as an extended multi-armed
bandit (MAB) problem, we propose an adaptive client selection strategy to
choose honest clients that are more likely to contribute high-quality updates.
We then propose two approaches to identify malicious updates from sybil and
non-sybil attacks, based on which rewards for each client selection decision
can be accurately evaluated to discourage malicious behaviors. MAB-RFL achieves
a satisfying balance between exploration and exploitation on the potential
benign clients. Extensive experimental results show that MAB-RFL outperforms
existing defenses in three attack scenarios under different percentages of
attackers.

### Title: An End-to-End Dialogue Summarization System for Sales Calls
* Paper ID: 2204.12951v2
* Paper URL: [http://arxiv.org/abs/2204.12951v2](http://arxiv.org/abs/2204.12951v2)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: Summarizing sales calls is a routine task performed manually by salespeople.
We present a production system which combines generative models fine-tuned for
customer-agent setting, with a human-in-the-loop user experience for an
interactive summary curation process. We address challenging aspects of
dialogue summarization task in a real-world setting including long input
dialogues, content validation, lack of labeled data and quality evaluation. We
show how GPT-3 can be leveraged as an offline data labeler to handle training
data scarcity and accommodate privacy constraints in an industrial setting.
Experiments show significant improvements by our models in tackling the
summarization and content validation tasks on public datasets.

