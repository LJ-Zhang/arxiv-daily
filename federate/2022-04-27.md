### Title: Minimizing Client Drift in Federated Learning via Adaptive Bias Estimation
* Paper ID: 2204.13170v1
* Paper URL: [http://arxiv.org/abs/2204.13170v1](http://arxiv.org/abs/2204.13170v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: In Federated Learning a number of clients collaborate to train a model
without sharing their data. Client models are optimized locally and are
communicated through a central hub called server. A major challenge is to deal
with heterogeneity among clients' data which causes the local optimization to
drift away with respect to the global objective. In order to estimate and
therefore remove this drift, variance reduction techniques have been
incorporated into Federated Learning optimization recently. However, the
existing solutions propagate the error of their estimations, throughout the
optimization trajectory which leads to inaccurate approximations of the
clients' drift and ultimately failure to remove them properly. In this paper,
we address this issue by introducing an adaptive algorithm that efficiently
reduces clients' drift. Compared to the previous works on adapting variance
reduction to Federated Learning, our approach uses less or the same level of
communication bandwidth, computation or memory. Additionally, it addresses the
instability problem--prevalent in prior work, caused by increasing norm of the
estimates which makes our approach a much more practical solution for large
scale Federated Learning settings. Our experimental results demonstrate that
the proposed algorithm converges significantly faster and achieves higher
accuracy compared to the baselines in an extensive set of Federated Learning
benchmarks.

### Title: FedShuffle: Recipes for Better Use of Local Work in Federated Learning
* Paper ID: 2204.13169v1
* Paper URL: [http://arxiv.org/abs/2204.13169v1](http://arxiv.org/abs/2204.13169v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: The practice of applying several local updates before aggregation across
clients has been empirically shown to be a successful approach to overcoming
the communication bottleneck in Federated Learning (FL). In this work, we
propose a general recipe, FedShuffle, that better utilizes the local updates in
FL, especially in the heterogeneous regime. Unlike many prior works, FedShuffle
does not assume any uniformity in the number of updates per device. Our
FedShuffle recipe comprises four simple-yet-powerful ingredients: 1) local
shuffling of the data, 2) adjustment of the local learning rates, 3) update
weighting, and 4) momentum variance reduction (Cutkosky and Orabona, 2019). We
present a comprehensive theoretical analysis of FedShuffle and show that both
theoretically and empirically, our approach does not suffer from the objective
function mismatch that is present in FL methods which assume homogeneous
updates in heterogeneous FL setups, e.g., FedAvg (McMahan et al., 2017). In
addition, by combining the ingredients above, FedShuffle improves upon FedNova
(Wang et al., 2020), which was previously proposed to solve this mismatch. We
also show that FedShuffle with momentum variance reduction can improve upon
non-local methods under a Hessian similarity assumption. Finally, through
experiments on synthetic and real-world datasets, we illustrate how each of the
four ingredients used in FedShuffle helps improve the use of local updates in
FL.

### Title: Heterogeneous Ensemble Knowledge Transfer for Training Large Models in Federated Learning
* Paper ID: 2204.12703v1
* Paper URL: [http://arxiv.org/abs/2204.12703v1](http://arxiv.org/abs/2204.12703v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Federated learning (FL) enables edge-devices to collaboratively learn a model
without disclosing their private data to a central aggregating server. Most
existing FL algorithms require models of identical architecture to be deployed
across the clients and server, making it infeasible to train large models due
to clients' limited system resources. In this work, we propose a novel ensemble
knowledge transfer method named Fed-ET in which small models (different in
architecture) are trained on clients, and used to train a larger model at the
server. Unlike in conventional ensemble learning, in FL the ensemble can be
trained on clients' highly heterogeneous data. Cognizant of this property,
Fed-ET uses a weighted consensus distillation scheme with diversity
regularization that efficiently extracts reliable consensus from the ensemble
while improving generalization by exploiting the diversity within the ensemble.
We show the generalization bound for the ensemble of weighted models trained on
heterogeneous datasets that supports the intuition of Fed-ET. Our experiments
on image and language tasks show that Fed-ET significantly outperforms other
state-of-the-art FL algorithms with fewer communicated parameters, and is also
robust against high data-heterogeneity.

### Title: Understanding A Class of Decentralized and Federated Optimization Algorithms: A Multi-Rate Feedback Control Perspective
* Paper ID: 2204.12663v1
* Paper URL: [http://arxiv.org/abs/2204.12663v1](http://arxiv.org/abs/2204.12663v1)
* Updated Date: 2022-04-27
* Code URL: null
* Summary: Distributed algorithms have been playing an increasingly important role in
many applications such as machine learning, signal processing, and control.
Significant research efforts have been devoted to developing and analyzing new
algorithms for various applications. In this work, we provide a fresh
perspective to understand, analyze, and design distributed optimization
algorithms. Through the lens of multi-rate feedback control, we show that a
wide class of distributed algorithms, including popular decentralized/federated
schemes, can be viewed as discretizing a certain continuous-time feedback
control system, possibly with multiple sampling rates, such as decentralized
gradient descent, gradient tracking, and federated averaging. This key
observation not only allows us to develop a generic framework to analyze the
convergence of the entire algorithm class. More importantly, it also leads to
an interesting way of designing new distributed algorithms. We develop the
theory behind our framework and provide examples to highlight how the framework
can be used in practice.

