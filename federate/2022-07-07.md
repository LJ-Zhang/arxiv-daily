### Title: Adaptive Personlization in Federated Learning for Highly Non-i.i.d. Data
* Paper ID: 2207.03448v1
* Paper URL: [http://arxiv.org/abs/2207.03448v1](http://arxiv.org/abs/2207.03448v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LG']
* Code URL: null
* Summary: Federated learning (FL) is a distributed learning method that offers medical
institutes the prospect of collaboration in a global model while preserving the
privacy of their patients. Although most medical centers conduct similar
medical imaging tasks, their differences, such as specializations, number of
patients, and devices, lead to distinctive data distributions. Data
heterogeneity poses a challenge for FL and the personalization of the local
models. In this work, we investigate an adaptive hierarchical clustering method
for FL to produce intermediate semi-global models, so clients with similar data
distribution have the chance of forming a more specialized model. Our method
forms several clusters consisting of clients with the most similar data
distributions; then, each cluster continues to train separately. Inside the
cluster, we use meta-learning to improve the personalization of the
participants' models. We compare the clustering approach with classical FedAvg
and centralized training by evaluating our proposed methods on the HAM10k
dataset for skin lesion classification with extreme heterogeneous data
distribution. Our experiments demonstrate significant performance gain in
heterogeneous distribution compared to standard FL methods in classification
accuracy. Moreover, we show that the models converge faster if applied in
clusters and outperform centralized training while using only a small subset of
data.

### Title: A Simple and Provably Efficient Algorithm for Asynchronous Federated Contextual Linear Bandits
* Paper ID: 2207.03106v1
* Paper URL: [http://arxiv.org/abs/2207.03106v1](http://arxiv.org/abs/2207.03106v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LG', 'stat.ML']
* Code URL: null
* Summary: We study federated contextual linear bandits, where $M$ agents cooperate with
each other to solve a global contextual linear bandit problem with the help of
a central server. We consider the asynchronous setting, where all agents work
independently and the communication between one agent and the server will not
trigger other agents' communication. We propose a simple algorithm named
\texttt{FedLinUCB} based on the principle of optimism. We prove that the regret
of \texttt{FedLinUCB} is bounded by $\tilde{O}(d\sqrt{\sum_{m=1}^M T_m})$ and
the communication complexity is $\tilde{O}(dM^2)$, where $d$ is the dimension
of the contextual vector and $T_m$ is the total number of interactions with the
environment by $m$-th agent. To the best of our knowledge, this is the first
provably efficient algorithm that allows fully asynchronous communication for
federated contextual linear bandits, while achieving the same regret guarantee
as in the single-agent setting.

### Title: Towards the Practical Utility of Federated Learning in the Medical Domain
* Paper ID: 2207.03075v1
* Paper URL: [http://arxiv.org/abs/2207.03075v1](http://arxiv.org/abs/2207.03075v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LG', 'cs.AI']
* Code URL: [https://github.com/wns823/medical_federated](https://github.com/wns823/medical_federated)
* Summary: Federated learning (FL) is an active area of research. One of the most
suitable areas for adopting FL is the medical domain, where patient privacy
must be respected. Previous research, however, does not fully consider who will
most likely use FL in the medical domain. It is not the hospitals who are eager
to adopt FL, but the service providers such as IT companies who want to develop
machine learning models with real patient records. Moreover, service providers
would prefer to focus on maximizing the performance of the models at the lowest
cost possible. In this work, we propose empirical benchmarks of FL methods
considering both performance and monetary cost with three real-world datasets:
electronic health records, skin cancer images, and electrocardiogram datasets.
We also propose Federated learning with Proximal regularization eXcept local
Normalization (FedPxN), which, using a simple combination of FedProx and FedBN,
outperforms all other FL algorithms while consuming only slightly more power
than the most power efficient method.

### Title: FedHeN: Federated Learning in Heterogeneous Networks
* Paper ID: 2207.03031v1
* Paper URL: [http://arxiv.org/abs/2207.03031v1](http://arxiv.org/abs/2207.03031v1)
* Updated Date: 2022-07-07
* Categories: ['cs.LG', 'cs.DC']
* Code URL: null
* Summary: We propose a novel training recipe for federated learning with heterogeneous
networks where each device can have different architectures. We introduce
training with a side objective to the devices of higher complexities to jointly
train different architectures in a federated setting. We empirically show that
our approach improves the performance of different architectures and leads to
high communication savings compared to the state-of-the-art methods.

