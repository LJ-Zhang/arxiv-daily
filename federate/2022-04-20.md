# federate

## 04-20

### Title: A Re-analysis of Repeatability and Reproducibility in the Ames-USDOE-FBI Study
* Paper ID: 2204.08889v1
* Paper URL: [http://arxiv.org/abs/2204.08889v1](http://arxiv.org/abs/2204.08889v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Forensic firearms identification, the determination by a trained firearms
examiner as to whether or not bullets or cartridges came from a common weapon,
has long been a mainstay in the criminal courts. Reliability of forensic
firearms identification has been challenged in the general scientific
community, and, in response, several studies have been carried out aimed at
showing that firearms examination is accurate, that is, has low error rates.
Less studied has been the question of consistency, of. whether two examinations
of the same bullets or cartridge cases come to the same conclusion, carried out
by an examiner on separate occasions -- intrarater reliability or repeatability
-- or by two examiners -- interrater reliability or reproducibility. One
important study, described in a 2020 Report by the Ames Laboratory-USDOE to the
Federal Bureau of Investigation, went beyond considerations of accuracy to
investigate firearms examination repeatability and reproducibility. The
Report's conclusions were paradoxical. The observed agreement of examiners with
themselves or with other examiners appears mediocre. However, the study
concluded repeatability and reproducibility are satisfactory, on grounds that
the observed agreement exceeds a quantity called the expected agreement. We
find that appropriately employing expected agreement as it was intended does
not suggest satisfactory repeatability and reproducibility, but the opposite.

### Title: How to Attain Communication-Efficient DNN Training? Convert, Compress, Correct
* Paper ID: 2204.08211v1
* Paper URL: [http://arxiv.org/abs/2204.08211v1](http://arxiv.org/abs/2204.08211v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: In this paper, we introduce $\mathsf{CO}_3$, an algorithm for
communication-efficiency federated Deep Neural Network (DNN)
training.$\mathsf{CO}_3$ takes its name from three processing applied steps
which reduce the communication load when transmitting the local gradients from
the remote users to the Parameter Server.Namely:(i) gradient quantization
through floating-point conversion, (ii) lossless compression of the quantized
gradient, and (iii) quantization error correction.We carefully design each of
the steps above so as to minimize the loss in the distributed DNN training when
the communication overhead is fixed.In particular, in the design of steps (i)
and (ii), we adopt the assumption that DNN gradients are distributed according
to a generalized normal distribution.This assumption is validated numerically
in the paper. For step (iii), we utilize an error feedback with memory decay
mechanism to correct the quantization error introduced in step (i). We argue
that this coefficient, similarly to the learning rate, can be optimally tuned
to improve convergence. The performance of $\mathsf{CO}_3$ is validated through
numerical simulations and is shown having better accuracy and improved
stability at a reduced communication payload.

### Title: PrivateRec: Differentially Private Training and Serving for Federated News Recommendation
* Paper ID: 2204.08146v1
* Paper URL: [http://arxiv.org/abs/2204.08146v1](http://arxiv.org/abs/2204.08146v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: Privacy protection is an essential issue in personalized news recommendation,
and federated learning can potentially mitigate the privacy concern by training
personalized news recommendation models over decentralized user data.For a
theoretical privacy guarantee, differential privacy is necessary. However,
applying differential privacy to federated recommendation training and serving
conventionally suffers from the unsatisfactory trade-off between privacy and
utility due to the high-dimensional characteristics of model gradients and
hidden representations. In addition, there is no formal privacy guarantee for
both training and serving in federated recommendation. In this paper, we
propose a unified federated news recommendation method for effective and
privacy-preserving model training and online serving with differential privacy
guarantees. We first clarify the notion of differential privacy over users'
behavior data for both model training and online serving in the federated
recommendation scenario. Next, we propose a privacy-preserving online serving
mechanism under this definition with differentially private user interest
decomposition. More specifically, it decomposes the high-dimensional and
privacy-sensitive user embedding into a combination of public basic vectors and
adds noise to the combination coefficients. In this way, it can avoid the
dimension curse and improve the utility by reducing the required noise
intensity for differential privacy. Besides, we design a federated
recommendation model training method with differential privacy, which can avoid
the dimension-dependent noise for large models via label permutation and
differentially private attention modules. Experiments on real-world news
recommendation datasets validate the effectiveness of our method in achieving a
good trade-off between privacy protection and utility for federated news
recommendations.

### Title: A Practical Cross-Device Federated Learning Framework over 5G Networks
* Paper ID: 2204.08134v1
* Paper URL: [http://arxiv.org/abs/2204.08134v1](http://arxiv.org/abs/2204.08134v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: The concept of federated learning (FL) was first proposed by Google in 2016.
Thereafter, FL has been widely studied for the feasibility of application in
various fields due to its potential to make full use of data without
compromising the privacy. However, limited by the capacity of wireless data
transmission, the employment of federated learning on mobile devices has been
making slow progress in practical. The development and commercialization of the
5th generation (5G) mobile networks has shed some light on this. In this paper,
we analyze the challenges of existing federated learning schemes for mobile
devices and propose a novel cross-device federated learning framework, which
utilizes the anonymous communication technology and ring signature to protect
the privacy of participants while reducing the computation overhead of mobile
devices participating in FL. In addition, our scheme implements a
contribution-based incentive mechanism to encourage mobile users to participate
in FL. We also give a case study of autonomous driving. Finally, we present the
performance evaluation of the proposed scheme and discuss some open issues in
federated learning.

### Title: FedKL: Tackling Data Heterogeneity in Federated Reinforcement Learning by Penalizing KL Divergence
* Paper ID: 2204.08125v1
* Paper URL: [http://arxiv.org/abs/2204.08125v1](http://arxiv.org/abs/2204.08125v1)
* Updated Date: 2022-04-18
* Code URL: null
* Summary: As a distributed learning paradigm, Federated Learning (FL) faces the
communication bottleneck issue due to many rounds of model synchronization and
aggregation. Heterogeneous data further deteriorates the situation by causing
slow convergence. Although the impact of data heterogeneity on supervised FL
has been widely studied, the related investigation for Federated Reinforcement
Learning (FRL) is still in its infancy. In this paper, we first define the type
and level of data heterogeneity for policy gradient based FRL systems. By
inspecting the connection between the global and local objective functions, we
prove that local training can benefit the global objective, if the local update
is properly penalized by the total variation (TV) distance between the local
and global policies. A necessary condition for the global policy to be
learn-able from the local policy is also derived, which is directly related to
the heterogeneity level. Based on the theoretical result, a Kullback-Leibler
(KL) divergence based penalty is proposed, which, different from the
conventional method that penalizes the model divergence in the parameter space,
directly constrains the model outputs in the distribution space. By jointly
penalizing the divergence of the local policy from the global policy with a
global penalty and constraining each iteration of the local training with a
local penalty, the proposed method achieves a better trade-off between training
speed (step size) and convergence. Experiment results on two popular RL
experiment platforms demonstrate the advantage of the proposed algorithm over
existing methods in accelerating and stabilizing the training process with
heterogeneous data.

