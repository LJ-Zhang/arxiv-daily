### Title: Personalized Federated Learning with Multiple Known Clusters
* Paper ID: 2204.13619v1
* Paper URL: [http://arxiv.org/abs/2204.13619v1](http://arxiv.org/abs/2204.13619v1)
* Updated Date: 2022-04-28
* Code URL: [https://github.com/shawnblyu/personalized-federated-learning-with-multiple-known-clusters](https://github.com/shawnblyu/personalized-federated-learning-with-multiple-known-clusters)
* Summary: We consider the problem of personalized federated learning when there are
known cluster structures within users. An intuitive approach would be to
regularize the parameters so that users in the same cluster share similar model
weights. The distances between the clusters can then be regularized to reflect
the similarity between different clusters of users. We develop an algorithm
that allows each cluster to communicate independently and derive the
convergence results. We study a hierarchical linear model to theoretically
demonstrate that our approach outperforms agents learning independently and
agents learning a single shared weight. Finally, we demonstrate the advantages
of our approach using both simulated and real-world data.

### Title: Improving the Robustness of Federated Learning for Severely Imbalanced Datasets
* Paper ID: 2204.13414v1
* Paper URL: [http://arxiv.org/abs/2204.13414v1](http://arxiv.org/abs/2204.13414v1)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: With the ever increasing data deluge and the success of deep neural networks,
the research of distributed deep learning has become pronounced. Two common
approaches to achieve this distributed learning is synchronous and asynchronous
weight update. In this manuscript, we have explored very simplistic synchronous
weight update mechanisms. It has been seen that with an increasing number of
worker nodes, the performance degrades drastically. This effect has been
studied in the context of extreme imbalanced classification (e.g. outlier
detection). In practical cases, the assumed conditions of i.i.d. may not be
fulfilled. There may also arise global class imbalance situations like that of
outlier detection where the local servers receive severely imbalanced data and
may not get any samples from the minority class. In that case, the DNNs in the
local servers will get completely biased towards the majority class that they
receive. This would highly impact the learning at the parameter server (which
practically does not see any data). It has been observed that in a parallel
setting if one uses the existing federated weight update mechanisms at the
parameter server, the performance degrades drastically with the increasing
number of worker nodes. This is mainly because, with the increasing number of
nodes, there is a high chance that one worker node gets a very small portion of
the data, either not enough to train the model without overfitting or having a
highly imbalanced class distribution. The chapter, hence, proposes a workaround
to this problem by introducing the concept of adaptive cost-sensitive momentum
averaging. It is seen that for the proposed system, there was no to minimal
degradation in performance while most of the other methods hit their bottom
performance before that.

### Title: Federated Learning on Heterogeneous and Long-Tailed Data via Classifier Re-Training with Federated Features
* Paper ID: 2204.13399v1
* Paper URL: [http://arxiv.org/abs/2204.13399v1](http://arxiv.org/abs/2204.13399v1)
* Updated Date: 2022-04-28
* Code URL: [https://github.com/shangxinyi/creff-fl](https://github.com/shangxinyi/creff-fl)
* Summary: Federated learning (FL) provides a privacy-preserving solution for
distributed machine learning tasks. One challenging problem that severely
damages the performance of FL models is the co-occurrence of data heterogeneity
and long-tail distribution, which frequently appears in real FL applications.
In this paper, we reveal an intriguing fact that the biased classifier is the
primary factor leading to the poor performance of the global model. Motivated
by the above finding, we propose a novel and privacy-preserving FL method for
heterogeneous and long-tailed data via Classifier Re-training with Federated
Features (CReFF). The classifier re-trained on federated features can produce
comparable performance as the one re-trained on real data in a
privacy-preserving manner without information leakage of local data or class
distribution. Experiments on several benchmark datasets show that the proposed
CReFF is an effective solution to obtain a promising FL model under
heterogeneous and long-tailed data. Comparative results with the
state-of-the-art FL methods also validate the superiority of CReFF. Our code is
available at https://github.com/shangxinyi/CReFF-FL.

### Title: On the Convergence of Momentum-Based Algorithms for Federated Stochastic Bilevel Optimization Problems
* Paper ID: 2204.13299v1
* Paper URL: [http://arxiv.org/abs/2204.13299v1](http://arxiv.org/abs/2204.13299v1)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: In this paper, we studied the federated stochastic bilevel optimization
problem. In particular, we developed two momentum-based algorithms for
optimizing this kind of problem. In addition, we established the convergence
rate of these two algorithms, providing their sample and communication
complexities. To the best of our knowledge, this is the first work achieving
such favorable theoretical results.

### Title: A Decision Model for Federated Learning Architecture Pattern Selection
* Paper ID: 2204.13291v1
* Paper URL: [http://arxiv.org/abs/2204.13291v1](http://arxiv.org/abs/2204.13291v1)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: Federated learning is growing fast in both academia and industry to resolve
data hungriness and privacy issues in machine learning. A federated learning
system being widely distributed with different components and stakeholders
requires software system design thinking. For instance, multiple patterns and
tactics have been summarised by researchers that cover various aspects, from
client management, training configuration, model deployment, etc. However, the
multitude of patterns leaves the designers confused about when and which
pattern to adopt or adapt. Therefore, in this paper, we present a set of
decision models to assist designers and architects who have limited knowledge
in federated learning, in selecting architectural patterns for federated
learning architecture design. Each decision model maps functional and
non-functional requirements of federated learning systems to a set of patterns.
we also clarify the trade-offs that may be implicit in the patterns. We
evaluated the decision model through a set of interviews with practitioners to
assess the correctness and usefulness in guiding the architecture design
process through various design decision options.

### Title: Shielding Federated Learning: Robust Aggregation with Adaptive Client Selection
* Paper ID: 2204.13256v1
* Paper URL: [http://arxiv.org/abs/2204.13256v1](http://arxiv.org/abs/2204.13256v1)
* Updated Date: 2022-04-28
* Code URL: null
* Summary: Federated learning (FL) enables multiple clients to collaboratively train an
accurate global model while protecting clients' data privacy. However, FL is
susceptible to Byzantine attacks from malicious participants. Although the
problem has gained significant attention, existing defenses have several flaws:
the server irrationally chooses malicious clients for aggregation even after
they have been detected in previous rounds; the defenses perform ineffectively
against sybil attacks or in the heterogeneous data setting.
  To overcome these issues, we propose MAB-RFL, a new method for robust
aggregation in FL. By modelling the client selection as an extended multi-armed
bandit (MAB) problem, we propose an adaptive client selection strategy to
choose honest clients that are more likely to contribute high-quality updates.
We then propose two approaches to identify malicious updates from sybil and
non-sybil attacks, based on which rewards for each client selection decision
can be accurately evaluated to discourage malicious behaviors. MAB-RFL achieves
a satisfying balance between exploration and exploitation on the potential
benign clients. Extensive experimental results show that MAB-RFL outperforms
existing defenses in three attack scenarios under different percentages of
attackers.

