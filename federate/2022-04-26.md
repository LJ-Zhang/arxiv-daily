### Title: Continual Learning for Peer-to-Peer Federated Learning: A Study on Automated Brain Metastasis Identification
* Paper ID: 2204.13591v1
* Paper URL: [http://arxiv.org/abs/2204.13591v1](http://arxiv.org/abs/2204.13591v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Due to data privacy constraints, data sharing among multiple centers is
restricted. Continual learning, as one approach to peer-to-peer federated
learning, can promote multicenter collaboration on deep learning algorithm
development by sharing intermediate models instead of training data. This work
aims to investigate the feasibility of continual learning for multicenter
collaboration on an exemplary application of brain metastasis identification
using DeepMedic. 920 T1 MRI contrast enhanced volumes are split to simulate
multicenter collaboration scenarios. A continual learning algorithm, synaptic
intelligence (SI), is applied to preserve important model weights for training
one center after another. In a bilateral collaboration scenario, continual
learning with SI achieves a sensitivity of 0.917, and naive continual learning
without SI achieves a sensitivity of 0.906, while two models trained on
internal data solely without continual learning achieve sensitivity of 0.853
and 0.831 only. In a seven-center multilateral collaboration scenario, the
models trained on internal datasets (100 volumes each center) without continual
learning obtain a mean sensitivity value of 0.725. With single-visit continual
learning (i.e., the shared model visits each center only once during training),
the sensitivity is improved to 0.788 and 0.849 without SI and with SI,
respectively. With iterative continual learning (i.e., the shared model
revisits each center multiple times during training), the sensitivity is
further improved to 0.914, which is identical to the sensitivity using mixed
data for training. Our experiments demonstrate that continual learning can
improve brain metastasis identification performance for centers with limited
data. This study demonstrates the feasibility of applying continual learning
for peer-to-peer federated learning in multicenter collaboration.

### Title: Online multi-resolution fusion of space-borne multispectral images
* Paper ID: 2204.12566v1
* Paper URL: [http://arxiv.org/abs/2204.12566v1](http://arxiv.org/abs/2204.12566v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Satellite imaging has a central role in monitoring, detecting and estimating
the intensity of key natural phenomena. One important feature of satellite
images is the trade-off between spatial/spectral resolution and their
revisiting time, a consequence of design and physical constraints imposed by
satellite orbit among other technical limitations. In this paper, we focus on
fusing multi-temporal, multi-spectral images where data acquired from different
instruments with different spatial resolutions is used. We leverage the spatial
relationship between images at multiple modalities to generate high-resolution
image sequences at higher revisiting rates. To achieve this goal, we formulate
the fusion method as a recursive state estimation problem and study its
performance in filtering and smoothing contexts. The proposed strategy clearly
outperforms competing methodologies, which is shown in the paper for real data
acquired by the Landsat and MODIS instruments.

### Title: A review of Federated Learning in Intrusion Detection Systems for IoT
* Paper ID: 2204.12443v1
* Paper URL: [http://arxiv.org/abs/2204.12443v1](http://arxiv.org/abs/2204.12443v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Intrusion detection systems are evolving into intelligent systems that
perform data analysis searching for anomalies in their environment. The
development of deep learning technologies opened the door to build more complex
and effective threat detection models. However, training those models may be
computationally infeasible in most Internet of Things devices. Current
approaches rely on powerful centralized servers that receive data from all
their parties -- violating basic privacy constraints and substantially
affecting response times and operational costs due to the huge communication
overheads. To mitigate these issues, Federated Learning emerged as a promising
approach where different agents collaboratively train a shared model, neither
exposing training data to others nor requiring a compute-intensive centralized
infrastructure. This paper focuses on the application of Federated Learning
approaches in the field of Intrusion Detection. Both technologies are described
in detail and current scientific progress is reviewed and categorized. Finally,
the paper highlights the limitations present in recent works and presents some
future directions for this technology.

### Title: Federated Progressive Sparsification (Purge, Merge, Tune)+
* Paper ID: 2204.12430v1
* Paper URL: [http://arxiv.org/abs/2204.12430v1](http://arxiv.org/abs/2204.12430v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: To improve federated training of neural networks, we develop FedSparsify, a
sparsification strategy based on progressive weight magnitude pruning. Our
method has several benefits. First, since the size of the network becomes
increasingly smaller, computation and communication costs during training are
reduced. Second, the models are incrementally constrained to a smaller set of
parameters, which facilitates alignment/merging of the local models and
improved learning performance at high sparsification rates. Third, the final
sparsified model is significantly smaller, which improves inference efficiency
and optimizes operations latency during encrypted communication. We show
experimentally that FedSparsify learns a subnetwork of both high sparsity and
learning performance. Our sparse models can reach a tenth of the size of the
original model with the same or better accuracy compared to existing pruning
and nonpruning baselines.

### Title: Time-triggered Federated Learning over Wireless Networks
* Paper ID: 2204.12426v1
* Paper URL: [http://arxiv.org/abs/2204.12426v1](http://arxiv.org/abs/2204.12426v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: The newly emerging federated learning (FL) framework offers a new way to
train machine learning models in a privacy-preserving manner. However,
traditional FL algorithms are based on an event-triggered aggregation, which
suffers from stragglers and communication overhead issues. To address these
issues, in this paper, we present a time-triggered FL algorithm (TT-Fed) over
wireless networks, which is a generalized form of classic synchronous and
asynchronous FL. Taking the constrained resource and unreliable nature of
wireless communication into account, we jointly study the user selection and
bandwidth optimization problem to minimize the FL training loss. To solve this
joint optimization problem, we provide a thorough convergence analysis for
TT-Fed. Based on the obtained analytical convergence upper bound, the
optimization problem is decomposed into tractable sub-problems with respect to
each global aggregation round, and finally solved by our proposed online search
algorithm. Simulation results show that compared to asynchronous FL (FedAsync)
and FL with asynchronous user tiers (FedAT) benchmarks, our proposed TT-Fed
algorithm improves the converged test accuracy by up to 12.5% and 5%,
respectively, under highly imbalanced and non-IID data, while substantially
reducing the communication overhead.

### Title: Poisoning Deep Learning based Recommender Model in Federated Learning Scenarios
* Paper ID: 2204.13594v1
* Paper URL: [http://arxiv.org/abs/2204.13594v1](http://arxiv.org/abs/2204.13594v1)
* Updated Date: 2022-04-26
* Code URL: [https://github.com/rdz98/poisonfeddlrs](https://github.com/rdz98/poisonfeddlrs)
* Summary: Various attack methods against recommender systems have been proposed in the
past years, and the security issues of recommender systems have drawn
considerable attention. Traditional attacks attempt to make target items
recommended to as many users as possible by poisoning the training data.
Benifiting from the feature of protecting users' private data, federated
recommendation can effectively defend such attacks. Therefore, quite a few
works have devoted themselves to developing federated recommender systems. For
proving current federated recommendation is still vulnerable, in this work we
probe to design attack approaches targeting deep learning based recommender
models in federated learning scenarios. Specifically, our attacks generate
poisoned gradients for manipulated malicious users to upload based on two
strategies (i.e., random approximation and hard user mining). Extensive
experiments show that our well-designed attacks can effectively poison the
target models, and the attack effectiveness sets the state-of-the-art.

### Title: Federated Stochastic Primal-dual Learning with Differential Privacy
* Paper ID: 2204.12284v1
* Paper URL: [http://arxiv.org/abs/2204.12284v1](http://arxiv.org/abs/2204.12284v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Federated learning (FL) is a new paradigm that enables many clients to
jointly train a machine learning (ML) model under the orchestration of a
parameter server while keeping the local data not being exposed to any third
party. However, the training of FL is an interactive process between local
clients and the parameter server. Such process would cause privacy leakage
since adversaries may retrieve sensitive information by analyzing the overheard
messages. In this paper, we propose a new federated stochastic primal-dual
algorithm with differential privacy (FedSPD-DP). Compared to the existing
methods, the proposed FedSPD-DP incorporates local stochastic gradient descent
(local SGD) and partial client participation (PCP) for addressing the issues of
communication efficiency and straggler effects due to randomly accessed
clients. Our analysis shows that the data sampling strategy and PCP can enhance
the data privacy whereas the larger number of local SGD steps could increase
privacy leakage, revealing a non-trivial tradeoff between algorithm
communication efficiency and privacy protection. Specifically, we show that, by
guaranteeing $(\epsilon, \delta)$-DP for each client per communication round,
the proposed algorithm guarantees $(\mathcal{O}(q\epsilon \sqrt{p T}),
\delta)$-DP after $T$ communication rounds while maintaining an
$\mathcal{O}(1/\sqrt{pTQ})$ convergence rate for a convex and non-smooth
learning problem, where $Q$ is the number of local SGD steps, $p$ is the client
sampling probability, $q=\max_{i} q_i/\sqrt{1-q_i}$ and $q_i$ is the data
sampling probability of each client under PCP. Experiment results are presented
to evaluate the practical performance of the proposed algorithm and comparison
with state-of-the-art methods.

### Title: Enhancing Privacy against Inversion Attacks in Federated Learning by using Mixing Gradients Strategies
* Paper ID: 2204.12495v1
* Paper URL: [http://arxiv.org/abs/2204.12495v1](http://arxiv.org/abs/2204.12495v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Federated learning reduces the risk of information leakage, but remains
vulnerable to attacks. We investigate how several neural network design
decisions can defend against gradients inversion attacks. We show that
overlapping gradients provides numerical resistance to gradient inversion on
the highly vulnerable dense layer. Specifically, we propose to leverage
batching to maximise mixing of gradients by choosing an appropriate loss
function and drawing identical labels. We show that otherwise it is possible to
directly recover all vectors in a mini-batch without any numerical optimisation
due to the de-mixing nature of the cross entropy loss. To accurately assess
data recovery, we introduce an absolute variation distance (AVD) metric for
information leakage in images, derived from total variation. In contrast to
standard metrics, e.g. Mean Squared Error or Structural Similarity Index, AVD
offers a continuous metric for extracting information in noisy images. Finally,
our empirical results on information recovery from various inversion attacks
and training performance supports our defense strategies. These strategies are
also shown to be useful for deep convolutional neural networks such as LeNET
for image recognition. We hope that this study will help guide the development
of further strategies that achieve a trustful federation policy.

### Title: Cybertwin-enabled 6G Space-air-ground Integrated Networks: Architecture, Open Issue, and Challenges
* Paper ID: 2204.12153v1
* Paper URL: [http://arxiv.org/abs/2204.12153v1](http://arxiv.org/abs/2204.12153v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Space-air-ground integrated network (SAGIN) is considered as a core
requirement in emerging 6G networks, which integrates the terrestrial and
non-terrestrial networks to reach the full network coverage and ubiquitous
services. To envision the ubiquitous intelligence and the deep integration in
6G SAGIN, a paradigm of cybertwin-enabled 6G SAGIN is presented in this paper.
Specifically, a cybertwin-enabled SAGIN architecture is first presented, where
a novel five-dimension digital twin (DT) model is presented. Particularly,
three categories of critical technologies are presented based on the cybertwin
of SAGIN, i.e., cybertwin-based multi-source heterogeneous network integration,
cybertwin-based integrated cloud-edge-end, and cybertwin-based integrated
sensing-communication-computing. Besides, two open issues in the
cybertwin-enabled SAGIN are studied, i.e., the networking decision and
optimization and the cybertwin-enabled cross-layer privacy and security, where
the challenges are discussed and the potential solutions are directed. In
addition, a case study with federal learning is developed and open research
issues are discussed.

### Title: One-shot Federated Learning without Server-side Training
* Paper ID: 2204.12493v1
* Paper URL: [http://arxiv.org/abs/2204.12493v1](http://arxiv.org/abs/2204.12493v1)
* Updated Date: 2022-04-26
* Code URL: null
* Summary: Federated Learning (FL) has recently made significant progress as a new
machine learning paradigm for privacy protection. Due to the high communication
cost of traditional FL, one-shot federated learning is gaining popularity as a
way to reduce communication cost between clients and the server. Most of the
existing one-shot FL methods are based on Knowledge Distillation; however,
distillation based approach requires an extra training phase and depends on
publicly available data sets. In this work, we consider a novel and challenging
setting: performing a single round of parameter aggregation on the local models
without server-side training on a public data set. In this new setting, we
propose an effective algorithm for Model Aggregation via Exploring Common
Harmonized Optima (MA-Echo), which iteratively updates the parameters of all
local models to bring them close to a common low-loss area on the loss surface,
without harming performance on their own data sets at the same time. Compared
to the existing methods, MA-Echo can work well even in extremely non-identical
data distribution settings where the support categories of each local model
have no overlapped labels with those of the others. We conduct extensive
experiments on two popular image classification data sets to compare the
proposed method with existing methods and demonstrate the effectiveness of
MA-Echo, which clearly outperforms the state-of-the-arts.

