### Title: sqSGD: Locally Private and Communication Efficient Federated Learning
* Paper ID: 2206.10565v1
* Paper URL: [http://arxiv.org/abs/2206.10565v1](http://arxiv.org/abs/2206.10565v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Federated learning (FL) is a technique that trains machine learning models
from decentralized data sources. We study FL under local notions of privacy
constraints, which provides strong protection against sensitive data
disclosures via obfuscating the data before leaving the client. We identify two
major concerns in designing practical privacy-preserving FL algorithms:
communication efficiency and high-dimensional compatibility. We then develop a
gradient-based learning algorithm called \emph{sqSGD} (selective quantized
stochastic gradient descent) that addresses both concerns. The proposed
algorithm is based on a novel privacy-preserving quantization scheme that uses
a constant number of bits per dimension per client. Then we improve the base
algorithm in three ways: first, we apply a gradient subsampling strategy that
simultaneously offers better training performance and smaller communication
costs under a fixed privacy budget. Secondly, we utilize randomized rotation as
a preprocessing step to reduce quantization error. Thirdly, an adaptive
gradient norm upper bound shrinkage strategy is adopted to improve accuracy and
stabilize training. Finally, the practicality of the proposed framework is
demonstrated on benchmark datasets. Experiment results show that sqSGD
successfully learns large models like LeNet and ResNet with local privacy
constraints. In addition, with fixed privacy and communication level, the
performance of sqSGD significantly dominates that of various baseline
algorithms.

### Title: FedHiSyn: A Hierarchical Synchronous Federated Learning Framework for Resource and Data Heterogeneity
* Paper ID: 2206.10546v1
* Paper URL: [http://arxiv.org/abs/2206.10546v1](http://arxiv.org/abs/2206.10546v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Federated Learning (FL) enables training a global model without sharing the
decentralized raw data stored on multiple devices to protect data privacy. Due
to the diverse capacity of the devices, FL frameworks struggle to tackle the
problems of straggler effects and outdated models. In addition, the data
heterogeneity incurs severe accuracy degradation of the global model in the FL
training process. To address aforementioned issues, we propose a hierarchical
synchronous FL framework, i.e., FedHiSyn. FedHiSyn first clusters all available
devices into a small number of categories based on their computing capacity.
After a certain interval of local training, the models trained in different
categories are simultaneously uploaded to a central server. Within a single
category, the devices communicate the local updated model weights to each other
based on a ring topology. As the efficiency of training in the ring topology
prefers devices with homogeneous resources, the classification based on the
computing capacity mitigates the impact of straggler effects. Besides, the
combination of the synchronous update of multiple categories and the device
communication within a single category help address the data heterogeneity
issue while achieving high accuracy. We evaluate the proposed framework based
on MNIST, EMNIST, CIFAR10 and CIFAR100 datasets and diverse heterogeneous
settings of devices. Experimental results show that FedHiSyn outperforms six
baseline methods, e.g., FedAvg, SCAFFOLD, and FedAT, in terms of training
accuracy and efficiency.

### Title: The Impact of Visibility on the Right to Opt-out of Sale under CCPA
* Paper ID: 2206.10545v1
* Paper URL: [http://arxiv.org/abs/2206.10545v1](http://arxiv.org/abs/2206.10545v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: The California Consumer Protection Act (CCPA) gives users the right to
opt-out of sale of their personal information, but prior work has found that
opt-out mechanisms provided under this law result in very low opt-out rates.
Privacy signals offer a solution for users who are aware of their rights and
are willing to proactively take steps to enable privacy-enhancing tools, but
this work findsthat many users are not aware of their rights under CCPA and
that current opt-out rates are very low. We therefore explore an alternative
approach to enhancing privacy under CCPA: increasing the visibility of opt-out
of sale mechanisms. For this purpose, we design and implement CCPA Opt-out
Assistant (COA), a browser extension that automatically detects when websites
sell personal information and presents users with a visible, standardized
banner that links to the opt-out of sale mechanism for the website. We conduct
an online user study with 54 participants that finds that these banners
significantly increases the rate at which users opt-out of sale of their
personal information. Participants also report less difficulty opting-out and
more satisfaction with opt-out mechanisms compared to the native mechanisms
currently provided by websites. Our results suggest that effective privacy
regulation depends on imposing clear, enforceable visibility standards, and
that CCPA's requirements for opt-out of sale mechanisms fall short.

### Title: Three-way optimization of privacy and utility of location data
* Paper ID: 2206.10525v1
* Paper URL: [http://arxiv.org/abs/2206.10525v1](http://arxiv.org/abs/2206.10525v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: With the recent bloom of data and the drive towards an information-based
society, the urge of and the advancements in data analytics is surging like
never before. And with this, the risks of privacy violation of various kinds
are also increasing manifold. Most of the methods to mitigate the privacy risks
for location data resort to adding some noise to the location, like the planar
Laplace used to achieve geo-indistinguishability. However, the noise should be
calibrated carefully, taking into account the implications for utility, because
it is far from ideal for the service providers to completely lose the utility
of the collected data succumbing to the privacy requirements of the users.
Similarly, the quality of service for the users should be optimized with their
personalized needs of privacy protection used to shield their sensitive
information. In this paper, we address this age-old battle between privacy and
utility from three ends: privacy of the users' data, the quality of service
(QoS) received by them in exchange for sharing their privatized data, and the
statistical utility of the privatized data for the service providers who wish
to perform various kinds of analysis and research on the data collected from
the users. We propose a method to produce a geo-indistinguishable
location-privacy mechanism that advances to optimize simultaneously between the
level of privacy attained, the QoS, and the statistical utility achieved by the
obfuscated data. We illustrate the soundness of this three-way privacy-utility
optimization mechanism both analytically and with experiments. Apart from the
novelty of the proposed method, this work is aimed to engender an analytical
perspective to bridge between geo-indistinguishable location-privacy, QoS, and
statistical utilities used in standard data analytics, from an information
theoretical, probabilistic, and statistical perspective.

### Title: An Overview of Privacy-enhancing Technologies in Biometric Recognition
* Paper ID: 2206.10465v1
* Paper URL: [http://arxiv.org/abs/2206.10465v1](http://arxiv.org/abs/2206.10465v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: Privacy-enhancing technologies are technologies that implement fundamental
data protection principles. With respect to biometric recognition, different
types of privacy-enhancing technologies have been introduced for protecting
stored biometric data which are generally classified as sensitive. In this
regard, various taxonomies and conceptual categorizations have been proposed
and standardization activities have been carried out. However, these efforts
have mainly been devoted to certain sub-categories of privacy-enhancing
technologies and therefore lack generalization. This work provides an overview
of concepts of privacy-enhancing technologies for biometrics in a unified
framework. Key aspects and differences between existing concepts are
highlighted in detail at each processing step. Fundamental properties and
limitations of existing approaches are discussed and related to data protection
techniques and principles. Moreover, scenarios and methods for the assessment
of privacy-enhancing technologies for biometrics are presented. This paper is
meant as a point of entry to the field of biometric data protection and is
directed towards experienced researchers as well as non-experts.

### Title: Using EBGAN for Anomaly Intrusion Detection
* Paper ID: 2206.10400v1
* Paper URL: [http://arxiv.org/abs/2206.10400v1](http://arxiv.org/abs/2206.10400v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: As an active network security protection scheme, intrusion detection system
(IDS) undertakes the important responsibility of detecting network attacks in
the form of malicious network traffic. Intrusion detection technology is an
important part of IDS. At present, many scholars have carried out extensive
research on intrusion detection technology. However, developing an efficient
intrusion detection method for massive network traffic data is still difficult.
Since Generative Adversarial Networks (GANs) have powerful modeling
capabilities for complex high-dimensional data, they provide new ideas for
addressing this problem. In this paper, we put forward an EBGAN-based intrusion
detection method, IDS-EBGAN, that classifies network records as normal traffic
or malicious traffic. The generator in IDS-EBGAN is responsible for converting
the original malicious network traffic in the training set into adversarial
malicious examples. This is because we want to use adversarial learning to
improve the ability of discriminator to detect malicious traffic. At the same
time, the discriminator adopts Autoencoder model. During testing, IDS-EBGAN
uses reconstruction error of discriminator to classify traffic records.

### Title: Identification of Attack Paths Using Kill Chain and Attack Graphs
* Paper ID: 2206.10272v1
* Paper URL: [http://arxiv.org/abs/2206.10272v1](http://arxiv.org/abs/2206.10272v1)
* Updated Date: 2022-06-21
* Code URL: null
* Summary: The ever-evolving capabilities of cyber attackers force security
administrators to focus on the early identification of emerging threats.
Targeted cyber attacks usually consist of several phases, from initial
reconnaissance of the network environment to final impact on objectives. This
paper investigates the identification of multi-step cyber threat scenarios
using kill chain and attack graphs. Kill chain and attack graphs are threat
modeling concepts that enable determining weak security defense points. We
propose a novel kill chain attack graph that merges kill chain and attack
graphs together. This approach determines possible chains of attacker's actions
and their materialization within the protected network. The graph generation
uses a categorization of threats according to violated security properties. The
graph allows determining the kill chain phase the administrator should focus on
and applicable countermeasures to mitigate possible cyber threats. We
implemented the proposed approach for a predefined range of cyber threats,
especially vulnerability exploitation and network threats. The approach was
validated on a real-world use case. Publicly available implementation contains
a proof-of-concept kill chain attack graph generator.

