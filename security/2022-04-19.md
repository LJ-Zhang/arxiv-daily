### Title: Identifying Near-Optimal Single-Shot Attacks on ICSs with Limited Process Knowledge
* Paper ID: 2204.09106v1
* Paper URL: [http://arxiv.org/abs/2204.09106v1](http://arxiv.org/abs/2204.09106v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Industrial Control Systems (ICSs) rely on insecure protocols and devices to
monitor and operate critical infrastructure. Prior work has demonstrated that
powerful attackers with detailed system knowledge can manipulate exchanged
sensor data to deteriorate performance of the process, even leading to full
shutdowns of plants. Identifying those attacks requires iterating over all
possible sensor values, and running detailed system simulation or analysis to
identify optimal attacks. That setup allows adversaries to identify attacks
that are most impactful when applied on the system for the first time, before
the system operators become aware of the manipulations.
  In this work, we investigate if constrained attackers without detailed system
knowledge and simulators can identify comparable attacks. In particular, the
attacker only requires abstract knowledge on general information flow in the
plant, instead of precise algorithms, operating parameters, process models, or
simulators. We propose an approach that allows single-shot attacks, i.e.,
near-optimal attacks that are reliably shutting down a system on the first try.
The approach is applied and validated on two use cases, and demonstrated to
achieve comparable results to prior work, which relied on detailed system
information and simulations.

### Title: Indiscriminate Data Poisoning Attacks on Neural Networks
* Paper ID: 2204.09092v1
* Paper URL: [http://arxiv.org/abs/2204.09092v1](http://arxiv.org/abs/2204.09092v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Data poisoning attacks, in which a malicious adversary aims to influence a
model by injecting "poisoned" data into the training process, have attracted
significant recent attention. In this work, we take a closer look at existing
poisoning attacks and connect them with old and new algorithms for solving
sequential Stackelberg games. By choosing an appropriate loss function for the
attacker and optimizing with algorithms that exploit second-order information,
we design poisoning attacks that are effective on neural networks. We present
efficient implementations that exploit modern auto-differentiation packages and
allow simultaneous and coordinated generation of tens of thousands of poisoned
points, in contrast to existing methods that generate poisoned points one by
one. We further perform extensive experiments that empirically explore the
effect of data poisoning attacks on deep neural networks.

### Title: Exploration of Machine Learning Classification Models Used for Behavioral Biometrics Authentication
* Paper ID: 2204.09088v1
* Paper URL: [http://arxiv.org/abs/2204.09088v1](http://arxiv.org/abs/2204.09088v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Mobile devices have been manufactured and enhanced at growing rates in the
past decades. While this growth has significantly evolved the capability of
these devices, their security has been falling behind. This contrast in
development between capability and security of mobile devices is a significant
problem with the sensitive information of the public at risk. Continuing the
previous work in this field, this study identifies key Machine Learning
algorithms currently being used for behavioral biometric mobile authentication
schemes and aims to provide a comprehensive review of these algorithms when
used with touch dynamics and phone movement. Throughout this paper the
benefits, limitations, and recommendations for future work will be discussed.

### Title: A Survey and Perspective on Artificial Intelligence for Security-Aware Electronic Design Automation
* Paper ID: 2204.09579v1
* Paper URL: [http://arxiv.org/abs/2204.09579v1](http://arxiv.org/abs/2204.09579v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Artificial intelligence (AI) and machine learning (ML) techniques have been
increasingly used in several fields to improve performance and the level of
automation. In recent years, this use has exponentially increased due to the
advancement of high-performance computing and the ever increasing size of data.
One of such fields is that of hardware design; specifically the design of
digital and analog integrated circuits~(ICs), where AI/ ML techniques have been
extensively used to address ever-increasing design complexity, aggressive
time-to-market, and the growing number of ubiquitous interconnected devices
(IoT). However, the security concerns and issues related to IC design have been
highly overlooked. In this paper, we summarize the state-of-the-art in AL/ML
for circuit design/optimization, security and engineering challenges, research
in security-aware CAD/EDA, and future research directions and needs for using
AI/ML for security-aware circuit design.

### Title: The 2020 Census Disclosure Avoidance System TopDown Algorithm
* Paper ID: 2204.08986v1
* Paper URL: [http://arxiv.org/abs/2204.08986v1](http://arxiv.org/abs/2204.08986v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: The Census TopDown Algorithm (TDA) is a disclosure avoidance system using
differential privacy for privacy-loss accounting. The algorithm ingests the
final, edited version of the 2020 Census data and the final tabulation
geographic definitions. The algorithm then creates noisy versions of key
queries on the data, referred to as measurements, using zero-Concentrated
Differential Privacy. Another key aspect of the TDA are invariants, statistics
that the Census Bureau has determined, as matter of policy, to exclude from the
privacy-loss accounting. The TDA post-processes the measurements together with
the invariants to produce a Microdata Detail File (MDF) that contains one
record for each person and one record for each housing unit enumerated in the
2020 Census. The MDF is passed to the 2020 Census tabulation system to produce
the 2020 Census Redistricting Data (P.L. 94-171) Summary File. This paper
describes the mathematics and testing of the TDA for this purpose.

### Title: HMT: A Hardware-Centric Hybrid Bonsai Merkle Tree Algorithm for High-Performance Authentication
* Paper ID: 2204.08976v1
* Paper URL: [http://arxiv.org/abs/2204.08976v1](http://arxiv.org/abs/2204.08976v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Bonsai Merkle tree (BMT) is a widely used data structure for authenticating
data/metadata in a secure computing system. However, the predominantly
recursive andsequential nature of traditional BMT algorithms make them
challenging to implement with Field-Programmable Gate Array (FPGA) in modern
heterogeneous computing platforms. In this work, we introduce HMT, a
hardware-friendly implementation methodology for BMT that enables the
verification and update processes to function independently, as well as saves
additional write-backs by making the update conditions more flexible compared
to previous algorithms. The methodology of HMT contributes both novel algorithm
revisions and innovative hardware techniques to implementing BMT. Our empirical
performance measurements have demonstrated that HMT can achieve up to 7x
improvement in bandwidth and 4.5x reduction in latency over the baseline.

### Title: Identifying organizations receiving personal data in Android Apps
* Paper ID: 2204.09495v1
* Paper URL: [http://arxiv.org/abs/2204.09495v1](http://arxiv.org/abs/2204.09495v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Many studies have demonstrated that mobile applications are common means to
collect massive amounts of personal data. This goes unnoticed by most users,
who are also unaware that many different organizations are receiving this data,
even from multiple apps in parallel. This paper assesses different techniques
to identify the organizations that are receiving personal data flows in the
Android ecosystem, namely the WHOIS service, SSL certificates inspection, and
privacy policy textual analysis. Based on our findings, we propose a fully
automated method that combines the most successful techniques, achieving a
94.73% precision score in identifying the recipient organization. We further
demonstrate our method by evaluating 1,000 Android apps and exposing the
corporations that collect the users' personal data.

### Title: Seculator: A Fast and Secure Neural Processing Unit
* Paper ID: 2204.08951v1
* Paper URL: [http://arxiv.org/abs/2204.08951v1](http://arxiv.org/abs/2204.08951v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Securing deep neural networks (DNNs) is a problem of significant interest
since an ML model incorporates high-quality intellectual property, features of
data sets painstakingly collated by mechanical turks, and novel methods of
training on large cluster computers. Sadly, attacks to extract model parameters
are on the rise, and thus designers are being forced to create architectures
for securing such models. State-of-the-art proposals in this field take the
deterministic memory access patterns of such networks into cognizance (albeit
partially), group a set of memory blocks into a tile, and maintain state at the
level of tiles (to reduce storage space). For providing integrity guarantees
(tamper avoidance), they don't propose any significant optimizations, and still
maintain block-level state.
  We observe that it is possible to exploit the deterministic memory access
patterns of DNNs even further, and maintain state information for only the
current tile and current layer, which may comprise a large number of tiles.
This reduces the storage space, reduces the number of memory accesses,
increases performance, and simplifies the design without sacrificing any
security guarantees. The key techniques in our proposed accelerator
architecture, Seculator, are to encode memory access patterns to create a small
HW-based tile version number generator for a given layer, and to store
layer-level MACs. We completely eliminate the need for having a MAC cache and a
tile version number store (as used in related work). We show that using
intelligently-designed mathematical operations, these structures are not
required. By reducing such overheads, we show a speedup of 16% over the closest
competing work.

### Title: Heterogeneous Feature Augmentation for Ponzi Detection in Ethereum
* Paper ID: 2204.08916v1
* Paper URL: [http://arxiv.org/abs/2204.08916v1](http://arxiv.org/abs/2204.08916v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: While blockchain technology triggers new industrial and technological
revolutions, it also brings new challenges. Recently, a large number of new
scams with a "blockchain" sock-puppet continue to emerge, such as Ponzi
schemes, money laundering, etc., seriously threatening financial security.
Existing fraud detection methods in blockchain mainly concentrate on manual
feature and graph analytics, which first construct a homogeneous transaction
graph using partial blockchain data and then use graph analytics to detect
anomaly, resulting in a loss of pattern information. In this paper, we mainly
focus on Ponzi scheme detection and propose HFAug, a generic Heterogeneous
Feature Augmentation module that can capture the heterogeneous information
associated with account behavior patterns and can be combined with existing
Ponzi detection methods. HFAug learns the metapath-based behavior
characteristics in an auxiliary heterogeneous interaction graph, and aggregates
the heterogeneous features to corresponding account nodes in the homogeneous
one where the Ponzi detection methods are performed. Comprehensive experimental
results demonstrate that our HFAug can help existing Ponzi detection methods
achieve significant performance improvement on Ethereum datasets, suggesting
the effectiveness of heterogeneous information on detecting Ponzi schemes.

### Title: Model Checking Strategic Abilities in Information-sharing Systems
* Paper ID: 2204.08896v1
* Paper URL: [http://arxiv.org/abs/2204.08896v1](http://arxiv.org/abs/2204.08896v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: We introduce a subclass of concurrent game structures (CGS) with imperfect
information in which agents are endowed with private data-sharing capabilities.
Importantly, our CGSs are such that it is still decidable to model-check these
CGSs against a relevant fragment of ATL. These systems can be thought as a
generalisation of architectures allowing information forks, in the sense that,
in the initial states of the system, we allow information forks from agents
outside a given set A to agents inside this A. For this reason, together with
the fact that the communication in our models underpins a specialised form of
broadcast, we call our formalism A-cast systems. To underline, the fragment of
ATL for which we show the model-checking problem to be decidable over A-cast is
a large and significant one; it expresses coalitions over agents in any subset
of the set A. Indeed, as we show, our systems and this ATL fragments can encode
security problems that are notoriously hard to express faithfully:
terrorist-fraud attacks in identity schemes.

### Title: Using a Semantic Knowledge Base to Improve the Management of Security Reports in Industrial DevOps Projects
* Paper ID: 2204.08888v1
* Paper URL: [http://arxiv.org/abs/2204.08888v1](http://arxiv.org/abs/2204.08888v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Integrating security activities into the software development lifecycle to
detect security flaws is essential for any project. These activities produce
reports that must be managed and looped back to project stakeholders like
developers to enable security improvements. This so-called Feedback Loop is a
crucial part of any project and is required by various industrial security
standards and models. However, the operation of this loop presents a variety of
challenges. These challenges range from ensuring that feedback data is of
sufficient quality over providing different stakeholders with the information
they need to the enormous effort to manage the reports. In this paper, we
propose a novel approach for treating findings from security activity reports
as belief in a Knowledge Base (KB). By utilizing continuous logical inferences,
we derive information necessary for practitioners and address existing
challenges in the industry. This approach is currently evaluated in industrial
DevOps projects, using data from continuous security testing.

### Title: Bodyless Block Propagation: TPS Fully Scalable Blockchain with Pre-Validation
* Paper ID: 2204.08769v1
* Paper URL: [http://arxiv.org/abs/2204.08769v1](http://arxiv.org/abs/2204.08769v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: The fundamental tradeoff between transaction per second (TPS) and security in
blockchain systems persists despite numerous prior attempts to boost TPS. To
increase TPS without compromising security, we propose a bodyless block
propagation (BBP) scheme for which the block body is not validated and
transmitted during the block propagation process. Rather, the nodes in the
blockchain network anticipate the transactions and their ordering in the next
upcoming block so that these transactions can be pre-executed and pre-validated
before the birth of the block. It is critical, however, all nodes have a
consensus on the transaction content of the next block.
  This paper puts forth a transaction selection, ordering, and synchronization
algorithm to drive the nodes to reach such a consensus. Yet, the coinbase
address of the miner of the next block cannot be anticipated, and therefore
transactions that depend on the coinbase address cannot be pre-executed and
pre-validated. This paper further puts forth an algorithm to deal with such
unresolvable transactions for an overall consistent and TPS-efficient scheme.
With our scheme, most transactions do not need to be validated and transmitted
during block propagation, ridding the dependence of propagation time on the
number of transactions in the block, and making the system fully TPS scalable.
Experimental results show that our protocol can reduce propagation time by 4x
with respect to the current Ethereum blockchain, and its TPS performance is
limited by the node hardware performance rather than block propagation.

### Title: CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution
* Paper ID: 2204.08742v1
* Paper URL: [http://arxiv.org/abs/2204.08742v1](http://arxiv.org/abs/2204.08742v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: The migration of computation to the cloud has raised privacy concerns as
sensitive data becomes vulnerable to attacks since they need to be decrypted
for processing. Fully Homomorphic Encryption (FHE) mitigates this issue as it
enables meaningful computations to be performed directly on encrypted data.
Nevertheless, FHE is orders of magnitude slower than unencrypted computation,
which hinders its practicality and adoption. Therefore, improving FHE
performance is essential for its real world deployment. In this paper, we
present a year-long effort to design, implement, fabricate, and post-silicon
validate a hardware accelerator for Fully Homomorphic Encryption dubbed CoFHEE.
With a design area of $12mm^2$, CoFHEE aims to improve performance of
ciphertext multiplications, the most demanding arithmetic FHE operation, by
accelerating several primitive operations on polynomials, such as polynomial
additions and subtractions, Hadamard product, and Number Theoretic Transform.
CoFHEE supports polynomial degrees of up to $n = 2^{14}$ with a maximum
coefficient sizes of 128 bits, while it is capable of performing ciphertext
multiplications entirely on chip for $n \leq 2^{13}$. CoFHEE is fabricated in
55nm CMOS technology and achieves 250 MHz with our custom-built low-power
digital PLL design. In addition, our chip includes two communication interfaces
to the host machine: UART and SPI. This manuscript presents all steps and
design techniques in the ASIC development process, ranging from RTL design to
fabrication and validation. We evaluate our chip with performance and power
experiments and compare it against state-of-the-art software implementations
and other ASIC designs. Developed RTL files are available in an open-source
repository.

### Title: Jacobian Ensembles Improve Robustness Trade-offs to Adversarial Attacks
* Paper ID: 2204.08726v1
* Paper URL: [http://arxiv.org/abs/2204.08726v1](http://arxiv.org/abs/2204.08726v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Deep neural networks have become an integral part of our software
infrastructure and are being deployed in many widely-used and safety-critical
applications. However, their integration into many systems also brings with it
the vulnerability to test time attacks in the form of Universal Adversarial
Perturbations (UAPs). UAPs are a class of perturbations that when applied to
any input causes model misclassification. Although there is an ongoing effort
to defend models against these adversarial attacks, it is often difficult to
reconcile the trade-offs in model accuracy and robustness to adversarial
attacks. Jacobian regularization has been shown to improve the robustness of
models against UAPs, whilst model ensembles have been widely adopted to improve
both predictive performance and model robustness. In this work, we propose a
novel approach, Jacobian Ensembles-a combination of Jacobian regularization and
model ensembles to significantly increase the robustness against UAPs whilst
maintaining or improving model accuracy. Our results show that Jacobian
Ensembles achieves previously unseen levels of accuracy and robustness, greatly
improving over previous methods that tend to skew towards only either accuracy
or robustness.

### Title: Quantum-Secured Space-Air-Ground Integrated Networks: Concept, Framework, and Case Study
* Paper ID: 2204.08673v1
* Paper URL: [http://arxiv.org/abs/2204.08673v1](http://arxiv.org/abs/2204.08673v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: In the upcoming 6G era, existing terrestrial networks have evolved toward
space-air-ground integrated networks (SAGIN), providing ultra-high data rates,
seamless network coverage, and ubiquitous intelligence for communications of
applications and services. However, conventional communications in SAGIN still
face data confidentiality issues. Fortunately, the concept of Quantum Key
Distribution (QKD) over SAGIN is able to provide information-theoretic security
for secure communications in SAGIN with quantum cryptography. Therefore, in
this paper, we propose the quantum-secured SAGIN which is feasible to achieve
proven secure communications using quantum mechanics to protect data channels
between space, air, and ground nodes. Moreover, we propose a universal QKD
service provisioning framework to minimize the cost of QKD services under the
uncertainty and dynamics of communications in quantum-secured SAGIN. In this
framework, fiber-based QKD services are deployed in passive optical networks
with the advantages of low loss and high stability. Moreover, the widely
covered and flexible satellite- and UAV-based QKD services are provisioned as a
supplement during the real-time data transmission phase. Finally, to examine
the effectiveness of the proposed concept and framework, a case study of
quantum-secured SAGIN in the Metaverse is conducted where uncertain and dynamic
factors of the secure communications in Metaverse applications are effectively
resolved in the proposed framework.

### Title: Basilic: Resilient Optimal Consensus Protocols With Benign and Deceitful Faults
* Paper ID: 2204.08670v1
* Paper URL: [http://arxiv.org/abs/2204.08670v1](http://arxiv.org/abs/2204.08670v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: The problem of Byzantine consensus has been key to designing secure
distributed systems. However, it is particularly difficult, mainly due to the
presence of Byzantine processes that act arbitrarily and the unknown message
delays in general networks.
  Although it is well known that both safety and liveness are at risk as soon
as $n/3$ Byzantine processes fail, very few works attempted to characterize
precisely the faults that produce safety violations from the faults that
produce termination violations.
  In this paper, we present a new lower bound on the solvability of the
consensus problem by distinguishing deceitful faults violating safety and
benign faults violating termination from the more general Byzantine faults, in
what we call the Byzantine-deceitful-benign fault model. We show that one
cannot solve consensus if $n\leq 3t+d+2q$ with $t$ Byzantine processes, $d$
deceitful processes, and $q$ benign processes.
  In addition, we show that this bound is tight by presenting the Basilic class
of consensus protocols that solve consensus when $n > 3t+d+2q$. These protocols
differ in the number of processes from which they wait to receive messages
before progressing. Each of these protocols is thus better suited for some
applications depending on the predominance of benign or deceitful faults.
  Finally, we study the fault tolerance of the Basilic class of consensus
protocols in the context of blockchains that need to solve the weaker problem
of eventual consensus. We demonstrate that Basilic solves this problem with
only $n > 2t+d+q$, hence demonstrating how it can strengthen blockchain
security.

### Title: Toward Understanding the Use of Centralized Exchanges for Decentralized Cryptocurrency
* Paper ID: 2204.08664v1
* Paper URL: [http://arxiv.org/abs/2204.08664v1](http://arxiv.org/abs/2204.08664v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Cryptocurrency has been extensively studied as a decentralized financial
technology built on blockchain. However, there is a lack of understanding of
user experience with cryptocurrency exchanges, the main means for novice users
to interact with cryptocurrency. We conduct a qualitative study to provide a
panoramic view of user experience and security perception of exchanges. All 15
Chinese participants mainly use centralized exchanges (CEX) instead of
decentralized exchanges (DEX) to trade decentralized cryptocurrency, which is
paradoxical. A closer examination reveals that CEXes provide better usability
and charge lower transaction fee than DEXes. Country-specific security
perceptions are observed. Though DEXes provide better anonymity and privacy
protection, and are free of governmental regulation, these are not necessary
features for many participants. Based on the findings, we propose design
implications to make cryptocurrency trading more decentralized.

### Title: Poisons that are learned faster are more effective
* Paper ID: 2204.08615v1
* Paper URL: [http://arxiv.org/abs/2204.08615v1](http://arxiv.org/abs/2204.08615v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Imperceptible poisoning attacks on entire datasets have recently been touted
as methods for protecting data privacy. However, among a number of defenses
preventing the practical use of these techniques, early-stopping stands out as
a simple, yet effective defense. To gauge poisons' vulnerability to
early-stopping, we benchmark error-minimizing, error-maximizing, and synthetic
poisons in terms of peak test accuracy over 100 epochs and make a number of
surprising observations. First, we find that poisons that reach a low training
loss faster have lower peak test accuracy. Second, we find that a current
state-of-the-art error-maximizing poison is 7 times less effective when poison
training is stopped at epoch 8. Third, we find that stronger, more transferable
adversarial attacks do not make stronger poisons. We advocate for evaluating
poisons in terms of peak test accuracy.

### Title: Context-Auditor: Context-sensitive Content Injection Mitigation
* Paper ID: 2204.08592v1
* Paper URL: [http://arxiv.org/abs/2204.08592v1](http://arxiv.org/abs/2204.08592v1)
* Updated Date: 2022-04-19
* Code URL: null
* Summary: Cross-site scripting (XSS) is the most common vulnerability class in web
applications over the last decade. Much research attention has focused on
building exploit mitigation defenses for this problem, but no technique
provides adequate protection in the face of advanced attacks. One technique
that bypasses XSS mitigations is the scriptless attack: a content injection
technique that uses (among other options) CSS and HTML injection to infiltrate
data. In studying this technique and others, we realized that the common
property among the exploitation of all content injection vulnerabilities,
including not just XSS and scriptless attacks, but also command injections and
several others, is an unintended context switch in the victim program's parsing
engine that is caused by untrusted user input.
  In this paper, we propose Context-Auditor, a novel technique that leverages
this insight to identify content injection vulnerabilities ranging from XSS to
scriptless attacks and command injections. We implemented Context-Auditor as a
general solution to content injection exploit detection problem in the form of
a flexible, stand-alone detection module. We deployed instances of
Context-Auditor as (1) a browser plugin, (2) a web proxy (3) a web server
plugin, and (4) as a wrapper around potentially-injectable system endpoints.
Because Context-Auditor targets the root cause of content injection
exploitation (and, more specifically for the purpose of our prototype, XSS
exploitation, scriptless exploitation, and command injection), our evaluation
results demonstrate that Context-Auditor can identify and block content
injection exploits that modern defenses cannot while maintaining low throughput
overhead and avoiding false positives.

