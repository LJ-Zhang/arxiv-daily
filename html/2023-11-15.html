<h2>diffusion</h2>
<h3>Title: Finetuning Text-to-Image Diffusion Models for Fairness. (arXiv:2311.07604v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07604">http://arxiv.org/abs/2311.07604</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07604] Finetuning Text-to-Image Diffusion Models for Fairness](http://arxiv.org/abs/2311.07604) #diffusion</code></li>
<li>Summary: <p>The rapid adoption of text-to-image diffusion models in society underscores
an urgent need to address their biases. Without interventions, these biases
could propagate a distorted worldview and limit opportunities for minority
groups. In this work, we frame fairness as a distributional alignment problem.
Our solution consists of two main technical contributions: (1) a distributional
alignment loss that steers specific characteristics of the generated images
towards a user-defined target distribution, and (2) biased direct finetuning of
diffusion model's sampling process, which leverages a biased gradient to more
effectively optimize losses defined on the generated images. Empirically, our
method markedly reduces gender, racial, and their intersectional biases for
occupational prompts. Gender bias is significantly reduced even when finetuning
just five soft tokens. Crucially, our method supports diverse perspectives of
fairness beyond absolute equality, which is demonstrated by controlling age to
a $75\%$ young and $25\%$ old distribution while simultaneously debiasing
gender and race. Finally, our method is scalable: it can debias multiple
concepts at once by simply including these prompts in the finetuning data. We
hope our work facilitates the social alignment of T2I generative AI. We will
share code and various debiased diffusion model adaptors.
</p></li>
</ul>
<h3>Title: One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion. (arXiv:2311.07885v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07885">http://arxiv.org/abs/2311.07885</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07885] One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion](http://arxiv.org/abs/2311.07885) #diffusion</code></li>
<li>Summary: <p>Recent advancements in open-world 3D object generation have been remarkable,
with image-to-3D methods offering superior fine-grained control over their
text-to-3D counterparts. However, most existing models fall short in
simultaneously providing rapid generation speeds and high fidelity to input
images - two features essential for practical applications. In this paper, we
present One-2-3-45++, an innovative method that transforms a single image into
a detailed 3D textured mesh in approximately one minute. Our approach aims to
fully harness the extensive knowledge embedded in 2D diffusion models and
priors from valuable yet limited 3D data. This is achieved by initially
finetuning a 2D diffusion model for consistent multi-view image generation,
followed by elevating these images to 3D with the aid of multi-view conditioned
3D native diffusion models. Extensive experimental evaluations demonstrate that
our method can produce high-quality, diverse 3D assets that closely mirror the
original input image. Our project webpage:
https://sudo-ai-3d.github.io/One2345plus_page.
</p></li>
</ul>
<h3>Title: CLAMP: A Contrastive Language And Molecule Pre-training Network. (arXiv:2311.07617v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07617">http://arxiv.org/abs/2311.07617</a></li>
<li>Code URL: <a href="https://github.com/neelr/clamp">https://github.com/neelr/clamp</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07617] CLAMP: A Contrastive Language And Molecule Pre-training Network](http://arxiv.org/abs/2311.07617) #diffusion</code></li>
<li>Summary: <p>This paper highlights a shift in how to approach material generation. Instead
of material-to-material, we propose a language-to-material generation
architecture that utilizes millions of untapped data points. Using a web
scraper to collect crystal text pairs from open-source research papers, a
contrastive model can be trained using a convolutional graph neural network
encoder and a language encoder. This would allow unsupervised zero-shot
classification which can be trained by taking advantage of linguistic
structure. Without any specific training data, an ~82\% accuracy was achieved
and ~75\% accuracy for photocatalyst prediction with an extremely small
dataset. This novel network could ideally be cross-applied to any reaction that
can be described via text, opening completely new methods to think about 3D
chemical framework generation. In the full experiment diffusion models would
likely be incorporated to fully exploit the latent space.
</p></li>
</ul>
<h3>Title: Brain-Driven Representation Learning Based on Diffusion Model. (arXiv:2311.07925v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07925">http://arxiv.org/abs/2311.07925</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07925] Brain-Driven Representation Learning Based on Diffusion Model](http://arxiv.org/abs/2311.07925) #diffusion</code></li>
<li>Summary: <p>Interpreting EEG signals linked to spoken language presents a complex
challenge, given the data's intricate temporal and spatial attributes, as well
as the various noise factors. Denoising diffusion probabilistic models (DDPMs),
which have recently gained prominence in diverse areas for their capabilities
in representation learning, are explored in our research as a means to address
this issue. Using DDPMs in conjunction with a conditional autoencoder, our new
approach considerably outperforms traditional machine learning algorithms and
established baseline models in accuracy. Our results highlight the potential of
DDPMs as a sophisticated computational method for the analysis of
speech-related EEG signals. This could lead to significant advances in
brain-computer interfaces tailored for spoken communication.
</p></li>
</ul>
<h3>Title: A Consistent Diffusion-Based Algorithm for Semi-Supervised Graph Learning. (arXiv:2311.07627v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07627">http://arxiv.org/abs/2311.07627</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07627] A Consistent Diffusion-Based Algorithm for Semi-Supervised Graph Learning](http://arxiv.org/abs/2311.07627) #diffusion</code></li>
<li>Summary: <p>The task of semi-supervised classification aims at assigning labels to all
nodes of a graph based on the labels known for a few nodes, called the seeds.
One of the most popular algorithms relies on the principle of heat diffusion,
where the labels of the seeds are spread by thermoconductance and the
temperature of each node at equilibrium is used as a score function for each
label. In this paper, we prove that this algorithm is not consistent unless the
temperatures of the nodes at equilibrium are centered before scoring. This
crucial step does not only make the algorithm provably consistent on a block
model but brings significant performance gains on real graphs.
</p></li>
</ul>
<h2>self-supervised</h2>
<h3>Title: PECoP: Parameter Efficient Continual Pretraining for Action Quality Assessment. (arXiv:2311.07603v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07603">http://arxiv.org/abs/2311.07603</a></li>
<li>Code URL: <a href="https://github.com/plrbear/pecop">https://github.com/plrbear/pecop</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07603] PECoP: Parameter Efficient Continual Pretraining for Action Quality Assessment](http://arxiv.org/abs/2311.07603) #self-supervised</code></li>
<li>Summary: <p>The limited availability of labelled data in Action Quality Assessment (AQA),
has forced previous works to fine-tune their models pretrained on large-scale
domain-general datasets. This common approach results in weak generalisation,
particularly when there is a significant domain shift. We propose a novel,
parameter efficient, continual pretraining framework, PECoP, to reduce such
domain shift via an additional pretraining stage. In PECoP, we introduce
3D-Adapters, inserted into the pretrained model, to learn spatiotemporal,
in-domain information via self-supervised learning where only the adapter
modules' parameters are updated. We demonstrate PECoP's ability to enhance the
performance of recent state-of-the-art methods (MUSDL, CoRe, and TSA) applied
to AQA, leading to considerable improvements on benchmark datasets, JIGSAWS
($\uparrow6.0\%$), MTL-AQA ($\uparrow0.99\%$), and FineDiving
($\uparrow2.54\%$). We also present a new Parkinson's Disease dataset, PD4T, of
real patients performing four various actions, where we surpass
($\uparrow3.56\%$) the state-of-the-art in comparison. Our code, pretrained
models, and the PD4T dataset are available at https://github.com/Plrbear/PECoP.
</p></li>
</ul>
<h3>Title: CSLP-AE: A Contrastive Split-Latent Permutation Autoencoder Framework for Zero-Shot Electroencephalography Signal Conversion. (arXiv:2311.07788v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07788">http://arxiv.org/abs/2311.07788</a></li>
<li>Code URL: <a href="https://github.com/andersxa/cslp-ae">https://github.com/andersxa/cslp-ae</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07788] CSLP-AE: A Contrastive Split-Latent Permutation Autoencoder Framework for Zero-Shot Electroencephalography Signal Conversion](http://arxiv.org/abs/2311.07788) #self-supervised</code></li>
<li>Summary: <p>Electroencephalography (EEG) is a prominent non-invasive neuroimaging
technique providing insights into brain function. Unfortunately, EEG data
exhibit a high degree of noise and variability across subjects hampering
generalizable signal extraction. Therefore, a key aim in EEG analysis is to
extract the underlying neural activation (content) as well as to account for
the individual subject variability (style). We hypothesize that the ability to
convert EEG signals between tasks and subjects requires the extraction of
latent representations accounting for content and style. Inspired by recent
advancements in voice conversion technologies, we propose a novel contrastive
split-latent permutation autoencoder (CSLP-AE) framework that directly
optimizes for EEG conversion. Importantly, the latent representations are
guided using contrastive learning to promote the latent splits to explicitly
represent subject (style) and task (content). We contrast CSLP-AE to
conventional supervised, unsupervised (AE), and self-supervised (contrastive
learning) training and find that the proposed approach provides favorable
generalizable characterizations of subject and task. Importantly, the procedure
also enables zero-shot conversion between unseen subjects. While the present
work only considers conversion of EEG, the proposed CSLP-AE provides a general
framework for signal conversion and extraction of content (task activation) and
style (subject variability) components of general interest for the modeling and
analysis of biological signals.
</p></li>
</ul>
<h3>Title: Bring Your Own KG: Self-Supervised Program Synthesis for Zero-Shot KGQA. (arXiv:2311.07850v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07850">http://arxiv.org/abs/2311.07850</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07850] Bring Your Own KG: Self-Supervised Program Synthesis for Zero-Shot KGQA](http://arxiv.org/abs/2311.07850) #self-supervised</code></li>
<li>Summary: <p>We present BYOKG, a universal question-answering (QA) system that can operate
on any knowledge graph (KG), requires no human-annotated training data, and can
be ready to use within a day -- attributes that are out-of-scope for current
KGQA systems. BYOKG draws inspiration from the remarkable ability of humans to
comprehend information present in an unseen KG through exploration -- starting
at random nodes, inspecting the labels of adjacent nodes and edges, and
combining them with their prior world knowledge. In BYOKG, exploration
leverages an LLM-backed symbolic agent that generates a diverse set of
query-program exemplars, which are then used to ground a retrieval-augmented
reasoning procedure to predict programs for arbitrary questions. BYOKG is
effective over both small- and large-scale graphs, showing dramatic gains in QA
accuracy over a zero-shot baseline of 27.89 and 58.02 F1 on GrailQA and MetaQA,
respectively. On GrailQA, we further show that our unsupervised BYOKG
outperforms a supervised in-context learning method, demonstrating the
effectiveness of exploration. Lastly, we find that performance of BYOKG
reliably improves with continued exploration as well as improvements in the
base LLM, notably outperforming a state-of-the-art fine-tuned model by 7.08 F1
on a sub-sampled zero-shot split of GrailQA.
</p></li>
</ul>
<h3>Title: PEMS: Pre-trained Epidmic Time-series Models. (arXiv:2311.07841v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07841">http://arxiv.org/abs/2311.07841</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07841] PEMS: Pre-trained Epidmic Time-series Models](http://arxiv.org/abs/2311.07841) #self-supervised</code></li>
<li>Summary: <p>Providing accurate and reliable predictions about the future of an epidemic
is an important problem for enabling informed public health decisions. Recent
works have shown that leveraging data-driven solutions that utilize advances in
deep learning methods to learn from past data of an epidemic often outperform
traditional mechanistic models. However, in many cases, the past data is sparse
and may not sufficiently capture the underlying dynamics. While there exists a
large amount of data from past epidemics, leveraging prior knowledge from
time-series data of other diseases is a non-trivial challenge. Motivated by the
success of pre-trained models in language and vision tasks, we tackle the
problem of pre-training epidemic time-series models to learn from multiple
datasets from different diseases and epidemics. We introduce Pre-trained
Epidemic Time-Series Models (PEMS) that learn from diverse time-series datasets
of a variety of diseases by formulating pre-training as a set of
self-supervised learning (SSL) tasks. We tackle various important challenges
specific to pre-training for epidemic time-series such as dealing with
heterogeneous dynamics and efficiently capturing useful patterns from multiple
epidemic datasets by carefully designing the SSL tasks to learn important
priors about the epidemic dynamics that can be leveraged for fine-tuning to
multiple downstream tasks. The resultant PEM outperforms previous
state-of-the-art methods in various downstream time-series tasks across
datasets of varying seasonal patterns, geography, and mechanism of contagion
including the novel Covid-19 pandemic unseen in pre-trained data with better
efficiency using smaller fraction of datasets.
</p></li>
</ul>
<h3>Title: Self-supervised Heterogeneous Graph Variational Autoencoders. (arXiv:2311.07929v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07929">http://arxiv.org/abs/2311.07929</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07929] Self-supervised Heterogeneous Graph Variational Autoencoders](http://arxiv.org/abs/2311.07929) #self-supervised</code></li>
<li>Summary: <p>Heterogeneous Information Networks (HINs), which consist of various types of
nodes and edges, have recently demonstrated excellent performance in graph
mining. However, most existing heterogeneous graph neural networks (HGNNs)
ignore the problems of missing attributes, inaccurate attributes and scarce
labels for nodes, which limits their expressiveness. In this paper, we propose
a generative self-supervised model SHAVA to address these issues
simultaneously. Specifically, SHAVA first initializes all the nodes in the
graph with a low-dimensional representation matrix. After that, based on the
variational graph autoencoder framework, SHAVA learns both node-level and
attribute-level embeddings in the encoder, which can provide fine-grained
semantic information to construct node attributes. In the decoder, SHAVA
reconstructs both links and attributes. Instead of directly reconstructing raw
features for attributed nodes, SHAVA generates the initial low-dimensional
representation matrix for all the nodes, based on which raw features of
attributed nodes are further reconstructed to leverage accurate attributes. In
this way, SHAVA can not only complete informative features for non-attributed
nodes, but rectify inaccurate ones for attributed nodes. Finally, we conduct
extensive experiments to show the superiority of SHAVA in tackling HINs with
missing and inaccurate attributes.
</p></li>
</ul>
<h3>Title: Neural Lattice Reduction: A Self-Supervised Geometric Deep Learning Approach. (arXiv:2311.08170v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.08170">http://arxiv.org/abs/2311.08170</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.08170] Neural Lattice Reduction: A Self-Supervised Geometric Deep Learning Approach](http://arxiv.org/abs/2311.08170) #self-supervised</code></li>
<li>Summary: <p>Lattice reduction is a combinatorial optimization problem aimed at finding
the most orthogonal basis in a given lattice. In this work, we address lattice
reduction via deep learning methods. We design a deep neural model outputting
factorized unimodular matrices and train it in a self-supervised manner by
penalizing non-orthogonal lattice bases. We incorporate the symmetries of
lattice reduction into the model by making it invariant and equivariant with
respect to appropriate continuous and discrete groups.
</p></li>
</ul>
<h3>Title: Mobility-Induced Graph Learning for WiFi Positioning. (arXiv:2311.08271v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.08271">http://arxiv.org/abs/2311.08271</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.08271] Mobility-Induced Graph Learning for WiFi Positioning](http://arxiv.org/abs/2311.08271) #self-supervised</code></li>
<li>Summary: <p>A smartphone-based user mobility tracking could be effective in finding
his/her location, while the unpredictable error therein due to low
specification of built-in inertial measurement units (IMUs) rejects its
standalone usage but demands the integration to another positioning technique
like WiFi positioning. This paper aims to propose a novel integration technique
using a graph neural network called Mobility-INduced Graph LEarning (MINGLE),
which is designed based on two types of graphs made by capturing different user
mobility features. Specifically, considering sequential measurement points
(MPs) as nodes, a user's regular mobility pattern allows us to connect neighbor
MPs as edges, called time-driven mobility graph (TMG). Second, a user's
relatively straight transition at a constant pace when moving from one position
to another can be captured by connecting the nodes on each path, called a
direction-driven mobility graph (DMG). Then, we can design graph convolution
network (GCN)-based cross-graph learning, where two different GCN models for
TMG and DMG are jointly trained by feeding different input features created by
WiFi RTTs yet sharing their weights. Besides, the loss function includes a
mobility regularization term such that the differences between adjacent
location estimates should be less variant due to the user's stable moving pace.
Noting that the regularization term does not require ground-truth location,
MINGLE can be designed under semi- and self-supervised learning frameworks. The
proposed MINGLE's effectiveness is extensively verified through field
experiments, showing a better positioning accuracy than benchmarks, say root
mean square errors (RMSEs) being 1.398 (m) and 1.073 (m) for self- and
semi-supervised learning cases, respectively.
</p></li>
</ul>
<h2>foundation model</h2>
<h3>Title: Zero-Shot Segmentation of Eye Features Using the Segment Anything Model (SAM). (arXiv:2311.08077v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.08077">http://arxiv.org/abs/2311.08077</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.08077] Zero-Shot Segmentation of Eye Features Using the Segment Anything Model (SAM)](http://arxiv.org/abs/2311.08077) #foundation model</code></li>
<li>Summary: <p>The advent of foundation models signals a new era in artificial intelligence.
The Segment Anything Model (SAM) is the first foundation model for image
segmentation. In this study, we evaluate SAM's ability to segment features from
eye images recorded in virtual reality setups. The increasing requirement for
annotated eye-image datasets presents a significant opportunity for SAM to
redefine the landscape of data annotation in gaze estimation. Our investigation
centers on SAM's zero-shot learning abilities and the effectiveness of prompts
like bounding boxes or point clicks. Our results are consistent with studies in
other domains, demonstrating that SAM's segmentation effectiveness can be
on-par with specialized models depending on the feature, with prompts improving
its performance, evidenced by an IoU of 93.34% for pupil segmentation in one
dataset. Foundation models like SAM could revolutionize gaze estimation by
enabling quick and easy image segmentation, reducing reliance on specialized
models and extensive manual annotation.
</p></li>
</ul>
<h2>generative</h2>
<h3>Title: A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated Class Incremental Learning for Vision Tasks. (arXiv:2311.07784v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07784">http://arxiv.org/abs/2311.07784</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07784] A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated Class Incremental Learning for Vision Tasks](http://arxiv.org/abs/2311.07784) #generative</code></li>
<li>Summary: <p>Deep learning models often suffer from forgetting previously learned
information when trained on new data. This problem is exacerbated in federated
learning (FL), where the data is distributed and can change independently for
each user. Many solutions are proposed to resolve this catastrophic forgetting
in a centralized setting. However, they do not apply directly to FL because of
its unique complexities, such as privacy concerns and resource limitations. To
overcome these challenges, this paper presents a framework for
\textbf{federated class incremental learning} that utilizes a generative model
to synthesize samples from past distributions. This data can be later exploited
alongside the training data to mitigate catastrophic forgetting. To preserve
privacy, the generative model is trained on the server using data-free methods
at the end of each task without requesting data from clients. Moreover, our
solution does not demand the users to store old data or models, which gives
them the freedom to join/leave the training at any time. Additionally, we
introduce SuperImageNet, a new regrouping of the ImageNet dataset specifically
tailored for federated continual learning. We demonstrate significant
improvements compared to existing baselines through extensive experiments on
multiple datasets.
</p></li>
</ul>
<h3>Title: AuthentiGPT: Detecting Machine-Generated Text via Black-Box Language Models Denoising. (arXiv:2311.07700v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07700">http://arxiv.org/abs/2311.07700</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07700] AuthentiGPT: Detecting Machine-Generated Text via Black-Box Language Models Denoising](http://arxiv.org/abs/2311.07700) #generative</code></li>
<li>Summary: <p>Large language models (LLMs) have opened up enormous opportunities while
simultaneously posing ethical dilemmas. One of the major concerns is their
ability to create text that closely mimics human writing, which can lead to
potential misuse, such as academic misconduct, disinformation, and fraud. To
address this problem, we present AuthentiGPT, an efficient classifier that
distinguishes between machine-generated and human-written texts. Under the
assumption that human-written text resides outside the distribution of
machine-generated text, AuthentiGPT leverages a black-box LLM to denoise input
text with artificially added noise, and then semantically compares the denoised
text with the original to determine if the content is machine-generated. With
only one trainable parameter, AuthentiGPT eliminates the need for a large
training dataset, watermarking the LLM's output, or computing the
log-likelihood. Importantly, the detection capability of AuthentiGPT can be
easily adapted to any generative language model. With a 0.918 AUROC score on a
domain-specific dataset, AuthentiGPT demonstrates its effectiveness over other
commercial algorithms, highlighting its potential for detecting
machine-generated text in academic settings.
</p></li>
</ul>
<h3>Title: The ART of LLM Refinement: Ask, Refine, and Trust. (arXiv:2311.07961v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07961">http://arxiv.org/abs/2311.07961</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07961] The ART of LLM Refinement: Ask, Refine, and Trust](http://arxiv.org/abs/2311.07961) #generative</code></li>
<li>Summary: <p>In recent years, Large Language Models (LLMs) have demonstrated remarkable
generative abilities, but can they judge the quality of their own generations?
A popular concept, referred to as self-refinement, postulates that LLMs can
detect and correct the errors in their generations when asked to do so.
However, recent empirical evidence points in the opposite direction, suggesting
that LLMs often struggle to accurately identify errors when reasoning is
involved. To address this, we propose a reasoning with refinement objective
called ART: Ask, Refine, and Trust, which asks necessary questions to decide
when an LLM should refine its output, and either affirm or withhold trust in
its refinement by ranking the refinement and the initial prediction. On two
multistep reasoning tasks of mathematical word problems (GSM8K) and question
answering (StrategyQA), ART achieves a performance gain of +5 points over
self-refinement baselines, while using a much smaller model as the decision
maker. We also demonstrate the benefit of using smaller models to make
refinement decisions as a cost-effective alternative to fine-tuning a larger
model.
</p></li>
</ul>
<h3>Title: How good are Large Language Models on African Languages?. (arXiv:2311.07978v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07978">http://arxiv.org/abs/2311.07978</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07978] How good are Large Language Models on African Languages?](http://arxiv.org/abs/2311.07978) #generative</code></li>
<li>Summary: <p>Recent advancements in natural language processing have led to the
proliferation of large language models (LLMs). These models have been shown to
yield good performance, using in-context learning, even on unseen tasks and
languages. Additionally, they have been widely adopted as
language-model-as-a-service commercial APIs like GPT-4 API. However, their
performance on African languages is largely unknown. We present an analysis of
three popular large language models (mT0, LLaMa 2, and GPT-4) on five tasks
(news topic classification, sentiment classification, machine translation,
question answering, and named entity recognition) across 30 African languages,
spanning different language families and geographical regions. Our results
suggest that all LLMs produce below-par performance on African languages, and
there is a large gap in performance compared to high-resource languages like
English most tasks. We find that GPT-4 has an average or impressive performance
on classification tasks but very poor results on generative tasks like machine
translation. Surprisingly, we find that mT0 had the best overall on
cross-lingual QA, better than the state-of-the-art supervised model (i.e.
fine-tuned mT5) and GPT-4 on African languages. Overall, LLaMa 2 records the
worst performance due to its limited multilingual capabilities and
English-centric pre-training corpus. In general, our findings present a
call-to-action to ensure African languages are well represented in large
language models, given their growing popularity.
</p></li>
</ul>
<h3>Title: Align after Pre-train: Improving Multilingual Generative Models with Cross-lingual Alignment. (arXiv:2311.08089v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.08089">http://arxiv.org/abs/2311.08089</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.08089] Align after Pre-train: Improving Multilingual Generative Models with Cross-lingual Alignment](http://arxiv.org/abs/2311.08089) #generative</code></li>
<li>Summary: <p>Multilingual generative models obtain remarkable cross-lingual capabilities
through pre-training on large-scale corpora. However, they still exhibit a
performance bias toward high-resource languages, and learn isolated
distributions of sentence representations across languages. To bridge this gap,
we propose a simple yet effective alignment framework exploiting pairs of
translation sentences. It aligns the internal sentence representations across
different languages via multilingual contrastive learning and aligns model
outputs by answering prompts in different languages. Experimental results
demonstrate that even with less than 0.1 {\textperthousand} of pre-training
tokens, our alignment framework significantly boosts the cross-lingual
abilities of generative models and mitigates the performance gap. Further
analysis reveals that it results in a better internal multilingual
representation distribution of multilingual models.
</p></li>
</ul>
<h3>Title: Eval-GCSC: A New Metric for Evaluating ChatGPT's Performance in Chinese Spelling Correction. (arXiv:2311.08219v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.08219">http://arxiv.org/abs/2311.08219</a></li>
<li>Code URL: <a href="https://github.com/ktlktl/eval-gcsc">https://github.com/ktlktl/eval-gcsc</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2311.08219] Eval-GCSC: A New Metric for Evaluating ChatGPT's Performance in Chinese Spelling Correction](http://arxiv.org/abs/2311.08219) #generative</code></li>
<li>Summary: <p>ChatGPT has demonstrated impressive performance in various downstream tasks.
However, in the Chinese Spelling Correction (CSC) task, we observe a
discrepancy: while ChatGPT performs well under human evaluation, it scores
poorly according to traditional metrics. We believe this inconsistency arises
because the traditional metrics are not well-suited for evaluating generative
models. Their overly strict length and phonics constraints may lead to
underestimating ChatGPT's correction capabilities. To better evaluate
generative models in the CSC task, this paper proposes a new evaluation metric:
Eval-GCSC. By incorporating word-level and semantic similarity judgments, it
relaxes the stringent length and phonics constraints. Experimental results show
that Eval-GCSC closely aligns with human evaluations. Under this metric,
ChatGPT's performance is comparable to traditional token-level classification
models (TCM), demonstrating its potential as a CSC tool. The source code and
scripts can be accessed at https://github.com/ktlKTL/Eval-GCSC.
</p></li>
</ul>
<h3>Title: Modeling Complex Disease Trajectories using Deep Generative Models with Semi-Supervised Latent Processes. (arXiv:2311.08149v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.08149">http://arxiv.org/abs/2311.08149</a></li>
<li>Code URL: <a href="https://github.com/uzh-dqbm-cmi/eustar_dgm4h">https://github.com/uzh-dqbm-cmi/eustar_dgm4h</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2311.08149] Modeling Complex Disease Trajectories using Deep Generative Models with Semi-Supervised Latent Processes](http://arxiv.org/abs/2311.08149) #generative</code></li>
<li>Summary: <p>In this paper, we propose a deep generative time series approach using latent
temporal processes for modeling and holistically analyzing complex disease
trajectories. We aim to find meaningful temporal latent representations of an
underlying generative process that explain the observed disease trajectories in
an interpretable and comprehensive way. To enhance the interpretability of
these latent temporal processes, we develop a semi-supervised approach for
disentangling the latent space using established medical concepts. By combining
the generative approach with medical knowledge, we leverage the ability to
discover novel aspects of the disease while integrating medical concepts into
the model. We show that the learned temporal latent processes can be utilized
for further data analysis and clinical hypothesis testing, including finding
similar patients and clustering the disease into new sub-types. Moreover, our
method enables personalized online monitoring and prediction of multivariate
time series including uncertainty quantification. We demonstrate the
effectiveness of our approach in modeling systemic sclerosis, showcasing the
potential of our machine learning model to capture complex disease trajectories
and acquire new medical knowledge.
</p></li>
</ul>
<h2>anomaly</h2>
<h3>Title: VegaEdge: Edge AI Confluence Anomaly Detection for Real-Time Highway IoT-Applications. (arXiv:2311.07880v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07880">http://arxiv.org/abs/2311.07880</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07880] VegaEdge: Edge AI Confluence Anomaly Detection for Real-Time Highway IoT-Applications](http://arxiv.org/abs/2311.07880) #anomaly</code></li>
<li>Summary: <p>Vehicle anomaly detection plays a vital role in highway safety applications
such as accident prevention, rapid response, traffic flow optimization, and
work zone safety. With the surge of the Internet of Things (IoT) in recent
years, there has arisen a pressing demand for Artificial Intelligence (AI)
based anomaly detection methods designed to meet the requirements of IoT
devices. Catering to this futuristic vision, we introduce a lightweight
approach to vehicle anomaly detection by utilizing the power of trajectory
prediction. Our proposed design identifies vehicles deviating from expected
paths, indicating highway risks from different camera-viewing angles from
real-world highway datasets. On top of that, we present VegaEdge - a
sophisticated AI confluence designed for real-time security and surveillance
applications in modern highway settings through edge-centric IoT-embedded
platforms equipped with our anomaly detection approach. Extensive testing
across multiple platforms and traffic scenarios showcases the versatility and
effectiveness of VegaEdge. This work also presents the Carolinas Anomaly
Dataset (CAD), to bridge the existing gap in datasets tailored for highway
anomalies. In real-world scenarios, our anomaly detection approach achieves an
AUC-ROC of 0.94, and our proposed VegaEdge design, on an embedded IoT platform,
processes 738 trajectories per second in a typical highway setting. The dataset
is available at
https://github.com/TeCSAR-UNCC/Carolinas_Dataset#chd-anomaly-test-set .
</p></li>
</ul>
<h2>in-context</h2>
<h3>Title: In-context Learning and Gradient Descent Revisited. (arXiv:2311.07772v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07772">http://arxiv.org/abs/2311.07772</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07772] In-context Learning and Gradient Descent Revisited](http://arxiv.org/abs/2311.07772) #in-context</code></li>
<li>Summary: <p>In-context learning (ICL) has shown impressive results in few-shot learning
tasks, yet its underlying mechanism is still not fully understood. Recent works
suggest that ICL can be thought of as a gradient descent (GD) based
optimization process. While promising, these results mainly focus on simplified
settings of ICL and provide only a preliminary evaluation of the similarities
between the two methods. In this work, we revisit the comparison between ICL
and GD-based finetuning and study what properties of ICL an equivalent process
must follow. We highlight a major difference in the flow of information between
ICL and standard finetuning. Namely, ICL can only rely on information from
lower layers at every point, while finetuning depends on loss gradients from
deeper layers. We refer to this discrepancy as Layer Causality and show that a
layer causal variant of the finetuning process aligns with ICL on par with
vanilla finetuning and is even better in most cases across relevant metrics. To
the best of our knowledge, this is the first work to discuss this discrepancy
explicitly and suggest a solution that tackles this problem with minimal
changes.
</p></li>
</ul>
<h3>Title: In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax. (arXiv:2311.07811v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07811">http://arxiv.org/abs/2311.07811</a></li>
<li>Code URL: <a href="https://github.com/aaronmueller/syntax-icl">https://github.com/aaronmueller/syntax-icl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07811] In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax](http://arxiv.org/abs/2311.07811) #in-context</code></li>
<li>Summary: <p>In-context learning (ICL) is now a common method for supervising large
language models (LLMs): given labeled examples in the input context, the LLM
learns to perform the task without weight updates. Despite ICL's prevalence and
utility, we understand little about whether models supervised in this manner
represent the underlying structure of their tasks, rather than superficial
heuristics that only generalize to identically distributed examples. In this
study, we investigate the robustness of LLMs supervised via ICL using the test
case of sensitivity to syntax, which is a prerequisite for robust language
understanding. Our experiments are based on two simple and well-controlled
syntactic transformations tasks, where correct out-of-distribution
generalization requires an accurate syntactic analysis of the input. We further
investigate whether out-of-distribution generalization can be improved via
chain-of-thought prompting, where the model is provided with a sequence of
intermediate computation steps that illustrate how the task ought to be
performed. In experiments with models from the GPT, PaLM, and Llama 2 families,
we find large variance across LMs on this fundamental linguistic phenomenon,
and that the variance is explained more by the composition of the pre-training
corpus and supervision methods than by model size. In particular, we find
evidence that models pre-trained on code generalize better, and benefit to a
greater extent from chain-of-thought prompting.
</p></li>
</ul>
<h2>memory</h2>
<h3>Title: Quality-Aware Prototype Memory for Face Representation Learning. (arXiv:2311.07734v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07734">http://arxiv.org/abs/2311.07734</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07734] Quality-Aware Prototype Memory for Face Representation Learning](http://arxiv.org/abs/2311.07734) #memory</code></li>
<li>Summary: <p>Prototype Memory is a powerful model for face representation learning. It
enables the training of face recognition models using datasets of any size,
with on-the-fly generation of prototypes (classifier weights) and efficient
ways of their utilization. Prototype Memory demonstrated strong results in many
face recognition benchmarks. However, the algorithm of prototype generation,
used in it, is prone to the problems of imperfectly calculated prototypes in
case of low-quality or poorly recognizable faces in the images, selected for
the prototype creation. All images of the same person, presented in the
mini-batch, used with equal weights, and the resulting averaged prototype could
be contaminated with imperfect embeddings of such face images. It can lead to
misdirected training signals and impair the performance of the trained face
recognition models. In this paper, we propose a simple and effective way to
improve Prototype Memory with quality-aware prototype generation. Quality-Aware
Prototype Memory uses different weights for images of different quality in the
process of prototype generation. With this improvement, prototypes get more
valuable information from high-quality images and less hurt by low-quality
ones. We propose and compare several methods of quality estimation and usage,
perform extensive experiments on the different face recognition benchmarks and
demonstrate the advantages of the proposed model compared to the basic version
of Prototype Memory.
</p></li>
</ul>
<h3>Title: Detection of Small Targets in Sea Clutter Based on RepVGG and Continuous Wavelet Transform. (arXiv:2311.07912v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07912">http://arxiv.org/abs/2311.07912</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07912] Detection of Small Targets in Sea Clutter Based on RepVGG and Continuous Wavelet Transform](http://arxiv.org/abs/2311.07912) #memory</code></li>
<li>Summary: <p>Constructing a high-performance target detector under the background of sea
clutter is always necessary and important. In this work, we propose a
RepVGGA0-CWT detector, where RepVGG is a residual network that gains a high
detection accuracy. Different from traditional residual networks, RepVGG keeps
an acceptable calculation speed. Giving consideration to both accuracy and
speed, the RepVGGA0 is selected among all the variants of RepVGG. Also,
continuous wavelet transform (CWT) is employed to extract the radar echoes'
time-frequency feature effectively. In the tests, other networks (ResNet50,
ResNet18 and AlexNet) and feature extraction methods (short-time Fourier
transform (STFT), CWT) are combined to build detectors for comparison. The
result of different datasets shows that the RepVGGA0-CWT detector performs
better than those detectors in terms of low controllable false alarm rate, high
training speed, high inference speed and low memory usage. This RepVGGA0-CWT
detector is hardware-friendly and can be applied in real-time scenes for its
high inference speed in detection.
</p></li>
</ul>
<h3>Title: Learning based Deep Disentangling Light Field Reconstruction and Disparity Estimation Application. (arXiv:2311.08129v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.08129">http://arxiv.org/abs/2311.08129</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.08129] Learning based Deep Disentangling Light Field Reconstruction and Disparity Estimation Application](http://arxiv.org/abs/2311.08129) #memory</code></li>
<li>Summary: <p>Light field cameras have a wide range of uses due to their ability to
simultaneously record light intensity and direction. The angular resolution of
light fields is important for downstream tasks such as depth estimation, yet is
often difficult to improve due to hardware limitations. Conventional methods
tend to perform poorly against the challenge of large disparity in sparse light
fields, while general CNNs have difficulty extracting spatial and angular
features coupled together in 4D light fields. The light field disentangling
mechanism transforms the 4D light field into 2D image format, which is more
favorable for CNN for feature extraction. In this paper, we propose a Deep
Disentangling Mechanism, which inherits the principle of the light field
disentangling mechanism and further develops the design of the feature
extractor and adds advanced network structure. We design a light-field
reconstruction network (i.e., DDASR) on the basis of the Deep Disentangling
Mechanism, and achieve SOTA performance in the experiments. In addition, we
design a Block Traversal Angular Super-Resolution Strategy for the practical
application of depth estimation enhancement where the input views is often
higher than 2x2 in the experiments resulting in a high memory usage, which can
reduce the memory usage while having a better reconstruction performance.
</p></li>
</ul>
<h3>Title: Memory-efficient Stochastic methods for Memory-based Transformers. (arXiv:2311.08123v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.08123">http://arxiv.org/abs/2311.08123</a></li>
<li>Code URL: <a href="https://github.com/vishwajit-vishnu/memory-efficient-stochastic-methods-for-memory-based-transformers">https://github.com/vishwajit-vishnu/memory-efficient-stochastic-methods-for-memory-based-transformers</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2311.08123] Memory-efficient Stochastic methods for Memory-based Transformers](http://arxiv.org/abs/2311.08123) #memory</code></li>
<li>Summary: <p>Training Memory-based transformers can require a large amount of memory and
can be quite inefficient. We propose a novel two-phase training mechanism and a
novel regularization technique to improve the training efficiency of
memory-based transformers, which are often used for long-range context
problems. For our experiments, we consider transformer-XL as our baseline model
which is one of memorybased transformer models. We show that our resultant
model, Skip Cross-head TransformerXL, outperforms the baseline on character
level language modeling task with similar parameters and outperforms the
baseline on word level language modelling task with almost 20% fewer
parameters. Our proposed methods do not require any additional memory. We also
demonstrate the effectiveness of our regularization mechanism on BERT which
shows similar performance with reduction in standard deviation of scores of
around 30% on multiple GLUE tasks.
</p></li>
</ul>
<h3>Title: ResMGCN: Residual Message Graph Convolution Network for Fast Biomedical Interactions Discovering. (arXiv:2311.07632v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07632">http://arxiv.org/abs/2311.07632</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07632] ResMGCN: Residual Message Graph Convolution Network for Fast Biomedical Interactions Discovering](http://arxiv.org/abs/2311.07632) #memory</code></li>
<li>Summary: <p>Biomedical information graphs are crucial for interaction discovering of
biomedical information in modern age, such as identification of multifarious
molecular interactions and drug discovery, which attracts increasing interests
in biomedicine, bioinformatics, and human healthcare communities. Nowadays,
more and more graph neural networks have been proposed to learn the entities of
biomedical information and precisely reveal biomedical molecule interactions
with state-of-the-art results. These methods remedy the fading of features from
a far distance but suffer from remedying such problem at the expensive cost of
redundant memory and time. In our paper, we propose a novel Residual Message
Graph Convolution Network (ResMGCN) for fast and precise biomedical interaction
prediction in a different idea. Specifically, instead of enhancing the message
from far nodes, ResMGCN aggregates lower-order information with the next round
higher information to guide the node update to obtain a more meaningful node
representation. ResMGCN is able to perceive and preserve various messages from
the previous layer and high-order information in the current layer with least
memory and time cost to obtain informative representations of biomedical
entities. We conduct experiments on four biomedical interaction network
datasets, including protein-protein, drug-drug, drug-target, and gene-disease
interactions, which demonstrates that ResMGCN outperforms previous
state-of-the-art models while achieving superb effectiveness on both storage
and time.
</p></li>
</ul>
<h3>Title: Leveraging Hamilton-Jacobi PDEs with time-dependent Hamiltonians for continual scientific machine learning. (arXiv:2311.07790v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07790">http://arxiv.org/abs/2311.07790</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07790] Leveraging Hamilton-Jacobi PDEs with time-dependent Hamiltonians for continual scientific machine learning](http://arxiv.org/abs/2311.07790) #memory</code></li>
<li>Summary: <p>We address two major challenges in scientific machine learning (SciML):
interpretability and computational efficiency. We increase the interpretability
of certain learning processes by establishing a new theoretical connection
between optimization problems arising from SciML and a generalized Hopf
formula, which represents the viscosity solution to a Hamilton-Jacobi partial
differential equation (HJ PDE) with time-dependent Hamiltonian. Namely, we show
that when we solve certain regularized learning problems with integral-type
losses, we actually solve an optimal control problem and its associated HJ PDE
with time-dependent Hamiltonian. This connection allows us to reinterpret
incremental updates to learned models as the evolution of an associated HJ PDE
and optimal control problem in time, where all of the previous information is
intrinsically encoded in the solution to the HJ PDE. As a result, existing HJ
PDE solvers and optimal control algorithms can be reused to design new
efficient training approaches for SciML that naturally coincide with the
continual learning framework, while avoiding catastrophic forgetting. As a
first exploration of this connection, we consider the special case of linear
regression and leverage our connection to develop a new Riccati-based
methodology for solving these learning problems that is amenable to continual
learning applications. We also provide some corresponding numerical examples
that demonstrate the potential computational and memory advantages our
Riccati-based approach can provide.
</p></li>
</ul>
<h3>Title: Toward Efficient and Incremental Spectral Clustering via Parametric Spectral Clustering. (arXiv:2311.07833v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07833">http://arxiv.org/abs/2311.07833</a></li>
<li>Code URL: <a href="https://github.com/109502518/psc_bigdata">https://github.com/109502518/psc_bigdata</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07833] Toward Efficient and Incremental Spectral Clustering via Parametric Spectral Clustering](http://arxiv.org/abs/2311.07833) #memory</code></li>
<li>Summary: <p>Spectral clustering is a popular method for effectively clustering
nonlinearly separable data. However, computational limitations, memory
requirements, and the inability to perform incremental learning challenge its
widespread application. To overcome these limitations, this paper introduces a
novel approach called parametric spectral clustering (PSC). By extending the
capabilities of spectral clustering, PSC addresses the challenges associated
with big data and real-time scenarios and enables efficient incremental
clustering with new data points. Experimental evaluations conducted on various
open datasets demonstrate the superiority of PSC in terms of computational
efficiency while achieving clustering quality mostly comparable to standard
spectral clustering. The proposed approach has significant potential for
incremental and real-time data analysis applications, facilitating timely and
accurate clustering in dynamic and evolving datasets. The findings of this
research contribute to the advancement of clustering techniques and open new
avenues for efficient and effective data analysis. We publish the experimental
code at https://github.<a href="http://export.arxiv.org/abs/com/1095025">com/1095025</a>18/PSC_BigData.
</p></li>
</ul>
<h2>few-shot</h2>
<h3>Title: Follow-Up Differential Descriptions: Language Models Resolve Ambiguities for Image Classification. (arXiv:2311.07593v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07593">http://arxiv.org/abs/2311.07593</a></li>
<li>Code URL: <a href="https://github.com/batsresearch/fudd">https://github.com/batsresearch/fudd</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07593] Follow-Up Differential Descriptions: Language Models Resolve Ambiguities for Image Classification](http://arxiv.org/abs/2311.07593) #few-shot</code></li>
<li>Summary: <p>A promising approach for improving the performance of vision-language models
like CLIP for image classification is to extend the class descriptions (i.e.,
prompts) with related attributes, e.g., using brown sparrow instead of sparrow.
However, current zero-shot methods select a subset of attributes regardless of
commonalities between the target classes, potentially providing no useful
information that would have helped to distinguish between them. For instance,
they may use color instead of bill shape to distinguish between sparrows and
wrens, which are both brown. We propose Follow-up Differential Descriptions
(FuDD), a zero-shot approach that tailors the class descriptions to each
dataset and leads to additional attributes that better differentiate the target
classes. FuDD first identifies the ambiguous classes for each image, and then
uses a Large Language Model (LLM) to generate new class descriptions that
differentiate between them. The new class descriptions resolve the initial
ambiguity and help predict the correct label. In our experiments, FuDD
consistently outperforms generic description ensembles and naive LLM-generated
descriptions on 12 datasets. We show that differential descriptions are an
effective tool to resolve class ambiguities, which otherwise significantly
degrade the performance. We also show that high quality natural language class
descriptions produced by FuDD result in comparable performance to few-shot
adaptation methods.
</p></li>
</ul>
<h3>Title: Dual-channel Prototype Network for few-shot Classification of Pathological Images. (arXiv:2311.07871v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07871">http://arxiv.org/abs/2311.07871</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07871] Dual-channel Prototype Network for few-shot Classification of Pathological Images](http://arxiv.org/abs/2311.07871) #few-shot</code></li>
<li>Summary: <p>In pathology, the rarity of certain diseases and the complexity in annotating
pathological images significantly hinder the creation of extensive,
high-quality datasets. This limitation impedes the progress of deep
learning-assisted diagnostic systems in pathology. Consequently, it becomes
imperative to devise a technology that can discern new disease categories from
a minimal number of annotated examples. Such a technology would substantially
advance deep learning models for rare diseases. Addressing this need, we
introduce the Dual-channel Prototype Network (DCPN), rooted in the few-shot
learning paradigm, to tackle the challenge of classifying pathological images
with limited samples. DCPN augments the Pyramid Vision Transformer (PVT)
framework for few-shot classification via self-supervised learning and
integrates it with convolutional neural networks. This combination forms a
dual-channel architecture that extracts multi-scale, highly precise
pathological features. The approach enhances the versatility of prototype
representations and elevates the efficacy of prototype networks in few-shot
pathological image classification tasks. We evaluated DCPN using three publicly
available pathological datasets, configuring small-sample classification tasks
that mirror varying degrees of clinical scenario domain shifts. Our
experimental findings robustly affirm DCPN's superiority in few-shot
pathological image classification, particularly in tasks within the same
domain, where it achieves the benchmarks of supervised learning.
</p></li>
</ul>
<h3>Title: Peer is Your Pillar: A Data-unbalanced Conditional GANs for Few-shot Image Generation. (arXiv:2311.08217v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.08217">http://arxiv.org/abs/2311.08217</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.08217] Peer is Your Pillar: A Data-unbalanced Conditional GANs for Few-shot Image Generation](http://arxiv.org/abs/2311.08217) #few-shot</code></li>
<li>Summary: <p>Few-shot image generation aims to train generative models using a small
number of training images. When there are few images available for training
(e.g. 10 images), Learning From Scratch (LFS) methods often generate images
that closely resemble the training data while Transfer Learning (TL) methods
try to improve performance by leveraging prior knowledge from GANs pre-trained
on large-scale datasets. However, current TL methods may not allow for
sufficient control over the degree of knowledge preservation from the source
model, making them unsuitable for setups where the source and target domains
are not closely related. To address this, we propose a novel pipeline called
Peer is your Pillar (PIP), which combines a target few-shot dataset with a peer
dataset to create a data-unbalanced conditional generation. Our approach
includes a class embedding method that separates the class space from the
latent space, and we use a direction loss based on pre-trained CLIP to improve
image diversity. Experiments on various few-shot datasets demonstrate the
advancement of the proposed PIP, especially reduces the training requirements
of few-shot image generation.
</p></li>
</ul>
<h3>Title: On the Analysis of Cross-Lingual Prompt Tuning for Decoder-based Multilingual Model. (arXiv:2311.07820v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07820">http://arxiv.org/abs/2311.07820</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07820] On the Analysis of Cross-Lingual Prompt Tuning for Decoder-based Multilingual Model](http://arxiv.org/abs/2311.07820) #few-shot</code></li>
<li>Summary: <p>An exciting advancement in the field of multilingual models is the emergence
of autoregressive models with zero- and few-shot capabilities, a phenomenon
widely reported in large-scale language models. To further improve model
adaptation to cross-lingual tasks, another trend is to further fine-tune the
language models with either full fine-tuning or parameter-efficient tuning.
However, the interaction between parameter-efficient fine-tuning (PEFT) and
cross-lingual tasks in multilingual autoregressive models has yet to be
studied. Specifically, we lack an understanding of the role of linguistic
distributions in multilingual models in the effectiveness of token-based prompt
tuning. To address this question, we conduct experiments comparing prompt
tuning and fine-tuning on the decoder-based multilingual model, XGLM, with four
cross-lingual tasks (XNLI, PAWS-X, POS, NER). According to our study, prompt
tuning achieves on par or better performance over fine-tuning across all
languages while updating at most 0.13\% of the model parameters. Moreover, we
empirically show that prompt tuning is more effective in enhancing the
performance of low-resource languages than fine-tuning. Our further analysis
shows that the phenomenon is related to the tokenization scheme of the
multilingual model.
</p></li>
</ul>
<h3>Title: CPopQA: Ranking Cultural Concept Popularity by LLMs. (arXiv:2311.07897v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.07897">http://arxiv.org/abs/2311.07897</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.07897] CPopQA: Ranking Cultural Concept Popularity by LLMs](http://arxiv.org/abs/2311.07897) #few-shot</code></li>
<li>Summary: <p>Prior work has demonstrated large language models' (LLMs) potential to
discern statistical tendencies within their pre-training corpora. Despite that,
many examinations of LLMs' knowledge capacity focus on knowledge explicitly
appearing in the training data or implicitly inferable from similar contexts.
How well an LLM captures the corpus-level statistical trends of concepts for
reasoning, especially long-tail ones, is still underexplored. In this study, we
introduce a novel few-shot question-answering task (CPopQA) that examines LLMs'
statistical ranking abilities for long-tail cultural concepts (e.g., holidays),
with a specific focus on these concepts' popularity in the United States and
the United Kingdom, respectively. We curate a dataset containing 459 holidays
across 58 countries, generating a total of 6,000 QA testing pairs. Experiments
on four strong LLMs show that large models are capable of ranking long-tail
cultural concepts regarding their statistical tendency. Notably, GPT-3.5
displayed superior performance and exhibited its potential to identify
geo-cultural proximity across continents.
</p></li>
</ul>
<h3>Title: Human-Centric Autonomous Systems With LLMs for User Command Reasoning. (arXiv:2311.08206v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.08206">http://arxiv.org/abs/2311.08206</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.08206] Human-Centric Autonomous Systems With LLMs for User Command Reasoning](http://arxiv.org/abs/2311.08206) #few-shot</code></li>
<li>Summary: <p>The evolution of autonomous driving has made remarkable advancements in
recent years, evolving into a tangible reality. However, a human-centric
large-scale adoption hinges on meeting a variety of multifaceted requirements.
To ensure that the autonomous system meets the user's intent, it is essential
to accurately discern and interpret user commands, especially in complex or
emergency situations. To this end, we propose to leverage the reasoning
capabilities of Large Language Models (LLMs) to infer system requirements from
in-cabin users' commands. Through a series of experiments that include
different LLM models and prompt designs, we explore the few-shot multivariate
binary classification accuracy of system requirements from natural language
textual commands. We confirm the general ability of LLMs to understand and
reason about prompts but underline that their effectiveness is conditioned on
the quality of both the LLM model and the design of appropriate sequential
prompts. Code and models are public with the link
\url{https://github.com/KTH-RPL/DriveCmd_LLM}.
</p></li>
</ul>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script>new ClipboardJS("#copy",{text:function(trigger){var res="[[2023-11-15]]\n\n";var input=document.querySelectorAll("input");for(var i=0;i<input.length;i++){if(input[i].type=="checkbox"&&input[i].checked){res+="- "+input[i].nextSibling.nodeValue+"\n"}}res+="\n";return res}}).on("success",function(e){e.clearSelection()});</script>
<button id="copy">Copy All</button>
