<h2>diffusion</h2>
<h3>Title: MagiCapture: High-Resolution Multi-Concept Portrait Customization. (arXiv:2309.06895v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06895">http://arxiv.org/abs/2309.06895</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06895] MagiCapture: High-Resolution Multi-Concept Portrait Customization](http://arxiv.org/abs/2309.06895) #diffusion</code></li>
<li>Summary: <p>Large-scale text-to-image models including Stable Diffusion are capable of
generating high-fidelity photorealistic portrait images. There is an active
research area dedicated to personalizing these models, aiming to synthesize
specific subjects or styles using provided sets of reference images. However,
despite the plausible results from these personalization methods, they tend to
produce images that often fall short of realism and are not yet on a
commercially viable level. This is particularly noticeable in portrait image
generation, where any unnatural artifact in human faces is easily discernible
due to our inherent human bias. To address this, we introduce MagiCapture, a
personalization method for integrating subject and style concepts to generate
high-resolution portrait images using just a few subject and style references.
For instance, given a handful of random selfies, our fine-tuned model can
generate high-quality portrait images in specific styles, such as passport or
profile photos. The main challenge with this task is the absence of ground
truth for the composed concepts, leading to a reduction in the quality of the
final output and an identity shift of the source subject. To address these
issues, we present a novel Attention Refocusing loss coupled with auxiliary
priors, both of which facilitate robust learning within this weakly supervised
learning setting. Our pipeline also includes additional post-processing steps
to ensure the creation of highly realistic outputs. MagiCapture outperforms
other baselines in both quantitative and qualitative evaluations and can also
be generalized to other non-human objects.
</p></li>
</ul>
<h3>Title: DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion Models. (arXiv:2309.06933v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06933">http://arxiv.org/abs/2309.06933</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06933] DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion Models](http://arxiv.org/abs/2309.06933) #diffusion</code></li>
<li>Summary: <p>Recent progresses in large-scale text-to-image models have yielded remarkable
accomplishments, finding various applications in art domain. However,
expressing unique characteristics of an artwork (e.g. brushwork, colortone, or
composition) with text prompts alone may encounter limitations due to the
inherent constraints of verbal description. To this end, we introduce
DreamStyler, a novel framework designed for artistic image synthesis,
proficient in both text-to-image synthesis and style transfer. DreamStyler
optimizes a multi-stage textual embedding with a context-aware text prompt,
resulting in prominent image quality. In addition, with content and style
guidance, DreamStyler exhibits flexibility to accommodate a range of style
references. Experimental results demonstrate its superior performance across
multiple scenarios, suggesting its promising potential in artistic product
creation.
</p></li>
</ul>
<h3>Title: Reasoning with Latent Diffusion in Offline Reinforcement Learning. (arXiv:2309.06599v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06599">http://arxiv.org/abs/2309.06599</a></li>
<li>Code URL: <a href="https://github.com/ldcq/ldcq">https://github.com/ldcq/ldcq</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06599] Reasoning with Latent Diffusion in Offline Reinforcement Learning](http://arxiv.org/abs/2309.06599) #diffusion</code></li>
<li>Summary: <p>Offline reinforcement learning (RL) holds promise as a means to learn
high-reward policies from a static dataset, without the need for further
environment interactions. However, a key challenge in offline RL lies in
effectively stitching portions of suboptimal trajectories from the static
dataset while avoiding extrapolation errors arising due to a lack of support in
the dataset. Existing approaches use conservative methods that are tricky to
tune and struggle with multi-modal data (as we show) or rely on noisy Monte
Carlo return-to-go samples for reward conditioning. In this work, we propose a
novel approach that leverages the expressiveness of latent diffusion to model
in-support trajectory sequences as compressed latent skills. This facilitates
learning a Q-function while avoiding extrapolation error via
batch-constraining. The latent space is also expressive and gracefully copes
with multi-modal data. We show that the learned temporally-abstract latent
space encodes richer task-specific information for offline RL tasks as compared
to raw state-actions. This improves credit assignment and facilitates faster
reward propagation during Q-learning. Our method demonstrates state-of-the-art
performance on the D4RL benchmarks, particularly excelling in long-horizon,
sparse-reward tasks.
</p></li>
</ul>
<h2>self-supervised</h2>
<h3>Title: GelFlow: Self-supervised Learning of Optical Flow for Vision-Based Tactile Sensor Displacement Measurement. (arXiv:2309.06735v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06735">http://arxiv.org/abs/2309.06735</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06735] GelFlow: Self-supervised Learning of Optical Flow for Vision-Based Tactile Sensor Displacement Measurement](http://arxiv.org/abs/2309.06735) #self-supervised</code></li>
<li>Summary: <p>High-resolution multi-modality information acquired by vision-based tactile
sensors can support more dexterous manipulations for robot fingers. Optical
flow is low-level information directly obtained by vision-based tactile
sensors, which can be transformed into other modalities like force, geometry
and depth. Current vision-tactile sensors employ optical flow methods from
OpenCV to estimate the deformation of markers in gels. However, these methods
need to be more precise for accurately measuring the displacement of markers
during large elastic deformation of the gel, as this can significantly impact
the accuracy of downstream tasks. This study proposes a self-supervised optical
flow method based on deep learning to achieve high accuracy in displacement
measurement for vision-based tactile sensors. The proposed method employs a
coarse-to-fine strategy to handle large deformations by constructing a
multi-scale feature pyramid from the input image. To better deal with the
elastic deformation caused by the gel, the Helmholtz velocity decomposition
constraint combined with the elastic deformation constraint are adopted to
address the distortion rate and area change rate, respectively. A local flow
fusion module is designed to smooth the optical flow, taking into account the
prior knowledge of the blurred effect of gel deformation. We trained the
proposed self-supervised network using an open-source dataset and compared it
with traditional and deep learning-based optical flow methods. The results show
that the proposed method achieved the highest displacement measurement
accuracy, thereby demonstrating its potential for enabling more precise
measurement of downstream tasks using vision-based tactile sensors.
</p></li>
</ul>
<h3>Title: Keep It SimPool: Who Said Supervised Transformers Suffer from Attention Deficit?. (arXiv:2309.06891v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06891">http://arxiv.org/abs/2309.06891</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06891] Keep It SimPool: Who Said Supervised Transformers Suffer from Attention Deficit?](http://arxiv.org/abs/2309.06891) #self-supervised</code></li>
<li>Summary: <p>Convolutional networks and vision transformers have different forms of
pairwise interactions, pooling across layers and pooling at the end of the
network. Does the latter really need to be different? As a by-product of
pooling, vision transformers provide spatial attention for free, but this is
most often of low quality unless self-supervised, which is not well studied. Is
supervision really the problem?
</p></li>
</ul>
<p>In this work, we develop a generic pooling framework and then we formulate a
number of existing methods as instantiations. By discussing the properties of
each group of methods, we derive SimPool, a simple attention-based pooling
mechanism as a replacement of the default one for both convolutional and
transformer encoders. We find that, whether supervised or self-supervised, this
improves performance on pre-training and downstream tasks and provides
attention maps delineating object boundaries in all cases. One could thus call
SimPool universal. To our knowledge, we are the first to obtain attention maps
in supervised transformers of at least as good quality as self-supervised,
without explicit losses or modifying the architecture. Code at:
https://github.com/billpsomas/simpool.
</p>

<h3>Title: Exploiting Multiple Priors for Neural 3D Indoor Reconstruction. (arXiv:2309.07021v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.07021">http://arxiv.org/abs/2309.07021</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.07021] Exploiting Multiple Priors for Neural 3D Indoor Reconstruction](http://arxiv.org/abs/2309.07021) #self-supervised</code></li>
<li>Summary: <p>Neural implicit modeling permits to achieve impressive 3D reconstruction
results on small objects, while it exhibits significant limitations in large
indoor scenes. In this work, we propose a novel neural implicit modeling method
that leverages multiple regularization strategies to achieve better
reconstructions of large indoor environments, while relying only on images. A
sparse but accurate depth prior is used to anchor the scene to the initial
model. A dense but less accurate depth prior is also introduced, flexible
enough to still let the model diverge from it to improve the estimated
geometry. Then, a novel self-supervised strategy to regularize the estimated
surface normals is presented. Finally, a learnable exposure compensation scheme
permits to cope with challenging lighting conditions. Experimental results show
that our approach produces state-of-the-art 3D reconstructions in challenging
indoor scenarios.
</p></li>
</ul>
<h3>Title: Domain-Aware Augmentations for Unsupervised Online General Continual Learning. (arXiv:2309.06896v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06896">http://arxiv.org/abs/2309.06896</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06896] Domain-Aware Augmentations for Unsupervised Online General Continual Learning](http://arxiv.org/abs/2309.06896) #self-supervised</code></li>
<li>Summary: <p>Continual Learning has been challenging, especially when dealing with
unsupervised scenarios such as Unsupervised Online General Continual Learning
(UOGCL), where the learning agent has no prior knowledge of class boundaries or
task change information. While previous research has focused on reducing
forgetting in supervised setups, recent studies have shown that self-supervised
learners are more resilient to forgetting. This paper proposes a novel approach
that enhances memory usage for contrastive learning in UOGCL by defining and
using stream-dependent data augmentations together with some implementation
tricks. Our proposed method is simple yet effective, achieves state-of-the-art
results compared to other unsupervised approaches in all considered setups, and
reduces the gap between supervised and unsupervised continual learning. Our
domain-aware augmentation procedure can be adapted to other replay-based
methods, making it a promising strategy for continual learning.
</p></li>
</ul>
<h2>foundation model</h2>
<h3>Title: Leveraging Foundation models for Unsupervised Audio-Visual Segmentation. (arXiv:2309.06728v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06728">http://arxiv.org/abs/2309.06728</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06728] Leveraging Foundation models for Unsupervised Audio-Visual Segmentation](http://arxiv.org/abs/2309.06728) #foundation model</code></li>
<li>Summary: <p>Audio-Visual Segmentation (AVS) aims to precisely outline audible objects in
a visual scene at the pixel level. Existing AVS methods require fine-grained
annotations of audio-mask pairs in supervised learning fashion. This limits
their scalability since it is time consuming and tedious to acquire such
cross-modality pixel level labels. To overcome this obstacle, in this work we
introduce unsupervised audio-visual segmentation with no need for task-specific
data annotations and model training. For tackling this newly proposed problem,
we formulate a novel Cross-Modality Semantic Filtering (CMSF) approach to
accurately associate the underlying audio-mask pairs by leveraging the
off-the-shelf multi-modal foundation models (e.g., detection [1], open-world
segmentation [2] and multi-modal alignment [3]). Guiding the proposal
generation by either audio or visual cues, we design two training-free
variants: AT-GDINO-SAM and OWOD-BIND. Extensive experiments on the AVS-Bench
dataset show that our unsupervised approach can perform well in comparison to
prior art supervised counterparts across complex scenarios with multiple
auditory objects. Particularly, in situations where existing supervised AVS
methods struggle with overlapping foreground objects, our models still excel in
accurately segmenting overlapped auditory objects. Our code will be publicly
released.
</p></li>
</ul>
<h3>Title: SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation. (arXiv:2309.06824v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06824">http://arxiv.org/abs/2309.06824</a></li>
<li>Code URL: <a href="https://github.com/xianlin7/samus">https://github.com/xianlin7/samus</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06824] SAMUS: Adapting Segment Anything Model for Clinically-Friendly and Generalizable Ultrasound Image Segmentation](http://arxiv.org/abs/2309.06824) #foundation model</code></li>
<li>Summary: <p>Segment anything model (SAM), an eminent universal image segmentation model,
has recently gathered considerable attention within the domain of medical image
segmentation. Despite the remarkable performance of SAM on natural images, it
grapples with significant performance degradation and limited generalization
when confronted with medical images, particularly with those involving objects
of low contrast, faint boundaries, intricate shapes, and diminutive sizes. In
this paper, we propose SAMUS, a universal model tailored for ultrasound image
segmentation. In contrast to previous SAM-based universal models, SAMUS pursues
not only better generalization but also lower deployment cost, rendering it
more suitable for clinical applications. Specifically, based on SAM, a parallel
CNN branch is introduced to inject local features into the ViT encoder through
cross-branch attention for better medical image segmentation. Then, a position
adapter and a feature adapter are developed to adapt SAM from natural to
medical domains and from requiring large-size inputs (1024x1024) to small-size
inputs (256x256) for more clinical-friendly deployment. A comprehensive
ultrasound dataset, comprising about 30k images and 69k masks and covering six
object categories, is collected for verification. Extensive comparison
experiments demonstrate SAMUS's superiority against the state-of-the-art
task-specific models and universal foundation models under both task-specific
evaluation and generalization evaluation. Moreover, SAMUS is deployable on
entry-level GPUs, as it has been liberated from the constraints of long
sequence encoding. The code, data, and models will be released at
https://github.com/xianlin7/SAMUS.
</p></li>
</ul>
<h3>Title: Hydra: Multi-head Low-rank Adaptation for Parameter Efficient Fine-tuning. (arXiv:2309.06922v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06922">http://arxiv.org/abs/2309.06922</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06922] Hydra: Multi-head Low-rank Adaptation for Parameter Efficient Fine-tuning](http://arxiv.org/abs/2309.06922) #foundation model</code></li>
<li>Summary: <p>The recent surge in large-scale foundation models has spurred the development
of efficient methods for adapting these models to various downstream tasks.
Low-rank adaptation methods, such as LoRA, have gained significant attention
due to their outstanding parameter efficiency and no additional inference
latency. This paper investigates a more general form of adapter module based on
the analysis that parallel and sequential adaptation branches learn novel and
general features during fine-tuning, respectively. The proposed method, named
Hydra, due to its multi-head computational branches, combines parallel and
sequential branch to integrate capabilities, which is more expressive than
existing single branch methods and enables the exploration of a broader range
of optimal points in the fine-tuning process. In addition, the proposed
adaptation method explicitly leverages the pre-trained weights by performing a
linear combination of the pre-trained features. It allows the learned features
to have better generalization performance across diverse downstream tasks.
Furthermore, we perform a comprehensive analysis of the characteristics of each
adaptation branch with empirical evidence. Through an extensive range of
experiments, encompassing comparisons and ablation studies, we substantiate the
efficiency and demonstrate the superior performance of Hydra. This
comprehensive evaluation underscores the potential impact and effectiveness of
Hydra in a variety of applications. Our code is available on
\url{https://github.com/extremebird/Hydra}
</p></li>
</ul>
<h2>generative</h2>
<h3>Title: Integrating GAN and Texture Synthesis for Enhanced Road Damage Detection. (arXiv:2309.06747v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06747">http://arxiv.org/abs/2309.06747</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06747] Integrating GAN and Texture Synthesis for Enhanced Road Damage Detection](http://arxiv.org/abs/2309.06747) #generative</code></li>
<li>Summary: <p>In the domain of traffic safety and road maintenance, precise detection of
road damage is crucial for ensuring safe driving and prolonging road
durability. However, current methods often fall short due to limited data.
Prior attempts have used Generative Adversarial Networks to generate damage
with diverse shapes and manually integrate it into appropriate positions.
However, the problem has not been well explored and is faced with two
challenges. First, they only enrich the location and shape of damage while
neglect the diversity of severity levels, and the realism still needs further
improvement. Second, they require a significant amount of manual effort. To
address these challenges, we propose an innovative approach. In addition to
using GAN to generate damage with various shapes, we further employ texture
synthesis techniques to extract road textures. These two elements are then
mixed with different weights, allowing us to control the severity of the
synthesized damage, which are then embedded back into the original images via
Poisson blending. Our method ensures both richness of damage severity and a
better alignment with the background. To save labor costs, we leverage
structural similarity for automated sample selection during embedding. Each
augmented data of an original image contains versions with varying severity
levels. We implement a straightforward screening strategy to mitigate
distribution drift. Experiments are conducted on a public road damage dataset.
The proposed method not only eliminates the need for manual labor but also
achieves remarkable enhancements, improving the mAP by 4.1% and the F1-score by
4.5%.
</p></li>
</ul>
<h3>Title: Instance Adaptive Prototypical Contrastive Embedding for Generalized Zero Shot Learning. (arXiv:2309.06987v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06987">http://arxiv.org/abs/2309.06987</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06987] Instance Adaptive Prototypical Contrastive Embedding for Generalized Zero Shot Learning](http://arxiv.org/abs/2309.06987) #generative</code></li>
<li>Summary: <p>Generalized zero-shot learning(GZSL) aims to classify samples from seen and
unseen labels, assuming unseen labels are not accessible during training.
Recent advancements in GZSL have been expedited by incorporating
contrastive-learning-based (instance-based) embedding in generative networks
and leveraging the semantic relationship between data points. However, existing
embedding architectures suffer from two limitations: (1) limited
discriminability of synthetic features' embedding without considering
fine-grained cluster structures; (2) inflexible optimization due to restricted
scaling mechanisms on existing contrastive embedding networks, leading to
overlapped representations in the embedding space. To enhance the quality of
representations in the embedding space, as mentioned in (1), we propose a
margin-based prototypical contrastive learning embedding network that reaps the
benefits of prototype-data (cluster quality enhancement) and implicit data-data
(fine-grained representations) interaction while providing substantial cluster
supervision to the embedding network and the generator. To tackle (2), we
propose an instance adaptive contrastive loss that leads to generalized
representations for unseen labels with increased inter-class margin. Through
comprehensive experimental evaluation, we show that our method can outperform
the current state-of-the-art on three benchmark datasets. Our approach also
consistently achieves the best unseen performance in the GZSL setting.
</p></li>
</ul>
<h3>Title: Text Encoders Lack Knowledge: Leveraging Generative LLMs for Domain-Specific Semantic Textual Similarity. (arXiv:2309.06541v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06541">http://arxiv.org/abs/2309.06541</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06541] Text Encoders Lack Knowledge: Leveraging Generative LLMs for Domain-Specific Semantic Textual Similarity](http://arxiv.org/abs/2309.06541) #generative</code></li>
<li>Summary: <p>Amidst the sharp rise in the evaluation of large language models (LLMs) on
various tasks, we find that semantic textual similarity (STS) has been
under-explored. In this study, we show that STS can be cast as a text
generation problem while maintaining strong performance on multiple STS
benchmarks. Additionally, we show generative LLMs significantly outperform
existing encoder-based STS models when characterizing the semantic similarity
between two texts with complex semantic relationships dependent on world
knowledge. We validate this claim by evaluating both generative LLMs and
existing encoder-based STS models on three newly collected STS challenge sets
which require world knowledge in the domains of Health, Politics, and Sports.
All newly collected data is sourced from social media content posted after May
2023 to ensure the performance of closed-source models like ChatGPT cannot be
credited to memorization. Our results show that, on average, generative LLMs
outperform the best encoder-only baselines by an average of 22.3% on STS tasks
requiring world knowledge. Our results suggest generative language models with
STS-specific prompting strategies achieve state-of-the-art performance in
complex, domain-specific STS tasks.
</p></li>
</ul>
<h3>Title: Do Generative Large Language Models need billions of parameters?. (arXiv:2309.06589v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06589">http://arxiv.org/abs/2309.06589</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06589] Do Generative Large Language Models need billions of parameters?](http://arxiv.org/abs/2309.06589) #generative</code></li>
<li>Summary: <p>This paper presents novel systems and methodologies for the development of
efficient large language models (LLMs). It explores the trade-offs between
model size, performance, and computational resources, with the aim of
maximizing the efficiency of these AI systems. The research explores novel
methods that allow different parts of the model to share parameters, reducing
the total number of unique parameters required. This approach ensures that the
model remains compact without sacrificing its ability to learn and represent
complex language structures. This study provides valuable insights and tools
for creating more efficient and effective LLMs, contributing to a more
sustainable and accessible future for AI language modeling.
</p></li>
</ul>
<h3>Title: Continual Learning with Dirichlet Generative-based Rehearsal. (arXiv:2309.06917v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06917">http://arxiv.org/abs/2309.06917</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06917] Continual Learning with Dirichlet Generative-based Rehearsal](http://arxiv.org/abs/2309.06917) #generative</code></li>
<li>Summary: <p>Recent advancements in data-driven task-oriented dialogue systems (ToDs)
struggle with incremental learning due to computational constraints and
time-consuming issues. Continual Learning (CL) attempts to solve this by
avoiding intensive pre-training, but it faces the problem of catastrophic
forgetting (CF). While generative-based rehearsal CL methods have made
significant strides, generating pseudo samples that accurately reflect the
underlying task-specific distribution is still a challenge. In this paper, we
present Dirichlet Continual Learning (DCL), a novel generative-based rehearsal
strategy for CL. Unlike the traditionally used Gaussian latent variable in the
Conditional Variational Autoencoder (CVAE), DCL leverages the flexibility and
versatility of the Dirichlet distribution to model the latent prior variable.
This enables it to efficiently capture sentence-level features of previous
tasks and effectively guide the generation of pseudo samples. In addition, we
introduce Jensen-Shannon Knowledge Distillation (JSKD), a robust logit-based
knowledge distillation method that enhances knowledge transfer during pseudo
sample generation. Our experiments confirm the efficacy of our approach in both
intent detection and slot-filling tasks, outperforming state-of-the-art
methods.
</p></li>
</ul>
<h2>anomaly</h2>
<h3>Title: Manufacturing Quality Control with Autoencoder-Based Defect Localization and Unsupervised Class Selection. (arXiv:2309.06884v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06884">http://arxiv.org/abs/2309.06884</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06884] Manufacturing Quality Control with Autoencoder-Based Defect Localization and Unsupervised Class Selection](http://arxiv.org/abs/2309.06884) #anomaly</code></li>
<li>Summary: <p>Manufacturing industries require efficient and voluminous production of
high-quality finished goods. In the context of Industry 4.0, visual anomaly
detection poses an optimistic solution for automatically controlling product
quality with high precision. Automation based on computer vision poses a
promising solution to prevent bottlenecks at the product quality checkpoint. We
considered recent advancements in machine learning to improve visual defect
localization, but challenges persist in obtaining a balanced feature set and
database of the wide variety of defects occurring in the production line. This
paper proposes a defect localizing autoencoder with unsupervised class
selection by clustering with k-means the features extracted from a pre-trained
VGG-16 network. The selected classes of defects are augmented with natural wild
textures to simulate artificial defects. The study demonstrates the
effectiveness of the defect localizing autoencoder with unsupervised class
selection for improving defect detection in manufacturing industries. The
proposed methodology shows promising results with precise and accurate
localization of quality defects on melamine-faced boards for the furniture
industry. Incorporating artificial defects into the training data shows
significant potential for practical implementation in real-world quality
control scenarios.
</p></li>
</ul>
<h3>Title: FAIR: Frequency-aware Image Restoration for Industrial Visual Anomaly Detection. (arXiv:2309.07068v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.07068">http://arxiv.org/abs/2309.07068</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.07068] FAIR: Frequency-aware Image Restoration for Industrial Visual Anomaly Detection](http://arxiv.org/abs/2309.07068) #anomaly</code></li>
<li>Summary: <p>Image reconstruction-based anomaly detection models are widely explored in
industrial visual inspection. However, existing models usually suffer from the
trade-off between normal reconstruction fidelity and abnormal reconstruction
distinguishability, which damages the performance. In this paper, we find that
the above trade-off can be better mitigated by leveraging the distinct
frequency biases between normal and abnormal reconstruction errors. To this
end, we propose Frequency-aware Image Restoration (FAIR), a novel
self-supervised image restoration task that restores images from their
high-frequency components. It enables precise reconstruction of normal patterns
while mitigating unfavorable generalization to anomalies. Using only a simple
vanilla UNet, FAIR achieves state-of-the-art performance with higher efficiency
on various defect detection datasets. Code: https://github.com/liutongkun/FAIR.
</p></li>
</ul>
<h2>in-context</h2>
<h3>Title: Narrowing the Gap between Supervised and Unsupervised Sentence Representation Learning with Large Language Model. (arXiv:2309.06453v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06453">http://arxiv.org/abs/2309.06453</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06453] Narrowing the Gap between Supervised and Unsupervised Sentence Representation Learning with Large Language Model](http://arxiv.org/abs/2309.06453) #in-context</code></li>
<li>Summary: <p>Sentence Representation Learning (SRL) is a fundamental task in Natural
Language Processing (NLP), with Contrastive learning of Sentence Embeddings
(CSE) as the mainstream technique due to its superior performance. An
intriguing phenomenon in CSE is the significant performance gap between
supervised and unsupervised methods, even when their sentence encoder and loss
function are the same. Previous works attribute this performance gap to
differences in two representation properties (alignment and uniformity).
However, alignment and uniformity only measure the results, which means they
cannot answer "What happens during the training process that leads to the
performance gap?" and "How can the performance gap be narrowed?". In this
paper, we conduct empirical experiments to answer these "What" and "How"
questions. We first answer the "What" question by thoroughly comparing the
behavior of supervised and unsupervised CSE during their respective training
processes. From the comparison, We observe a significant difference in fitting
difficulty. Thus, we introduce a metric, called Fitting Difficulty Increment
(FDI), to measure the fitting difficulty gap between the evaluation dataset and
the held-out training dataset, and use the metric to answer the "What"
question. Then, based on the insights gained from the "What" question, we
tackle the "How" question by increasing the fitting difficulty of the training
dataset. We achieve this by leveraging the In-Context Learning (ICL) capability
of the Large Language Model (LLM) to generate data that simulates complex
patterns. By utilizing the hierarchical patterns in the LLM-generated data, we
effectively narrow the gap between supervised and unsupervised CSE.
</p></li>
</ul>
<h3>Title: Unsupervised Contrast-Consistent Ranking with Language Models. (arXiv:2309.06991v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06991">http://arxiv.org/abs/2309.06991</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06991] Unsupervised Contrast-Consistent Ranking with Language Models](http://arxiv.org/abs/2309.06991) #in-context</code></li>
<li>Summary: <p>Language models contain ranking-based knowledge and are powerful solvers of
in-context ranking tasks. For instance, they may have parametric knowledge
about the ordering of countries by size or may be able to rank reviews by
sentiment. Recent work focuses on pairwise, pointwise, and listwise prompting
techniques to elicit a language model's ranking knowledge. However, we find
that even with careful calibration and constrained decoding, prompting-based
techniques may not always be self-consistent in the rankings they produce. This
motivates us to explore an alternative approach that is inspired by an
unsupervised probing method called Contrast-Consistent Search (CCS). The idea
is to train a probing model guided by a logical constraint: a model's
representation of a statement and its negation must be mapped to contrastive
true-false poles consistently across multiple statements. We hypothesize that
similar constraints apply to ranking tasks where all items are related via
consistent pairwise or listwise comparisons. To this end, we extend the binary
CCS method to Contrast-Consistent Ranking (CCR) by adapting existing ranking
methods such as the Max-Margin Loss, Triplet Loss, and Ordinal Regression
objective. Our results confirm that, for the same language model, CCR probing
outperforms prompting and even performs on a par with prompting much larger
language models.
</p></li>
</ul>
<h2>memory</h2>
<h3>Title: Evaluating Homomorphic Operations on a Real-World Processing-In-Memory System. (arXiv:2309.06545v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06545">http://arxiv.org/abs/2309.06545</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06545] Evaluating Homomorphic Operations on a Real-World Processing-In-Memory System](http://arxiv.org/abs/2309.06545) #memory</code></li>
<li>Summary: <p>Computing on encrypted data is a promising approach to reduce data security
and privacy risks, with homomorphic encryption serving as a facilitator in
achieving this goal. In this work, we accelerate homomorphic operations using
the Processing-in- Memory (PIM) paradigm to mitigate the large memory capacity
and frequent data movement requirements. Using a real-world PIM system, we
accelerate the Brakerski-Fan-Vercauteren (BFV) scheme for homomorphic addition
and multiplication. We evaluate the PIM implementations of these homomorphic
operations with statistical workloads (arithmetic mean, variance, linear
regression) and compare to CPU and GPU implementations. Our results demonstrate
50-100x speedup with a real PIM system (UPMEM) over the CPU and 2-15x over the
GPU in vector addition. For vector multiplication, the real PIM system
outperforms the CPU by 40-50x. However, it lags 10-15x behind the GPU due to
the lack of native sufficiently wide multiplication support in the evaluated
first-generation real PIM system. For mean, variance, and linear regression,
the real PIM system performance improvements vary between 30x and 300x over the
CPU and between 10x and 30x over the GPU, uncovering real PIM system trade-offs
in terms of scalability of homomorphic operations for varying amounts of data.
We plan to make our implementation open-source in the future.
</p></li>
</ul>
<h3>Title: Functional Encryption in the Bounded Storage Models. (arXiv:2309.06702v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06702">http://arxiv.org/abs/2309.06702</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06702] Functional Encryption in the Bounded Storage Models](http://arxiv.org/abs/2309.06702) #memory</code></li>
<li>Summary: <p>Functional encryption is a powerful paradigm for public-key encryption which
allows for controlled access to encrypted data. This primitive is generally
impossible in the standard setting so we investigate possibilities in the
bounded quantum storage model (BQSM) and the bounded classical storage model
(BCSM). In these models, ciphertexts potentially disappear which nullifies
impossibility results and allows us to obtain positive outcomes.
</p></li>
</ul>
<p>Firstly, in the BQSM, we construct information-theoretically secure
functional encryption with $\texttt{q}=O(\sqrt{\texttt{s}/\texttt{r}})$ where
$\texttt{r}$ can be set to any value less than $\texttt{s}$. Here $\texttt{r}$
denotes the number of times that an adversary is restricted to
$\texttt{s}$--qubits of quantum memory in the protocol and $\texttt{q}$ denotes
the required quantum memory to run the protocol honestly. We then show that our
scheme is optimal by proving that it is impossible to attain
information-theoretically secure functional encryption with $\texttt{q} <
\sqrt{\texttt{s}/\texttt{r}}$. However, by assuming the existence of
post-quantum one-way functions, we can do far better and achieve functional
encryption with classical keys and with $\texttt{q}=0$ and $\texttt{r}=1$.
</p>
<p>Secondly, in the BCSM, we construct $(O(\texttt{n}),\texttt{n}^2)$ functional
encryption assuming the existence of $(\texttt{n},\texttt{n}^2)$ virtual weak
grey-box obfuscation. Here, the pair $(\texttt{n},\texttt{n}^2)$ indicates the
required memory to run honestly and the needed memory to break security,
respectively. This memory gap is optimal and the assumption is minimal. In
particular, we also construct $(O(\texttt{n}),\texttt{n}^2)$ virtual weak
grey-box obfuscation assuming $(\texttt{n},\texttt{n}^2)$ functional
encryption.
</p>

<h3>Title: DP-Forward: Fine-tuning and Inference on Language Models with Differential Privacy in Forward Pass. (arXiv:2309.06746v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06746">http://arxiv.org/abs/2309.06746</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06746] DP-Forward: Fine-tuning and Inference on Language Models with Differential Privacy in Forward Pass](http://arxiv.org/abs/2309.06746) #memory</code></li>
<li>Summary: <p>Differentially private stochastic gradient descent (DP-SGD) adds noise to
gradients in back-propagation, safeguarding training data from privacy leakage,
particularly membership inference. It fails to cover (inference-time) threats
like embedding inversion and sensitive attribute inference. It is also costly
in storage and computation when used to fine-tune large pre-trained language
models (LMs).
</p></li>
</ul>
<p>We propose DP-Forward, which directly perturbs embedding matrices in the
forward pass of LMs. It satisfies stringent local DP requirements for training
and inference data. To instantiate it using the smallest matrix-valued noise,
we devise an analytic matrix Gaussian~mechanism (aMGM) by drawing possibly
non-i.i.d. noise from a matrix Gaussian distribution. We then investigate
perturbing outputs from different hidden (sub-)layers of LMs with aMGM noises.
Its utility on three typical tasks almost hits the non-private baseline and
outperforms DP-SGD by up to 7.7pp at a moderate privacy level. It saves
3$\times$ time and memory costs compared to DP-SGD with the latest high-speed
library. It also reduces the average success rates of embedding inversion and
sensitive attribute inference by up to 88pp and 41pp, respectively, whereas
DP-SGD fails.
</p>

<h3>Title: Cryptography: Against AI and QAI Odds. (arXiv:2309.07022v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.07022">http://arxiv.org/abs/2309.07022</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.07022] Cryptography: Against AI and QAI Odds](http://arxiv.org/abs/2309.07022) #memory</code></li>
<li>Summary: <p>Artificial Intelligence (AI) presents prodigious technological prospects for
development, however, all that glitters is not gold! The cyber-world faces the
worst nightmare with the advent of AI and quantum computers. Together with
Quantum Artificial Intelligence (QAI), they pose a catastrophic threat to
modern cryptography. It would also increase the capability of cryptanalysts
manifold, with its built-in persistent and extensive predictive intelligence.
This prediction ability incapacitates the constrained message space in device
cryptography. With the comparison of these assumptions and the intercepted
ciphertext, the code-cracking process will considerably accelerate. Before the
vigorous and robust developments in AI, we have never faced and never had to
prepare for such a plaintext-originating attack. The supremacy of AI can be
challenged by creating ciphertexts that would give the AI attacker erroneous
responses stymied by randomness and misdirect them. AI threat is deterred by
deviating from the conventional use of small, known-size keys and
pattern-loaded ciphers. The strategy is vested in implementing larger secret
size keys, supplemented by ad-hoc unilateral randomness of unbound limitations
and a pattern-devoid technique. The very large key size can be handled with low
processing and computational burden to achieve desired unicity distances. The
strategy against AI odds is feasible by implementing non-algorithmic
randomness, large and inexpensive memory chips, and wide-area communication
networks. The strength of AI, i.e., randomness and pattern detection can be
used to generate highly optimized ciphers and algorithms. These pattern-devoid,
randomness-rich ciphers also provide a timely and plausible solution for NIST's
proactive approach toward the quantum challenge.
</p></li>
</ul>
<h3>Title: A Distributed Data-Parallel PyTorch Implementation of the Distributed Shampoo Optimizer for Training Neural Networks At-Scale. (arXiv:2309.06497v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06497">http://arxiv.org/abs/2309.06497</a></li>
<li>Code URL: <a href="https://github.com/facebookresearch/optimizers/tree/main/distributed_shampoo">https://github.com/facebookresearch/optimizers/tree/main/distributed_shampoo</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06497] A Distributed Data-Parallel PyTorch Implementation of the Distributed Shampoo Optimizer for Training Neural Networks At-Scale](http://arxiv.org/abs/2309.06497) #memory</code></li>
<li>Summary: <p>Shampoo is an online and stochastic optimization algorithm belonging to the
AdaGrad family of methods for training neural networks. It constructs a
block-diagonal preconditioner where each block consists of a coarse Kronecker
product approximation to full-matrix AdaGrad for each parameter of the neural
network. In this work, we provide a complete description of the algorithm as
well as the performance optimizations that our implementation leverages to
train deep networks at-scale in PyTorch. Our implementation enables fast
multi-GPU distributed data-parallel training by distributing the memory and
computation associated with blocks of each parameter via PyTorch's DTensor data
structure and performing an AllGather primitive on the computed search
directions at each iteration. This major performance enhancement enables us to
achieve at most a 10% performance reduction in per-step wall-clock time
compared against standard diagonal-scaling-based adaptive gradient methods. We
validate our implementation by performing an ablation study on training
ImageNet ResNet50, demonstrating Shampoo's superiority over standard training
recipes with minimal hyperparameter tuning.
</p></li>
</ul>
<h3>Title: Electricity Demand Forecasting through Natural Language Processing with Long Short-Term Memory Networks. (arXiv:2309.06793v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06793">http://arxiv.org/abs/2309.06793</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06793] Electricity Demand Forecasting through Natural Language Processing with Long Short-Term Memory Networks](http://arxiv.org/abs/2309.06793) #memory</code></li>
<li>Summary: <p>Electricity demand forecasting is a well established research field. Usually
this task is performed considering historical loads, weather forecasts,
calendar information and known major events. Recently attention has been given
on the possible use of new sources of information from textual news in order to
improve the performance of these predictions. This paper proposes a Long and
Short-Term Memory (LSTM) network incorporating textual news features that
successfully predicts the deterministic and probabilistic tasks of the UK
national electricity demand. The study finds that public sentiment and word
vector representations related to transport and geopolitics have
time-continuity effects on electricity demand. The experimental results show
that the LSTM with textual features improves by more than 3% compared to the
pure LSTM benchmark and by close to 10% over the official benchmark.
Furthermore, the proposed model effectively reduces forecasting uncertainty by
narrowing the confidence interval and bringing the forecast distribution closer
to the truth.
</p></li>
</ul>
<h3>Title: FedDIP: Federated Learning with Extreme Dynamic Pruning and Incremental Regularization. (arXiv:2309.06805v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06805">http://arxiv.org/abs/2309.06805</a></li>
<li>Code URL: <a href="https://github.com/ericloong/feddip">https://github.com/ericloong/feddip</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06805] FedDIP: Federated Learning with Extreme Dynamic Pruning and Incremental Regularization](http://arxiv.org/abs/2309.06805) #memory</code></li>
<li>Summary: <p>Federated Learning (FL) has been successfully adopted for distributed
training and inference of large-scale Deep Neural Networks (DNNs). However,
DNNs are characterized by an extremely large number of parameters, thus,
yielding significant challenges in exchanging these parameters among
distributed nodes and managing the memory. Although recent DNN compression
methods (e.g., sparsification, pruning) tackle such challenges, they do not
holistically consider an adaptively controlled reduction of parameter exchange
while maintaining high accuracy levels. We, therefore, contribute with a novel
FL framework (coined FedDIP), which combines (i) dynamic model pruning with
error feedback to eliminate redundant information exchange, which contributes
to significant performance improvement, with (ii) incremental regularization
that can achieve \textit{extreme} sparsity of models. We provide convergence
analysis of FedDIP and report on a comprehensive performance and comparative
assessment against state-of-the-art methods using benchmark data sets and DNN
models. Our results showcase that FedDIP not only controls the model sparsity
but efficiently achieves similar or better performance compared to other model
pruning methods adopting incremental regularization during distributed model
training. The code is available at: https://github.com/EricLoong/feddip.
</p></li>
</ul>
<h3>Title: DNNShifter: An Efficient DNN Pruning System for Edge Computing. (arXiv:2309.06973v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06973">http://arxiv.org/abs/2309.06973</a></li>
<li>Code URL: <a href="https://github.com/blessonvar/dnnshifter">https://github.com/blessonvar/dnnshifter</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06973] DNNShifter: An Efficient DNN Pruning System for Edge Computing](http://arxiv.org/abs/2309.06973) #memory</code></li>
<li>Summary: <p>Deep neural networks (DNNs) underpin many machine learning applications.
Production quality DNN models achieve high inference accuracy by training
millions of DNN parameters which has a significant resource footprint. This
presents a challenge for resources operating at the extreme edge of the
network, such as mobile and embedded devices that have limited computational
and memory resources. To address this, models are pruned to create lightweight,
more suitable variants for these devices. Existing pruning methods are unable
to provide similar quality models compared to their unpruned counterparts
without significant time costs and overheads or are limited to offline use
cases. Our work rapidly derives suitable model variants while maintaining the
accuracy of the original model. The model variants can be swapped quickly when
system and network conditions change to match workload demand. This paper
presents DNNShifter, an end-to-end DNN training, spatial pruning, and model
switching system that addresses the challenges mentioned above. At the heart of
DNNShifter is a novel methodology that prunes sparse models using structured
pruning. The pruned model variants generated by DNNShifter are smaller in size
and thus faster than dense and sparse model predecessors, making them suitable
for inference at the edge while retaining near similar accuracy as of the
original dense model. DNNShifter generates a portfolio of model variants that
can be swiftly interchanged depending on operational conditions. DNNShifter
produces pruned model variants up to 93x faster than conventional training
methods. Compared to sparse models, the pruned model variants are up to 5.14x
smaller and have a 1.67x inference latency speedup, with no compromise to
sparse model accuracy. In addition, DNNShifter has up to 11.9x lower overhead
for switching models and up to 3.8x lower memory utilisation than existing
approaches.
</p></li>
</ul>
<h3>Title: Characterizing Speed Performance of Multi-Agent Reinforcement Learning. (arXiv:2309.07108v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.07108">http://arxiv.org/abs/2309.07108</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.07108] Characterizing Speed Performance of Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2309.07108) #memory</code></li>
<li>Summary: <p>Multi-Agent Reinforcement Learning (MARL) has achieved significant success in
large-scale AI systems and big-data applications such as smart grids,
surveillance, etc. Existing advancements in MARL algorithms focus on improving
the rewards obtained by introducing various mechanisms for inter-agent
cooperation. However, these optimizations are usually compute- and
memory-intensive, thus leading to suboptimal speed performance in end-to-end
training time. In this work, we analyze the speed performance (i.e.,
latency-bounded throughput) as the key metric in MARL implementations.
Specifically, we first introduce a taxonomy of MARL algorithms from an
acceleration perspective categorized by (1) training scheme and (2)
communication method. Using our taxonomy, we identify three state-of-the-art
MARL algorithms - Multi-Agent Deep Deterministic Policy Gradient (MADDPG),
Target-oriented Multi-agent Communication and Cooperation (ToM2C), and
Networked Multi-Agent RL (NeurComm) - as target benchmark algorithms, and
provide a systematic analysis of their performance bottlenecks on a homogeneous
multi-core CPU platform. We justify the need for MARL latency-bounded
throughput to be a key performance metric in future literature while also
addressing opportunities for parallelization and acceleration.
</p></li>
</ul>
<h2>few-shot</h2>
<h3>Title: CONVERSER: Few-Shot Conversational Dense Retrieval with Synthetic Data Generation. (arXiv:2309.06748v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06748">http://arxiv.org/abs/2309.06748</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06748] CONVERSER: Few-Shot Conversational Dense Retrieval with Synthetic Data Generation](http://arxiv.org/abs/2309.06748) #few-shot</code></li>
<li>Summary: <p>Conversational search provides a natural interface for information retrieval
(IR). Recent approaches have demonstrated promising results in applying dense
retrieval to conversational IR. However, training dense retrievers requires
large amounts of in-domain paired data. This hinders the development of
conversational dense retrievers, as abundant in-domain conversations are
expensive to collect. In this paper, we propose CONVERSER, a framework for
training conversational dense retrievers with at most 6 examples of in-domain
dialogues. Specifically, we utilize the in-context learning capability of large
language models to generate conversational queries given a passage in the
retrieval corpus. Experimental results on conversational retrieval benchmarks
OR-QuAC and TREC CAsT 19 show that the proposed CONVERSER achieves comparable
performance to fully-supervised models, demonstrating the effectiveness of our
proposed framework in few-shot conversational dense retrieval. All source code
and generated datasets are available at https://github.com/MiuLab/CONVERSER
</p></li>
</ul>
<h3>Title: Scaled Prompt-Tuning for Few-Shot Natural Language Generation. (arXiv:2309.06759v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06759">http://arxiv.org/abs/2309.06759</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06759] Scaled Prompt-Tuning for Few-Shot Natural Language Generation](http://arxiv.org/abs/2309.06759) #few-shot</code></li>
<li>Summary: <p>The increasingly Large Language Models (LLMs) demonstrate stronger language
understanding and generation capabilities, while the memory demand and
computation cost of fine-tuning LLMs on downstream tasks are non-negligible.
Besides, fine-tuning generally requires a certain amount of data from
individual tasks whilst data collection cost is another issue to consider in
real-world applications. In this work, we focus on Parameter-Efficient
Fine-Tuning (PEFT) methods for few-shot Natural Language Generation (NLG),
which freeze most parameters in LLMs and tune a small subset of parameters in
few-shot cases so that memory footprint, training cost, and labeling cost are
reduced while maintaining or even improving the performance. We propose a
Scaled Prompt-Tuning (SPT) method which surpasses conventional PT with better
performance and generalization ability but without an obvious increase in
training cost. Further study on intermediate SPT suggests the superior
transferability of SPT in few-shot scenarios, providing a recipe for
data-deficient and computation-limited circumstances. Moreover, a comprehensive
comparison of existing PEFT methods reveals that certain approaches exhibiting
decent performance with modest training cost such as Prefix-Tuning in prior
study could struggle in few-shot NLG tasks, especially on challenging datasets.
</p></li>
</ul>
<h3>Title: Gpachov at CheckThat! 2023: A Diverse Multi-Approach Ensemble for Subjectivity Detection in News Articles. (arXiv:2309.06844v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.06844">http://arxiv.org/abs/2309.06844</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.06844] Gpachov at CheckThat! 2023: A Diverse Multi-Approach Ensemble for Subjectivity Detection in News Articles](http://arxiv.org/abs/2309.06844) #few-shot</code></li>
<li>Summary: <p>The wide-spread use of social networks has given rise to subjective,
misleading, and even false information on the Internet. Thus, subjectivity
detection can play an important role in ensuring the objectiveness and the
quality of a piece of information. This paper presents the solution built by
the Gpachov team for the CLEF-2023 CheckThat! lab Task~2 on subjectivity
detection. Three different research directions are explored. The first one is
based on fine-tuning a sentence embeddings encoder model and dimensionality
reduction. The second one explores a sample-efficient few-shot learning model.
The third one evaluates fine-tuning a multilingual transformer on an altered
dataset, using data from multiple languages. Finally, the three approaches are
combined in a simple majority voting ensemble, resulting in 0.77 macro F1 on
the test set and achieving 2nd place on the English subtask.
</p></li>
</ul>
<h3>Title: SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions. (arXiv:2309.07045v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2309.07045">http://arxiv.org/abs/2309.07045</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2309.07045] SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions](http://arxiv.org/abs/2309.07045) #few-shot</code></li>
<li>Summary: <p>With the rapid development of Large Language Models (LLMs), increasing
attention has been paid to their safety concerns. Consequently, evaluating the
safety of LLMs has become an essential task for facilitating the broad
applications of LLMs. Nevertheless, the absence of comprehensive safety
evaluation benchmarks poses a significant impediment to effectively assess and
enhance the safety of LLMs. In this work, we present SafetyBench, a
comprehensive benchmark for evaluating the safety of LLMs, which comprises
11,435 diverse multiple choice questions spanning across 7 distinct categories
of safety concerns. Notably, SafetyBench also incorporates both Chinese and
English data, facilitating the evaluation in both languages. Our extensive
tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot
settings reveal a substantial performance advantage for GPT-4 over its
counterparts, and there is still significant room for improving the safety of
current LLMs. We believe SafetyBench will enable fast and comprehensive
evaluation of LLMs' safety, and foster the development of safer LLMs. Data and
evaluation guidelines are available at https://github.com/thu-coai/SafetyBench.
Submission entrance and leaderboard are available at
https://llmbench.ai/safety.
</p></li>
</ul>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script>new ClipboardJS("#copy",{text:function(trigger){var res="[[2023-09-14]]\n\n";var input=document.querySelectorAll("input");for(var i=0;i<input.length;i++){if(input[i].type=="checkbox"&&input[i].checked){res+="- "+input[i].nextSibling.nodeValue+"\n"}}res+="\n";return res}}).on("success",function(e){e.clearSelection()});</script>
<button id="copy">Copy All</button>
